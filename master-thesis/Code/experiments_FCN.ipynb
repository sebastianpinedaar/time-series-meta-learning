{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: '../Models/POLLUTION_FCN/0/'\n",
      "Regression error on test: 0.042617\n",
      "Validation loss decreased (inf --> 0.042617).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066392\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.019056\n",
      "Validation loss decreased (0.042617 --> 0.019056).  Saving model ...\n",
      "done\n",
      "Max train: tensor(2.1850, device='cuda:0')\n",
      "Mean train: tensor(0.0067, device='cuda:0')\n",
      "Regression error on test: 0.050087\n",
      "Max test: tensor(6.8122, device='cuda:0')\n",
      "Mean test: tensor(-0.2084, device='cuda:0')\n",
      "0.050086893141269684\n",
      "Regression error on test: 0.035745\n",
      "Validation loss decreased (inf --> 0.035745).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040679\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065882\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.6205, device='cuda:0')\n",
      "Mean train: tensor(-0.1559, device='cuda:0')\n",
      "Regression error on test: 0.035745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max test: tensor(6.6353, device='cuda:0')\n",
      "Mean test: tensor(-0.0238, device='cuda:0')\n",
      "0.03574453294277191\n",
      "Regression error on test: 0.024636\n",
      "Validation loss decreased (inf --> 0.024636).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056882\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041727\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.7272, device='cuda:0')\n",
      "Mean train: tensor(-0.1573, device='cuda:0')\n",
      "Regression error on test: 0.024636\n",
      "Max test: tensor(5.0632, device='cuda:0')\n",
      "Mean test: tensor(-0.0337, device='cuda:0')\n",
      "0.024635571986436844\n",
      "Regression error on test: 0.022922\n",
      "Validation loss decreased (inf --> 0.022922).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053805\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081217\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.6834, device='cuda:0')\n",
      "Mean train: tensor(-0.3406, device='cuda:0')\n",
      "Regression error on test: 0.022922\n",
      "Max test: tensor(2.3813, device='cuda:0')\n",
      "Mean test: tensor(-0.0831, device='cuda:0')\n",
      "0.0229217316955328\n",
      "Regression error on test: 0.023577\n",
      "Validation loss decreased (inf --> 0.023577).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029295\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038156\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.5566, device='cuda:0')\n",
      "Mean train: tensor(-0.0815, device='cuda:0')\n",
      "Regression error on test: 0.023577\n",
      "Max test: tensor(3.0059, device='cuda:0')\n",
      "Mean test: tensor(-0.0987, device='cuda:0')\n",
      "0.023577000945806503\n",
      "Regression error on test: 0.023797\n",
      "Validation loss decreased (inf --> 0.023797).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.047429\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041213\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.1511, device='cuda:0')\n",
      "Mean train: tensor(-0.1589, device='cuda:0')\n",
      "Regression error on test: 0.023797\n",
      "Max test: tensor(2.2932, device='cuda:0')\n",
      "Mean test: tensor(-0.0667, device='cuda:0')\n",
      "0.023796506226062775\n",
      "Regression error on test: 0.025189\n",
      "Validation loss decreased (inf --> 0.025189).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051639\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055343\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.6531, device='cuda:0')\n",
      "Mean train: tensor(-0.1380, device='cuda:0')\n",
      "Regression error on test: 0.025189\n",
      "Max test: tensor(5.8932, device='cuda:0')\n",
      "Mean test: tensor(-0.0299, device='cuda:0')\n",
      "0.025188779458403587\n",
      "Regression error on test: 0.028145\n",
      "Validation loss decreased (inf --> 0.028145).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041392\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091248\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.9143, device='cuda:0')\n",
      "Mean train: tensor(-0.0701, device='cuda:0')\n",
      "Regression error on test: 0.028145\n",
      "Max test: tensor(5.4066, device='cuda:0')\n",
      "Mean test: tensor(-0.0583, device='cuda:0')\n",
      "0.02814534120261669\n",
      "Regression error on test: 0.027415\n",
      "Validation loss decreased (inf --> 0.027415).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031107\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039393\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.8437, device='cuda:0')\n",
      "Mean train: tensor(-0.3119, device='cuda:0')\n",
      "Regression error on test: 0.027415\n",
      "Max test: tensor(2.5862, device='cuda:0')\n",
      "Mean test: tensor(-0.0610, device='cuda:0')\n",
      "0.027414662763476372\n",
      "Regression error on test: 0.027441\n",
      "Validation loss decreased (inf --> 0.027441).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061275\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023530\n",
      "Validation loss decreased (0.027441 --> 0.023530).  Saving model ...\n",
      "done\n",
      "Max train: tensor(5.6022, device='cuda:0')\n",
      "Mean train: tensor(0.1199, device='cuda:0')\n",
      "Regression error on test: 0.108468\n",
      "Max test: tensor(10.5083, device='cuda:0')\n",
      "Mean test: tensor(-0.0587, device='cuda:0')\n",
      "0.10846836119890213\n",
      "Regression error on test: 0.024738\n",
      "Validation loss decreased (inf --> 0.024738).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060584\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031482\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.5828, device='cuda:0')\n",
      "Mean train: tensor(-0.1732, device='cuda:0')\n",
      "Regression error on test: 0.024738\n",
      "Max test: tensor(2.0589, device='cuda:0')\n",
      "Mean test: tensor(-0.0903, device='cuda:0')\n",
      "0.024738440290093422\n",
      "Regression error on test: 0.022851\n",
      "Validation loss decreased (inf --> 0.022851).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046371\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.349920\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(6.6643, device='cuda:0')\n",
      "Mean train: tensor(-0.2292, device='cuda:0')\n",
      "Regression error on test: 0.022851\n",
      "Max test: tensor(2.4553, device='cuda:0')\n",
      "Mean test: tensor(-0.1201, device='cuda:0')\n",
      "0.02285103127360344\n",
      "Regression error on test: 0.030140\n",
      "Validation loss decreased (inf --> 0.030140).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048017\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035324\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.5095, device='cuda:0')\n",
      "Mean train: tensor(0.0093, device='cuda:0')\n",
      "Regression error on test: 0.030140\n",
      "Max test: tensor(2.1511, device='cuda:0')\n",
      "Mean test: tensor(-0.1062, device='cuda:0')\n",
      "0.03014017827808857\n",
      "Regression error on test: 0.038945\n",
      "Validation loss decreased (inf --> 0.038945).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057348\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027618\n",
      "Validation loss decreased (0.038945 --> 0.027618).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.8950, device='cuda:0')\n",
      "Mean train: tensor(-0.1822, device='cuda:0')\n",
      "Regression error on test: 0.109391\n",
      "Max test: tensor(7.4371, device='cuda:0')\n",
      "Mean test: tensor(-0.1254, device='cuda:0')\n",
      "0.1093914806842804\n",
      "Regression error on test: 0.042451\n",
      "Validation loss decreased (inf --> 0.042451).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063701\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.150906\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(5.5291, device='cuda:0')\n",
      "Mean train: tensor(0.1012, device='cuda:0')\n",
      "Regression error on test: 0.042451\n",
      "Max test: tensor(2.7718, device='cuda:0')\n",
      "Mean test: tensor(-0.1206, device='cuda:0')\n",
      "0.042451292276382446\n",
      "Regression error on test: 0.051502\n",
      "Validation loss decreased (inf --> 0.051502).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.082109\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083347\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.4029, device='cuda:0')\n",
      "Mean train: tensor(-0.2410, device='cuda:0')\n",
      "Regression error on test: 0.051502\n",
      "Max test: tensor(3.0830, device='cuda:0')\n",
      "Mean test: tensor(-0.1037, device='cuda:0')\n",
      "0.051501788198947906\n",
      "Regression error on test: 0.065705\n",
      "Validation loss decreased (inf --> 0.065705).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045476\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.185001\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(5.6823, device='cuda:0')\n",
      "Mean train: tensor(-0.2261, device='cuda:0')\n",
      "Regression error on test: 0.065705\n",
      "Max test: tensor(2.4729, device='cuda:0')\n",
      "Mean test: tensor(-0.0839, device='cuda:0')\n",
      "0.0657050609588623\n",
      "Regression error on test: 0.044112\n",
      "Validation loss decreased (inf --> 0.044112).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076804\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.136827\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.6501, device='cuda:0')\n",
      "Mean train: tensor(-0.0637, device='cuda:0')\n",
      "Regression error on test: 0.044112\n",
      "Max test: tensor(3.0770, device='cuda:0')\n",
      "Mean test: tensor(-0.0793, device='cuda:0')\n",
      "0.04411233589053154\n",
      "Regression error on test: 0.042333\n",
      "Validation loss decreased (inf --> 0.042333).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097346\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.120991\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.0037, device='cuda:0')\n",
      "Mean train: tensor(0.0220, device='cuda:0')\n",
      "Regression error on test: 0.042333\n",
      "Max test: tensor(3.1624, device='cuda:0')\n",
      "Mean test: tensor(-0.0497, device='cuda:0')\n",
      "0.04233254864811897\n",
      "Regression error on test: 0.048065\n",
      "Validation loss decreased (inf --> 0.048065).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055371\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038032\n",
      "Validation loss decreased (0.048065 --> 0.038032).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.6195, device='cuda:0')\n",
      "Mean train: tensor(-0.0608, device='cuda:0')\n",
      "Regression error on test: 0.140496\n",
      "Max test: tensor(15.3386, device='cuda:0')\n",
      "Mean test: tensor(0.2729, device='cuda:0')\n",
      "0.14049580693244934\n",
      "Regression error on test: 0.059158\n",
      "Validation loss decreased (inf --> 0.059158).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060319\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.089470\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train: tensor(3.0553, device='cuda:0')\n",
      "Mean train: tensor(-0.1254, device='cuda:0')\n",
      "Regression error on test: 0.059158\n",
      "Max test: tensor(4.1912, device='cuda:0')\n",
      "Mean test: tensor(-0.0611, device='cuda:0')\n",
      "0.05915764346718788\n",
      "Regression error on test: 0.068782\n",
      "Validation loss decreased (inf --> 0.068782).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030808\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035557\n",
      "Validation loss decreased (0.068782 --> 0.035557).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.2594, device='cuda:0')\n",
      "Mean train: tensor(-0.3059, device='cuda:0')\n",
      "Regression error on test: 0.084467\n",
      "Max test: tensor(8.6007, device='cuda:0')\n",
      "Mean test: tensor(-0.4247, device='cuda:0')\n",
      "0.08446735888719559\n",
      "Regression error on test: 0.083173\n",
      "Validation loss decreased (inf --> 0.083173).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078114\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.258255\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(6.3935, device='cuda:0')\n",
      "Mean train: tensor(-0.0963, device='cuda:0')\n",
      "Regression error on test: 0.083173\n",
      "Max test: tensor(4.4168, device='cuda:0')\n",
      "Mean test: tensor(-0.0623, device='cuda:0')\n",
      "0.08317288011312485\n",
      "Regression error on test: 0.068800\n",
      "Validation loss decreased (inf --> 0.068800).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.128412\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044111\n",
      "Validation loss decreased (0.068800 --> 0.044111).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.9308, device='cuda:0')\n",
      "Mean train: tensor(-0.0858, device='cuda:0')\n",
      "Regression error on test: 0.067675\n",
      "Max test: tensor(11.3674, device='cuda:0')\n",
      "Mean test: tensor(-0.0953, device='cuda:0')\n",
      "0.06767486780881882\n",
      "Regression error on test: 0.051697\n",
      "Validation loss decreased (inf --> 0.051697).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076938\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.273689\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.0774, device='cuda:0')\n",
      "Mean train: tensor(-0.0779, device='cuda:0')\n",
      "Regression error on test: 0.051697\n",
      "Max test: tensor(4.5834, device='cuda:0')\n",
      "Mean test: tensor(-0.1083, device='cuda:0')\n",
      "0.051696762442588806\n",
      "Regression error on test: 0.045191\n",
      "Validation loss decreased (inf --> 0.045191).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061914\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.095020\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.6789, device='cuda:0')\n",
      "Mean train: tensor(-0.0388, device='cuda:0')\n",
      "Regression error on test: 0.045191\n",
      "Max test: tensor(3.0954, device='cuda:0')\n",
      "Mean test: tensor(-0.1093, device='cuda:0')\n",
      "0.04519101232290268\n",
      "Regression error on test: 0.045032\n",
      "Validation loss decreased (inf --> 0.045032).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.092292\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066330\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.9592, device='cuda:0')\n",
      "Mean train: tensor(-0.0111, device='cuda:0')\n",
      "Regression error on test: 0.045032\n",
      "Max test: tensor(3.2821, device='cuda:0')\n",
      "Mean test: tensor(-0.1010, device='cuda:0')\n",
      "0.04503185302019119\n",
      "Regression error on test: 0.041173\n",
      "Validation loss decreased (inf --> 0.041173).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054158\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080338\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.2311, device='cuda:0')\n",
      "Mean train: tensor(-0.1495, device='cuda:0')\n",
      "Regression error on test: 0.041173\n",
      "Max test: tensor(3.0222, device='cuda:0')\n",
      "Mean test: tensor(-0.1299, device='cuda:0')\n",
      "0.04117295518517494\n",
      "Regression error on test: 0.050931\n",
      "Validation loss decreased (inf --> 0.050931).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.047656\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.025160\n",
      "Validation loss decreased (0.050931 --> 0.025160).  Saving model ...\n",
      "done\n",
      "Max train: tensor(6.7871, device='cuda:0')\n",
      "Mean train: tensor(0.0515, device='cuda:0')\n",
      "Regression error on test: 0.066493\n",
      "Max test: tensor(9.0231, device='cuda:0')\n",
      "Mean test: tensor(-0.0775, device='cuda:0')\n",
      "0.06649347394704819\n",
      "Regression error on test: 0.054905\n",
      "Validation loss decreased (inf --> 0.054905).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061206\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062249\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.4251, device='cuda:0')\n",
      "Mean train: tensor(-0.1090, device='cuda:0')\n",
      "Regression error on test: 0.054905\n",
      "Max test: tensor(3.1826, device='cuda:0')\n",
      "Mean test: tensor(-0.1151, device='cuda:0')\n",
      "0.05490501597523689\n",
      "Regression error on test: 0.048834\n",
      "Validation loss decreased (inf --> 0.048834).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032895\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.116597\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.2490, device='cuda:0')\n",
      "Mean train: tensor(-0.1122, device='cuda:0')\n",
      "Regression error on test: 0.048834\n",
      "Max test: tensor(2.9542, device='cuda:0')\n",
      "Mean test: tensor(-0.0982, device='cuda:0')\n",
      "0.04883367940783501\n",
      "Regression error on test: 0.033272\n",
      "Validation loss decreased (inf --> 0.033272).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048143\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050476\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(1.9806, device='cuda:0')\n",
      "Mean train: tensor(-0.0551, device='cuda:0')\n",
      "Regression error on test: 0.033272\n",
      "Max test: tensor(2.9892, device='cuda:0')\n",
      "Mean test: tensor(-0.0623, device='cuda:0')\n",
      "0.03327224403619766\n",
      "Regression error on test: 0.037709\n",
      "Validation loss decreased (inf --> 0.037709).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.049877\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.087804\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.7995, device='cuda:0')\n",
      "Mean train: tensor(-0.0157, device='cuda:0')\n",
      "Regression error on test: 0.037709\n",
      "Max test: tensor(3.2368, device='cuda:0')\n",
      "Mean test: tensor(-0.0358, device='cuda:0')\n",
      "0.03770864009857178\n",
      "Regression error on test: 0.038459\n",
      "Validation loss decreased (inf --> 0.038459).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041259\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118038\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(5.1721, device='cuda:0')\n",
      "Mean train: tensor(0.0664, device='cuda:0')\n",
      "Regression error on test: 0.038459\n",
      "Max test: tensor(2.6592, device='cuda:0')\n",
      "Mean test: tensor(-0.0622, device='cuda:0')\n",
      "0.03845871239900589\n",
      "Regression error on test: 0.030281\n",
      "Validation loss decreased (inf --> 0.030281).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057019\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035026\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.2456, device='cuda:0')\n",
      "Mean train: tensor(-0.2156, device='cuda:0')\n",
      "Regression error on test: 0.030281\n",
      "Max test: tensor(2.8565, device='cuda:0')\n",
      "Mean test: tensor(-0.0841, device='cuda:0')\n",
      "0.03028101660311222\n",
      "Regression error on test: 0.030806\n",
      "Validation loss decreased (inf --> 0.030806).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032532\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.030354\n",
      "Validation loss decreased (0.030806 --> 0.030354).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.9238, device='cuda:0')\n",
      "Mean train: tensor(-0.2637, device='cuda:0')\n",
      "Regression error on test: 0.054920\n",
      "Max test: tensor(8.4432, device='cuda:0')\n",
      "Mean test: tensor(-0.1096, device='cuda:0')\n",
      "0.05492022633552551\n",
      "Regression error on test: 0.032064\n",
      "Validation loss decreased (inf --> 0.032064).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035624\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060643\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.9290, device='cuda:0')\n",
      "Mean train: tensor(0.2025, device='cuda:0')\n",
      "Regression error on test: 0.032064\n",
      "Max test: tensor(5.2587, device='cuda:0')\n",
      "Mean test: tensor(-0.0607, device='cuda:0')\n",
      "0.03206430375576019\n",
      "Regression error on test: 0.030671\n",
      "Validation loss decreased (inf --> 0.030671).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055708\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104300\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.4034, device='cuda:0')\n",
      "Mean train: tensor(-0.1739, device='cuda:0')\n",
      "Regression error on test: 0.030671\n",
      "Max test: tensor(4.3523, device='cuda:0')\n",
      "Mean test: tensor(-0.0455, device='cuda:0')\n",
      "0.030671004205942154\n",
      "Regression error on test: 0.029568\n",
      "Validation loss decreased (inf --> 0.029568).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041491\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045818\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.3049, device='cuda:0')\n",
      "Mean train: tensor(-0.1283, device='cuda:0')\n",
      "Regression error on test: 0.029568\n",
      "Max test: tensor(6.7250, device='cuda:0')\n",
      "Mean test: tensor(-0.0192, device='cuda:0')\n",
      "0.029568258672952652\n",
      "Regression error on test: 0.025766\n",
      "Validation loss decreased (inf --> 0.025766).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.068396\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057878\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(5.0992, device='cuda:0')\n",
      "Mean train: tensor(-0.2075, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.025766\n",
      "Max test: tensor(7.1636, device='cuda:0')\n",
      "Mean test: tensor(-0.0372, device='cuda:0')\n",
      "0.025766411796212196\n",
      "Regression error on test: 0.026533\n",
      "Validation loss decreased (inf --> 0.026533).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040026\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040375\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.0805, device='cuda:0')\n",
      "Mean train: tensor(0.4071, device='cuda:0')\n",
      "Regression error on test: 0.026533\n",
      "Max test: tensor(4.1541, device='cuda:0')\n",
      "Mean test: tensor(-0.0778, device='cuda:0')\n",
      "0.026532793417572975\n",
      "Regression error on test: 0.026848\n",
      "Validation loss decreased (inf --> 0.026848).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057501\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075631\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.7826, device='cuda:0')\n",
      "Mean train: tensor(-0.0623, device='cuda:0')\n",
      "Regression error on test: 0.026848\n",
      "Max test: tensor(2.7183, device='cuda:0')\n",
      "Mean test: tensor(-0.0789, device='cuda:0')\n",
      "0.026848338544368744\n",
      "Regression error on test: 0.032397\n",
      "Validation loss decreased (inf --> 0.032397).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055943\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082338\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.8042, device='cuda:0')\n",
      "Mean train: tensor(-0.1376, device='cuda:0')\n",
      "Regression error on test: 0.032397\n",
      "Max test: tensor(1.8166, device='cuda:0')\n",
      "Mean test: tensor(-0.0709, device='cuda:0')\n",
      "0.03239695727825165\n",
      "Regression error on test: 0.026651\n",
      "Validation loss decreased (inf --> 0.026651).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076725\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033867\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.5323, device='cuda:0')\n",
      "Mean train: tensor(-0.0638, device='cuda:0')\n",
      "Regression error on test: 0.026651\n",
      "Max test: tensor(2.1724, device='cuda:0')\n",
      "Mean test: tensor(-0.0801, device='cuda:0')\n",
      "0.026651054620742798\n",
      "Regression error on test: 0.034929\n",
      "Validation loss decreased (inf --> 0.034929).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.100731\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.129465\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.9571, device='cuda:0')\n",
      "Mean train: tensor(-0.1766, device='cuda:0')\n",
      "Regression error on test: 0.034929\n",
      "Max test: tensor(1.8324, device='cuda:0')\n",
      "Mean test: tensor(-0.0832, device='cuda:0')\n",
      "0.03492910787463188\n",
      "Regression error on test: 0.030022\n",
      "Validation loss decreased (inf --> 0.030022).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058193\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038074\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.6720, device='cuda:0')\n",
      "Mean train: tensor(-0.0335, device='cuda:0')\n",
      "Regression error on test: 0.030022\n",
      "Max test: tensor(2.8707, device='cuda:0')\n",
      "Mean test: tensor(-0.0724, device='cuda:0')\n",
      "0.030021755024790764\n",
      "Regression error on test: 0.028149\n",
      "Validation loss decreased (inf --> 0.028149).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064689\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053921\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.5400, device='cuda:0')\n",
      "Mean train: tensor(-0.1396, device='cuda:0')\n",
      "Regression error on test: 0.028149\n",
      "Max test: tensor(2.7019, device='cuda:0')\n",
      "Mean test: tensor(-0.0843, device='cuda:0')\n",
      "0.028149379417300224\n",
      "Regression error on test: 0.027846\n",
      "Validation loss decreased (inf --> 0.027846).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037272\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033607\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.9152, device='cuda:0')\n",
      "Mean train: tensor(-0.1692, device='cuda:0')\n",
      "Regression error on test: 0.027846\n",
      "Max test: tensor(2.2719, device='cuda:0')\n",
      "Mean test: tensor(-0.1006, device='cuda:0')\n",
      "0.027845609933137894\n",
      "Regression error on test: 0.027410\n",
      "Validation loss decreased (inf --> 0.027410).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.044194\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.022831\n",
      "Validation loss decreased (0.027410 --> 0.022831).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.0625, device='cuda:0')\n",
      "Mean train: tensor(-0.1540, device='cuda:0')\n",
      "Regression error on test: 0.055668\n",
      "Max test: tensor(7.8772, device='cuda:0')\n",
      "Mean test: tensor(-0.0190, device='cuda:0')\n",
      "0.05566775053739548\n",
      "Regression error on test: 0.030936\n",
      "Validation loss decreased (inf --> 0.030936).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055125\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067103\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.2212, device='cuda:0')\n",
      "Mean train: tensor(-0.1275, device='cuda:0')\n",
      "Regression error on test: 0.030936\n",
      "Max test: tensor(2.6830, device='cuda:0')\n",
      "Mean test: tensor(-0.1035, device='cuda:0')\n",
      "0.03093622624874115\n",
      "Regression error on test: 0.027681\n",
      "Validation loss decreased (inf --> 0.027681).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059095\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048825\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.7670, device='cuda:0')\n",
      "Mean train: tensor(-0.0216, device='cuda:0')\n",
      "Regression error on test: 0.027681\n",
      "Max test: tensor(2.8022, device='cuda:0')\n",
      "Mean test: tensor(-0.1343, device='cuda:0')\n",
      "0.027680667117238045\n",
      "Regression error on test: 0.029077\n",
      "Validation loss decreased (inf --> 0.029077).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063562\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041771\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.5364, device='cuda:0')\n",
      "Mean train: tensor(-0.0792, device='cuda:0')\n",
      "Regression error on test: 0.029077\n",
      "Max test: tensor(3.8075, device='cuda:0')\n",
      "Mean test: tensor(-0.1043, device='cuda:0')\n",
      "0.029077038168907166\n",
      "Regression error on test: 0.030107\n",
      "Validation loss decreased (inf --> 0.030107).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052233\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.025622\n",
      "Validation loss decreased (0.030107 --> 0.025622).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.8151, device='cuda:0')\n",
      "Mean train: tensor(-0.1145, device='cuda:0')\n",
      "Regression error on test: 0.111519\n",
      "Max test: tensor(29.4655, device='cuda:0')\n",
      "Mean test: tensor(-0.0008, device='cuda:0')\n",
      "0.11151929944753647\n",
      "Regression error on test: 0.041170\n",
      "Validation loss decreased (inf --> 0.041170).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032406\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.013387\n",
      "Validation loss decreased (0.041170 --> 0.013387).  Saving model ...\n",
      "done\n",
      "Max train: tensor(2.5044, device='cuda:0')\n",
      "Mean train: tensor(-0.1175, device='cuda:0')\n",
      "Regression error on test: 0.069388\n",
      "Max test: tensor(6.2099, device='cuda:0')\n",
      "Mean test: tensor(-0.1697, device='cuda:0')\n",
      "0.06938838213682175\n",
      "Regression error on test: 0.062315\n",
      "Validation loss decreased (inf --> 0.062315).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.049193\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.070426\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.6681, device='cuda:0')\n",
      "Mean train: tensor(-0.2921, device='cuda:0')\n",
      "Regression error on test: 0.062315\n",
      "Max test: tensor(3.2861, device='cuda:0')\n",
      "Mean test: tensor(-0.0925, device='cuda:0')\n",
      "0.06231498718261719\n",
      "Regression error on test: 0.092501\n",
      "Validation loss decreased (inf --> 0.092501).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038725\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042130\n",
      "Validation loss decreased (0.092501 --> 0.042130).  Saving model ...\n",
      "done\n",
      "Max train: tensor(4.2922, device='cuda:0')\n",
      "Mean train: tensor(-0.2072, device='cuda:0')\n",
      "Regression error on test: 0.096603\n",
      "Max test: tensor(8.6098, device='cuda:0')\n",
      "Mean test: tensor(0.0362, device='cuda:0')\n",
      "0.09660326689481735\n",
      "Regression error on test: 0.086107\n",
      "Validation loss decreased (inf --> 0.086107).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.106052\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041471\n",
      "Validation loss decreased (0.086107 --> 0.041471).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.8268, device='cuda:0')\n",
      "Mean train: tensor(0.0047, device='cuda:0')\n",
      "Regression error on test: 0.212892\n",
      "Max test: tensor(11.6517, device='cuda:0')\n",
      "Mean test: tensor(0.0319, device='cuda:0')\n",
      "0.21289190649986267\n",
      "Regression error on test: 0.069556\n",
      "Validation loss decreased (inf --> 0.069556).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.174245\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.483024\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.0456, device='cuda:0')\n",
      "Mean train: tensor(0.0154, device='cuda:0')\n",
      "Regression error on test: 0.069556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test: tensor(3.3177, device='cuda:0')\n",
      "Mean test: tensor(-0.0844, device='cuda:0')\n",
      "0.06955555826425552\n",
      "Regression error on test: 0.056904\n",
      "Validation loss decreased (inf --> 0.056904).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.096244\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044727\n",
      "Validation loss decreased (0.056904 --> 0.044727).  Saving model ...\n",
      "done\n",
      "Max train: tensor(2.8561, device='cuda:0')\n",
      "Mean train: tensor(0.0610, device='cuda:0')\n",
      "Regression error on test: 0.159878\n",
      "Max test: tensor(10.8342, device='cuda:0')\n",
      "Mean test: tensor(0.1178, device='cuda:0')\n",
      "0.15987755358219147\n",
      "Regression error on test: 0.049224\n",
      "Validation loss decreased (inf --> 0.049224).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.114062\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.112909\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(1.8338, device='cuda:0')\n",
      "Mean train: tensor(-0.1335, device='cuda:0')\n",
      "Regression error on test: 0.049224\n",
      "Max test: tensor(3.6016, device='cuda:0')\n",
      "Mean test: tensor(-0.0719, device='cuda:0')\n",
      "0.04922439530491829\n",
      "Regression error on test: 0.068878\n",
      "Validation loss decreased (inf --> 0.068878).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.044727\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054435\n",
      "Validation loss decreased (0.068878 --> 0.054435).  Saving model ...\n",
      "done\n",
      "Max train: tensor(4.4089, device='cuda:0')\n",
      "Mean train: tensor(-0.3124, device='cuda:0')\n",
      "Regression error on test: 0.103097\n",
      "Max test: tensor(9.1367, device='cuda:0')\n",
      "Mean test: tensor(-0.2518, device='cuda:0')\n",
      "0.10309680551290512\n",
      "Regression error on test: 0.084545\n",
      "Validation loss decreased (inf --> 0.084545).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031405\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117136\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.3043, device='cuda:0')\n",
      "Mean train: tensor(-0.1225, device='cuda:0')\n",
      "Regression error on test: 0.084545\n",
      "Max test: tensor(4.1740, device='cuda:0')\n",
      "Mean test: tensor(-0.0711, device='cuda:0')\n",
      "0.0845450758934021\n",
      "Regression error on test: 0.083423\n",
      "Validation loss decreased (inf --> 0.083423).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.147819\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034890\n",
      "Validation loss decreased (0.083423 --> 0.034890).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.5782, device='cuda:0')\n",
      "Mean train: tensor(-0.0285, device='cuda:0')\n",
      "Regression error on test: 0.081704\n",
      "Max test: tensor(12.6174, device='cuda:0')\n",
      "Mean test: tensor(-0.0906, device='cuda:0')\n",
      "0.081703782081604\n",
      "Regression error on test: 0.077154\n",
      "Validation loss decreased (inf --> 0.077154).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066772\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126775\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.9938, device='cuda:0')\n",
      "Mean train: tensor(-0.0686, device='cuda:0')\n",
      "Regression error on test: 0.077154\n",
      "Max test: tensor(3.8990, device='cuda:0')\n",
      "Mean test: tensor(-0.1021, device='cuda:0')\n",
      "0.07715359330177307\n",
      "Regression error on test: 0.073656\n",
      "Validation loss decreased (inf --> 0.073656).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051038\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068792\n",
      "Validation loss decreased (0.073656 --> 0.068792).  Saving model ...\n",
      "done\n",
      "Max train: tensor(4.7750, device='cuda:0')\n",
      "Mean train: tensor(0.1177, device='cuda:0')\n",
      "Regression error on test: 0.082938\n",
      "Max test: tensor(10.2438, device='cuda:0')\n",
      "Mean test: tensor(0.0493, device='cuda:0')\n",
      "0.08293759822845459\n",
      "Regression error on test: 0.070155\n",
      "Validation loss decreased (inf --> 0.070155).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108089\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118891\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.3997, device='cuda:0')\n",
      "Mean train: tensor(-0.0661, device='cuda:0')\n",
      "Regression error on test: 0.070155\n",
      "Max test: tensor(3.6404, device='cuda:0')\n",
      "Mean test: tensor(-0.1093, device='cuda:0')\n",
      "0.07015548646450043\n",
      "Regression error on test: 0.066013\n",
      "Validation loss decreased (inf --> 0.066013).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.147590\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.175515\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.5503, device='cuda:0')\n",
      "Mean train: tensor(-0.1510, device='cuda:0')\n",
      "Regression error on test: 0.066013\n",
      "Max test: tensor(4.0001, device='cuda:0')\n",
      "Mean test: tensor(-0.1209, device='cuda:0')\n",
      "0.0660133883357048\n",
      "Regression error on test: 0.078203\n",
      "Validation loss decreased (inf --> 0.078203).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042152\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092862\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.9096, device='cuda:0')\n",
      "Mean train: tensor(-0.1779, device='cuda:0')\n",
      "Regression error on test: 0.078203\n",
      "Max test: tensor(3.8698, device='cuda:0')\n",
      "Mean test: tensor(-0.1143, device='cuda:0')\n",
      "0.0782029926776886\n",
      "Regression error on test: 0.078310\n",
      "Validation loss decreased (inf --> 0.078310).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039803\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.022148\n",
      "Validation loss decreased (0.078310 --> 0.022148).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.3235, device='cuda:0')\n",
      "Mean train: tensor(-0.2229, device='cuda:0')\n",
      "Regression error on test: 0.083274\n",
      "Max test: tensor(9.8640, device='cuda:0')\n",
      "Mean test: tensor(-0.0313, device='cuda:0')\n",
      "0.08327411860227585\n",
      "Regression error on test: 0.063997\n",
      "Validation loss decreased (inf --> 0.063997).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045709\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100722\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(6.1513, device='cuda:0')\n",
      "Mean train: tensor(-0.2312, device='cuda:0')\n",
      "Regression error on test: 0.063997\n",
      "Max test: tensor(3.3236, device='cuda:0')\n",
      "Mean test: tensor(-0.0699, device='cuda:0')\n",
      "0.06399720907211304\n",
      "Regression error on test: 0.040018\n",
      "Validation loss decreased (inf --> 0.040018).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040094\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031597\n",
      "Validation loss decreased (0.040018 --> 0.031597).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.4110, device='cuda:0')\n",
      "Mean train: tensor(-0.2304, device='cuda:0')\n",
      "Regression error on test: 0.054518\n",
      "Max test: tensor(12.3801, device='cuda:0')\n",
      "Mean test: tensor(0.0283, device='cuda:0')\n",
      "0.05451838672161102\n",
      "Regression error on test: 0.040582\n",
      "Validation loss decreased (inf --> 0.040582).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.095923\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.136324\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.3544, device='cuda:0')\n",
      "Mean train: tensor(0.0343, device='cuda:0')\n",
      "Regression error on test: 0.040582\n",
      "Max test: tensor(3.2750, device='cuda:0')\n",
      "Mean test: tensor(-0.0568, device='cuda:0')\n",
      "0.04058164358139038\n",
      "Regression error on test: 0.032792\n",
      "Validation loss decreased (inf --> 0.032792).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056528\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058062\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.6841, device='cuda:0')\n",
      "Mean train: tensor(-0.2161, device='cuda:0')\n",
      "Regression error on test: 0.032792\n",
      "Max test: tensor(3.3536, device='cuda:0')\n",
      "Mean test: tensor(-0.0634, device='cuda:0')\n",
      "0.0327921137213707\n",
      "Regression error on test: 0.028287\n",
      "Validation loss decreased (inf --> 0.028287).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051800\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047016\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.7644, device='cuda:0')\n",
      "Mean train: tensor(0.0775, device='cuda:0')\n",
      "Regression error on test: 0.028287\n",
      "Max test: tensor(3.1880, device='cuda:0')\n",
      "Mean test: tensor(-0.0579, device='cuda:0')\n",
      "0.028286810964345932\n",
      "Regression error on test: 0.026030\n",
      "Validation loss decreased (inf --> 0.026030).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040922\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059845\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.0284, device='cuda:0')\n",
      "Mean train: tensor(-0.2069, device='cuda:0')\n",
      "Regression error on test: 0.026030\n",
      "Max test: tensor(3.2950, device='cuda:0')\n",
      "Mean test: tensor(-0.0634, device='cuda:0')\n",
      "0.026029590517282486\n",
      "Regression error on test: 0.024323\n",
      "Validation loss decreased (inf --> 0.024323).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053257\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036665\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.1712, device='cuda:0')\n",
      "Mean train: tensor(0.0207, device='cuda:0')\n",
      "Regression error on test: 0.024323\n",
      "Max test: tensor(3.6724, device='cuda:0')\n",
      "Mean test: tensor(-0.0592, device='cuda:0')\n",
      "0.02432338148355484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.026183\n",
      "Validation loss decreased (inf --> 0.026183).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032413\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053627\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.2707, device='cuda:0')\n",
      "Mean train: tensor(0.1744, device='cuda:0')\n",
      "Regression error on test: 0.026183\n",
      "Max test: tensor(2.9710, device='cuda:0')\n",
      "Mean test: tensor(-0.0505, device='cuda:0')\n",
      "0.02618332952260971\n",
      "Regression error on test: 0.028543\n",
      "Validation loss decreased (inf --> 0.028543).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030743\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060482\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.0635, device='cuda:0')\n",
      "Mean train: tensor(-0.2105, device='cuda:0')\n",
      "Regression error on test: 0.028543\n",
      "Max test: tensor(5.2631, device='cuda:0')\n",
      "Mean test: tensor(-0.0409, device='cuda:0')\n",
      "0.02854268252849579\n",
      "Regression error on test: 0.026828\n",
      "Validation loss decreased (inf --> 0.026828).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050143\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027415\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(5.8050, device='cuda:0')\n",
      "Mean train: tensor(0.1177, device='cuda:0')\n",
      "Regression error on test: 0.026828\n",
      "Max test: tensor(9.3951, device='cuda:0')\n",
      "Mean test: tensor(0.0149, device='cuda:0')\n",
      "0.02682768926024437\n",
      "Regression error on test: 0.022092\n",
      "Validation loss decreased (inf --> 0.022092).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069052\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.105432\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(4.4723, device='cuda:0')\n",
      "Mean train: tensor(0.0406, device='cuda:0')\n",
      "Regression error on test: 0.022092\n",
      "Max test: tensor(9.0437, device='cuda:0')\n",
      "Mean test: tensor(-0.0079, device='cuda:0')\n",
      "0.02209164761006832\n",
      "Regression error on test: 0.022203\n",
      "Validation loss decreased (inf --> 0.022203).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036418\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.139723\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(6.0899, device='cuda:0')\n",
      "Mean train: tensor(-0.2562, device='cuda:0')\n",
      "Regression error on test: 0.022203\n",
      "Max test: tensor(3.8125, device='cuda:0')\n",
      "Mean test: tensor(-0.0702, device='cuda:0')\n",
      "0.02220289036631584\n",
      "Regression error on test: 0.024011\n",
      "Validation loss decreased (inf --> 0.024011).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036365\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.030123\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.4140, device='cuda:0')\n",
      "Mean train: tensor(-0.0756, device='cuda:0')\n",
      "Regression error on test: 0.024011\n",
      "Max test: tensor(2.5864, device='cuda:0')\n",
      "Mean test: tensor(-0.0592, device='cuda:0')\n",
      "0.02401082031428814\n",
      "Regression error on test: 0.023213\n",
      "Validation loss decreased (inf --> 0.023213).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057010\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.070720\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.9631, device='cuda:0')\n",
      "Mean train: tensor(-0.0313, device='cuda:0')\n",
      "Regression error on test: 0.023213\n",
      "Max test: tensor(2.3837, device='cuda:0')\n",
      "Mean test: tensor(-0.0946, device='cuda:0')\n",
      "0.02321314811706543\n",
      "Regression error on test: 0.025116\n",
      "Validation loss decreased (inf --> 0.025116).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060833\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044237\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.9530, device='cuda:0')\n",
      "Mean train: tensor(-0.2408, device='cuda:0')\n",
      "Regression error on test: 0.025116\n",
      "Max test: tensor(2.7258, device='cuda:0')\n",
      "Mean test: tensor(-0.0957, device='cuda:0')\n",
      "0.025116266682744026\n",
      "Regression error on test: 0.027301\n",
      "Validation loss decreased (inf --> 0.027301).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.073303\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058274\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.5971, device='cuda:0')\n",
      "Mean train: tensor(-0.1208, device='cuda:0')\n",
      "Regression error on test: 0.027301\n",
      "Max test: tensor(2.6079, device='cuda:0')\n",
      "Mean test: tensor(-0.0882, device='cuda:0')\n",
      "0.027300506830215454\n",
      "Regression error on test: 0.030447\n",
      "Validation loss decreased (inf --> 0.030447).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041813\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.020502\n",
      "Validation loss decreased (0.030447 --> 0.020502).  Saving model ...\n",
      "done\n",
      "Max train: tensor(3.1751, device='cuda:0')\n",
      "Mean train: tensor(-0.1696, device='cuda:0')\n",
      "Regression error on test: 0.040671\n",
      "Max test: tensor(5.6503, device='cuda:0')\n",
      "Mean test: tensor(-0.1623, device='cuda:0')\n",
      "0.04067143425345421\n",
      "Regression error on test: 0.029733\n",
      "Validation loss decreased (inf --> 0.029733).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.071959\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049710\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(2.3372, device='cuda:0')\n",
      "Mean train: tensor(-0.0522, device='cuda:0')\n",
      "Regression error on test: 0.029733\n",
      "Max test: tensor(3.8965, device='cuda:0')\n",
      "Mean test: tensor(-0.0970, device='cuda:0')\n",
      "0.029732922092080116\n",
      "Regression error on test: 0.022553\n",
      "Validation loss decreased (inf --> 0.022553).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048831\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.086229\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(6.2240, device='cuda:0')\n",
      "Mean train: tensor(-0.3229, device='cuda:0')\n",
      "Regression error on test: 0.022553\n",
      "Max test: tensor(2.6329, device='cuda:0')\n",
      "Mean test: tensor(-0.1273, device='cuda:0')\n",
      "0.02255341038107872\n",
      "Regression error on test: 0.022154\n",
      "Validation loss decreased (inf --> 0.022154).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053833\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056561\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.3314, device='cuda:0')\n",
      "Mean train: tensor(-0.1253, device='cuda:0')\n",
      "Regression error on test: 0.022154\n",
      "Max test: tensor(2.2630, device='cuda:0')\n",
      "Mean test: tensor(-0.1156, device='cuda:0')\n",
      "0.02215413935482502\n",
      "Regression error on test: 0.029207\n",
      "Validation loss decreased (inf --> 0.029207).  Saving model ...\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.049564\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067704\n",
      "EarlyStopping counter: 1 out of 20\n",
      "done\n",
      "Max train: tensor(3.4896, device='cuda:0')\n",
      "Mean train: tensor(0.0298, device='cuda:0')\n",
      "Regression error on test: 0.029207\n",
      "Max test: tensor(2.7366, device='cuda:0')\n",
      "Mean test: tensor(-0.0993, device='cuda:0')\n",
      "0.029207108542323112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-0d74f89b3df7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0minitial_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model_file_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"FCN\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-199-0d74f89b3df7>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, test_loader, output_directory, model_file, verbose, threshold)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mmean_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_test_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Regression error on test: %f\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-199-0d74f89b3df7>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(model, data_iter, len_dataloader, optimizer, loss, is_train, threshold)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Data Analytics Master\\Semester4-Thesis\\repo\\time-series-meta-learning\\master-thesis\\Code\\base_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Data Analytics Master\\Semester4-Thesis\\repo\\time-series-meta-learning\\master-thesis\\Code\\base_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# input (batch_size, num_variables, time_steps), e.g. (128, 1, 512)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# input (batch_size, out_channel, L_out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 202\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from pytorchtools import count_parameters, to_torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from base_models import LSTMModel, FCN, ExtendedFCN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from metrics import torch_mae as mae\n",
    "import argparse\n",
    "from pytorchtools import EarlyStopping\n",
    "from ts_dataset import TSDataset, SimpleDataset\n",
    "from ts_transform import split_idx_50_50\n",
    "from ts_dataset import DomainTSDataset, SimpleDataset\n",
    "\n",
    "\n",
    "def set_bn_eval(module):\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.eval()\n",
    "        \n",
    "\n",
    "\n",
    "def step(model, data_iter, len_dataloader, optimizer = None, loss = mae, is_train=False, threshold = False):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        #model.eval()\n",
    "        model.eval()\n",
    "\n",
    "    accum_err = 0\n",
    "    accum_size = 0\n",
    "    i = 0\n",
    "    while i < len_dataloader:\n",
    "\n",
    "        # training model using source data\n",
    "        data_source = data_iter.next()\n",
    "        x, y = data_source\n",
    "\n",
    "        if is_train:\n",
    "            model.zero_grad()\n",
    "        \n",
    "        x = torch.tensor(x).float().to(device)\n",
    "        y = torch.tensor(y).float().to(device)\n",
    "\n",
    "        y_pred = model(x) \n",
    "\n",
    "        if threshold:\n",
    "            y_pred = torch.clamp(y_pred, 0, 1)\n",
    "\n",
    "        err = loss(y, y_pred)\n",
    "\n",
    "        if is_train:\n",
    "            err.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #print(err)\n",
    "        accum_err +=err*x.shape[0]\n",
    "        accum_size += x.shape[0]\n",
    "        i += 1\n",
    "\n",
    "    return float(accum_err/accum_size)\n",
    "        \n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, early_stopping, learning_rate = 0.001, epochs = 500, add_weight_decay = False, monitor_stopping = True):\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate) if ~add_weight_decay else optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 10e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = early_stopping.patience//4, verbose=True)\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        len_train_loader = len(train_loader)\n",
    "        train_iter = iter(train_loader)\n",
    "\n",
    "        len_val_loader = len(val_loader)\n",
    "        val_iter = iter(val_loader)\n",
    "\n",
    "        mean_err = step(model, train_iter, len_train_loader, optimizer, is_train=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mean_err_val = step(model, val_iter, len_val_loader)\n",
    "\n",
    "        print ('epoch: %d, \\n TRAINING -> mean_err: %f' % (epoch, mean_err))\n",
    "        print ('epoch: %d, \\n VAL -> mean_err: %f' % (epoch, mean_err_val))\n",
    "\n",
    "        scheduler.step(mean_err_val)\n",
    "\n",
    "        if monitor_stopping:\n",
    "            early_stopping(mean_err_val, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        print('done')\n",
    "\n",
    "    return epoch+1\n",
    "\n",
    "\n",
    "def test(model, test_loader, output_directory, model_file, verbose = True, threshold = False):\n",
    "\n",
    "    len_test_loader = len(test_loader)\n",
    "    test_iter = iter(test_loader)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mean_err = step(model, test_iter, len_test_loader, threshold=True)\n",
    "\n",
    "    print(\"Regression error on test: %f\"%(mean_err))\n",
    "\n",
    "    if verbose:\n",
    "        f=open(output_directory+\"/results.txt\", \"a+\")\n",
    "        f.write(\"Test error :%f\"% mean_err)\n",
    "        f.write(\"\\n\")\n",
    "        f.close()\n",
    "\n",
    "    return mean_err\n",
    "\n",
    "\n",
    "def freeze_fcn(fcn):\n",
    "\n",
    "    for params in fcn.named_parameters():\n",
    "        if(params[0][:6]!=\"linear\"):\n",
    "            params[1].requires_grad=False\n",
    "        elif (params[0]==\"linear.weight\"):\n",
    "            l2_reg=torch.norm(params[1])\n",
    "    \n",
    "    return l2_reg\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meta_info = {\"POLLUTION\": [5, 50, 14],\n",
    "             \"HR\": [32, 50, 13],\n",
    "             \"BATTERY\": [20, 50, 3] }\n",
    "\n",
    "output_directory = \"output/\"\n",
    "verbose=True\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "params = {'batch_size': batch_size,\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0}\n",
    "\n",
    "dataset_name = \"POLLUTION\" \n",
    "mode = \"WFT\"\n",
    "save_model_file = \"temp_model.pt\"\n",
    "load_model_file = \"model.pt\"\n",
    "lower_trial = 0\n",
    "upper_trial = 1\n",
    "learning_rate = 0.0001\n",
    "regularization_penalty = 0.001\n",
    "model_name = \"FCN\"\n",
    "is_test = 1\n",
    "patience_stopping = 20\n",
    "epochs = 1\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "\n",
    "assert mode in (\"WFT\", \"WOFT\", \"50\"), \"Mode was not correctly specified\"\n",
    "assert model_name in (\"FCN\", \"LSTM\"), \"Model was not correctly specified\"\n",
    "assert dataset_name in (\"POLLUTION\", \"HR\", \"BATTERY\")\n",
    "\n",
    "window_size, task_size, input_dim = meta_info[dataset_name]\n",
    "\n",
    "train_data = pickle.load(  open( \"../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "train_data_ML = pickle.load(  open( \"../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "validation_data = pickle.load( open( \"../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "validation_data_ML = pickle.load( open( \"../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "test_data_ML = pickle.load( open( \"../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#test_data_ML = train_data_ML\n",
    "\n",
    "for trial in range(lower_trial, upper_trial):\n",
    "\n",
    "    output_directory = \"../Models/\"+dataset_name+\"_\"+model_name+\"/\"+str(trial)+\"/\"\n",
    "    save_model_file_ = output_directory + save_model_file\n",
    "    load_model_file_ = output_directory + load_model_file\n",
    "\n",
    "    try:\n",
    "        os.mkdir(output_directory)\n",
    "    except OSError as error: \n",
    "        print(error)\n",
    "\n",
    "    f=open(output_directory+\"/results.txt\", \"a+\")\n",
    "    f.write(\"Dataset :%s\"% dataset_name)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    save_model_file_ = output_directory+save_model_file\n",
    "    load_model_file_ = output_directory+load_model_file\n",
    "\n",
    "    assert save_model_file!=load_model_file, \"Files cannot be the same\"\n",
    "\n",
    "    n_tasks, task_size, dim, channels = test_data_ML.x.shape if is_test else validation_data_ML.x.shape\n",
    "    horizon = 10\n",
    "    #epochs = 20\n",
    "    test_loss_list = []\n",
    "    initial_test_loss_list = []\n",
    "    train_mean_list = []\n",
    "    test_mean_list = []\n",
    "\n",
    "    for task_id in range(0, (n_tasks-horizon-1), n_tasks//100):\n",
    "\n",
    "\n",
    "        #check that all files blong to the same domain\n",
    "        temp_file_idx = test_data_ML.file_idx[task_id:task_id+horizon+1]\n",
    "        if(len(np.unique(temp_file_idx))>1):\n",
    "            continue\n",
    "\n",
    "        if is_test: \n",
    "            temp_x_train = test_data_ML.x[task_id][:int(task_size*0.8)]\n",
    "            temp_y_train = test_data_ML.y[task_id][:int(task_size*0.8)]\n",
    "\n",
    "            temp_x_val = test_data_ML.x[task_id][int(task_size*0.8):]\n",
    "            temp_y_val = test_data_ML.y[task_id][int(task_size*0.8):]\n",
    "\n",
    "            temp_x_test = test_data_ML.x[(task_id+1):(task_id+horizon+1)].reshape(-1, dim, channels)\n",
    "            temp_y_test = test_data_ML.y[(task_id+1):(task_id+horizon+1)].reshape(-1, 1)\n",
    "\n",
    "        else:\n",
    "            temp_x_train = validation_data_ML.x[task_id][:int(task_size*0.8)]\n",
    "            temp_y_train = validation_data_ML.y[task_id][:int(task_size*0.8)]\n",
    "\n",
    "            temp_x_val = validation_data_ML.x[task_id][int(task_size*0.8):]\n",
    "            temp_y_val = validation_data_ML.y[task_id][int(task_size*0.8):]\n",
    "\n",
    "            temp_x_test = validation_data_ML.x[(task_id+1):(task_id+horizon+1)].reshape(-1, dim, channels)\n",
    "            temp_y_test = validation_data_ML.y[(task_id+1):(task_id+horizon+1)].reshape(-1, 1)               \n",
    "\n",
    "        if model_name == \"FCN\":\n",
    "\n",
    "            kernels = [8,5,3] if dataset_name!= \"POLLUTION\" else [4,2,1]\n",
    "            temp_x_train = np.transpose(temp_x_train, [0,2,1])\n",
    "            temp_x_test = np.transpose(temp_x_test, [0,2,1])\n",
    "            temp_x_val = np.transpose(temp_x_val, [0,2,1])\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=patience_stopping, model_file=save_model_file_, verbose=verbose)\n",
    "\n",
    "\n",
    "        if model_name == \"LSTM\":\n",
    "            model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n",
    "        elif model_name == \"FCN\":\n",
    "            model = FCN(time_steps = window_size, channels=[input_dim, 128, 128, 128], kernels=kernels )\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(load_model_file_))\n",
    "\n",
    "        for name, layer in model.named_modules():\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "\n",
    "        train_loader = DataLoader(SimpleDataset(x=temp_x_train, y=temp_y_train), **params)\n",
    "        val_loader = DataLoader(SimpleDataset(x=temp_x_val, y=temp_y_val), **params)\n",
    "        test_loader = DataLoader(SimpleDataset(x=temp_x_test, y=temp_y_test), **params)\n",
    "\n",
    "        model.cuda()\n",
    "        initial_loss = test(model, test_loader, output_directory, load_model_file_, True)\n",
    "\n",
    "        if model_name == \"FCN\":\n",
    "            #pass\n",
    "            freeze_fcn(model)\n",
    "            #model.apply(set_bn_eval)\n",
    "            #model = ExtendedFCN(model, 20,1)\n",
    "            #model.cuda()\n",
    "\n",
    "        early_stopping(initial_loss, model)\n",
    "        train(model, train_loader, val_loader, early_stopping, learning_rate, epochs, add_weight_decay=True)\n",
    "        print(\"Max train:\" , torch.max(activation[\"conv1.batch_norm\"]))\n",
    "        print(\"Mean train:\" , torch.mean(activation[\"conv1.batch_norm\"]))\n",
    "        train_mean_list.append(activation[\"conv1.batch_norm\"])\n",
    "      \n",
    "        loss = test(model, test_loader, output_directory, save_model_file_, False)\n",
    "        print(\"Max test:\",  torch.max(activation[\"conv1.batch_norm\"]))\n",
    "        print(\"Mean test:\" , torch.mean(activation[\"conv1.batch_norm\"]))\n",
    "        test_mean_list.append(activation[\"conv1.batch_norm\"])\n",
    "        print(loss)\n",
    "\n",
    "        test_loss_list.append(loss)\n",
    "        initial_test_loss_list.append(initial_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN(time_steps = window_size, channels=[input_dim, 128, 128, 128], kernels=kernels )\n",
    "model.load_state_dict(torch.load(load_model_file_))\n",
    "model.cuda()\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    layer.register_forward_hook(get_activation(name))\n",
    "model.apply(set_bn_eval)\n",
    "\n",
    "n_samples = 10000\n",
    "#model.apply(set_bn_eval)\n",
    "temp_x_train = train_data.x[:n_samples]\n",
    "temp_x_test = test_data.x[:n_samples]\n",
    "\n",
    "temp_x_train = np.transpose(temp_x_train, [0,2,1])\n",
    "temp_x_test = np.transpose(temp_x_test, [0,2,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19da1fb2b08>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model(to_torch(temp_x_train))\n",
    "train_activation = activation[\"conv1.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "pred_test = model(to_torch(temp_x_test))\n",
    "test_activation = activation[\"conv1.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "plt.scatter(np.mean(train_activation, 0), np.mean(test_activation, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19da1fb2a48>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model(to_torch(temp_x_train))\n",
    "train_activation = activation[\"conv2.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "pred_test = model(to_torch(temp_x_test))\n",
    "test_activation = activation[\"conv2.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "plt.scatter(np.mean(train_activation, 0), np.mean(test_activation, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19da563bd08>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAXyklEQVR4nO3de4yddZ3H8c93pod6Cq5TpCI9UNt1u0W6XaxMlN1uNguoxRvUgoiXDYlmySaaFWMa262RuspSd7L4x15immiWxMpFwaEETeXSjVndIlOnBWo7S1GkPTQwLgwaOgun0+/+cZ4zPXPmec79zHOZ9yuZzDnPcy6/x9Zvf3yf7+/7M3cXACCb+uIeAACgdwjyAJBhBHkAyDCCPABkGEEeADJsQdwDqHbOOef48uXL4x4GAKTKvn37fuvuS8LOJSrIL1++XCMjI3EPAwBSxcx+E3Wu43SNmV1gZnvM7JCZHTSzzwXHzzazB83sqeD34k6/CwDQmm7k5E9K+oK7v03SpZI+Y2YXSdos6WF3Xynp4eA5AGAOdRzk3f24u/8iePx7SYckFSRdLen24GW3S9rQ6XcBAFrT1eoaM1suaa2kRyWd6+7HpfI/BJLe1M3vAgA01rUgb2ZnSbpH0k3u/rsW3nejmY2Y2cj4+Hi3hgMAUJeqa8wsp3KA3+nu9waHnzez89z9uJmdJ+mFsPe6+w5JOyRpcHCQbmkA5pXh0aKGdo/puYlJLR3Ia9P6VdqwttC1z+9GdY1J+pakQ+5+W9WpXZJuCB7fIOm+Tr8LALJkeLSoLfc+oeLEpFxScWJSW+59QsOjxa59RzfSNesk/bWky81sf/DzfknbJb3HzJ6S9J7gOQAgMLR7TJOlqRnHJktTGto91rXv6Dhd4+7/JckiTl/R6ecDQFY9NzHZ0vF20LsGAGKydCDf0vF2EOQBICab1q9SPtc/41g+169N61d17TsS1bsGAOaTShVNL6trCPIAEKMNawtdDeq1SNcAQIYR5AEgwwjyAJBhBHkAyDCCPABkGEEeADKMIA8AGUaQB4AMI8gDQIYR5AEgwwjyAJBhBHkAyDAalAFAiF7vvTpXCPIAUKOy92pla77K3quSUhfoSdcAQI252Ht1rhDkAaDGXOy9OldI1wCYN5rNsy8dyKsYEtC7uffqXCHIA5gX6uXZpZlb8F124RLds684I2XT7b1X5wpBHsC8EJVn/8r9B/V/pVMzgv89+4q65pKC9hwep7oGANIgKp/+0onSrGOTpSntOTyun26+vNfD6jmCPIDMqJdzj8qzR0njTdYwVNcAyIRKzr04MSnX6Zz78GhRkrRp/Srlc/0z3pPP9Wsgnwv9vDTeZA1DkAeQCY1q2zesLejWjWtUGMjLJBUG8rp14xptu2p1aPBP403WMKRrAKROWFqmmdr2DWsLkTdPs9DCIAxBHkCqRJVCDizKhd5EbSbtUi/4px3pGgCpEpWWcVem0y7tIsgDSJWotMzLk6XQnHtWZ+jNIl0DILHCcu/1Wg5kOe3SLmbyABIpqiRy+RvDc+yXXbhkbgeYEgR5AIkUlXv/2dMvhr5+z+HxuRhW6pCuAZAolRRN1OpUj3hfVlaodhtBHkBi1JZHtiIrK1S7jSAPIBZhN1XDUjTNoFQyGkEewJyLWtDUbIBfvCinRWcsyOQK1W7rSpA3s29L+qCkF9z9T4JjZ0u6S9JySc9Ius7dX+rG9wFIt6ibqs26+UOrCepN6lZ1zX9IurLm2GZJD7v7SkkPB88BoKObpH0mAnwLuhLk3f0nkmrrmq6WdHvw+HZJG7rxXQDSr5ObpKeiymsQqpd18ue6+3FJCn6/KexFZnajmY2Y2cj4OHWuwHywaf0qWZvvLVBF05LYF0O5+w53H3T3wSVLWLEGZF2lqqadCTlVNK3rZXXN82Z2nrsfN7PzJL3Qw+8CkALN1MH32emUTD7Xp9fl+jVxokQVTZt6GeR3SbpB0vbg9309/C4ACVVdD99npimvP4f/+LuW6Wsb1szR6LKvWyWUd0j6K0nnmNkxSTerHNzvNrNPS3pW0ke68V0A0qN25t4owEv0oOm2rgR5d/9YxKkruvH5AJItbPXqhrWFtlaw0oOmu1jxCqAjUatXpfYCNj1ouiv26hoA6Ra1evULdx/QG/K50Pf0W7mAsraMkuqZ7iPIA+hIVEvgKXe98tpJ5fpmhvJ8rl//fN3Femb7B/SNj76d7fp6jHQNgKbV5t4vu3CJTNE93ktTXreZGNv19R5BHkBThkeL2vS9AyoFRezFiUl9Z++zDd83caKk0S+/t9fDQwTSNQCasm3XwekA3wpupMaLmTyAWcJKIicmSy1/DjdS40eQBzBDvZLIZlRy9AXaECQCQR7ADK1u6LEo16fFZy5kl6aEIsgDmDY8WowsiQzT32f6x41/SlBPMG68ApB0Ok3TitcvXECATziCPABJ4WmaRl5u42Ys5hZBHoAk+sxkFTl5IOOiOkTWHh9YlNNLJ1qbmVMemXzmTfR3niuDg4M+MjIS9zCAzAjbialS4ljbjiDXZ5KVWxE045OXsrlHUpjZPncfDDvHTB7IsLA8u9f8riidcg3kczpzYbnPzMCinNzLefc35HMyE9vwpRBBHsiwVvPsL0+WtP9m+sxkCTdegQxr9cYoN1KzhyAPZNim9auUz/U39Vr6zGQT6RogA6IqaCp586HdY3VXstJnJruorgFSLqqC5hM11S/Do0Vt+v6BGdUzuX7T0LUXE9xTjuoaIIMqs/ewGbpL0xt6VAL90O6xWeWRpSnX0O4xgnyGkZMHUqgye2/UTGzn3mc1PFqUFF1p085KV6QHQR5IoWb7zHjwWim6coaKmmwjyAMp1Mrsu/LasEobKmqyjyAPpFArs+/KazesLejWjWtUGMjLVK6ouXXjGvLxGceNVyBhosohq21av2pWRU2U6pl6dVkl5geCPJAg9fZXrQTnyj8Ck6Up9Ztpyn36d62BfI6gPs8R5IEEidpf9e/vfXy6XLK6e+SUu/K5fl1zSUH37CvOeG8+169tV62eu8EjkcjJAwkSdUP1ROnUdLlk7Xx9sjSlPYfHybcjFDN5IEGWDuRb2ki74rmJSfLtCMVMHkiQdssZqXVHFII8kCAb1hY0kM+19B5q3VEPQR5ImG1XrW7YHtiC3+Te0Qg5eSBhKgF7266DmpicvbH24kU53fyh1QR2NIWZPJBAG9YWdObC8DnYojMWEODRNII8kFB0jUQ39DzIm9mVZjZmZkfMbHOvvw9IsuHRotZtf0QrNj+gddsfmW4DHIaukeiGngZ5M+uX9G+S3ifpIkkfM7OLevmdQFJV94B3nW5ZEBXo6RqJbuj1TP6dko64+6/c/TVJd0q6usffCSRSVMuCSr/3WnSNRDf0urqmIOlo1fNjkt5V/QIzu1HSjZK0bNmyHg8HiE87OXZWsaJTvZ7JW8ixGa033H2Huw+6++CSJUt6PBwgPuTYEYdeB/ljki6oen6+pOd6/J1AIpFjRxx6na55TNJKM1shqSjpekkf7/F3AolUSbs02hAE6KaeBnl3P2lmn5W0W1K/pG+7+8FefieQZOTYMdd63tbA3X8o6Ye9/h4AwGyseAWADCPIA0CGEeQBIMMI8gCQYQR5AMgwgjwAZBhBHgAyjCAPABlGkAeADGMjb6DK8GiR3jLIFII8EKjs3FTZ2KOyc5MkAj1Si3QNEGh15yYgDQjyQKDYxs5NQNIR5AGVUzVh25hJ7NyEdCPIAyqnajzkuEns3IRUI8gDik7JuLjpinQjyAOKTskUSNUg5QjygNhkG9lFnTwgNtlGdhHkgQCbbCOLSNcAQIYxk0fsmu0XQ18ZoHUEecSq2X4x9JUB2kO6BrFqtl8MfWWA9hDkEauoRUi1x5t9HYCZCPKIVdQipNrjb8jnWno/gDKCPGLVzCKk4dGiXnnt5Kz35vqMxUpAA9x4RayaWYQ0tHtMpanZ7cPOet0CbroCDRDkEbtGi5Ci8u4TJ0q9GhKQGaRrkHjN5u0BzEaQR+LRPAxoH+kaJB7Nw4D2EeTRM91sQ0DzMKA95h626Vk8BgcHfWRkJO5hoA21AX35G/P62dMvzthSL9dvOvOMBXp5ssRsHOgiM9vn7oNh55jJo2NhfWWKIRUxpSnXxGRp+jX0ngF6jyCPtlVm72EBvRmV3jMEeaB3CPJoS+3svV30ngF6q6MSSjP7iJkdNLNTZjZYc26LmR0xszEzW9/ZMJE0YV0h20GtO9BbndbJPylpo6SfVB80s4skXS9ptaQrJf27mfXPfjvSqp0ZeJ/NfE6tO9B7HQV5dz/k7mENva+WdKe7v+ruv5Z0RNI7O/kuJMvAovCukFEWL8rptuversJAXiapMJDXrRvXkI8HeqxXOfmCpL1Vz48Fx2Yxsxsl3ShJy5Yt69Fw0C1fGn5Cdzx6VFMtlt5OnChR6w7EoGGQN7OHJL055NRWd78v6m0hx0KjgrvvkLRDKtfJNxoP4vOl4Sf0nb3PtvVecu9APBoGeXd/dxufe0zSBVXPz5f0XBufgxhErVS949GjbX0euXcgPr1K1+yS9F0zu03SUkkrJf28R9+FFjRqNVBvw+xGKZpcn0mmGb3fTdI1l5CmAeLSUZA3sw9L+hdJSyQ9YGb73X29ux80s7sl/VLSSUmfcffO6+3QkXoBvLoJWNiG2Tfdtb/h50+569Spmcdc0p7D450PHkBbOq2u+YG7n+/uC939XHdfX3XuFnd/q7uvcvcfdT5UdCoqgA/tPl0g1cnipFMRE30WPAHxoZ/8PBIVbKuP9+IGKTddgfgQ5OeRZnZYCtugo5ZJemb7B5r6Tm66AvEiyM8jUQH8xVde1dp/+LFWbH5AQ7vHdM0lBS2us9hp6UBew6PF0DpZSeo3Y8ETkBA0KJsHhkeL2rbr4HSbX9PMRQuTpVOaLJXvmBYnJnXXY0cjVjWcnpkP7R4LfYlJ+ufrLiawAwnBTD7jhkeL2vS9A9MBXoqM39NKU65SyF3UfrPpmXlUft9Ff3ggSQjyGTe0eyw0YLfjlPt0AI/K7xe4yQokCkE+A4ZHi1q3/RGt2PyA1m1/RMOjxelz7W7oEabRDVpusgLJQ04+5cIWOH3+rv266a79Gsi31imyntoAXr14qhsbdQPoDYJ8ig2PFvWFuw/MajdQeVadh2/V4kU5LTpjQd0ATldJIPkI8ilVmcG32vK34pOXLtNdjx2d0WemIp/r180fWk0ABzKAnHxKdbL9XmEgr8G3nK2zFp7+N96qzlHbDmQHM/mUarcfTD7Xr8suXDJrE+7X5foJ7kAGMZNPkeoqmj6LWm8arTJL33N4vGGjMgDZQJBPiUoOvjgxKVfj3u61CgN5/XTz5XUXMtEtEsgegnxKbNt1sO0cfK7fZpQ/NtOoDEA2EORTYHi02HY55OJFOQ1dO7OXDAuZgPmDG68p0E6uvF4rYBYyAfMHQT4h6u292mquvJmVrixkAuYHgnwCfGn4Ce3c++z0StXK3qsjv3lRew6PN+waWeuV105qeLRIEAdATj5uw6PFGQG+YrI0pZ17n22rwVhpyimHBCCJmXzsojbfkBr3fa8nLMVTLyUEIJsI8jHrVW16bTlkWLfKLfc+IYlNPoAsI10Ts05r0/O5PuX6rebY7HLIsF43rHIFso8gH7OozbWb8cz2D+jQV9+noWsvVmEgX3fzbFa5AvMT6ZqYVdest3KTtb+qd00z5ZBLB/Khn88qVyDbmMnHqNJw7PN37W/5vR971wUtvZ5VrsD8xEx+DlSqWooTk+o305S7BvI5vfLayelNO4oTkzI1V1Gz7q1n62sb1rQ0Bla5AvMTQb7HaqtaKt0jw3rRNFsyufNv/qytsbDKFZh/SNf02Ffub717ZL1O8QVy6ABaQJDvoeHRol460Xr3SFe5/ww5dACdIsj30LZdB9t+78uTJd26cU3D0kgAqIecfBeEtQuQwvPuzVo6kCeHDqBjBPkODY8Wten7B2ZUyWz6/gGdtbD9/2lN0mUXLtG67Y9QCQOgIwT5Dn3l/oPTAb6iNOVt5eKlcoD/87eerXv2FekzA6Bj5OQ71E4w/+Sly6Zz7YsX5TSQz03n3b/x0bfrmf+dpM8MgK5gJh+DRguZolbA0mcGQKuYyXeoma32qjVT5x7VT4Y+MwBa1VGQN7MhMztsZo+b2Q/MbKDq3BYzO2JmY2a2vvOhJtO2q1Yr11dv+dJpzda502cGQLd0mq55UNIWdz9pZl+XtEXSF83sIknXS1otaamkh8zsj929taWfMagth7zswiXac3g8ssqltidMvdYEzda502cGQLeYeyebzFV9kNmHJV3r7p8wsy2S5O63Bud2S9rm7v9d7zMGBwd9ZGSkK+NpR22fmTD5XH/dYL1u+yOhLX0LA3n9dPPlXRsrAFSY2T53Hww7182c/Kck/Sh4XJB0tOrcseBY2OBuNLMRMxsZHx/v4nBaF7Z7Uq1GVS6kWgAkScN0jZk9JOnNIae2uvt9wWu2SjopaWflbSGvD/1PBnffIWmHVJ7JNzHmrqtuBdyMelUupFoAJEnDIO/u76533sxukPRBSVf46dzPMUnVu1qcL+m5dgfZS82kaGo1qnKhHQGApOi0uuZKSV+UdJW7n6g6tUvS9Wa20MxWSFop6eedfFevNJOiqUbqBUCadFpd86+SFkp60Mp7ju51979194NmdrekX6qcxvlMUitr6qVeCk1U19QKa1bGrB5AXDoK8u7+R3XO3SLplk4+fy5EbXDdTjVMbeqHnjMA4jbvV7x2sxomLPVDzxkAcZr3vWu6WQ0Tlfqh5wyAuMz7IC91rxomKvVDzxkAcZn36ZpuYiEUgKRhJt9FLIQCkDQE+S5jIRSAJCFdAwAZRpAHgAwjyANAhmUiJ08rAQAIl/ogTysBAIiW+nQNrQQAIFrqgzytBAAgWuqDfFTLAFoJAEAGgjytBAAgWupvvNJKAACipT7IS7QSAIAoqU/XAACiEeQBIMMI8gCQYQR5AMgwgjwAZJi5e9xjmGZm45J+E/MwzpH025jH0C1cS/Jk5TokriVJ3uLuS8JOJCrIJ4GZjbj7YNzj6AauJXmych0S15IWpGsAIMMI8gCQYQT52XbEPYAu4lqSJyvXIXEtqUBOHgAyjJk8AGQYQR4AMowgHzCzr5rZ42a238x+bGZLq85tMbMjZjZmZuvjHGcjZjZkZoeDa/mBmQ1UnUvNdUiSmX3EzA6a2SkzG6w5l6prkSQzuzIY7xEz2xz3eFphZt82sxfM7MmqY2eb2YNm9lTwe3GcY2yWmV1gZnvM7FDw9+tzwfFUXk9D7s5P+b7EH1Q9/jtJ3wweXyTpgKSFklZIelpSf9zjrXMd75W0IHj8dUlfT+N1BGN+m6RVkv5T0mDV8TReS38wzj+UdEYw/oviHlcL4/9LSe+Q9GTVsX+StDl4vLnydy3pP5LOk/SO4PHrJf1P8HcqldfT6IeZfMDdf1f19ExJlTvSV0u6091fdfdfSzoi6Z1zPb5mufuP3f1k8HSvpPODx6m6Dkly90PuHrYje+quReXxHXH3X7n7a5LuVPk6UsHdfyLpxZrDV0u6PXh8u6QNczqoNrn7cXf/RfD495IOSSoopdfTCEG+ipndYmZHJX1C0peDwwVJR6tediw4lgafkvSj4HGar6NWGq8ljWNu5Fx3Py6VA6ekN8U8npaZ2XJJayU9qgxcT5hM7AzVLDN7SNKbQ05tdff73H2rpK1mtkXSZyXdLMlCXh9r3Wmj6whes1XSSUk7K28LeX3s9bPNXEvY20KOxX4tDaRxzJlmZmdJukfSTe7+O7OwP6L0m1dB3t3f3eRLvyvpAZWD/DFJF1SdO1/Sc10eWksaXYeZ3SDpg5Ku8CDBqAReh9TSn0m1RF5LA2kccyPPm9l57n7czM6T9ELcA2qWmeVUDvA73f3e4HBqr6ce0jUBM1tZ9fQqSYeDx7skXW9mC81shaSVkn4+1+NrlpldKemLkq5y9xNVp1J1HQ2k8Voek7TSzFaY2RmSrlf5OtJsl6Qbgsc3SIr6L69EsfKU/VuSDrn7bVWnUnk9DcV95zcpPyr/q/6kpMcl3S+pUHVuq8qVEWOS3hf3WBtcxxGVc7/7g59vpvE6gvF+WOUZ8KuSnpe0O63XEoz5/SpXcjytcjoq9jG1MPY7JB2XVAr+TD4t6Y2SHpb0VPD77LjH2eS1/IXKqbLHq/5/8v60Xk+jH9oaAECGka4BgAwjyANAhhHkASDDCPIAkGEEeQDIMII8AGQYQR4AMuz/AbwKdQ3B5hGWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model(to_torch(temp_x_train))\n",
    "train_activation = activation[\"conv3.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "pred_test = model(to_torch(temp_x_test))\n",
    "test_activation = activation[\"conv3.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "plt.scatter(np.mean(train_activation, 0), np.mean(test_activation, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066968\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080482\n",
      "Validation loss decreased (inf --> 0.080482).  Saving model ...\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.066833\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061462\n",
      "Validation loss decreased (0.080482 --> 0.061462).  Saving model ...\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.066698\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.060971\n",
      "Validation loss decreased (0.061462 --> 0.060971).  Saving model ...\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.066563\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.060867\n",
      "Validation loss decreased (0.060971 --> 0.060867).  Saving model ...\n",
      "done\n",
      "epoch: 4, \n",
      " TRAINING -> mean_err: 0.066427\n",
      "epoch: 4, \n",
      " VAL -> mean_err: 0.060767\n",
      "Validation loss decreased (0.060867 --> 0.060767).  Saving model ...\n",
      "done\n",
      "epoch: 5, \n",
      " TRAINING -> mean_err: 0.066295\n",
      "epoch: 5, \n",
      " VAL -> mean_err: 0.060689\n",
      "Validation loss decreased (0.060767 --> 0.060689).  Saving model ...\n",
      "done\n",
      "epoch: 6, \n",
      " TRAINING -> mean_err: 0.066161\n",
      "epoch: 6, \n",
      " VAL -> mean_err: 0.060611\n",
      "Validation loss decreased (0.060689 --> 0.060611).  Saving model ...\n",
      "done\n",
      "epoch: 7, \n",
      " TRAINING -> mean_err: 0.066036\n",
      "epoch: 7, \n",
      " VAL -> mean_err: 0.060508\n",
      "Validation loss decreased (0.060611 --> 0.060508).  Saving model ...\n",
      "done\n",
      "epoch: 8, \n",
      " TRAINING -> mean_err: 0.065911\n",
      "epoch: 8, \n",
      " VAL -> mean_err: 0.060426\n",
      "Validation loss decreased (0.060508 --> 0.060426).  Saving model ...\n",
      "done\n",
      "epoch: 9, \n",
      " TRAINING -> mean_err: 0.065787\n",
      "epoch: 9, \n",
      " VAL -> mean_err: 0.060323\n",
      "Validation loss decreased (0.060426 --> 0.060323).  Saving model ...\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, early_stopping, learning_rate, 1, add_weight_decay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.078716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07871595025062561"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test(model, test_loader, output_directory, save_model_file_, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19df1043108>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model(to_torch(temp_x_train))\n",
    "train_activation = activation[\"conv1.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "pred_test = model(to_torch(temp_x_test))\n",
    "test_activation = activation[\"conv1.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "plt.scatter(np.mean(train_activation, 0), np.mean(test_activation, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19df2ea9908>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model(to_torch(temp_x_train))\n",
    "train_activation = activation[\"conv2.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "pred_test = model(to_torch(temp_x_test))\n",
    "test_activation = activation[\"conv2.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "plt.scatter(np.mean(train_activation, 0), np.mean(test_activation, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19dfef94ec8>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_train = model(to_torch(temp_x_train))\n",
    "train_activation = activation[\"conv3.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "pred_test = model(to_torch(temp_x_test))\n",
    "test_activation = activation[\"conv3.batch_norm\"].reshape(n_samples,-1).cpu().numpy()\n",
    "\n",
    "plt.scatter(np.mean(train_activation, 0), np.mean(test_activation, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-1ceb7c895935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_embedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_embedded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    889\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \"\"\"\n\u001b[1;32m--> 891\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    801\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m     def _tsne(self, P, degrees_of_freedom, n_samples, X_embedded,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[1;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_iter_without_progress'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[1;32m--> 857\u001b[1;33m                                                           **opt_args)\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;31m# Save the final number of iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[1;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compute_error'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[1;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[0mX_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[0mval_P\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "x = np.concatenate([train_tensor.cpu().numpy(), test_tensor.cpu().numpy()])\n",
    "x_embedded = TSNE(n_components=2).fit_transform(x)\n",
    "plt.scatter(train_embedded[:,0], x_embedded[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05310412021163775"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04361950606107712"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(initial_test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.858769416809082,\n",
       " 0.6871629953384399,\n",
       " 0.6871629953384399,\n",
       " 0.5269408822059631,\n",
       " 0.4071384072303772,\n",
       " 0.4653656482696533,\n",
       " 0.6015992760658264,\n",
       " 0.6015992760658264,\n",
       " 0.40011513233184814,\n",
       " 14.171381950378418,\n",
       " 12.543201446533203,\n",
       " 0.6434835195541382,\n",
       " 28.845848083496094,\n",
       " 18.203317642211914,\n",
       " 43.29744338989258,\n",
       " 5.762270450592041,\n",
       " 1.3677839040756226,\n",
       " 0.9711898565292358,\n",
       " 1.399558186531067,\n",
       " 61.61814880371094,\n",
       " 37.43205261230469,\n",
       " 2.856884717941284,\n",
       " 2.1980061531066895,\n",
       " 10.318024635314941,\n",
       " 2.481008768081665,\n",
       " 1.8975188732147217,\n",
       " 51.82759094238281,\n",
       " 1.126019835472107,\n",
       " 11.637490272521973,\n",
       " 7.908130168914795,\n",
       " 1.3847213983535767,\n",
       " 11.427200317382812,\n",
       " 1.1226650476455688,\n",
       " 0.9623705148696899,\n",
       " 1.125654697418213,\n",
       " 8.254537582397461,\n",
       " 63.58479309082031,\n",
       " 0.7109610438346863,\n",
       " 1.3608527183532715,\n",
       " 1.5712834596633911,\n",
       " 0.4483189582824707,\n",
       " 0.45068833231925964,\n",
       " 20.549781799316406,\n",
       " 0.42190927267074585,\n",
       " 0.42126578092575073,\n",
       " 21.160276412963867,\n",
       " 0.4225389361381531,\n",
       " 0.4379439055919647,\n",
       " 11.329731941223145,\n",
       " 0.5392850637435913,\n",
       " 0.8964909315109253,\n",
       " 0.6558243036270142,\n",
       " 39.81766891479492,\n",
       " 5.274534225463867,\n",
       " 74.89175415039062,\n",
       " 17.676210403442383,\n",
       " 39.978389739990234,\n",
       " 1.5728950500488281,\n",
       " 34.02902603149414,\n",
       " 1.417568564414978,\n",
       " 17.259742736816406,\n",
       " 2.79380464553833,\n",
       " 10.120524406433105,\n",
       " 2.0291943550109863,\n",
       " 18.97245979309082,\n",
       " 2.5562798976898193,\n",
       " 2.5562798976898193,\n",
       " 35.53513717651367,\n",
       " 8.378735542297363,\n",
       " 15.761114120483398,\n",
       " 13.842616081237793,\n",
       " 1.269018530845642,\n",
       " 52.010433197021484,\n",
       " 0.7714123129844666,\n",
       " 0.8960443139076233,\n",
       " 0.627953052520752,\n",
       " 8.122356414794922,\n",
       " 0.8847754597663879,\n",
       " 184.77806091308594,\n",
       " 1.338106393814087,\n",
       " 0.5377759337425232,\n",
       " 12.742331504821777,\n",
       " 0.41911542415618896,\n",
       " 0.3706416189670563,\n",
       " 0.43863359093666077,\n",
       " 3.325584888458252,\n",
       " 0.403889536857605,\n",
       " 0.7426595687866211,\n",
       " 0.7648844122886658,\n",
       " 13.21705150604248,\n",
       " 1.1904481649398804,\n",
       " 40.31416320800781,\n",
       " 31.473114013671875,\n",
       " 25.333866119384766,\n",
       " 107.28396606445312,\n",
       " 62.600040435791016,\n",
       " 13.15068531036377,\n",
       " 44.54566192626953]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mean_list = [float(value.cpu().numpy()) for value in test_mean_list]\n",
    "test_mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean_list = [float(value) for value in test_mean_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1fc107614c8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_mean_list, np.array(test_loss_list)*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.40497154],\n",
       "       [0.40497154, 1.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef( np.array(test_loss_list), np.array(test_mean_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function correlate in module numpy:\n",
      "\n",
      "correlate(a, v, mode='valid')\n",
      "    Cross-correlation of two 1-dimensional sequences.\n",
      "    \n",
      "    This function computes the correlation as generally defined in signal\n",
      "    processing texts::\n",
      "    \n",
      "        c_{av}[k] = sum_n a[n+k] * conj(v[n])\n",
      "    \n",
      "    with a and v sequences being zero-padded where necessary and conj being\n",
      "    the conjugate.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a, v : array_like\n",
      "        Input sequences.\n",
      "    mode : {'valid', 'same', 'full'}, optional\n",
      "        Refer to the `convolve` docstring.  Note that the default\n",
      "        is 'valid', unlike `convolve`, which uses 'full'.\n",
      "    old_behavior : bool\n",
      "        `old_behavior` was removed in NumPy 1.10. If you need the old\n",
      "        behavior, use `multiarray.correlate`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Discrete cross-correlation of `a` and `v`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    convolve : Discrete, linear convolution of two one-dimensional sequences.\n",
      "    multiarray.correlate : Old, no conjugate, version of correlate.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The definition of correlation above is not unique and sometimes correlation\n",
      "    may be defined differently. Another common definition is::\n",
      "    \n",
      "        c'_{av}[k] = sum_n a[n] conj(v[n+k])\n",
      "    \n",
      "    which is related to ``c_{av}[k]`` by ``c'_{av}[k] = c_{av}[-k]``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5])\n",
      "    array([3.5])\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5], \"same\")\n",
      "    array([2. ,  3.5,  3. ])\n",
      "    >>> np.correlate([1, 2, 3], [0, 1, 0.5], \"full\")\n",
      "    array([0.5,  2. ,  3.5,  3. ,  0. ])\n",
      "    \n",
      "    Using complex sequences:\n",
      "    \n",
      "    >>> np.correlate([1+1j, 2, 3-1j], [0, 1, 0.5j], 'full')\n",
      "    array([ 0.5-0.5j,  1.0+0.j ,  1.5-1.5j,  3.0-1.j ,  0.0+0.j ])\n",
      "    \n",
      "    Note that you get the time reversed, complex conjugated result\n",
      "    when the two input sequences change places, i.e.,\n",
      "    ``c_{va}[k] = c^{*}_{av}[-k]``:\n",
      "    \n",
      "    >>> np.correlate([0, 1, 0.5j], [1+1j, 2, 3-1j], 'full')\n",
      "    array([ 0.0+0.j ,  3.0+1.j ,  1.5+1.5j,  1.0+0.j ,  0.5+0.5j])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.correlate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.85876942e+00, 4.87865694e-02],\n",
       "       [6.87162995e-01, 3.57445292e-02],\n",
       "       [6.87162995e-01, 2.46355738e-02],\n",
       "       [5.26940882e-01, 2.29217317e-02],\n",
       "       [4.07138407e-01, 2.35769991e-02],\n",
       "       [4.65365648e-01, 2.37965062e-02],\n",
       "       [6.01599276e-01, 2.51887832e-02],\n",
       "       [6.01599276e-01, 2.81453393e-02],\n",
       "       [4.00115132e-01, 2.74146665e-02],\n",
       "       [1.41713820e+01, 1.04562968e-01],\n",
       "       [1.25432014e+01, 4.03604060e-02],\n",
       "       [6.43483520e-01, 2.28510294e-02],\n",
       "       [2.88458481e+01, 4.77253273e-02],\n",
       "       [1.82033176e+01, 8.96150172e-02],\n",
       "       [4.32974434e+01, 6.45654052e-02],\n",
       "       [5.76227045e+00, 1.08684771e-01],\n",
       "       [1.36778390e+00, 6.57050684e-02],\n",
       "       [9.71189857e-01, 4.41123396e-02],\n",
       "       [1.39955819e+00, 4.23325486e-02],\n",
       "       [6.16181488e+01, 1.06336646e-01],\n",
       "       [3.74320526e+01, 9.89117250e-02],\n",
       "       [2.85688472e+00, 8.24431777e-02],\n",
       "       [2.19800615e+00, 8.31728801e-02],\n",
       "       [1.03180246e+01, 1.02133252e-01],\n",
       "       [2.48100877e+00, 5.16967587e-02],\n",
       "       [1.89751887e+00, 4.51910198e-02],\n",
       "       [5.18275909e+01, 9.85614806e-02],\n",
       "       [1.12601984e+00, 4.11729589e-02],\n",
       "       [1.16374903e+01, 6.16815537e-02],\n",
       "       [7.90813017e+00, 6.98579401e-02],\n",
       "       [1.38472140e+00, 4.88336757e-02],\n",
       "       [1.14272003e+01, 5.59129789e-02],\n",
       "       [1.12266505e+00, 3.77086401e-02],\n",
       "       [9.62370515e-01, 3.84587087e-02],\n",
       "       [1.12565470e+00, 3.02810166e-02],\n",
       "       [8.25453758e+00, 6.32463098e-02],\n",
       "       [6.35847931e+01, 4.27840836e-02],\n",
       "       [7.10961044e-01, 3.06710042e-02],\n",
       "       [1.36085272e+00, 2.95682549e-02],\n",
       "       [1.57128346e+00, 2.57664118e-02],\n",
       "       [4.48318958e-01, 2.65327916e-02],\n",
       "       [4.50688332e-01, 2.68483404e-02],\n",
       "       [2.05497818e+01, 4.76233587e-02],\n",
       "       [4.21909273e-01, 2.66510546e-02],\n",
       "       [4.21265781e-01, 3.49291041e-02],\n",
       "       [2.11602764e+01, 4.81699891e-02],\n",
       "       [4.22538936e-01, 2.81493776e-02],\n",
       "       [4.37943906e-01, 2.78456099e-02],\n",
       "       [1.13297319e+01, 5.58276549e-02],\n",
       "       [5.39285064e-01, 3.09362244e-02],\n",
       "       [8.96490932e-01, 2.76806671e-02],\n",
       "       [6.55824304e-01, 2.90770363e-02],\n",
       "       [3.98176689e+01, 6.23183362e-02],\n",
       "       [5.27453423e+00, 6.92280605e-02],\n",
       "       [7.48917542e+01, 8.51740539e-02],\n",
       "       [1.76762104e+01, 9.49405432e-02],\n",
       "       [3.99783897e+01, 2.25818679e-01],\n",
       "       [1.57289505e+00, 6.95555508e-02],\n",
       "       [3.40290260e+01, 1.84962109e-01],\n",
       "       [1.41756856e+00, 4.92243953e-02],\n",
       "       [1.72597427e+01, 6.74419552e-02],\n",
       "       [2.79380465e+00, 8.45450759e-02],\n",
       "       [1.01205244e+01, 1.08403005e-01],\n",
       "       [2.02919436e+00, 7.71535933e-02],\n",
       "       [1.89724598e+01, 7.80223012e-02],\n",
       "       [2.55627990e+00, 7.01554865e-02],\n",
       "       [2.55627990e+00, 6.60133883e-02],\n",
       "       [3.55351372e+01, 1.15334958e-01],\n",
       "       [8.37873554e+00, 8.53343904e-02],\n",
       "       [1.57611141e+01, 5.86825125e-02],\n",
       "       [1.38426161e+01, 6.28607124e-02],\n",
       "       [1.26901853e+00, 4.05816436e-02],\n",
       "       [5.20104332e+01, 8.70951787e-02],\n",
       "       [7.71412313e-01, 2.82868110e-02],\n",
       "       [8.96044314e-01, 2.60295905e-02],\n",
       "       [6.27953053e-01, 2.43233815e-02],\n",
       "       [8.12235641e+00, 3.37469019e-02],\n",
       "       [8.84775460e-01, 2.85426825e-02],\n",
       "       [1.84778061e+02, 3.83528806e-02],\n",
       "       [1.33810639e+00, 2.20916476e-02],\n",
       "       [5.37775934e-01, 2.22028885e-02],\n",
       "       [1.27423315e+01, 3.22413146e-02],\n",
       "       [4.19115424e-01, 2.32131518e-02],\n",
       "       [3.70641619e-01, 2.51162667e-02],\n",
       "       [4.38633591e-01, 2.73005087e-02],\n",
       "       [3.32558489e+00, 3.87642756e-02],\n",
       "       [4.03889537e-01, 2.97329184e-02],\n",
       "       [7.42659569e-01, 2.25534067e-02],\n",
       "       [7.64884412e-01, 2.21541412e-02],\n",
       "       [1.32170515e+01, 4.55877297e-02],\n",
       "       [1.19044816e+00, 3.70251946e-02],\n",
       "       [4.03141632e+01, 6.04857765e-02],\n",
       "       [3.14731140e+01, 1.02078676e-01],\n",
       "       [2.53338661e+01, 1.41093388e-01],\n",
       "       [1.07283966e+02, 1.26739874e-01],\n",
       "       [6.26000404e+01, 8.48273560e-02],\n",
       "       [1.31506853e+01, 8.54778588e-02],\n",
       "       [4.45456619e+01, 1.55176833e-01]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.array([np.array(test_mean_list), np.array(test_loss_list)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_list = [float(value.cpu().numpy()) for value in train_mean_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69476694],\n",
       "       [ 4.08794785],\n",
       "       [ 3.46697855],\n",
       "       [ 3.67487478],\n",
       "       [ 1.53541088],\n",
       "       [ 0.74450016],\n",
       "       [ 0.87775272],\n",
       "       [ 7.28045797],\n",
       "       [ 0.896106  ],\n",
       "       [ 2.32488894],\n",
       "       [ 3.46690083],\n",
       "       [ 5.87622738],\n",
       "       [ 2.4660449 ],\n",
       "       [ 2.65226793],\n",
       "       [24.8105526 ],\n",
       "       [ 0.82698828],\n",
       "       [ 3.58082652],\n",
       "       [ 4.236485  ],\n",
       "       [ 1.5969944 ],\n",
       "       [ 3.23333931],\n",
       "       [ 1.32442319],\n",
       "       [ 1.4947139 ],\n",
       "       [ 7.37392473],\n",
       "       [ 0.6975252 ],\n",
       "       [ 2.1145699 ],\n",
       "       [ 1.6653769 ],\n",
       "       [ 7.32581568],\n",
       "       [ 1.71675408],\n",
       "       [ 5.62009859],\n",
       "       [ 1.50227487],\n",
       "       [ 0.84008986],\n",
       "       [ 1.09163427],\n",
       "       [ 2.44197893],\n",
       "       [ 6.41746712],\n",
       "       [ 1.34061682],\n",
       "       [ 1.31571043],\n",
       "       [14.97131348],\n",
       "       [ 1.30785549],\n",
       "       [ 2.11955261],\n",
       "       [11.42291451],\n",
       "       [ 8.081007  ],\n",
       "       [ 3.56057978],\n",
       "       [ 1.42133546],\n",
       "       [ 2.17818594],\n",
       "       [ 1.83935237],\n",
       "       [ 1.8370893 ],\n",
       "       [ 1.79055846],\n",
       "       [ 1.83970976],\n",
       "       [ 0.90549999],\n",
       "       [ 2.09543967],\n",
       "       [ 2.21131134],\n",
       "       [ 2.97991371],\n",
       "       [ 2.41656828],\n",
       "       [ 0.3957504 ],\n",
       "       [ 2.52650213],\n",
       "       [ 2.11262417],\n",
       "       [ 4.02447414],\n",
       "       [ 4.18360186],\n",
       "       [ 6.7538476 ],\n",
       "       [ 2.83841276],\n",
       "       [ 2.02835464],\n",
       "       [ 4.6545701 ],\n",
       "       [ 3.74867153],\n",
       "       [ 3.20534706],\n",
       "       [ 8.3735981 ],\n",
       "       [10.92158031],\n",
       "       [ 1.48001146],\n",
       "       [ 4.34817171],\n",
       "       [ 1.27673948],\n",
       "       [ 3.36756659],\n",
       "       [ 1.8452903 ],\n",
       "       [13.3936348 ],\n",
       "       [ 7.6064496 ],\n",
       "       [ 5.36400938],\n",
       "       [ 1.62515926],\n",
       "       [ 1.66179478],\n",
       "       [ 5.5591321 ],\n",
       "       [ 2.21647453],\n",
       "       [ 9.34587955],\n",
       "       [20.68800545],\n",
       "       [ 3.80155373],\n",
       "       [ 1.51259089],\n",
       "       [ 5.47138739],\n",
       "       [ 2.69815993],\n",
       "       [ 3.45136738],\n",
       "       [ 1.89756989],\n",
       "       [ 1.35648656],\n",
       "       [ 7.01419735],\n",
       "       [ 2.42811084],\n",
       "       [ 3.764045  ],\n",
       "       [ 6.83899355],\n",
       "       [13.45357037],\n",
       "       [ 7.61994123],\n",
       "       [ 2.75607395],\n",
       "       [ 2.50505018],\n",
       "       [ 4.35521841],\n",
       "       [ 4.99487686],\n",
       "       [ 8.1511488 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([train_mean_list]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "conv1.conv.weight\n",
      "False\n",
      "conv1.conv.bias\n",
      "False\n",
      "conv1.batch_norm.weight\n",
      "False\n",
      "conv1.batch_norm.bias\n",
      "False\n",
      "conv2.conv.weight\n",
      "False\n",
      "conv2.conv.bias\n",
      "False\n",
      "conv2.batch_norm.weight\n",
      "False\n",
      "conv2.batch_norm.bias\n",
      "False\n",
      "conv3.conv.weight\n",
      "False\n",
      "conv3.conv.bias\n",
      "False\n",
      "conv3.batch_norm.weight\n",
      "False\n",
      "conv3.batch_norm.bias\n",
      "True\n",
      "linear.weight\n",
      "True\n",
      "linear.bias\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(parameter.requires_grad)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 14 elements not 128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-90687a23b0bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorchtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_x_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m     )\n\u001b[0;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: running_mean should contain 14 elements not 128"
     ]
    }
   ],
   "source": [
    "from pytorchtools import to_torch\n",
    "model.conv3.batch_norm(to_torch(temp_x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max train:\" , torch.max(activation[\"conv3.batch_norm\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "model.conv3.register_backward_hook(get_activation('conv3'))\n",
    "y = model(Variable(to_torch(temp_x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-150ed9312049>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mactivation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conv3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'conv3'"
     ]
    }
   ],
   "source": [
    "activation[\"conv3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2374, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(Variable(to_torch(temp_x_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
