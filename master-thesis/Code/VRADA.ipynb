{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from data_loader import GetLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from model import CNNModel\n",
    "import numpy as np\n",
    "from test import test\n",
    "\n",
    "source_dataset_name = 'MNIST'\n",
    "target_dataset_name = 'mnist_m'\n",
    "source_image_root = os.path.join('dataset', source_dataset_name)\n",
    "target_image_root = os.path.join('dataset', target_dataset_name)\n",
    "model_root = 'models'\n",
    "cuda = True\n",
    "cudnn.benchmark = True\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "image_size = 28\n",
    "n_epoch = 100\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# load data\n",
    "\n",
    "img_transform_source = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "\n",
    "img_transform_target = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset_source = datasets.MNIST(\n",
    "    root='dataset',\n",
    "    train=True,\n",
    "    transform=img_transform_source,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "dataloader_source = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_source,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "train_list = os.path.join(target_image_root, 'mnist_m_train_labels.txt')\n",
    "\n",
    "dataset_target = GetLoader(\n",
    "    data_root=os.path.join(target_image_root, 'mnist_m_train'),\n",
    "    data_list=train_list,\n",
    "    transform=img_transform_target\n",
    ")\n",
    "\n",
    "dataloader_target = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_target,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "# load model\n",
    "\n",
    "my_net = CNNModel()\n",
    "\n",
    "# setup optimizer\n",
    "\n",
    "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "if cuda:\n",
    "    my_net = my_net.cuda()\n",
    "    loss_class = loss_class.cuda()\n",
    "    loss_domain = loss_domain.cuda()\n",
    "\n",
    "for p in my_net.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# training\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "    data_source_iter = iter(dataloader_source)\n",
    "    data_target_iter = iter(dataloader_target)\n",
    "\n",
    "    i = 0\n",
    "    while i < len_dataloader:\n",
    "\n",
    "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        # training model using source data\n",
    "        data_source = data_source_iter.next()\n",
    "        s_img, s_label = data_source\n",
    "\n",
    "        my_net.zero_grad()\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "        class_label = torch.LongTensor(batch_size)\n",
    "        domain_label = torch.zeros(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "\n",
    "        if cuda:\n",
    "            s_img = s_img.cuda()\n",
    "            s_label = s_label.cuda()\n",
    "            input_img = input_img.cuda()\n",
    "            class_label = class_label.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "        input_img.resize_as_(s_img).copy_(s_img)\n",
    "        class_label.resize_as_(s_label).copy_(s_label)\n",
    "\n",
    "        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
    "        err_s_label = loss_class(class_output, class_label)\n",
    "        err_s_domain = loss_domain(domain_output, domain_label)\n",
    "\n",
    "        # training model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, _ = data_target\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "\n",
    "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "        domain_label = torch.ones(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            input_img = input_img.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "        input_img.resize_as_(t_img).copy_(t_img)\n",
    "\n",
    "        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
    "        err_t_domain = loss_domain(domain_output, domain_label)\n",
    "        err = err_t_domain + err_s_domain + err_s_label\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()))\n",
    "\n",
    "    torch.save(my_net, '{0}/mnist_mnistm_model_epoch_{1}.pth'.format(model_root, epoch))\n",
    "    test(source_dataset_name, epoch)\n",
    "    test(target_dataset_name, epoch)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"DANN_py3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from data_loader import GetLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from model import CNNModel\n",
    "import numpy as np\n",
    "from test import test\n",
    "from pytorchtools import count_parameters\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dataset_name = \"POLLUTION\"\n",
    "task_size = 50\n",
    "window_size = 5\n",
    "\n",
    "train_data = pickle.load(  open( \"../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "validation_data = pickle.load( open( \"../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119483, 5, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VariationalRecurrentNeuralNetwork.model import VRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 14\n",
    "h_dim = 50\n",
    "z_dim = 16\n",
    "n_layers =  1\n",
    "n_epochs = 100\n",
    "clip = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "seed = 128\n",
    "print_every = 100\n",
    "save_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 14])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.tensor(train_data.x[0:5]).float()\n",
    "\n",
    "sample = sample.squeeze().transpose(0, 1)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49092"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VRNN(x_dim, h_dim, z_dim, n_layers, device)\n",
    "model.cuda()\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld_loss, nll_loss, (all_enc_mean, all_enc_std), (all_dec_mean, all_dec_std), x1, h = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRADA(nn.Module):\n",
    "    \n",
    "    def __init__(self, x_dim, h_dim, z_dim, out_dim, n_layers, device, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.vrnn = VRNN(x_dim, h_dim, z_dim, n_layers, device)\n",
    "        self.linear = nn.Linear (h_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        x = x.squeeze().transpose(0, 1)\n",
    "        kld_loss, nll_loss, (all_enc_mean, all_enc_std), (all_dec_mean, all_dec_std), x1, h = self.vrnn(x)\n",
    "        out = self.linear(h.squeeze())\n",
    "        \n",
    "        return out, kld_loss, nll_loss\n",
    "        \n",
    "    def cuda(self):\n",
    "        \n",
    "        self.vrnn.cuda()\n",
    "        \n",
    "        super().cuda()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim = 1\n",
    "model = VRADA(x_dim, h_dim, z_dim, out_dim, n_layers, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VRADA(\n",
       "  (vrnn): VRNN(\n",
       "    (phi_x): Sequential(\n",
       "      (0): Linear(in_features=14, out_features=50, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (phi_z): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=50, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (enc): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (enc_mean): Linear(in_features=50, out_features=16, bias=True)\n",
       "    (enc_std): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=16, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (prior): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (prior_mean): Linear(in_features=50, out_features=16, bias=True)\n",
       "    (prior_std): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=16, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (dec): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (dec_std): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=14, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (dec_mean): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=14, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (rnn): GRU(100, 50, bias=False)\n",
       "  )\n",
       "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from metrics import torch_mae as mae\n",
    "\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "train_loader = DataLoader(train_data, **params)\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "val_loader = DataLoader(validation_data, **params)\n",
    "val_iter = iter(val_loader)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step (model, data_loader, loss_function, train =False, optimizer=None):\n",
    "\n",
    "    data_iter = iter(data_loader)\n",
    "    total_loss = 0.0\n",
    "    for x, y in data_iter:\n",
    "\n",
    "        model.zero_grad()\n",
    "        x, y = torch.tensor(x).float().to(device), torch.tensor(y).float().to(device)\n",
    "        y_pred, kld_loss, nll_loss = model(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "\n",
    "        loss += 0.00001*kld_loss+ 0.00001*nll_loss\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        current_loss = loss.cpu().data.numpy()*x.shape[0]\n",
    "        total_loss += current_loss\n",
    "        \n",
    "    return total_loss/len(data_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 26.500867009099085\n",
      "Val: 25.11963867925995\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    \n",
    "    train_loss = step(model, train_loader, mae, train = True, optimizer = optimizer)\n",
    "    val_loss = step(model, val_loader, mae)\n",
    "    \n",
    "    print(\"Train:\", train_loss)\n",
    "    print(\"Val:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "val_loss = step(model, val_loader, mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: nan\n",
      "Val: nan\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train_loss)\n",
    "print(\"Val:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6704e+00, -1.6808e+00, -1.6615e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -3.6489e-01,  8.3746e-01, -2.6723e+00,  1.3031e+00, -3.4612e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.5170e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -3.0141e-01,  7.3925e-01, -2.7678e+00,  1.3031e+00, -2.5573e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.3726e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -3.6489e-01,  6.4105e-01, -2.6723e+00,  1.3031e+00, -2.0404e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.2281e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -1.7447e-01,  6.4105e-01, -2.9588e+00,  1.3031e+00, -1.1364e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.0836e+00,  1.3676e+00, -4.9214e-01,\n",
       "          -2.3794e-01,  5.4284e-01, -2.7678e+00,  1.3031e+00, -2.3253e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01]],\n",
       "\n",
       "        [[-1.6704e+00, -1.6808e+00, -1.5170e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -3.0141e-01,  7.3925e-01, -2.7678e+00,  1.3031e+00, -2.5573e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.3726e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -3.6489e-01,  6.4105e-01, -2.6723e+00,  1.3031e+00, -2.0404e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.2281e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -1.7447e-01,  6.4105e-01, -2.9588e+00,  1.3031e+00, -1.1364e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.0836e+00,  1.3676e+00, -4.9214e-01,\n",
       "          -2.3794e-01,  5.4284e-01, -2.7678e+00,  1.3031e+00, -2.3253e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -9.3912e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.0141e-01,  4.4463e-01, -2.5767e+00,  1.3031e+00,  6.7138e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01]],\n",
       "\n",
       "        [[-1.6704e+00, -1.6808e+00, -1.3726e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -3.6489e-01,  6.4105e-01, -2.6723e+00,  1.3031e+00, -2.0404e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.2281e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -1.7447e-01,  6.4105e-01, -2.9588e+00,  1.3031e+00, -1.1364e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.0836e+00,  1.3676e+00, -4.9214e-01,\n",
       "          -2.3794e-01,  5.4284e-01, -2.7678e+00,  1.3031e+00, -2.3253e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -9.3912e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.0141e-01,  4.4463e-01, -2.5767e+00,  1.3031e+00,  6.7138e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -7.9464e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.4902e-01,  4.4463e-01, -2.4812e+00,  1.3031e+00,  1.5753e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01]],\n",
       "\n",
       "        [[-1.6704e+00, -1.6808e+00, -1.2281e+00,  1.3676e+00, -5.0900e-01,\n",
       "          -1.7447e-01,  6.4105e-01, -2.9588e+00,  1.3031e+00, -1.1364e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -1.0836e+00,  1.3676e+00, -4.9214e-01,\n",
       "          -2.3794e-01,  5.4284e-01, -2.7678e+00,  1.3031e+00, -2.3253e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -9.3912e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.0141e-01,  4.4463e-01, -2.5767e+00,  1.3031e+00,  6.7138e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -7.9464e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.4902e-01,  4.4463e-01, -2.4812e+00,  1.3031e+00,  1.5753e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -6.5016e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.4902e-01,  4.4463e-01, -2.4812e+00,  1.3031e+00,  2.0922e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01]],\n",
       "\n",
       "        [[-1.6704e+00, -1.6808e+00, -1.0836e+00,  1.3676e+00, -4.9214e-01,\n",
       "          -2.3794e-01,  5.4284e-01, -2.7678e+00,  1.3031e+00, -2.3253e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -9.3912e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.0141e-01,  4.4463e-01, -2.5767e+00,  1.3031e+00,  6.7138e-02,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -7.9464e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.4902e-01,  4.4463e-01, -2.4812e+00,  1.3031e+00,  1.5753e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -6.5016e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.4902e-01,  4.4463e-01, -2.4812e+00,  1.3031e+00,  2.0922e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01],\n",
       "         [-1.6704e+00, -1.6808e+00, -5.0568e-01,  1.3676e+00, -4.7528e-01,\n",
       "          -3.4902e-01,  4.4463e-01, -2.4812e+00,  1.3031e+00,  2.9962e-01,\n",
       "          -2.9373e-03, -3.1029e-03, -6.4236e-02, -5.3738e-01]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VRADA(x_dim, h_dim, z_dim, out_dim, n_layers, device)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "y_pred, kld_loss, nll_loss = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mae(y_pred, torch.tensor(train_data.y[:5]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(503.8247, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss +=  kld_loss + nll_loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
