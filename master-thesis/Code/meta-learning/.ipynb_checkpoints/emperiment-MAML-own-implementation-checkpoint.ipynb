{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "from ts_dataset import TSDataset\n",
    "from base_models import LSTMModel\n",
    "from metrics import torch_mae as mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from maml.models.model import Model\n",
    "\n",
    "\n",
    "def weight_init(module):\n",
    "    if (isinstance(module, torch.nn.Linear)\n",
    "        or isinstance(module, torch.nn.Conv2d)):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "\n",
    "class ConvModel(Model):\n",
    "    \"\"\"\n",
    "    NOTE: difference to tf implementation: batch norm scaling is enabled here\n",
    "    TODO: enable 'non-transductive' setting as per\n",
    "          https://arxiv.org/abs/1803.02999\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, output_size, num_channels=64,\n",
    "                 kernel_size=3, padding=1, nonlinearity=F.relu,\n",
    "                 use_max_pool=False, img_side_len=28, verbose=False):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self._input_channels = input_channels\n",
    "        self._output_size = output_size\n",
    "        self._num_channels = num_channels\n",
    "        self._kernel_size = kernel_size\n",
    "        self._nonlinearity = nonlinearity\n",
    "        self._use_max_pool = use_max_pool\n",
    "        self._padding = padding\n",
    "        self._bn_affine = False\n",
    "        self._reuse = False\n",
    "        self._verbose = verbose\n",
    "\n",
    "        if self._use_max_pool:\n",
    "            self._conv_stride = 1\n",
    "            self._features_size = 1\n",
    "            self.features = torch.nn.Sequential(OrderedDict([\n",
    "                ('layer1_conv', torch.nn.Conv2d(self._input_channels,\n",
    "                                                self._num_channels,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer1_bn', torch.nn.BatchNorm2d(self._num_channels,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer1_max_pool', torch.nn.MaxPool2d(kernel_size=2,\n",
    "                                                       stride=2)),\n",
    "                ('layer1_relu', torch.nn.ReLU(inplace=True)),\n",
    "                ('layer2_conv', torch.nn.Conv2d(self._num_channels,\n",
    "                                                self._num_channels*2,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer2_bn', torch.nn.BatchNorm2d(self._num_channels*2,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer2_max_pool', torch.nn.MaxPool2d(kernel_size=2,\n",
    "                                                       stride=2)),\n",
    "                ('layer2_relu', torch.nn.ReLU(inplace=True)),\n",
    "                ('layer3_conv', torch.nn.Conv2d(self._num_channels*2,\n",
    "                                                self._num_channels*4,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer3_bn', torch.nn.BatchNorm2d(self._num_channels*4,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer3_max_pool', torch.nn.MaxPool2d(kernel_size=2,\n",
    "                                                       stride=2)),\n",
    "                ('layer3_relu', torch.nn.ReLU(inplace=True)),\n",
    "                ('layer4_conv', torch.nn.Conv2d(self._num_channels*4,\n",
    "                                                self._num_channels*8,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer4_bn', torch.nn.BatchNorm2d(self._num_channels*8,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer4_max_pool', torch.nn.MaxPool2d(kernel_size=2,\n",
    "                                                       stride=2)),\n",
    "                ('layer4_relu', torch.nn.ReLU(inplace=True)),\n",
    "            ]))\n",
    "        else:\n",
    "            self._conv_stride = 2\n",
    "            self._features_size = (img_side_len // 14)**2\n",
    "            self.features = torch.nn.Sequential(OrderedDict([\n",
    "                ('layer1_conv', torch.nn.Conv2d(self._input_channels,\n",
    "                                                self._num_channels,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer1_bn', torch.nn.BatchNorm2d(self._num_channels,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer1_relu', torch.nn.ReLU(inplace=True)),\n",
    "                ('layer2_conv', torch.nn.Conv2d(self._num_channels,\n",
    "                                                self._num_channels*2,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer2_bn', torch.nn.BatchNorm2d(self._num_channels*2,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer2_relu', torch.nn.ReLU(inplace=True)),\n",
    "                ('layer3_conv', torch.nn.Conv2d(self._num_channels*2,\n",
    "                                                self._num_channels*4,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer3_bn', torch.nn.BatchNorm2d(self._num_channels*4,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer3_relu', torch.nn.ReLU(inplace=True)),\n",
    "                ('layer4_conv', torch.nn.Conv2d(self._num_channels*4,\n",
    "                                                self._num_channels*8,\n",
    "                                                self._kernel_size,\n",
    "                                                stride=self._conv_stride,\n",
    "                                                padding=self._padding)),\n",
    "                ('layer4_bn', torch.nn.BatchNorm2d(self._num_channels*8,\n",
    "                                                   affine=self._bn_affine,\n",
    "                                                   momentum=0.001)),\n",
    "                ('layer4_relu', torch.nn.ReLU(inplace=True)),\n",
    "            ]))\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(OrderedDict([\n",
    "            ('fully_connected', torch.nn.Linear(self._num_channels*8,\n",
    "                                                self._output_size))\n",
    "        ]))\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, task, params=None, embeddings=None):\n",
    "        if not self._reuse and self._verbose: print('='*10 + ' Model ' + '='*10)\n",
    "        if params is None:\n",
    "            params = OrderedDict(self.named_parameters())\n",
    "\n",
    "        x = task.x\n",
    "        if not self._reuse and self._verbose: print('input size: {}'.format(x.size()))\n",
    "        for layer_name, layer in self.features.named_children():\n",
    "            weight = params.get('features.' + layer_name + '.weight', None)\n",
    "            bias = params.get('features.' + layer_name + '.bias', None)\n",
    "            if 'conv' in layer_name:\n",
    "                x = F.conv2d(x, weight=weight, bias=bias,\n",
    "                             stride=self._conv_stride, padding=self._padding)\n",
    "            elif 'bn' in layer_name:\n",
    "                x = F.batch_norm(x, weight=weight, bias=bias,\n",
    "                                 running_mean=layer.running_mean,\n",
    "                                 running_var=layer.running_var,\n",
    "                                 training=True)\n",
    "            elif 'max_pool' in layer_name:\n",
    "                x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "            elif 'relu' in layer_name:\n",
    "                x = F.relu(x)\n",
    "            elif 'fully_connected' in layer_name:\n",
    "                break\n",
    "            else:\n",
    "                raise ValueError('Unrecognized layer {}'.format(layer_name))\n",
    "            if not self._reuse and self._verbose: print('{}: {}'.format(layer_name, x.size()))\n",
    "\n",
    "        # in maml network the conv maps are average pooled\n",
    "        x = x.view(x.size(0), self._num_channels*8, self._features_size)\n",
    "        if not self._reuse and self._verbose: print('reshape to: {}'.format(x.size()))\n",
    "        x = torch.mean(x, dim=2)\n",
    "        if not self._reuse and self._verbose: print('reduce mean: {}'.format(x.size()))\n",
    "        logits = F.linear(\n",
    "            x, weight=params['classifier.fully_connected.weight'],\n",
    "            bias=params['classifier.fully_connected.bias'])\n",
    "        if not self._reuse and self._verbose: print('logits size: {}'.format(logits.size()))\n",
    "        if not self._reuse and self._verbose: print('='*27)\n",
    "        self._reuse = True\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(RNNBase):\n",
    "    r\"\"\"Applies a multi-layer long short-term memory (LSTM) RNN to an input\n",
    "    sequence.\n",
    "\n",
    "\n",
    "    For each element in the input sequence, each layer computes the following\n",
    "    function:\n",
    "\n",
    "    .. math::\n",
    "        \\begin{array}{ll} \\\\\n",
    "            i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "            f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "            g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "            o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "            c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "            h_t = o_t \\odot \\tanh(c_t) \\\\\n",
    "        \\end{array}\n",
    "\n",
    "    where :math:`h_t` is the hidden state at time `t`, :math:`c_t` is the cell\n",
    "    state at time `t`, :math:`x_t` is the input at time `t`, :math:`h_{t-1}`\n",
    "    is the hidden state of the layer at time `t-1` or the initial hidden\n",
    "    state at time `0`, and :math:`i_t`, :math:`f_t`, :math:`g_t`,\n",
    "    :math:`o_t` are the input, forget, cell, and output gates, respectively.\n",
    "    :math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n",
    "\n",
    "    In a multilayer LSTM, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n",
    "    (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n",
    "    dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n",
    "    variable which is :math:`0` with probability :attr:`dropout`.\n",
    "\n",
    "    Args:\n",
    "        input_size: The number of expected features in the input `x`\n",
    "        hidden_size: The number of features in the hidden state `h`\n",
    "        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
    "            would mean stacking two LSTMs together to form a `stacked LSTM`,\n",
    "            with the second LSTM taking in outputs of the first LSTM and\n",
    "            computing the final results. Default: 1\n",
    "        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
    "            Default: ``True``\n",
    "        batch_first: If ``True``, then the input and output tensors are provided\n",
    "            as (batch, seq, feature). Default: ``False``\n",
    "        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
    "            LSTM layer except the last layer, with dropout probability equal to\n",
    "            :attr:`dropout`. Default: 0\n",
    "        bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``\n",
    "\n",
    "    Inputs: input, (h_0, c_0)\n",
    "        - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
    "          of the input sequence.\n",
    "          The input can also be a packed variable length sequence.\n",
    "          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
    "          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
    "        - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "          containing the initial hidden state for each element in the batch.\n",
    "          If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "        - **c_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "          containing the initial cell state for each element in the batch.\n",
    "\n",
    "          If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n",
    "\n",
    "\n",
    "    Outputs: output, (h_n, c_n)\n",
    "        - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
    "          containing the output features `(h_t)` from the last layer of the LSTM,\n",
    "          for each `t`. If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n",
    "          given as the input, the output will also be a packed sequence.\n",
    "\n",
    "          For the unpacked case, the directions can be separated\n",
    "          using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
    "          with forward and backward being direction `0` and `1` respectively.\n",
    "          Similarly, the directions can be separated in the packed case.\n",
    "        - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "          containing the hidden state for `t = seq_len`.\n",
    "\n",
    "          Like *output*, the layers can be separated using\n",
    "          ``h_n.view(num_layers, num_directions, batch, hidden_size)`` and similarly for *c_n*.\n",
    "        - **c_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "          containing the cell state for `t = seq_len`.\n",
    "\n",
    "    Attributes:\n",
    "        weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n",
    "            `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n",
    "            Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`\n",
    "        weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n",
    "            `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`\n",
    "        bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n",
    "            `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`\n",
    "        bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n",
    "            `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`\n",
    "\n",
    "    .. note::\n",
    "        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
    "        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
    "\n",
    "    .. include:: ../cudnn_persistent_rnn.rst\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> rnn = nn.LSTM(10, 20, 2)\n",
    "        >>> input = torch.randn(5, 3, 10)\n",
    "        >>> h0 = torch.randn(2, 3, 20)\n",
    "        >>> c0 = torch.randn(2, 3, 20)\n",
    "        >>> output, (hn, cn) = rnn(input, (h0, c0))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(LSTM, self).__init__('LSTM', *args, **kwargs)\n",
    "\n",
    "    def check_forward_args(self, input: Tensor, hidden: Tuple[Tensor, Tensor], batch_sizes: Optional[Tensor]):\n",
    "        self.check_input(input, batch_sizes)\n",
    "        expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)\n",
    "\n",
    "        self.check_hidden_size(hidden[0], expected_hidden_size,\n",
    "                               'Expected hidden[0] size {}, got {}')\n",
    "        self.check_hidden_size(hidden[1], expected_hidden_size,\n",
    "                               'Expected hidden[1] size {}, got {}')\n",
    "\n",
    "    def permute_hidden(self, hx: Tuple[Tensor, Tensor], permutation: Optional[Tensor]) -> Tuple[Tensor, Tensor]:\n",
    "        if permutation is None:\n",
    "            return hx\n",
    "        return apply_permutation(hx[0], permutation), apply_permutation(hx[1], permutation)\n",
    "\n",
    "    @overload\n",
    "    @torch._jit_internal._overload_method  # noqa: F811\n",
    "    def forward(self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None\n",
    "                ) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:  # noqa: F811\n",
    "        pass\n",
    "\n",
    "    @overload\n",
    "    @torch._jit_internal._overload_method  # noqa: F811\n",
    "    def forward(self, input: PackedSequence, hx: Optional[Tuple[Tensor, Tensor]] = None\n",
    "                ) -> Tuple[PackedSequence, Tuple[Tensor, Tensor]]:  # noqa: F811\n",
    "        pass\n",
    "\n",
    "    def forward(self, input, hx=None):  # noqa: F811\n",
    "        orig_input = input\n",
    "        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
    "        if isinstance(orig_input, PackedSequence):\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = input\n",
    "            max_batch_size = batch_sizes[0]\n",
    "            max_batch_size = int(max_batch_size)\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
    "            sorted_indices = None\n",
    "            unsorted_indices = None\n",
    "\n",
    "        if hx is None:\n",
    "            num_directions = 2 if self.bidirectional else 1\n",
    "            zeros = torch.zeros(self.num_layers * num_directions,\n",
    "                                max_batch_size, self.hidden_size,\n",
    "                                dtype=input.dtype, device=input.device)\n",
    "            hx = (zeros, zeros)\n",
    "        else:\n",
    "            # Each batch of the hidden state should match the input sequence that\n",
    "            # the user believes he/she is passing in.\n",
    "            hx = self.permute_hidden(hx, sorted_indices)\n",
    "\n",
    "        self.check_forward_args(input, hx, batch_sizes)\n",
    "        if batch_sizes is None:\n",
    "            result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
    "                              self.dropout, self.training, self.bidirectional, self.batch_first)\n",
    "        else:\n",
    "            result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
    "                              self.num_layers, self.dropout, self.training, self.bidirectional)\n",
    "        output = result[0]\n",
    "        hidden = result[1:]\n",
    "        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
    "        if isinstance(orig_input, PackedSequence):\n",
    "            output_packed = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
    "            return output_packed, self.permute_hidden(hidden, unsorted_indices)\n",
    "        else:\n",
    "            return output, self.permute_hidden(hidden, unsorted_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import _VF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"HR\"\n",
    "dataset_name = \"POLLUTION\"\n",
    "model_name = \"LSTM\"\n",
    "\n",
    "task_size = 50\n",
    "batch_size = 64\n",
    "output_dim = 1\n",
    "\n",
    "batch_size = 20\n",
    "horizon = 10\n",
    "meta_learning_rate = 10e-6\n",
    "learning_rate = 10e-5\n",
    "n_inner_iter = 1\n",
    "##test\n",
    "\n",
    "if dataset_name == \"HR\":\n",
    "    window_size = 32\n",
    "    input_dim = 13\n",
    "elif dataset_name == \"POLLUTION\":\n",
    "    window_size = 5\n",
    "    input_dim = 14\n",
    "\n",
    "model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedLSTMModel(LSTMModel):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ExtendedLSTMModel, self).__init__( *args, **kwargs)  \n",
    "    \n",
    "    def get_flat_weights(self):\n",
    "        \n",
    "        self._flat_weights = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn)] \n",
    "        return self._flat_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtendedLSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-205ea8887ff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_flat_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-92f6229b6dab>\u001b[0m in \u001b[0;36mget_flat_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_flat_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wn' is not defined"
     ]
    }
   ],
   "source": [
    "model.get_flat_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.LSTM):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(LSTMModel, self).__init__( *args, **kwargs)  \n",
    "        \n",
    "    def forward(self, input, params = None, hx=None, embeddings = None):  # noqa: F811\n",
    "        \n",
    "            if params is None:\n",
    "                params = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn)] \n",
    "                \n",
    "            \n",
    "            orig_input = input\n",
    "            # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
    "            if isinstance(orig_input, PackedSequence):\n",
    "                input, batch_sizes, sorted_indices, unsorted_indices = input\n",
    "                max_batch_size = batch_sizes[0]\n",
    "                max_batch_size = int(max_batch_size)\n",
    "            else:\n",
    "                batch_sizes = None\n",
    "                max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
    "                sorted_indices = None\n",
    "                unsorted_indices = None\n",
    "\n",
    "            if hx is None:\n",
    "                num_directions = 2 if self.bidirectional else 1\n",
    "                zeros = torch.zeros(self.num_layers * num_directions,\n",
    "                                    max_batch_size, self.hidden_size,\n",
    "                                    dtype=input.dtype, device=input.device)\n",
    "                hx = (zeros, zeros)\n",
    "            else:\n",
    "                # Each batch of the hidden state should match the input sequence that\n",
    "                # the user believes he/she is passing in.\n",
    "                hx = self.permute_hidden(hx, sorted_indices)\n",
    "\n",
    "            self.check_forward_args(input, hx, batch_sizes)\n",
    "            if batch_sizes is None:\n",
    "                result = _VF.lstm(input, hx, params, bias, self.num_layers,\n",
    "                                  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
    "            else:\n",
    "                result = _VF.lstm(input, batch_sizes, hx, params, bias,\n",
    "                                  self.num_layers, self.dropout, self.training, self.bidirectional)\n",
    "            output = result[0]\n",
    "            hidden = result[1:]\n",
    "            # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
    "            if isinstance(orig_input, PackedSequence):\n",
    "                output_packed = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
    "                return output_packed, self.permute_hidden(hidden, unsorted_indices)\n",
    "            else:\n",
    "                return output, self.permute_hidden(hidden, unsorted_indices)\n",
    "\n",
    "    def get_flat_weights(self):\n",
    "        \n",
    "        self._flat_weights = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn) for wn in self._flat_weights_names]\n",
    "        return self._flat_weights\n",
    "    \n",
    "    def set_weights_names(self, names):\n",
    "        self._flat_weights_names = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1864, -0.1020, -0.0542, -0.2225, -0.1711, -0.2549,  0.2816, -0.0213,\n",
       "           0.1339, -0.2140],\n",
       "         [-0.0253, -0.0252, -0.2634, -0.2152, -0.2168, -0.1847,  0.2027, -0.1384,\n",
       "           0.0336, -0.1987],\n",
       "         [-0.2594,  0.0354,  0.2068, -0.0355, -0.0759,  0.1903,  0.2200, -0.0020,\n",
       "          -0.2667, -0.1872],\n",
       "         [ 0.2406,  0.1528,  0.0144,  0.2642, -0.0766, -0.2302,  0.1422,  0.1423,\n",
       "           0.1520,  0.1857],\n",
       "         [-0.2977, -0.2405, -0.1424, -0.2855,  0.3041, -0.0335,  0.2057, -0.1081,\n",
       "           0.0950, -0.1421],\n",
       "         [ 0.2610,  0.1224, -0.1570, -0.1070, -0.1861, -0.2650,  0.2597, -0.1921,\n",
       "           0.0733, -0.0582],\n",
       "         [ 0.0858,  0.2482,  0.3040,  0.1830,  0.0109, -0.0207, -0.0294, -0.0480,\n",
       "           0.2048, -0.0468],\n",
       "         [-0.2926, -0.3000, -0.1401, -0.0004, -0.0733, -0.1035,  0.1918,  0.1821,\n",
       "           0.0571,  0.2439],\n",
       "         [-0.1654, -0.2939, -0.0889, -0.0926, -0.0903,  0.0923, -0.0872,  0.0194,\n",
       "          -0.1670,  0.1744],\n",
       "         [-0.0084, -0.2083, -0.1262,  0.0921, -0.0190,  0.1156, -0.1515,  0.1938,\n",
       "          -0.0141,  0.1782],\n",
       "         [ 0.0177, -0.2367,  0.0817,  0.1148, -0.1651,  0.0121, -0.0133, -0.1612,\n",
       "          -0.0865,  0.1693],\n",
       "         [-0.0886,  0.0535,  0.0138, -0.2453,  0.2439, -0.2790,  0.2651,  0.1228,\n",
       "           0.2933,  0.0525],\n",
       "         [ 0.1115, -0.2294, -0.0272,  0.1370,  0.2306,  0.0266,  0.2022, -0.3063,\n",
       "           0.2558,  0.2904],\n",
       "         [ 0.1113,  0.0393, -0.3061, -0.0167,  0.2970, -0.1180,  0.1479,  0.0975,\n",
       "          -0.0527, -0.0178],\n",
       "         [ 0.1136,  0.2254,  0.2131, -0.0635, -0.2209,  0.0140, -0.2545,  0.0214,\n",
       "          -0.2985, -0.1590],\n",
       "         [ 0.2758, -0.0018,  0.0516,  0.0937,  0.1688,  0.1166,  0.1846,  0.0521,\n",
       "          -0.2089, -0.1738],\n",
       "         [-0.1738, -0.0602,  0.1088, -0.2066, -0.2023, -0.0083, -0.1362, -0.0295,\n",
       "          -0.2931,  0.1465],\n",
       "         [-0.0553, -0.1812,  0.1803, -0.2881,  0.1323,  0.2528, -0.1075, -0.0230,\n",
       "           0.1471,  0.0217],\n",
       "         [-0.0529,  0.1549,  0.2738,  0.0160,  0.0685, -0.1486, -0.0908, -0.1565,\n",
       "          -0.2161, -0.1379],\n",
       "         [ 0.1798, -0.1878, -0.2588, -0.2733,  0.2064, -0.0058,  0.1146,  0.2644,\n",
       "           0.1412, -0.1360],\n",
       "         [-0.1115, -0.2698, -0.1617,  0.3102, -0.2932, -0.1193, -0.0096, -0.2869,\n",
       "          -0.0132,  0.1325],\n",
       "         [-0.2317,  0.2409, -0.2077,  0.0426,  0.2614, -0.2923, -0.1443,  0.2790,\n",
       "           0.0129, -0.2129],\n",
       "         [-0.1903, -0.2646, -0.2590, -0.1868,  0.0196, -0.0368, -0.0611,  0.1969,\n",
       "          -0.3161,  0.3008],\n",
       "         [ 0.1678,  0.2270, -0.0413, -0.0751, -0.1875,  0.0542,  0.2750,  0.0878,\n",
       "           0.1976,  0.2462],\n",
       "         [-0.1075, -0.1913, -0.1848, -0.1088, -0.3107,  0.1971,  0.2703,  0.0425,\n",
       "          -0.0107,  0.2618],\n",
       "         [-0.2163, -0.1627,  0.2173, -0.2216, -0.0760, -0.3090,  0.2999, -0.1762,\n",
       "           0.2543,  0.0727],\n",
       "         [ 0.2493, -0.2349, -0.0928,  0.2807, -0.1184,  0.1500,  0.2560,  0.1175,\n",
       "           0.0831,  0.2017],\n",
       "         [ 0.2478, -0.1231, -0.1484,  0.0316, -0.3098, -0.1232, -0.2269,  0.2566,\n",
       "          -0.0863,  0.0074],\n",
       "         [ 0.1248,  0.1751,  0.2524, -0.2711,  0.2339,  0.0839, -0.0707, -0.0516,\n",
       "           0.1411, -0.3040],\n",
       "         [-0.0534, -0.1212,  0.0048,  0.1231, -0.0495,  0.0845, -0.2902,  0.0874,\n",
       "          -0.2919,  0.2860],\n",
       "         [ 0.2674, -0.0157, -0.3120, -0.0517,  0.0997, -0.1072,  0.3160, -0.0505,\n",
       "           0.2314, -0.2919],\n",
       "         [ 0.2962, -0.0213,  0.1779, -0.0019, -0.0548,  0.2146,  0.2511,  0.0379,\n",
       "           0.0610, -0.1010],\n",
       "         [-0.1053, -0.1111,  0.0706, -0.2319,  0.1768,  0.2057, -0.0312,  0.0244,\n",
       "           0.1629,  0.1633],\n",
       "         [ 0.1653, -0.3090,  0.2213, -0.0962, -0.0160, -0.2483,  0.2141,  0.1885,\n",
       "          -0.1497,  0.0639],\n",
       "         [-0.3152, -0.0510,  0.3098,  0.2689,  0.2440, -0.2703, -0.0948,  0.2984,\n",
       "           0.1907,  0.2368],\n",
       "         [-0.2489,  0.0770,  0.0759,  0.1001, -0.2518, -0.1438,  0.0496,  0.1480,\n",
       "           0.1048,  0.2422],\n",
       "         [ 0.3136, -0.2403, -0.1395, -0.2212, -0.1079,  0.1489, -0.1254,  0.1269,\n",
       "          -0.1319,  0.0104],\n",
       "         [ 0.0680,  0.0573, -0.0330,  0.1564, -0.0792,  0.0161,  0.2180,  0.2876,\n",
       "          -0.0542, -0.1633],\n",
       "         [-0.1256, -0.0238, -0.3081, -0.2575, -0.0884, -0.2917, -0.0214,  0.2269,\n",
       "          -0.3091,  0.2721],\n",
       "         [-0.0513,  0.1324, -0.1288, -0.2274,  0.0792, -0.2486,  0.0068, -0.0992,\n",
       "           0.2377, -0.0831]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2040,  0.1121, -0.1740, -0.0424,  0.0015,  0.2608, -0.0932, -0.0874,\n",
       "          -0.2591, -0.2918],\n",
       "         [-0.1769,  0.3115, -0.1625,  0.0756, -0.0751,  0.1160,  0.1478,  0.0258,\n",
       "           0.2911, -0.2443],\n",
       "         [ 0.0355, -0.1913, -0.1690,  0.0081,  0.0333,  0.2275, -0.2358,  0.1671,\n",
       "           0.2971, -0.2033],\n",
       "         [ 0.1334,  0.1964,  0.0122, -0.2065,  0.1181, -0.1678, -0.1905,  0.1475,\n",
       "           0.3155, -0.0130],\n",
       "         [-0.0464,  0.0527,  0.0570, -0.2814, -0.2317,  0.3114,  0.1129, -0.1924,\n",
       "           0.2283, -0.2812],\n",
       "         [-0.1443, -0.1038,  0.3124,  0.2418, -0.1566, -0.0152, -0.1898,  0.0371,\n",
       "          -0.1267,  0.1294],\n",
       "         [ 0.1147,  0.1785,  0.1296, -0.1229, -0.0906,  0.0832, -0.2014,  0.1105,\n",
       "          -0.3057,  0.2997],\n",
       "         [ 0.2894, -0.2022, -0.0003, -0.1388,  0.0049, -0.1132,  0.2409,  0.2546,\n",
       "          -0.1466,  0.1415],\n",
       "         [ 0.1886, -0.0244, -0.0594,  0.3076, -0.2853, -0.2609, -0.2314, -0.2494,\n",
       "          -0.0466,  0.1627],\n",
       "         [ 0.0477, -0.1234,  0.0882,  0.1488, -0.2432,  0.1579,  0.2347, -0.0125,\n",
       "           0.0418,  0.0010],\n",
       "         [ 0.1501, -0.0722,  0.1588,  0.0346, -0.3141,  0.2586,  0.2874,  0.1045,\n",
       "          -0.0272,  0.1156],\n",
       "         [ 0.2688, -0.0566, -0.1498, -0.0275,  0.0253,  0.1868,  0.2502, -0.2543,\n",
       "           0.2223, -0.2930],\n",
       "         [-0.2544,  0.0739, -0.1156,  0.0174,  0.0124, -0.2317,  0.2966,  0.3073,\n",
       "           0.1375, -0.1404],\n",
       "         [ 0.0817,  0.1133, -0.1309,  0.0791, -0.0264,  0.0754,  0.2694,  0.2175,\n",
       "          -0.2853, -0.0394],\n",
       "         [-0.0515,  0.0687, -0.0664,  0.1156, -0.2399, -0.2161, -0.2429,  0.2570,\n",
       "           0.0902,  0.2171],\n",
       "         [ 0.2111, -0.0089,  0.0036, -0.2189, -0.2483,  0.1022,  0.3077, -0.2996,\n",
       "           0.2040,  0.0707],\n",
       "         [ 0.2739,  0.0010, -0.1217, -0.0280, -0.0107,  0.3096, -0.1398,  0.1582,\n",
       "           0.0547, -0.0287],\n",
       "         [-0.0768,  0.1786,  0.1332,  0.1015,  0.2741,  0.0106, -0.1209, -0.3130,\n",
       "           0.2632,  0.0893],\n",
       "         [ 0.0533,  0.1775, -0.1601,  0.0259,  0.2482,  0.1267, -0.2025,  0.1414,\n",
       "           0.2785,  0.0274],\n",
       "         [ 0.2164,  0.0638,  0.2795,  0.1684,  0.3161, -0.0965,  0.1662, -0.0687,\n",
       "           0.3018, -0.1367],\n",
       "         [ 0.2771,  0.2407,  0.2662,  0.2859, -0.1215, -0.1939,  0.0333,  0.2570,\n",
       "           0.1269,  0.1151],\n",
       "         [-0.0811, -0.1307, -0.0738,  0.2729,  0.0487, -0.0168,  0.0726,  0.1350,\n",
       "          -0.0751, -0.2508],\n",
       "         [ 0.3055,  0.1488, -0.2395, -0.1697,  0.0237, -0.2411, -0.2456, -0.3046,\n",
       "          -0.1053, -0.0599],\n",
       "         [-0.0748, -0.0635, -0.0082, -0.2811, -0.1715,  0.0594,  0.2364,  0.1019,\n",
       "           0.1427, -0.0959],\n",
       "         [-0.1425,  0.2771, -0.0308,  0.0686,  0.3028,  0.2578,  0.0449,  0.0831,\n",
       "           0.3077,  0.0023],\n",
       "         [ 0.1934, -0.2823,  0.2065,  0.1349,  0.1673, -0.2490,  0.0098, -0.0987,\n",
       "           0.2552, -0.0610],\n",
       "         [-0.2970,  0.3152, -0.2923, -0.2376, -0.0024, -0.1822,  0.1211, -0.0996,\n",
       "          -0.1258,  0.2454],\n",
       "         [ 0.1980,  0.2980,  0.0169, -0.0374, -0.2860,  0.3152, -0.1805, -0.2762,\n",
       "           0.0640, -0.0005],\n",
       "         [ 0.1948, -0.1618, -0.0026,  0.0119,  0.2044, -0.3126,  0.0667,  0.1509,\n",
       "          -0.0121, -0.0039],\n",
       "         [ 0.2402,  0.2810, -0.1670,  0.3017,  0.0900,  0.0327, -0.2776,  0.2811,\n",
       "           0.2071, -0.2832],\n",
       "         [-0.3137, -0.0166,  0.1396, -0.2962,  0.1302, -0.2037,  0.0769, -0.0387,\n",
       "          -0.2957,  0.0825],\n",
       "         [-0.2072,  0.2324,  0.1523, -0.1075,  0.2435,  0.1069,  0.0152, -0.0646,\n",
       "           0.1204,  0.1146],\n",
       "         [-0.2625,  0.2074,  0.1527,  0.0787,  0.2332,  0.1715,  0.0497, -0.1804,\n",
       "           0.0437,  0.1782],\n",
       "         [ 0.2630,  0.1397,  0.1939, -0.0090, -0.0794,  0.0927, -0.1177, -0.3079,\n",
       "          -0.2447,  0.2112],\n",
       "         [ 0.0519, -0.1488, -0.1795, -0.0069,  0.0525,  0.0308, -0.3130,  0.1550,\n",
       "           0.0838, -0.0598],\n",
       "         [ 0.2056,  0.0898,  0.1892, -0.1476,  0.0881,  0.0535,  0.2651, -0.1605,\n",
       "          -0.0689,  0.1116],\n",
       "         [-0.0870, -0.1020, -0.0662,  0.0409, -0.3047,  0.0504, -0.3015,  0.3072,\n",
       "          -0.3148,  0.2448],\n",
       "         [ 0.2640,  0.2769, -0.1313, -0.0834,  0.0466,  0.0589, -0.3108,  0.3016,\n",
       "          -0.1766,  0.2585],\n",
       "         [-0.0209,  0.2874, -0.0630,  0.3142,  0.2356,  0.1354,  0.1755, -0.1045,\n",
       "           0.1488, -0.0694],\n",
       "         [ 0.1379,  0.1471, -0.2628, -0.1104, -0.2050, -0.2692, -0.0615, -0.1318,\n",
       "           0.1117, -0.0515]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2318, -0.2484, -0.2058,  0.2744,  0.2842, -0.2594,  0.2883,  0.0589,\n",
       "         -0.1881,  0.2426,  0.1486, -0.0230,  0.2615,  0.2205,  0.2329, -0.3119,\n",
       "          0.0051, -0.2638,  0.3125, -0.1219,  0.1960, -0.1402, -0.0584, -0.2668,\n",
       "          0.2994,  0.2444,  0.3096, -0.2577,  0.2149, -0.1327,  0.0628,  0.0514,\n",
       "         -0.2846, -0.0200, -0.0572, -0.1460, -0.0670, -0.1471, -0.0258, -0.1983],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1457, -0.1875,  0.1078, -0.1024, -0.2095, -0.1560,  0.2384,  0.0731,\n",
       "          0.0767,  0.1283, -0.2357,  0.1600,  0.2393, -0.0288,  0.1533,  0.1521,\n",
       "          0.0931, -0.1501, -0.0014,  0.3156, -0.1991, -0.2113,  0.2478, -0.1612,\n",
       "         -0.1359, -0.0073, -0.2009, -0.0518, -0.1583,  0.3143,  0.2235,  0.3103,\n",
       "         -0.1853,  0.0580,  0.0241, -0.0352, -0.2973,  0.2805,  0.1683,  0.2422],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = OrderedDict(model.named_parameters())\n",
    "\n",
    "parameters_names = parameters.keys()\n",
    "model.set_weights_names(parameters_names)\n",
    "model.get_flat_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1864, -0.1020, -0.0542, -0.2225, -0.1711, -0.2549,  0.2816, -0.0213,\n",
       "          0.1339, -0.2140],\n",
       "        [-0.0253, -0.0252, -0.2634, -0.2152, -0.2168, -0.1847,  0.2027, -0.1384,\n",
       "          0.0336, -0.1987],\n",
       "        [-0.2594,  0.0354,  0.2068, -0.0355, -0.0759,  0.1903,  0.2200, -0.0020,\n",
       "         -0.2667, -0.1872],\n",
       "        [ 0.2406,  0.1528,  0.0144,  0.2642, -0.0766, -0.2302,  0.1422,  0.1423,\n",
       "          0.1520,  0.1857],\n",
       "        [-0.2977, -0.2405, -0.1424, -0.2855,  0.3041, -0.0335,  0.2057, -0.1081,\n",
       "          0.0950, -0.1421],\n",
       "        [ 0.2610,  0.1224, -0.1570, -0.1070, -0.1861, -0.2650,  0.2597, -0.1921,\n",
       "          0.0733, -0.0582],\n",
       "        [ 0.0858,  0.2482,  0.3040,  0.1830,  0.0109, -0.0207, -0.0294, -0.0480,\n",
       "          0.2048, -0.0468],\n",
       "        [-0.2926, -0.3000, -0.1401, -0.0004, -0.0733, -0.1035,  0.1918,  0.1821,\n",
       "          0.0571,  0.2439],\n",
       "        [-0.1654, -0.2939, -0.0889, -0.0926, -0.0903,  0.0923, -0.0872,  0.0194,\n",
       "         -0.1670,  0.1744],\n",
       "        [-0.0084, -0.2083, -0.1262,  0.0921, -0.0190,  0.1156, -0.1515,  0.1938,\n",
       "         -0.0141,  0.1782],\n",
       "        [ 0.0177, -0.2367,  0.0817,  0.1148, -0.1651,  0.0121, -0.0133, -0.1612,\n",
       "         -0.0865,  0.1693],\n",
       "        [-0.0886,  0.0535,  0.0138, -0.2453,  0.2439, -0.2790,  0.2651,  0.1228,\n",
       "          0.2933,  0.0525],\n",
       "        [ 0.1115, -0.2294, -0.0272,  0.1370,  0.2306,  0.0266,  0.2022, -0.3063,\n",
       "          0.2558,  0.2904],\n",
       "        [ 0.1113,  0.0393, -0.3061, -0.0167,  0.2970, -0.1180,  0.1479,  0.0975,\n",
       "         -0.0527, -0.0178],\n",
       "        [ 0.1136,  0.2254,  0.2131, -0.0635, -0.2209,  0.0140, -0.2545,  0.0214,\n",
       "         -0.2985, -0.1590],\n",
       "        [ 0.2758, -0.0018,  0.0516,  0.0937,  0.1688,  0.1166,  0.1846,  0.0521,\n",
       "         -0.2089, -0.1738],\n",
       "        [-0.1738, -0.0602,  0.1088, -0.2066, -0.2023, -0.0083, -0.1362, -0.0295,\n",
       "         -0.2931,  0.1465],\n",
       "        [-0.0553, -0.1812,  0.1803, -0.2881,  0.1323,  0.2528, -0.1075, -0.0230,\n",
       "          0.1471,  0.0217],\n",
       "        [-0.0529,  0.1549,  0.2738,  0.0160,  0.0685, -0.1486, -0.0908, -0.1565,\n",
       "         -0.2161, -0.1379],\n",
       "        [ 0.1798, -0.1878, -0.2588, -0.2733,  0.2064, -0.0058,  0.1146,  0.2644,\n",
       "          0.1412, -0.1360],\n",
       "        [-0.1115, -0.2698, -0.1617,  0.3102, -0.2932, -0.1193, -0.0096, -0.2869,\n",
       "         -0.0132,  0.1325],\n",
       "        [-0.2317,  0.2409, -0.2077,  0.0426,  0.2614, -0.2923, -0.1443,  0.2790,\n",
       "          0.0129, -0.2129],\n",
       "        [-0.1903, -0.2646, -0.2590, -0.1868,  0.0196, -0.0368, -0.0611,  0.1969,\n",
       "         -0.3161,  0.3008],\n",
       "        [ 0.1678,  0.2270, -0.0413, -0.0751, -0.1875,  0.0542,  0.2750,  0.0878,\n",
       "          0.1976,  0.2462],\n",
       "        [-0.1075, -0.1913, -0.1848, -0.1088, -0.3107,  0.1971,  0.2703,  0.0425,\n",
       "         -0.0107,  0.2618],\n",
       "        [-0.2163, -0.1627,  0.2173, -0.2216, -0.0760, -0.3090,  0.2999, -0.1762,\n",
       "          0.2543,  0.0727],\n",
       "        [ 0.2493, -0.2349, -0.0928,  0.2807, -0.1184,  0.1500,  0.2560,  0.1175,\n",
       "          0.0831,  0.2017],\n",
       "        [ 0.2478, -0.1231, -0.1484,  0.0316, -0.3098, -0.1232, -0.2269,  0.2566,\n",
       "         -0.0863,  0.0074],\n",
       "        [ 0.1248,  0.1751,  0.2524, -0.2711,  0.2339,  0.0839, -0.0707, -0.0516,\n",
       "          0.1411, -0.3040],\n",
       "        [-0.0534, -0.1212,  0.0048,  0.1231, -0.0495,  0.0845, -0.2902,  0.0874,\n",
       "         -0.2919,  0.2860],\n",
       "        [ 0.2674, -0.0157, -0.3120, -0.0517,  0.0997, -0.1072,  0.3160, -0.0505,\n",
       "          0.2314, -0.2919],\n",
       "        [ 0.2962, -0.0213,  0.1779, -0.0019, -0.0548,  0.2146,  0.2511,  0.0379,\n",
       "          0.0610, -0.1010],\n",
       "        [-0.1053, -0.1111,  0.0706, -0.2319,  0.1768,  0.2057, -0.0312,  0.0244,\n",
       "          0.1629,  0.1633],\n",
       "        [ 0.1653, -0.3090,  0.2213, -0.0962, -0.0160, -0.2483,  0.2141,  0.1885,\n",
       "         -0.1497,  0.0639],\n",
       "        [-0.3152, -0.0510,  0.3098,  0.2689,  0.2440, -0.2703, -0.0948,  0.2984,\n",
       "          0.1907,  0.2368],\n",
       "        [-0.2489,  0.0770,  0.0759,  0.1001, -0.2518, -0.1438,  0.0496,  0.1480,\n",
       "          0.1048,  0.2422],\n",
       "        [ 0.3136, -0.2403, -0.1395, -0.2212, -0.1079,  0.1489, -0.1254,  0.1269,\n",
       "         -0.1319,  0.0104],\n",
       "        [ 0.0680,  0.0573, -0.0330,  0.1564, -0.0792,  0.0161,  0.2180,  0.2876,\n",
       "         -0.0542, -0.1633],\n",
       "        [-0.1256, -0.0238, -0.3081, -0.2575, -0.0884, -0.2917, -0.0214,  0.2269,\n",
       "         -0.3091,  0.2721],\n",
       "        [-0.0513,  0.1324, -0.1288, -0.2274,  0.0792, -0.2486,  0.0068, -0.0992,\n",
       "          0.2377, -0.0831]], requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.get_flat_weights()\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = OrderedDict(model.named_parameters())\n",
    "type(a.get(\"weight_ih_l0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(self, loss, params):\n",
    "    \"\"\"Apply one step of gradient descent on the loss function `loss`,\n",
    "    with step-size `self._fast_lr`, and returns the updated parameters.\n",
    "    \"\"\"\n",
    "    create_graph = not self._first_order\n",
    "    grads = torch.autograd.grad(loss, params.values(),\n",
    "                                create_graph=create_graph, allow_unused=True)\n",
    "    for (name, param), grad in zip(params.items(), grads):\n",
    "        if self._inner_loop_grad_clip > 0 and grad is not None:\n",
    "            grad = grad.clamp(min=-self._inner_loop_grad_clip,\n",
    "                              max=self._inner_loop_grad_clip)\n",
    "        if grad is not None:\n",
    "            params[name] = param - self._fast_lr * grad\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def step(self, adapted_params_list, embeddings_list, val_tasks,\n",
    "         is_training):\n",
    "    for optimizer in self._optimizers:\n",
    "        optimizer.zero_grad()\n",
    "    post_update_losses = []\n",
    "\n",
    "    for adapted_params, embeddings, task in zip(\n",
    "            adapted_params_list, embeddings_list, val_tasks):\n",
    "        preds = self._model(task, params=adapted_params,\n",
    "                            embeddings=embeddings)\n",
    "        loss = self._loss_func(preds, task.y)\n",
    "        post_update_losses.append(loss)\n",
    "        self._update_measurements(task, loss, preds)\n",
    "\n",
    "    mean_loss = torch.mean(torch.stack(post_update_losses))\n",
    "    if is_training:\n",
    "        mean_loss.backward()\n",
    "        if self._alternating:\n",
    "            self._optimizers[self._alternating_index].step()\n",
    "            self._alternating_count += 1\n",
    "            if self._alternating_count % self._alternating_schedules[self._alternating_index] == 0:\n",
    "                self._alternating_index = (1 - self._alternating_index)\n",
    "                self._alternating_count = 0\n",
    "        else:\n",
    "            self._optimizers[0].step()\n",
    "            if len(self._optimizers) > 1:\n",
    "                if self._embedding_grad_clip > 0:\n",
    "                    _grad_norm = clip_grad_norm_(self._embedding_model.parameters(), self._embedding_grad_clip)\n",
    "                else:\n",
    "                    _grad_norm = get_grad_norm(self._embedding_model.parameters())\n",
    "                    # grad_norm\n",
    "                    self._grads_mean.append(_grad_norm)\n",
    "                    self._optimizers[1].step()\n",
    "\n",
    "    measurements = self._pop_measurements()\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt(self, train_tasks):\n",
    "    adapted_params = []\n",
    "    embeddings_list = []\n",
    "\n",
    "    for task in train_tasks:\n",
    "        params = self._model.param_dict\n",
    "        embeddings = None\n",
    "        if self._embedding_model:\n",
    "            embeddings = self._embedding_model(task)\n",
    "        for i in range(self._num_updates):\n",
    "            preds = self._model(task, params=params, embeddings=embeddings)\n",
    "            loss = self._loss_func(preds, task.y)\n",
    "            params = self.update_params(loss, params=params)\n",
    "            if i == 0:\n",
    "                self._update_measurements(task, loss, preds)\n",
    "        adapted_params.append(params)\n",
    "        embeddings_list.append(embeddings)\n",
    "\n",
    "    measurements = self._pop_measurements()\n",
    "    return measurements, adapted_params, embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_grad_norm(parameters, norm_type=2):\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "    norm_type = float(norm_type)\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "    total_norm = total_norm ** (1. / norm_type)\n",
    "\n",
    "    return total_norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomLSTM(nn.LSTM):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomLSTM, self).__init__( *args, **kwargs)  \n",
    "        \n",
    "    def forward(self, input, params = None, hx=None, embeddings = None):  # noqa: F811\n",
    "        \n",
    "            if params is None:\n",
    "                params = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn)] \n",
    "                \n",
    "            \n",
    "            orig_input = input\n",
    "            # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
    "            if isinstance(orig_input, PackedSequence):\n",
    "                input, batch_sizes, sorted_indices, unsorted_indices = input\n",
    "                max_batch_size = batch_sizes[0]\n",
    "                max_batch_size = int(max_batch_size)\n",
    "            else:\n",
    "                batch_sizes = None\n",
    "                max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
    "                sorted_indices = None\n",
    "                unsorted_indices = None\n",
    "\n",
    "            if hx is None:\n",
    "                num_directions = 2 if self.bidirectional else 1\n",
    "                zeros = torch.zeros(self.num_layers * num_directions,\n",
    "                                    max_batch_size, self.hidden_size,\n",
    "                                    dtype=input.dtype, device=input.device)\n",
    "                hx = (zeros, zeros)\n",
    "            else:\n",
    "                # Each batch of the hidden state should match the input sequence that\n",
    "                # the user believes he/she is passing in.\n",
    "                hx = self.permute_hidden(hx, sorted_indices)\n",
    "\n",
    "            self.check_forward_args(input, hx, batch_sizes)\n",
    "            if batch_sizes is None:\n",
    "                result = _VF.lstm(input, hx, params, bias, self.num_layers,\n",
    "                                  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
    "            else:\n",
    "                result = _VF.lstm(input, batch_sizes, hx, params, bias,\n",
    "                                  self.num_layers, self.dropout, self.training, self.bidirectional)\n",
    "            output = result[0]\n",
    "            hidden = result[1:]\n",
    "            # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
    "            if isinstance(orig_input, PackedSequence):\n",
    "                output_packed = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
    "                return output_packed, self.permute_hidden(hidden, unsorted_indices)\n",
    "            else:\n",
    "                return output, self.permute_hidden(hidden, unsorted_indices)\n",
    "\n",
    "    def get_flat_weights(self):\n",
    "        \n",
    "        self._flat_weights = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn) for wn in self._flat_weights_names]\n",
    "        return self._flat_weights\n",
    "    \n",
    "    def set_weights_names(self, names):\n",
    "        self._flat_weights_names = names\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, seq_len, input_dim, n_layers, hidden_dim, output_dim, lin_hidden_dim = 100):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        #self.lstm = nn.CustomLSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        #self.linear = nn.Linear(hidden_dim, output_dim)#\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        #self.hidden = self.init_hidden()\n",
    "        self.input_dim = input_dim\n",
    "        self.features = torch.nn.Sequential(OrderedDict([\n",
    "            (\"lstm\",  nn.CustomLSTM(input_dim, hidden_dim, n_layers, batch_first=True)),\n",
    "            (\"linear\", nn.Linear(hidden_dim, output_dim))]))\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.n_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.n_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, x, params):\n",
    "        \n",
    "        if params is None:\n",
    "            params = OrderedDict(self.named_parameters())\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'CustomLSTM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-e86cc1e3d3dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLSTMModel\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-67f899f95564>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_size, seq_len, input_dim, n_layers, hidden_dim, output_dim, lin_hidden_dim)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         self.features = torch.nn.Sequential(OrderedDict([\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[1;34m\"lstm\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCustomLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             (\"linear\", nn.Linear(hidden_dim, output_dim))]))\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'CustomLSTM'"
     ]
    }
   ],
   "source": [
    "model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
