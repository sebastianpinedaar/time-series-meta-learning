{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import higher\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,\"..\")\n",
    "from ts_dataset import TSDataset\n",
    "from base_models import LSTMModel, FCN\n",
    "from metrics import torch_mae as mae\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"HR\"\n",
    "dataset_name = \"POLLUTION\"\n",
    "model_name = \"LSTM\"\n",
    "\n",
    "task_size = 50\n",
    "batch_size = 64\n",
    "output_dim = 1\n",
    "\n",
    "batch_size = 20\n",
    "horizon = 10\n",
    "meta_learning_rate = 10e-6\n",
    "learning_rate = 10e-5\n",
    "n_inner_iter = 1\n",
    "##test\n",
    "\n",
    "if dataset_name == \"HR\":\n",
    "    window_size = 32\n",
    "    input_dim = 13\n",
    "elif dataset_name == \"POLLUTION\":\n",
    "    window_size = 5\n",
    "    input_dim = 14\n",
    "\n",
    "def to_torch(numpy_tensor):\n",
    "    \n",
    "    return torch.tensor(numpy_tensor).float().cuda()\n",
    "\n",
    "\n",
    "train_data = pickle.load(  open( \"../../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "train_data_ML = pickle.load( open( \"../../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "validation_data = pickle.load( open( \"../../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "validation_data_ML = pickle.load( open( \"../../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "test_data_ML = pickle.load( open( \"../../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"LSTM\":\n",
    "    model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n",
    "\n",
    "elif model_name == \"FCN\":\n",
    "    kernels = [8,5,3] if window_size != 5 else [4,2,1]\n",
    "    model = FCN(time_steps = window_size,  channels=[input_dim, 128, 128, 128] , kernels=kernels)\n",
    "    \n",
    "model.cuda()\n",
    "meta_opt = optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(model, test_data_ML, horizon, n_inner_iter):\n",
    "\n",
    "    model.train()\n",
    "    total_tasks_test, task_size, window_size, input_dim = test_data_ML.x.shape\n",
    "    \n",
    "    qry_losses = []\n",
    "\n",
    "\n",
    "    for task in range(0, (total_tasks_test-horizon-1), total_tasks_test//100):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # Sample a batch of support and query images and labels.\n",
    "\n",
    "        x_spt, y_spt = test_data_ML[task]\n",
    "        x_qry = test_data_ML.x[(task+1):(task+1+horizon)].reshape(-1, window_size, input_dim)\n",
    "        y_qry = test_data_ML.y[(task+1):(task+1+horizon)].reshape(-1, output_dim)\n",
    "\n",
    "        x_spt, y_spt = to_torch(x_spt), to_torch(y_spt)\n",
    "        x_qry = to_torch(x_qry)\n",
    "        y_qry = to_torch(y_qry)\n",
    "        \n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        # TODO: Maybe pull this out into a separate module so it\n",
    "        # doesn't have to be duplicated between `train` and `test`?\n",
    "\n",
    "        # Initialize the inner optimizer to adapt the parameters to\n",
    "        # the support set.\n",
    "        \n",
    "        inner_opt = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "        with higher.innerloop_ctx(model, inner_opt, track_higher_grads=False) as (fnet, diffopt):\n",
    "            # Optimize the likelihood of the support set by taking\n",
    "            # gradient steps w.r.t. the model's parameters.\n",
    "            # This adapts the model's meta-parameters to the task.\n",
    "            for _ in range(n_inner_iter):\n",
    "                spt_logits = fnet(x_spt)\n",
    "                spt_loss = mae(spt_logits, y_spt)\n",
    "                diffopt.step(spt_loss)\n",
    "\n",
    "            # The query loss and acc induced by these parameters.\n",
    "            qry_logits = fnet(x_qry).detach()\n",
    "            qry_loss = mae(qry_logits, y_qry)\n",
    "            \n",
    "            qry_losses.append(qry_loss.detach())\n",
    "\n",
    "\n",
    "    qry_losses = torch.stack(qry_losses).mean().item()\n",
    "\n",
    "    \n",
    "    print(qry_losses)\n",
    "    return qry_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0.00] Train Loss: 0.1001  | Time: 6.48\n",
      "0.06130401790142059\n",
      "0.08580785989761353\n",
      "[Epoch 0.01] Train Loss: 0.1016  | Time: 6.78\n",
      "0.060051001608371735\n",
      "0.08433961868286133\n",
      "[Epoch 0.02] Train Loss: 0.1070  | Time: 6.69\n",
      "0.058799535036087036\n",
      "0.0828726589679718\n",
      "[Epoch 0.03] Train Loss: 0.1031  | Time: 6.91\n",
      "0.05754739046096802\n",
      "0.08140676468610764\n",
      "[Epoch 0.04] Train Loss: 0.1028  | Time: 6.93\n",
      "0.05629550665616989\n",
      "0.0799437165260315\n",
      "[Epoch 0.05] Train Loss: 0.1038  | Time: 6.98\n",
      "0.055052828043699265\n",
      "0.07848794013261795\n",
      "[Epoch 0.06] Train Loss: 0.1010  | Time: 6.78\n",
      "0.05381219461560249\n",
      "0.07703561335802078\n",
      "[Epoch 0.07] Train Loss: 0.0900  | Time: 7.35\n",
      "0.052572254091501236\n",
      "0.07558497786521912\n",
      "[Epoch 0.08] Train Loss: 0.0840  | Time: 7.17\n",
      "0.051338378340005875\n",
      "0.07414201647043228\n",
      "[Epoch 0.09] Train Loss: 0.0870  | Time: 6.90\n",
      "0.05012376978993416\n",
      "0.07271445542573929\n",
      "[Epoch 0.10] Train Loss: 0.0842  | Time: 6.93\n",
      "0.048933349549770355\n",
      "0.07130029797554016\n",
      "[Epoch 0.11] Train Loss: 0.0839  | Time: 6.69\n",
      "0.04777092486619949\n",
      "0.06991201639175415\n",
      "[Epoch 0.12] Train Loss: 0.0898  | Time: 6.43\n",
      "0.04663974046707153\n",
      "0.06855131685733795\n",
      "[Epoch 0.13] Train Loss: 0.0906  | Time: 6.47\n",
      "0.045540161430835724\n",
      "0.06722292304039001\n",
      "[Epoch 0.14] Train Loss: 0.0901  | Time: 6.53\n",
      "0.04447391629219055\n",
      "0.06593374907970428\n",
      "[Epoch 0.15] Train Loss: 0.0846  | Time: 6.65\n",
      "0.04344197362661362\n",
      "0.06468677520751953\n",
      "[Epoch 0.16] Train Loss: 0.0838  | Time: 6.72\n",
      "0.042441923171281815\n",
      "0.06347847729921341\n",
      "[Epoch 0.17] Train Loss: 0.0879  | Time: 6.76\n",
      "0.04147600010037422\n",
      "0.062311768531799316\n",
      "[Epoch 0.18] Train Loss: 0.0847  | Time: 6.60\n",
      "0.04053495451807976\n",
      "0.061179257929325104\n",
      "[Epoch 0.19] Train Loss: 0.0857  | Time: 6.83\n",
      "0.039618659764528275\n",
      "0.06008080765604973\n",
      "[Epoch 0.20] Train Loss: 0.0824  | Time: 6.96\n",
      "0.038734469562768936\n",
      "0.059016548097133636\n",
      "[Epoch 0.21] Train Loss: 0.0806  | Time: 6.80\n",
      "0.03788451477885246\n",
      "0.05799223855137825\n",
      "[Epoch 0.22] Train Loss: 0.0714  | Time: 7.19\n",
      "0.037074360996484756\n",
      "0.0570124052464962\n",
      "[Epoch 0.23] Train Loss: 0.0680  | Time: 6.69\n",
      "0.03630963712930679\n",
      "0.0560762882232666\n",
      "[Epoch 0.24] Train Loss: 0.0711  | Time: 6.62\n",
      "0.035589251667261124\n",
      "0.0551854632794857\n",
      "[Epoch 0.25] Train Loss: 0.0727  | Time: 6.69\n",
      "0.034905191510915756\n",
      "0.054337821900844574\n",
      "[Epoch 0.25] Train Loss: 0.0740  | Time: 6.62\n",
      "0.03425964340567589\n",
      "0.05352519452571869\n",
      "[Epoch 0.26] Train Loss: 0.0717  | Time: 7.40\n",
      "0.03365068882703781\n",
      "0.05274434760212898\n",
      "[Epoch 0.27] Train Loss: 0.0724  | Time: 7.31\n",
      "0.033075615763664246\n",
      "0.05199180170893669\n",
      "[Epoch 0.28] Train Loss: 0.0674  | Time: 6.77\n",
      "0.032534901052713394\n",
      "0.05127241089940071\n",
      "[Epoch 0.29] Train Loss: 0.0643  | Time: 6.70\n",
      "0.03204162046313286\n",
      "0.05059824883937836\n",
      "[Epoch 0.30] Train Loss: 0.0653  | Time: 6.86\n",
      "0.03158820420503616\n",
      "0.049959901720285416\n",
      "[Epoch 0.31] Train Loss: 0.0612  | Time: 6.52\n",
      "0.03116884082555771\n",
      "0.049362070858478546\n",
      "[Epoch 0.32] Train Loss: 0.0598  | Time: 6.64\n",
      "0.030789954587817192\n",
      "0.048806242644786835\n",
      "[Epoch 0.33] Train Loss: 0.0621  | Time: 6.50\n",
      "0.03044094704091549\n",
      "0.048287056386470795\n",
      "[Epoch 0.34] Train Loss: 0.0620  | Time: 6.75\n",
      "0.03012135997414589\n",
      "0.04780584201216698\n",
      "[Epoch 0.35] Train Loss: 0.0613  | Time: 6.52\n",
      "0.02982892282307148\n",
      "0.04736204817891121\n",
      "[Epoch 0.36] Train Loss: 0.0615  | Time: 6.67\n",
      "0.029562538489699364\n",
      "0.04694840684533119\n",
      "[Epoch 0.37] Train Loss: 0.0615  | Time: 6.68\n",
      "0.02931707166135311\n",
      "0.04656142368912697\n",
      "[Epoch 0.38] Train Loss: 0.0587  | Time: 6.75\n",
      "0.02908977121114731\n",
      "0.04620109498500824\n",
      "[Epoch 0.39] Train Loss: 0.0610  | Time: 6.77\n",
      "0.02888183295726776\n",
      "0.045856330543756485\n",
      "[Epoch 0.40] Train Loss: 0.0593  | Time: 6.56\n",
      "0.028691325336694717\n",
      "0.045532986521720886\n",
      "[Epoch 0.41] Train Loss: 0.0599  | Time: 6.74\n",
      "0.02851812355220318\n",
      "0.04522869363427162\n",
      "[Epoch 0.42] Train Loss: 0.0631  | Time: 6.59\n",
      "0.02836470864713192\n",
      "0.04493778571486473\n",
      "[Epoch 0.43] Train Loss: 0.0592  | Time: 6.61\n",
      "0.02823246829211712\n",
      "0.044661328196525574\n",
      "[Epoch 0.44] Train Loss: 0.0559  | Time: 6.68\n",
      "0.028123091906309128\n",
      "0.044404204934835434\n",
      "[Epoch 0.45] Train Loss: 0.0526  | Time: 6.60\n",
      "0.02803911082446575\n",
      "0.04416976869106293\n",
      "[Epoch 0.46] Train Loss: 0.0550  | Time: 6.58\n",
      "0.02797633223235607\n",
      "0.04395619034767151\n",
      "[Epoch 0.47] Train Loss: 0.0558  | Time: 6.66\n",
      "0.0279376283288002\n",
      "0.04375823587179184\n",
      "[Epoch 0.48] Train Loss: 0.0558  | Time: 6.62\n",
      "0.027925539761781693\n",
      "0.04357363283634186\n",
      "[Epoch 0.49] Train Loss: 0.0568  | Time: 6.81\n",
      "0.02793874591588974\n",
      "0.043404482305049896\n",
      "[Epoch 0.50] Train Loss: 0.0563  | Time: 6.57\n",
      "0.02798238955438137\n",
      "0.043250128626823425\n",
      "[Epoch 0.51] Train Loss: 0.0581  | Time: 6.47\n",
      "0.028054291382431984\n",
      "0.0431157723069191\n",
      "[Epoch 0.52] Train Loss: 0.0589  | Time: 6.64\n",
      "0.028155319392681122\n",
      "0.04300152510404587\n",
      "[Epoch 0.53] Train Loss: 0.0617  | Time: 6.71\n",
      "0.02828732319176197\n",
      "0.042904067784547806\n",
      "[Epoch 0.54] Train Loss: 0.0609  | Time: 6.49\n",
      "0.02845105342566967\n",
      "0.042824942618608475\n",
      "[Epoch 0.55] Train Loss: 0.0618  | Time: 6.72\n",
      "0.028652409091591835\n",
      "0.042766671627759933\n",
      "[Epoch 0.56] Train Loss: 0.0564  | Time: 7.88\n",
      "0.02888532169163227\n",
      "0.042731188237667084\n",
      "[Epoch 0.57] Train Loss: 0.0557  | Time: 7.46\n",
      "0.029151227325201035\n",
      "0.04271775856614113\n",
      "[Epoch 0.58] Train Loss: 0.0579  | Time: 6.74\n",
      "0.029454896226525307\n",
      "0.042729780077934265\n",
      "[Epoch 0.59] Train Loss: 0.0568  | Time: 7.15\n",
      "0.02979441173374653\n",
      "0.04276488721370697\n",
      "[Epoch 0.60] Train Loss: 0.0615  | Time: 6.59\n",
      "0.030173007398843765\n",
      "0.04282389581203461\n",
      "[Epoch 0.61] Train Loss: 0.0652  | Time: 6.90\n",
      "0.030589552596211433\n",
      "0.04290369525551796\n",
      "[Epoch 0.62] Train Loss: 0.0606  | Time: 6.39\n",
      "0.031042400747537613\n",
      "0.04300839453935623\n",
      "[Epoch 0.63] Train Loss: 0.0640  | Time: 6.65\n",
      "0.0315290130674839\n",
      "0.04313814640045166\n",
      "[Epoch 0.64] Train Loss: 0.0645  | Time: 6.50\n",
      "0.032050784677267075\n",
      "0.04329497367143631\n",
      "[Epoch 0.65] Train Loss: 0.0686  | Time: 6.42\n",
      "0.03261056914925575\n",
      "0.04347825422883034\n",
      "[Epoch 0.66] Train Loss: 0.0728  | Time: 6.85\n",
      "0.033211011439561844\n",
      "0.043685849756002426\n",
      "[Epoch 0.67] Train Loss: 0.0718  | Time: 6.65\n",
      "0.03384794294834137\n",
      "0.04391815513372421\n",
      "[Epoch 0.68] Train Loss: 0.0736  | Time: 6.43\n",
      "0.03451833501458168\n",
      "0.0441741868853569\n",
      "[Epoch 0.69] Train Loss: 0.0724  | Time: 6.66\n",
      "0.03520970791578293\n",
      "0.04444847255945206\n",
      "[Epoch 0.70] Train Loss: 0.0711  | Time: 6.69\n",
      "0.035923805087804794\n",
      "0.04474124684929848\n",
      "[Epoch 0.71] Train Loss: 0.0721  | Time: 6.72\n",
      "0.03665969893336296\n",
      "0.04505477473139763\n",
      "[Epoch 0.72] Train Loss: 0.0702  | Time: 6.84\n",
      "0.037412386387586594\n",
      "0.045384638011455536\n",
      "[Epoch 0.73] Train Loss: 0.0675  | Time: 6.42\n",
      "0.0381774865090847\n",
      "0.04573272913694382\n",
      "[Epoch 0.74] Train Loss: 0.0685  | Time: 6.46\n",
      "0.03896506875753403\n",
      "0.0460980087518692\n",
      "[Epoch 0.75] Train Loss: 0.0683  | Time: 6.60\n",
      "0.03976621851325035\n",
      "0.046477142721414566\n",
      "[Epoch 0.75] Train Loss: 0.0685  | Time: 6.46\n",
      "0.04058030992746353\n",
      "0.046875450760126114\n",
      "[Epoch 0.76] Train Loss: 0.0680  | Time: 6.47\n",
      "0.04140458256006241\n",
      "0.04728495329618454\n",
      "[Epoch 0.77] Train Loss: 0.0667  | Time: 6.72\n",
      "0.04222610220313072\n",
      "0.047701772302389145\n",
      "[Epoch 0.78] Train Loss: 0.0649  | Time: 6.53\n",
      "0.04304021596908569\n",
      "0.04812239482998848\n",
      "[Epoch 0.79] Train Loss: 0.0605  | Time: 6.45\n",
      "0.04384258762001991\n",
      "0.048540446907281876\n",
      "[Epoch 0.80] Train Loss: 0.0576  | Time: 6.43\n",
      "0.0446237176656723\n",
      "0.04895385354757309\n",
      "[Epoch 0.81] Train Loss: 0.0602  | Time: 6.49\n",
      "0.04539326950907707\n",
      "0.049366727471351624\n",
      "[Epoch 0.82] Train Loss: 0.0587  | Time: 6.56\n",
      "0.04614885896444321\n",
      "0.049773119390010834\n",
      "[Epoch 0.83] Train Loss: 0.0583  | Time: 6.50\n",
      "0.046877916902303696\n",
      "0.05016648769378662\n",
      "[Epoch 0.84] Train Loss: 0.0577  | Time: 6.55\n",
      "0.047574590891599655\n",
      "0.05054633319377899\n",
      "[Epoch 0.85] Train Loss: 0.0605  | Time: 6.50\n",
      "0.0482429601252079\n",
      "0.05091262236237526\n",
      "[Epoch 0.86] Train Loss: 0.0596  | Time: 6.62\n",
      "0.048878252506256104\n",
      "0.051261696964502335\n",
      "[Epoch 0.87] Train Loss: 0.0588  | Time: 6.89\n",
      "0.04947229474782944\n",
      "0.051588550209999084\n",
      "[Epoch 0.88] Train Loss: 0.0609  | Time: 6.75\n",
      "0.050043243914842606\n",
      "0.05190267786383629\n",
      "[Epoch 0.89] Train Loss: 0.0610  | Time: 6.60\n",
      "0.05057293176651001\n",
      "0.05219707638025284\n",
      "[Epoch 0.90] Train Loss: 0.0656  | Time: 6.53\n",
      "0.05106142535805702\n",
      "0.052470285445451736\n",
      "[Epoch 0.91] Train Loss: 0.0785  | Time: 6.67\n",
      "0.051518991589546204\n",
      "0.052725858986377716\n",
      "[Epoch 0.92] Train Loss: 0.0830  | Time: 6.63\n",
      "0.051938336342573166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05296102911233902\n",
      "[Epoch 0.93] Train Loss: 0.0828  | Time: 6.52\n",
      "0.05230892077088356\n",
      "0.0531684011220932\n",
      "[Epoch 0.94] Train Loss: 0.0813  | Time: 6.58\n",
      "0.052630942314863205\n",
      "0.05334977060556412\n",
      "[Epoch 0.95] Train Loss: 0.0800  | Time: 6.60\n",
      "0.05289890617132187\n",
      "0.05350331589579582\n",
      "[Epoch 0.96] Train Loss: 0.0785  | Time: 6.51\n",
      "0.05312482640147209\n",
      "0.05363628268241882\n",
      "[Epoch 0.97] Train Loss: 0.0801  | Time: 6.55\n",
      "0.053327251225709915\n",
      "0.05375835299491882\n",
      "[Epoch 0.98] Train Loss: 0.0831  | Time: 6.50\n",
      "0.05350477620959282\n",
      "0.05387134850025177\n",
      "[Epoch 1.00] Train Loss: 0.0648  | Time: 6.55\n",
      "0.053565818816423416\n",
      "0.05392572283744812\n",
      "[Epoch 1.01] Train Loss: 0.0659  | Time: 6.49\n",
      "0.05353972688317299\n",
      "0.05393483489751816\n",
      "[Epoch 1.02] Train Loss: 0.0699  | Time: 6.99\n",
      "0.053450386971235275\n",
      "0.05391380563378334\n",
      "[Epoch 1.03] Train Loss: 0.0693  | Time: 7.01\n",
      "0.05330350622534752\n",
      "0.053865887224674225\n",
      "[Epoch 1.04] Train Loss: 0.0684  | Time: 6.42\n",
      "0.05310969427227974\n",
      "0.05379823222756386\n",
      "[Epoch 1.05] Train Loss: 0.0687  | Time: 6.60\n",
      "0.052884817123413086\n",
      "0.05371852591633797\n",
      "[Epoch 1.06] Train Loss: 0.0690  | Time: 6.49\n",
      "0.05263280123472214\n",
      "0.053629446774721146\n",
      "[Epoch 1.07] Train Loss: 0.0615  | Time: 7.52\n",
      "0.052346646785736084\n",
      "0.05352922901511192\n",
      "[Epoch 1.08] Train Loss: 0.0579  | Time: 6.41\n",
      "0.052030693739652634\n",
      "0.053418636322021484\n",
      "[Epoch 1.09] Train Loss: 0.0586  | Time: 6.66\n",
      "0.051704030483961105\n",
      "0.05330868437886238\n",
      "[Epoch 1.10] Train Loss: 0.0557  | Time: 6.49\n",
      "0.05136772245168686\n",
      "0.05320051684975624\n",
      "[Epoch 1.11] Train Loss: 0.0550  | Time: 6.85\n",
      "0.05102488026022911\n",
      "0.05309328809380531\n",
      "[Epoch 1.12] Train Loss: 0.0577  | Time: 6.75\n",
      "0.05069538578391075\n",
      "0.053001031279563904\n",
      "[Epoch 1.13] Train Loss: 0.0589  | Time: 6.72\n",
      "0.05037436634302139\n",
      "0.05291619524359703\n",
      "[Epoch 1.14] Train Loss: 0.0606  | Time: 6.79\n",
      "0.05005602166056633\n",
      "0.05283486470580101\n",
      "[Epoch 1.15] Train Loss: 0.0596  | Time: 6.71\n",
      "0.04973073676228523\n",
      "0.05275297537446022\n",
      "[Epoch 1.16] Train Loss: 0.0572  | Time: 6.73\n",
      "0.04940042272210121\n",
      "0.05266997963190079\n",
      "[Epoch 1.17] Train Loss: 0.0608  | Time: 6.77\n",
      "0.04907260835170746\n",
      "0.05258987098932266\n",
      "[Epoch 1.18] Train Loss: 0.0582  | Time: 6.56\n",
      "0.048747897148132324\n",
      "0.052509259432554245\n",
      "[Epoch 1.19] Train Loss: 0.0578  | Time: 6.65\n",
      "0.048430535942316055\n",
      "0.05243266373872757\n",
      "[Epoch 1.20] Train Loss: 0.0569  | Time: 6.84\n",
      "0.04811788722872734\n",
      "0.05235792696475983\n",
      "[Epoch 1.21] Train Loss: 0.0550  | Time: 6.57\n",
      "0.047816526144742966\n",
      "0.05228843539953232\n",
      "[Epoch 1.22] Train Loss: 0.0496  | Time: 6.75\n",
      "0.04751208797097206\n",
      "0.052220698446035385\n",
      "[Epoch 1.23] Train Loss: 0.0478  | Time: 6.76\n",
      "0.0472058430314064\n",
      "0.0521535649895668\n",
      "[Epoch 1.24] Train Loss: 0.0501  | Time: 6.70\n",
      "0.04690882936120033\n",
      "0.0520930290222168\n",
      "[Epoch 1.25] Train Loss: 0.0510  | Time: 6.84\n",
      "0.04662922024726868\n",
      "0.05204455927014351\n",
      "[Epoch 1.25] Train Loss: 0.0513  | Time: 6.85\n",
      "0.04637158662080765\n",
      "0.05200865864753723\n",
      "[Epoch 1.26] Train Loss: 0.0521  | Time: 6.84\n",
      "0.04612596705555916\n",
      "0.05197831615805626\n",
      "[Epoch 1.27] Train Loss: 0.0525  | Time: 6.90\n",
      "0.04590107500553131\n",
      "0.05195547640323639\n",
      "[Epoch 1.28] Train Loss: 0.0516  | Time: 6.76\n",
      "0.04568790644407272\n",
      "0.0519365556538105\n",
      "[Epoch 1.29] Train Loss: 0.0518  | Time: 6.76\n",
      "0.04548459127545357\n",
      "0.05191795900464058\n",
      "[Epoch 1.30] Train Loss: 0.0515  | Time: 6.94\n",
      "0.04529375582933426\n",
      "0.051900170743465424\n",
      "[Epoch 1.31] Train Loss: 0.0484  | Time: 6.77\n",
      "0.04511197283864021\n",
      "0.05188031122088432\n",
      "[Epoch 1.32] Train Loss: 0.0486  | Time: 6.89\n",
      "0.04493768885731697\n",
      "0.05185788497328758\n",
      "[Epoch 1.33] Train Loss: 0.0488  | Time: 6.84\n",
      "0.04478328675031662\n",
      "0.05183885246515274\n",
      "[Epoch 1.34] Train Loss: 0.0488  | Time: 6.95\n",
      "0.04464784637093544\n",
      "0.05181979387998581\n",
      "[Epoch 1.35] Train Loss: 0.0493  | Time: 6.95\n",
      "0.044522374868392944\n",
      "0.05179724842309952\n",
      "[Epoch 1.36] Train Loss: 0.0467  | Time: 6.97\n",
      "0.04441678151488304\n",
      "0.051776934415102005\n",
      "[Epoch 1.37] Train Loss: 0.0469  | Time: 6.88\n",
      "0.04432348534464836\n",
      "0.05175446346402168\n",
      "[Epoch 1.38] Train Loss: 0.0467  | Time: 6.85\n",
      "0.04423130303621292\n",
      "0.051723551005125046\n",
      "[Epoch 1.39] Train Loss: 0.0464  | Time: 6.80\n",
      "0.044149525463581085\n",
      "0.051688700914382935\n",
      "[Epoch 1.40] Train Loss: 0.0466  | Time: 7.01\n",
      "0.044059958308935165\n",
      "0.05164412036538124\n",
      "[Epoch 1.41] Train Loss: 0.0466  | Time: 6.61\n",
      "0.043963201344013214\n",
      "0.051589444279670715\n",
      "[Epoch 1.42] Train Loss: 0.0488  | Time: 6.63\n",
      "0.04386081174015999\n",
      "0.051527056843042374\n",
      "[Epoch 1.43] Train Loss: 0.0458  | Time: 6.60\n",
      "0.043742746114730835\n",
      "0.05145668238401413\n",
      "[Epoch 1.44] Train Loss: 0.0437  | Time: 6.61\n",
      "0.043602220714092255\n",
      "0.05137808248400688\n",
      "[Epoch 1.45] Train Loss: 0.0400  | Time: 6.56\n",
      "0.043445684015750885\n",
      "0.05129397660493851\n",
      "[Epoch 1.46] Train Loss: 0.0410  | Time: 6.79\n",
      "0.0432826466858387\n",
      "0.05120670050382614\n",
      "[Epoch 1.47] Train Loss: 0.0412  | Time: 6.72\n",
      "0.04311218857765198\n",
      "0.05111716687679291\n",
      "[Epoch 1.48] Train Loss: 0.0408  | Time: 6.62\n",
      "0.04293568804860115\n",
      "0.05102551728487015\n",
      "[Epoch 1.49] Train Loss: 0.0416  | Time: 7.96\n",
      "0.04274817556142807\n",
      "0.050929825752973557\n",
      "[Epoch 1.50] Train Loss: 0.0437  | Time: 7.04\n",
      "0.042544975876808167\n",
      "0.05082901567220688\n",
      "[Epoch 1.51] Train Loss: 0.0447  | Time: 7.73\n",
      "0.04233340919017792\n",
      "0.05072719231247902\n",
      "[Epoch 1.52] Train Loss: 0.0430  | Time: 6.33\n",
      "0.042129747569561005\n",
      "0.050631847232580185\n",
      "[Epoch 1.53] Train Loss: 0.0443  | Time: 6.34\n",
      "0.041944582015275955\n",
      "0.05054659768939018\n",
      "[Epoch 1.54] Train Loss: 0.0451  | Time: 6.32\n",
      "0.041777677834033966\n",
      "0.050468675792217255\n",
      "[Epoch 1.55] Train Loss: 0.0456  | Time: 6.58\n",
      "0.04163032025098801\n",
      "0.05039680004119873\n",
      "[Epoch 1.56] Train Loss: 0.0434  | Time: 6.74\n",
      "0.04148146137595177\n",
      "0.050322357565164566\n",
      "[Epoch 1.57] Train Loss: 0.0433  | Time: 6.36\n",
      "0.04133312404155731\n",
      "0.050245705991983414\n",
      "[Epoch 1.58] Train Loss: 0.0437  | Time: 6.43\n",
      "0.04119623079895973\n",
      "0.05017263814806938\n",
      "[Epoch 1.59] Train Loss: 0.0436  | Time: 6.44\n",
      "0.04107033833861351\n",
      "0.05010126531124115\n",
      "[Epoch 1.60] Train Loss: 0.0470  | Time: 6.51\n",
      "0.04096759110689163\n",
      "0.050037845969200134\n",
      "[Epoch 1.61] Train Loss: 0.0496  | Time: 6.43\n",
      "0.04089928790926933\n",
      "0.049985162913799286\n",
      "[Epoch 1.62] Train Loss: 0.0477  | Time: 6.42\n",
      "0.040852125734090805\n",
      "0.04993915930390358\n",
      "[Epoch 1.63] Train Loss: 0.0498  | Time: 6.47\n",
      "0.040836889296770096\n",
      "0.04990419000387192\n",
      "[Epoch 1.64] Train Loss: 0.0497  | Time: 6.42\n",
      "0.04085599631071091\n",
      "0.04988168925046921\n",
      "[Epoch 1.65] Train Loss: 0.0535  | Time: 6.36\n",
      "0.04091615602374077\n",
      "0.04987356439232826\n",
      "[Epoch 1.66] Train Loss: 0.0563  | Time: 6.40\n",
      "0.04102596268057823\n",
      "0.04988502338528633\n",
      "[Epoch 1.67] Train Loss: 0.0575  | Time: 6.58\n",
      "0.04117567092180252\n",
      "0.04991254583001137\n",
      "[Epoch 1.68] Train Loss: 0.0590  | Time: 6.39\n",
      "0.041372835636138916\n",
      "0.04995885118842125\n",
      "[Epoch 1.69] Train Loss: 0.0579  | Time: 6.40\n",
      "0.04160943999886513\n",
      "0.05002366006374359\n",
      "[Epoch 1.70] Train Loss: 0.0563  | Time: 6.93\n",
      "0.04189086705446243\n",
      "0.05011050030589104\n",
      "[Epoch 1.71] Train Loss: 0.0577  | Time: 6.37\n",
      "0.04221528396010399\n",
      "0.05021943151950836\n",
      "[Epoch 1.72] Train Loss: 0.0570  | Time: 6.38\n",
      "0.04256947711110115\n",
      "0.05034288018941879\n",
      "[Epoch 1.73] Train Loss: 0.0565  | Time: 6.35\n",
      "0.042939603328704834\n",
      "0.05047569423913956\n",
      "[Epoch 1.74] Train Loss: 0.0569  | Time: 6.36\n",
      "0.04333985969424248\n",
      "0.050622131675481796\n",
      "[Epoch 1.75] Train Loss: 0.0576  | Time: 6.59\n",
      "0.043762873858213425\n",
      "0.05078491196036339\n",
      "[Epoch 1.75] Train Loss: 0.0575  | Time: 6.65\n",
      "0.04421481490135193\n",
      "0.0509665422141552\n",
      "[Epoch 1.76] Train Loss: 0.0571  | Time: 6.86\n",
      "0.044693414121866226\n",
      "0.051166389137506485\n",
      "[Epoch 1.77] Train Loss: 0.0566  | Time: 6.93\n",
      "0.045188404619693756\n",
      "0.0513799823820591\n",
      "[Epoch 1.78] Train Loss: 0.0555  | Time: 6.69\n",
      "0.04568519443273544\n",
      "0.0516015850007534\n",
      "[Epoch 1.79] Train Loss: 0.0525  | Time: 6.69\n",
      "0.04617306962609291\n",
      "0.051827333867549896\n",
      "[Epoch 1.80] Train Loss: 0.0501  | Time: 6.65\n",
      "0.04664348438382149\n",
      "0.05205024033784866\n",
      "[Epoch 1.81] Train Loss: 0.0517  | Time: 6.64\n",
      "0.047113679349422455\n",
      "0.052276454865932465\n",
      "[Epoch 1.82] Train Loss: 0.0513  | Time: 6.56\n",
      "0.047577716410160065\n",
      "0.05250127986073494\n",
      "[Epoch 1.83] Train Loss: 0.0516  | Time: 6.54\n",
      "0.04802580922842026\n",
      "0.052719756960868835\n",
      "[Epoch 1.84] Train Loss: 0.0517  | Time: 6.74\n",
      "0.04844842478632927\n",
      "0.05292576178908348\n",
      "[Epoch 1.85] Train Loss: 0.0560  | Time: 6.71\n",
      "0.048841677606105804\n",
      "0.053111933171749115\n",
      "[Epoch 1.86] Train Loss: 0.0556  | Time: 6.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04920510575175285\n",
      "0.053282901644706726\n",
      "[Epoch 1.87] Train Loss: 0.0556  | Time: 6.80\n",
      "0.04952835291624069\n",
      "0.05343689024448395\n",
      "[Epoch 1.88] Train Loss: 0.0585  | Time: 6.74\n",
      "0.0498293861746788\n",
      "0.053576137870550156\n",
      "[Epoch 1.89] Train Loss: 0.0580  | Time: 6.55\n",
      "0.05011171102523804\n",
      "0.05370103940367699\n",
      "[Epoch 1.90] Train Loss: 0.0629  | Time: 6.63\n",
      "0.05037420243024826\n",
      "0.05380837991833687\n",
      "[Epoch 1.91] Train Loss: 0.0753  | Time: 6.87\n",
      "0.050635963678359985\n",
      "0.05390387400984764\n",
      "[Epoch 1.92] Train Loss: 0.0791  | Time: 6.65\n",
      "0.05089222267270088\n",
      "0.053988974541425705\n",
      "[Epoch 1.93] Train Loss: 0.0787  | Time: 6.80\n",
      "0.05112902820110321\n",
      "0.05405980721116066\n",
      "[Epoch 1.94] Train Loss: 0.0764  | Time: 6.72\n",
      "0.05135991796851158\n",
      "0.054121941328048706\n",
      "[Epoch 1.95] Train Loss: 0.0748  | Time: 6.73\n",
      "0.05158663168549538\n",
      "0.054177138954401016\n",
      "[Epoch 1.96] Train Loss: 0.0733  | Time: 6.83\n",
      "0.0518205426633358\n",
      "0.05422871932387352\n",
      "[Epoch 1.97] Train Loss: 0.0748  | Time: 6.90\n",
      "0.052077312022447586\n",
      "0.05428079515695572\n",
      "[Epoch 1.98] Train Loss: 0.0761  | Time: 6.68\n",
      "0.05236135050654411\n",
      "0.05434245243668556\n",
      "[Epoch 2.00] Train Loss: 0.0559  | Time: 6.67\n",
      "0.052655674517154694\n",
      "0.05434856563806534\n",
      "[Epoch 2.01] Train Loss: 0.0570  | Time: 6.77\n",
      "0.05295750871300697\n",
      "0.05431605875492096\n",
      "[Epoch 2.02] Train Loss: 0.0609  | Time: 6.72\n",
      "0.05327627435326576\n",
      "0.054259348660707474\n",
      "[Epoch 2.03] Train Loss: 0.0591  | Time: 6.66\n",
      "0.05360811576247215\n",
      "0.054196715354919434\n",
      "[Epoch 2.04] Train Loss: 0.0592  | Time: 6.61\n",
      "0.05394875630736351\n",
      "0.05413397029042244\n",
      "[Epoch 2.05] Train Loss: 0.0599  | Time: 6.57\n",
      "0.054291196167469025\n",
      "0.05408700555562973\n",
      "[Epoch 2.06] Train Loss: 0.0595  | Time: 7.08\n",
      "0.054635029286146164\n",
      "0.05405709147453308\n",
      "[Epoch 2.07] Train Loss: 0.0510  | Time: 6.60\n",
      "0.05497538670897484\n",
      "0.05405052751302719\n",
      "[Epoch 2.08] Train Loss: 0.0475  | Time: 6.58\n",
      "0.05531314015388489\n",
      "0.054065849632024765\n",
      "[Epoch 2.09] Train Loss: 0.0495  | Time: 6.55\n",
      "0.055648405104875565\n",
      "0.05410046502947807\n",
      "[Epoch 2.10] Train Loss: 0.0471  | Time: 6.77\n",
      "0.05598621070384979\n",
      "0.05415496975183487\n",
      "[Epoch 2.11] Train Loss: 0.0467  | Time: 6.67\n",
      "0.05632947012782097\n",
      "0.054228901863098145\n",
      "[Epoch 2.12] Train Loss: 0.0503  | Time: 6.64\n",
      "0.05668962374329567\n",
      "0.05432530865073204\n",
      "[Epoch 2.13] Train Loss: 0.0513  | Time: 6.65\n",
      "0.057057928293943405\n",
      "0.05444244667887688\n",
      "[Epoch 2.14] Train Loss: 0.0522  | Time: 6.71\n",
      "0.05742061883211136\n",
      "0.05457625538110733\n",
      "[Epoch 2.15] Train Loss: 0.0507  | Time: 6.81\n",
      "0.057755280286073685\n",
      "0.05471917986869812\n",
      "[Epoch 2.16] Train Loss: 0.0485  | Time: 7.10\n",
      "0.05806451663374901\n",
      "0.05486582964658737\n",
      "[Epoch 2.17] Train Loss: 0.0534  | Time: 6.94\n",
      "0.05835220590233803\n",
      "0.05501038208603859\n",
      "[Epoch 2.18] Train Loss: 0.0505  | Time: 6.98\n",
      "0.05862225964665413\n",
      "0.055149927735328674\n",
      "[Epoch 2.19] Train Loss: 0.0508  | Time: 6.65\n",
      "0.058878861367702484\n",
      "0.05528568476438522\n",
      "[Epoch 2.20] Train Loss: 0.0500  | Time: 6.60\n",
      "0.05910944938659668\n",
      "0.05541381984949112\n",
      "[Epoch 2.21] Train Loss: 0.0489  | Time: 6.75\n",
      "0.05932718515396118\n",
      "0.055537816137075424\n",
      "[Epoch 2.22] Train Loss: 0.0448  | Time: 6.63\n",
      "0.0595083050429821\n",
      "0.05564635619521141\n",
      "[Epoch 2.23] Train Loss: 0.0430  | Time: 6.58\n",
      "0.05966726318001747\n",
      "0.055740419775247574\n",
      "[Epoch 2.24] Train Loss: 0.0457  | Time: 6.66\n",
      "0.05981742590665817\n",
      "0.055824726819992065\n",
      "[Epoch 2.25] Train Loss: 0.0469  | Time: 6.76\n",
      "0.059968624264001846\n",
      "0.05590423196554184\n",
      "[Epoch 2.25] Train Loss: 0.0480  | Time: 6.73\n",
      "0.060115713626146317\n",
      "0.055976711213588715\n",
      "[Epoch 2.26] Train Loss: 0.0485  | Time: 6.65\n",
      "0.06023835763335228\n",
      "0.05603286996483803\n",
      "[Epoch 2.27] Train Loss: 0.0488  | Time: 6.72\n",
      "0.060339946299791336\n",
      "0.05607426166534424\n",
      "[Epoch 2.28] Train Loss: 0.0481  | Time: 6.79\n",
      "0.06040504202246666\n",
      "0.056093730032444\n",
      "[Epoch 2.29] Train Loss: 0.0478  | Time: 7.10\n",
      "0.06042105704545975\n",
      "0.05608569085597992\n",
      "[Epoch 2.30] Train Loss: 0.0476  | Time: 6.76\n",
      "0.060381099581718445\n",
      "0.05604718625545502\n",
      "[Epoch 2.31] Train Loss: 0.0449  | Time: 6.66\n",
      "0.06028663367033005\n",
      "0.055980194360017776\n",
      "[Epoch 2.32] Train Loss: 0.0449  | Time: 7.07\n",
      "0.060142092406749725\n",
      "0.055886317044496536\n",
      "[Epoch 2.33] Train Loss: 0.0450  | Time: 6.80\n",
      "0.059972893446683884\n",
      "0.05578012764453888\n",
      "[Epoch 2.34] Train Loss: 0.0455  | Time: 6.73\n",
      "0.059779390692710876\n",
      "0.05566183105111122\n",
      "[Epoch 2.35] Train Loss: 0.0464  | Time: 6.77\n",
      "0.05955488607287407\n",
      "0.055527642369270325\n",
      "[Epoch 2.36] Train Loss: 0.0431  | Time: 6.86\n",
      "0.059331849217414856\n",
      "0.05539504811167717\n",
      "[Epoch 2.37] Train Loss: 0.0442  | Time: 6.96\n",
      "0.0590960830450058\n",
      "0.055257074534893036\n",
      "[Epoch 2.38] Train Loss: 0.0447  | Time: 6.80\n",
      "0.05883004516363144\n",
      "0.05509898066520691\n",
      "[Epoch 2.39] Train Loss: 0.0443  | Time: 6.66\n",
      "0.05854807421565056\n",
      "0.05493033677339554\n",
      "[Epoch 2.40] Train Loss: 0.0449  | Time: 6.58\n",
      "0.05822563171386719\n",
      "0.05474163591861725\n",
      "[Epoch 2.41] Train Loss: 0.0450  | Time: 6.63\n",
      "0.057871442288160324\n",
      "0.05453548952937126\n",
      "[Epoch 2.42] Train Loss: 0.0470  | Time: 6.97\n",
      "0.05749925598502159\n",
      "0.05432191863656044\n",
      "[Epoch 2.43] Train Loss: 0.0442  | Time: 6.68\n",
      "0.0570967011153698\n",
      "0.05409759283065796\n",
      "[Epoch 2.44] Train Loss: 0.0424  | Time: 6.76\n",
      "0.056659262627363205\n",
      "0.0538613460958004\n",
      "[Epoch 2.45] Train Loss: 0.0388  | Time: 6.96\n",
      "0.05618702247738838\n",
      "0.05361385643482208\n",
      "[Epoch 2.46] Train Loss: 0.0401  | Time: 6.77\n",
      "0.055698636919260025\n",
      "0.05336252972483635\n",
      "[Epoch 2.47] Train Loss: 0.0405  | Time: 6.70\n",
      "0.05518608167767525\n",
      "0.053101446479558945\n",
      "[Epoch 2.48] Train Loss: 0.0417  | Time: 6.68\n",
      "0.05465816706418991\n",
      "0.052833691239356995\n",
      "[Epoch 2.49] Train Loss: 0.0431  | Time: 6.73\n",
      "0.05409562587738037\n",
      "0.05255694314837456\n",
      "[Epoch 2.50] Train Loss: 0.0454  | Time: 6.78\n",
      "0.05348866805434227\n",
      "0.05226976051926613\n",
      "[Epoch 2.51] Train Loss: 0.0461  | Time: 7.13\n",
      "0.052848801016807556\n",
      "0.0519808754324913\n",
      "[Epoch 2.52] Train Loss: 0.0440  | Time: 7.19\n",
      "0.05220092833042145\n",
      "0.05169948562979698\n",
      "[Epoch 2.53] Train Loss: 0.0443  | Time: 6.97\n",
      "0.05156514421105385\n",
      "0.05143442749977112\n",
      "[Epoch 2.54] Train Loss: 0.0457  | Time: 6.88\n",
      "0.05095193162560463\n",
      "0.05118505284190178\n",
      "[Epoch 2.55] Train Loss: 0.0461  | Time: 6.78\n",
      "0.05036482959985733\n",
      "0.05094614252448082\n",
      "[Epoch 2.56] Train Loss: 0.0443  | Time: 6.70\n",
      "0.04977796971797943\n",
      "0.05070910230278969\n",
      "[Epoch 2.57] Train Loss: 0.0444  | Time: 6.92\n",
      "0.04919004812836647\n",
      "0.05047301575541496\n",
      "[Epoch 2.58] Train Loss: 0.0444  | Time: 6.97\n",
      "0.0486266054213047\n",
      "0.05025087296962738\n",
      "[Epoch 2.59] Train Loss: 0.0437  | Time: 6.82\n",
      "0.04808428883552551\n",
      "0.05003829300403595\n",
      "[Epoch 2.60] Train Loss: 0.0465  | Time: 6.65\n",
      "0.04758743196725845\n",
      "0.04984498396515846\n",
      "[Epoch 2.61] Train Loss: 0.0486  | Time: 6.56\n",
      "0.04714721813797951\n",
      "0.04967386648058891\n",
      "[Epoch 2.62] Train Loss: 0.0470  | Time: 6.66\n",
      "0.04674290120601654\n",
      "0.0495186522603035\n",
      "[Epoch 2.63] Train Loss: 0.0488  | Time: 6.76\n",
      "0.04639289900660515\n",
      "0.049385253340005875\n",
      "[Epoch 2.64] Train Loss: 0.0486  | Time: 7.02\n",
      "0.046102944761514664\n",
      "0.049272097647190094\n",
      "[Epoch 2.65] Train Loss: 0.0522  | Time: 6.70\n",
      "0.04588092118501663\n",
      "0.0491810217499733\n",
      "[Epoch 2.66] Train Loss: 0.0545  | Time: 7.00\n",
      "0.04573650658130646\n",
      "0.04911624640226364\n",
      "[Epoch 2.67] Train Loss: 0.0559  | Time: 6.95\n",
      "0.04565370827913284\n",
      "0.04907209798693657\n",
      "[Epoch 2.68] Train Loss: 0.0567  | Time: 6.62\n",
      "0.04564633592963219\n",
      "0.049052268266677856\n",
      "[Epoch 2.69] Train Loss: 0.0556  | Time: 6.58\n",
      "0.0457049235701561\n",
      "0.049055520445108414\n",
      "[Epoch 2.70] Train Loss: 0.0543  | Time: 6.66\n",
      "0.0458345040678978\n",
      "0.04908265918493271\n",
      "[Epoch 2.71] Train Loss: 0.0556  | Time: 6.86\n",
      "0.046035345643758774\n",
      "0.04913312569260597\n",
      "[Epoch 2.72] Train Loss: 0.0550  | Time: 6.72\n",
      "0.04628616198897362\n",
      "0.04920024797320366\n",
      "[Epoch 2.73] Train Loss: 0.0547  | Time: 6.87\n",
      "0.046575356274843216\n",
      "0.04927953705191612\n",
      "[Epoch 2.74] Train Loss: 0.0551  | Time: 6.77\n",
      "0.04692080616950989\n",
      "0.04937546327710152\n",
      "[Epoch 2.75] Train Loss: 0.0560  | Time: 7.06\n",
      "0.04731032997369766\n",
      "0.04948911815881729\n",
      "[Epoch 2.75] Train Loss: 0.0560  | Time: 6.70\n",
      "0.0477520115673542\n",
      "0.049623042345047\n",
      "[Epoch 2.76] Train Loss: 0.0554  | Time: 7.17\n",
      "0.04824400320649147\n",
      "0.0497807078063488\n",
      "[Epoch 2.77] Train Loss: 0.0547  | Time: 6.68\n",
      "0.048770155757665634\n",
      "0.0499567873775959\n",
      "[Epoch 2.78] Train Loss: 0.0537  | Time: 6.68\n",
      "0.04931274428963661\n",
      "0.050148047506809235\n",
      "[Epoch 2.79] Train Loss: 0.0508  | Time: 6.66\n",
      "0.04985588416457176\n",
      "0.05034748464822769\n",
      "[Epoch 2.80] Train Loss: 0.0482  | Time: 6.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050380807369947433\n",
      "0.05054768547415733\n",
      "[Epoch 2.81] Train Loss: 0.0493  | Time: 6.63\n",
      "0.050910256803035736\n",
      "0.05075585097074509\n",
      "[Epoch 2.82] Train Loss: 0.0488  | Time: 6.83\n",
      "0.05143694207072258\n",
      "0.050966329872608185\n",
      "[Epoch 2.83] Train Loss: 0.0490  | Time: 6.66\n",
      "0.051943015307188034\n",
      "0.05117475986480713\n",
      "[Epoch 2.84] Train Loss: 0.0489  | Time: 6.54\n",
      "0.0524163581430912\n",
      "0.05137532949447632\n",
      "[Epoch 2.85] Train Loss: 0.0528  | Time: 6.64\n",
      "0.052856143563985825\n",
      "0.05155859887599945\n",
      "[Epoch 2.86] Train Loss: 0.0533  | Time: 6.55\n",
      "0.05325336009263992\n",
      "0.05172676965594292\n",
      "[Epoch 2.87] Train Loss: 0.0540  | Time: 6.57\n",
      "0.053591422736644745\n",
      "0.05187535658478737\n",
      "[Epoch 2.88] Train Loss: 0.0568  | Time: 6.56\n",
      "0.05389276519417763\n",
      "0.05200871452689171\n",
      "[Epoch 2.89] Train Loss: 0.0561  | Time: 6.52\n",
      "0.05416370555758476\n",
      "0.05212758481502533\n",
      "[Epoch 2.90] Train Loss: 0.0607  | Time: 6.57\n",
      "0.054403964430093765\n",
      "0.05222916975617409\n",
      "[Epoch 2.91] Train Loss: 0.0720  | Time: 6.64\n",
      "0.054644882678985596\n",
      "0.05232078209519386\n",
      "[Epoch 2.92] Train Loss: 0.0758  | Time: 6.49\n",
      "0.0548756904900074\n",
      "0.05240505561232567\n",
      "[Epoch 2.93] Train Loss: 0.0753  | Time: 6.78\n",
      "0.05507773905992508\n",
      "0.05247793346643448\n",
      "[Epoch 2.94] Train Loss: 0.0731  | Time: 6.71\n",
      "0.055266015231609344\n",
      "0.05254342034459114\n",
      "[Epoch 2.95] Train Loss: 0.0716  | Time: 7.50\n",
      "0.0554414764046669\n",
      "0.052603624761104584\n",
      "[Epoch 2.96] Train Loss: 0.0707  | Time: 6.49\n",
      "0.05561032518744469\n",
      "0.05266454070806503\n",
      "[Epoch 2.97] Train Loss: 0.0721  | Time: 6.59\n",
      "0.05578861013054848\n",
      "0.05272947996854782\n",
      "[Epoch 2.98] Train Loss: 0.0735  | Time: 6.63\n",
      "0.05598926171660423\n",
      "0.0528036430478096\n",
      "[Epoch 3.00] Train Loss: 0.0513  | Time: 6.69\n",
      "0.05621408298611641\n",
      "0.052829988300800323\n",
      "[Epoch 3.01] Train Loss: 0.0526  | Time: 6.34\n",
      "0.056456293910741806\n",
      "0.052819523960351944\n",
      "[Epoch 3.02] Train Loss: 0.0558  | Time: 6.33\n",
      "0.05672237277030945\n",
      "0.05278670787811279\n",
      "[Epoch 3.03] Train Loss: 0.0548  | Time: 6.37\n",
      "0.05700009688735008\n",
      "0.052744679152965546\n",
      "[Epoch 3.04] Train Loss: 0.0549  | Time: 6.39\n",
      "0.05728159472346306\n",
      "0.05270396173000336\n",
      "[Epoch 3.05] Train Loss: 0.0569  | Time: 6.29\n",
      "0.05755113810300827\n",
      "0.052676957100629807\n",
      "[Epoch 3.06] Train Loss: 0.0573  | Time: 6.36\n",
      "0.05781284719705582\n",
      "0.052664127200841904\n",
      "[Epoch 3.07] Train Loss: 0.0501  | Time: 6.36\n",
      "0.05806498974561691\n",
      "0.05266527459025383\n",
      "[Epoch 3.08] Train Loss: 0.0477  | Time: 6.50\n",
      "0.058310963213443756\n",
      "0.052676279097795486\n",
      "[Epoch 3.09] Train Loss: 0.0498  | Time: 6.51\n",
      "0.05855594575405121\n",
      "0.05270039662718773\n",
      "[Epoch 3.10] Train Loss: 0.0484  | Time: 6.39\n",
      "0.05880916863679886\n",
      "0.052738018333911896\n",
      "[Epoch 3.11] Train Loss: 0.0484  | Time: 6.29\n",
      "0.059077125042676926\n",
      "0.05278761312365532\n",
      "[Epoch 3.12] Train Loss: 0.0523  | Time: 6.40\n",
      "0.05938415229320526\n",
      "0.05285376310348511\n",
      "[Epoch 3.13] Train Loss: 0.0533  | Time: 6.38\n",
      "0.0597354993224144\n",
      "0.052941419184207916\n",
      "[Epoch 3.14] Train Loss: 0.0541  | Time: 6.56\n",
      "0.06013903766870499\n",
      "0.05305520445108414\n",
      "[Epoch 3.15] Train Loss: 0.0520  | Time: 6.32\n",
      "0.060576848685741425\n",
      "0.05319761484861374\n",
      "[Epoch 3.16] Train Loss: 0.0494  | Time: 6.35\n",
      "0.0610608235001564\n",
      "0.053367890417575836\n",
      "[Epoch 3.17] Train Loss: 0.0541  | Time: 6.34\n",
      "0.06158876046538353\n",
      "0.053562313318252563\n",
      "[Epoch 3.18] Train Loss: 0.0511  | Time: 6.44\n",
      "0.06217412278056145\n",
      "0.053781285881996155\n",
      "[Epoch 3.19] Train Loss: 0.0512  | Time: 6.36\n",
      "0.06282170116901398\n",
      "0.054031647741794586\n",
      "[Epoch 3.20] Train Loss: 0.0498  | Time: 6.34\n",
      "0.06350862979888916\n",
      "0.05431539937853813\n",
      "[Epoch 3.21] Train Loss: 0.0485  | Time: 6.37\n",
      "0.06423905491828918\n",
      "0.05463165044784546\n",
      "[Epoch 3.22] Train Loss: 0.0441  | Time: 6.35\n",
      "0.06496910750865936\n",
      "0.054968006908893585\n",
      "[Epoch 3.23] Train Loss: 0.0416  | Time: 6.38\n",
      "0.06570278108119965\n",
      "0.05532184615731239\n",
      "[Epoch 3.24] Train Loss: 0.0438  | Time: 6.42\n",
      "0.06643442809581757\n",
      "0.055687494575977325\n",
      "[Epoch 3.25] Train Loss: 0.0451  | Time: 6.37\n",
      "0.06713934987783432\n",
      "0.056056149303913116\n",
      "[Epoch 3.25] Train Loss: 0.0462  | Time: 6.35\n",
      "0.06779533624649048\n",
      "0.05641750246286392\n",
      "[Epoch 3.26] Train Loss: 0.0463  | Time: 6.62\n",
      "0.06837355345487595\n",
      "0.056749798357486725\n",
      "[Epoch 3.27] Train Loss: 0.0466  | Time: 6.40\n",
      "0.06887145340442657\n",
      "0.057044606655836105\n",
      "[Epoch 3.28] Train Loss: 0.0461  | Time: 6.41\n",
      "0.06925913691520691\n",
      "0.057284459471702576\n",
      "[Epoch 3.29] Train Loss: 0.0466  | Time: 6.37\n",
      "0.06947916746139526\n",
      "0.05744246765971184\n",
      "[Epoch 3.30] Train Loss: 0.0467  | Time: 6.37\n",
      "0.0695287212729454\n",
      "0.05751510336995125\n",
      "[Epoch 3.31] Train Loss: 0.0443  | Time: 6.39\n",
      "0.06941235065460205\n",
      "0.0575026273727417\n",
      "[Epoch 3.32] Train Loss: 0.0443  | Time: 6.34\n",
      "0.06914778798818588\n",
      "0.05741186812520027\n",
      "[Epoch 3.33] Train Loss: 0.0442  | Time: 6.31\n",
      "0.06877924501895905\n",
      "0.05726781487464905\n",
      "[Epoch 3.34] Train Loss: 0.0448  | Time: 6.33\n",
      "0.06832084059715271\n",
      "0.057080384343862534\n",
      "[Epoch 3.35] Train Loss: 0.0456  | Time: 6.34\n",
      "0.06777045130729675\n",
      "0.056851912289857864\n",
      "[Epoch 3.36] Train Loss: 0.0419  | Time: 6.37\n",
      "0.06718355417251587\n",
      "0.05661485344171524\n",
      "[Epoch 3.37] Train Loss: 0.0430  | Time: 6.57\n",
      "0.0665707141160965\n",
      "0.05636860430240631\n",
      "[Epoch 3.38] Train Loss: 0.0433  | Time: 6.34\n",
      "0.06591543555259705\n",
      "0.05610673502087593\n",
      "[Epoch 3.39] Train Loss: 0.0427  | Time: 6.35\n",
      "0.06525879353284836\n",
      "0.05584138631820679\n",
      "[Epoch 3.40] Train Loss: 0.0432  | Time: 6.35\n",
      "0.06461863219738007\n",
      "0.055571913719177246\n",
      "[Epoch 3.41] Train Loss: 0.0431  | Time: 6.86\n",
      "0.06402261555194855\n",
      "0.05530872941017151\n",
      "[Epoch 3.42] Train Loss: 0.0451  | Time: 6.35\n",
      "0.06347388029098511\n",
      "0.05505649372935295\n",
      "[Epoch 3.43] Train Loss: 0.0424  | Time: 6.58\n",
      "0.0629497841000557\n",
      "0.0548042356967926\n",
      "[Epoch 3.44] Train Loss: 0.0411  | Time: 7.42\n",
      "0.06242628023028374\n",
      "0.05454413592815399\n",
      "[Epoch 3.45] Train Loss: 0.0380  | Time: 6.47\n",
      "0.061898764222860336\n",
      "0.054273057729005814\n",
      "[Epoch 3.46] Train Loss: 0.0395  | Time: 6.57\n",
      "0.0613846518099308\n",
      "0.05399752035737038\n",
      "[Epoch 3.47] Train Loss: 0.0401  | Time: 6.36\n",
      "0.060866355895996094\n",
      "0.05370854213833809\n",
      "[Epoch 3.48] Train Loss: 0.0420  | Time: 6.46\n",
      "0.0603378526866436\n",
      "0.053405918180942535\n",
      "[Epoch 3.49] Train Loss: 0.0434  | Time: 6.37\n",
      "0.0597541406750679\n",
      "0.05308391526341438\n",
      "[Epoch 3.50] Train Loss: 0.0457  | Time: 6.35\n",
      "0.0591004341840744\n",
      "0.052740130573511124\n",
      "[Epoch 3.51] Train Loss: 0.0464  | Time: 6.36\n",
      "0.05839218571782112\n",
      "0.052383217960596085\n",
      "[Epoch 3.52] Train Loss: 0.0445  | Time: 6.68\n",
      "0.05765270069241524\n",
      "0.052023857831954956\n",
      "[Epoch 3.53] Train Loss: 0.0444  | Time: 6.72\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ba563ced5277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[1;34mf'[Epoch {i:.2f}] Train Loss: {qry_losses:.4f}  | Time: {iter_time:.2f}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             )\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data_ML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_inner_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_ML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_inner_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-8993b7944e46>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, test_data_ML, horizon, n_inner_iter)\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mspt_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_spt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mspt_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspt_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mdiffopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspt_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;31m# The query loss and acc induced by these parameters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\higher\\optim.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, loss, params, override, grad_callback, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mgrad_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_track_higher_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mallow_unused\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m  \u001b[1;31m# boo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         )\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "batch_size = 20\n",
    "n_iterations = 10\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "\n",
    "    n_train_iter = train_data_ML.x.shape[0] // batch_size\n",
    "\n",
    "    for batch_idx in range(n_train_iter-1):\n",
    "        start_time = time.time()\n",
    "        # Sample a batch of support and query images and labels.\n",
    "\n",
    "        x_spt, y_spt = train_data_ML[batch_idx:batch_size+batch_idx]\n",
    "        x_qry, y_qry = train_data_ML[batch_idx+1 : batch_idx+batch_size+1]\n",
    "        \n",
    "        x_spt, y_spt = to_torch(x_spt), to_torch(y_spt)\n",
    "        x_qry = to_torch(x_qry)\n",
    "        y_qry = to_torch(y_qry)\n",
    "        \n",
    "        task_num, setsz, c_, w = x_spt.size()\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        # TODO: Maybe pull this out into a separate module so it\n",
    "        # doesn't have to be duplicated between `train` and `test`?\n",
    "\n",
    "        # Initialize the inner optimizer to adapt the parameters to\n",
    "        # the support set.\n",
    "        n_inner_iter = 5\n",
    "        inner_opt = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "        qry_losses = []\n",
    "        meta_opt.zero_grad()\n",
    "        for i in range(task_num):\n",
    "            with higher.innerloop_ctx(\n",
    "                model, inner_opt, copy_initial_weights=False\n",
    "            ) as (fnet, diffopt):\n",
    "                # Optimize the likelihood of the support set by taking\n",
    "                # gradient steps w.r.t. the model's parameters.\n",
    "                # This adapts the model's meta-parameters to the task.\n",
    "                # higher is able to automatically keep copies of\n",
    "                # your network's parameters as they are being updated.\n",
    "                for _ in range(n_inner_iter):\n",
    "                    spt_logits = fnet(x_spt[i])\n",
    "                    spt_loss = mae(spt_logits, y_spt[i])\n",
    "                    diffopt.step(spt_loss)\n",
    "\n",
    "                # The final set of adapted parameters will induce some\n",
    "                # final loss and accuracy on the query dataset.\n",
    "                # These will be used to update the model's meta-parameters.\n",
    "                qry_logits = fnet(x_qry[i])\n",
    "                qry_loss = mae(qry_logits, y_qry[i])\n",
    "                qry_losses.append(qry_loss.detach())\n",
    "\n",
    "                # Update the model's meta-parameters to optimize the query\n",
    "                # losses across all of the tasks sampled in this batch.\n",
    "                # This unrolls through the gradient steps.\n",
    "                qry_loss.backward()\n",
    "\n",
    "        meta_opt.step()\n",
    "        qry_losses = sum(qry_losses) / task_num\n",
    "        i = epoch + float(batch_idx) / n_train_iter\n",
    "        iter_time = time.time() - start_time\n",
    "        if batch_idx % 1 == 0:\n",
    "            print(\n",
    "                f'[Epoch {i:.2f}] Train Loss: {qry_losses:.4f}  | Time: {iter_time:.2f}'\n",
    "            )\n",
    "            test(model, validation_data_ML, horizon, n_inner_iter)\n",
    "            test(model, test_data_ML, horizon, n_inner_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
