{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the conditional layer without MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import learn2learn as l2l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "from ts_dataset import TSDataset\n",
    "from base_models import LSTMModel, FCN\n",
    "from metrics import torch_mae as mae\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = \"HR\"\n",
    "dataset_name = \"POLLUTION\"\n",
    "window_size = 32\n",
    "window_size = 5\n",
    "task_size = 50\n",
    "batch_size = 64\n",
    "input_dim = 13\n",
    "input_dim = 14\n",
    "output_dim = 1\n",
    "hidden_dim = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(  open( \"../../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "train_data_ML = pickle.load( open( \"../../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "validation_data = pickle.load( open( \"../../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "validation_data_ML = pickle.load( open( \"../../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "test_data_ML = pickle.load( open( \"../../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_encoder_input(data_ML):\n",
    "    \n",
    "    task_encoder_input = np.concatenate((data_ML.x[:,:,0,:], data_ML.y), axis=2)\n",
    "    \n",
    "    return task_encoder_input\n",
    "\n",
    "\n",
    "   \n",
    "class LSTMDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, seq_len, output_dim, n_layers, hidden_dim, latent_dim, device):\n",
    "        \n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.sequence_length = seq_len\n",
    "        \n",
    "        self.lstm = nn.LSTM(1, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        self.latent_to_hidden = nn.Linear(self.latent_dim, self.hidden_dim)\n",
    "        self.hidden_to_output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "    \n",
    "        self.decoder_inputs = torch.zeros( self.batch_size, self.sequence_length, 1, requires_grad=True).to(device)\n",
    "        self.c_0 = torch.zeros(self.n_layers, self.batch_size, self.hidden_dim, requires_grad=True).to(device)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.latent_to_hidden.weight)\n",
    "        nn.init.xavier_uniform_(self.hidden_to_output.weight)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, latent):\n",
    "        \n",
    "        h_state = self.latent_to_hidden(latent).unsqueeze(0)\n",
    "        h_0 = torch.cat([h_state for _ in range(self.n_layers)], axis=0)\n",
    "        decoder_output, _ = self.lstm(self.decoder_inputs, (h_0, self.c_0))\n",
    "        out = self.hidden_to_output(decoder_output)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "\n",
    "    \"\"\"Lambda module converts output of encoder to latent vector\n",
    "\n",
    "    :param hidden_size: hidden size of the encoder\n",
    "    :param latent_length: latent vector length\n",
    "    https://github.com/abhmalik/timeseries-clustering-vae/blob/master/vrae/vrae.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, latent_dim):\n",
    "\n",
    "        super(Lambda, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.hidden_to_mean = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "        self.hidden_to_logvar = nn.Linear(self.hidden_dim, self.latent_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.hidden_to_mean.weight)\n",
    "        nn.init.xavier_uniform_(self.hidden_to_logvar.weight)\n",
    "\n",
    "\n",
    "    def forward(self, cell_output):\n",
    "\n",
    "        \"\"\"Given last hidden state of encoder, passes through a linear layer, and finds the mean and variance\n",
    "\n",
    "        :param cell_output: last hidden state of encoder\n",
    "        :return: latent vector\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.latent_mean = self.hidden_to_mean(cell_output)\n",
    "        self.latent_logvar = self.hidden_to_logvar(cell_output)\n",
    "\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * self.latent_logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(self.latent_mean)\n",
    "        else:\n",
    "            return self.latent_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramters wto increase capactiy of the model\n",
    "n_layers_task_net = 2\n",
    "n_layers_task_encoder = 1\n",
    "n_layers_task_decoder = 1\n",
    "\n",
    "hidden_dim_task_net = 120\n",
    "hidden_dim_encoder = 120\n",
    "hidden_dim_decoder = 120\n",
    "\n",
    "#fixed values\n",
    "input_dim_task_net = input_dim\n",
    "input_dim_task_encoder = input_dim +1 \n",
    "output_dim_task_net = 1\n",
    "output_dim_task_decoder = input_dim+1\n",
    "\n",
    "        \n",
    "total_tasks = len(train_data_ML)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class MultimodalLearner(nn.Module):\n",
    "    \n",
    "    def __init__(self, task_net, task_encoder, task_decoder, lmbd):\n",
    "        \n",
    "        super(MultimodalLearner, self).__init__()\n",
    "        \n",
    "        self.task_net = task_net\n",
    "        self.task_encoder = task_encoder\n",
    "        self.task_decoder = task_decoder\n",
    "        self.lmbd = lmbd\n",
    "        self.modulation_layer = nn.Linear(task_encoder.hidden_dim, task_net.hidden_dim*2)\n",
    "        self.output_layer = nn.Linear(task_net.hidden_dim, 1)\n",
    "        self.task_decoder = task_decoder\n",
    "        self.rec_loss = nn.SmoothL1Loss(size_average=False)\n",
    "    \n",
    "    \n",
    "    def conditional_layer(self, x, embedding):\n",
    "        \n",
    "        ###apply by deffault the affine transformation -- FiLM layer\n",
    "        \n",
    "        gammas, betas = torch.split(embedding, x.size(1), dim=-1)\n",
    "        gammas = gammas + torch.ones_like(gammas)\n",
    "        x = x*gammas + betas\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def compute_loss(self, x_decoded, x):\n",
    "        \n",
    "        \n",
    "        latent_mean, latent_logvar = self.lmbd.latent_mean, self.lmbd.latent_logvar\n",
    "        kl_loss = -0.5 * torch.mean(1 + latent_logvar - latent_mean.pow(2) - latent_logvar.exp())\n",
    "        recon_loss = self.rec_loss(x_decoded, x)\n",
    "        \n",
    "        return recon_loss + kl_loss, kl_loss, recon_loss\n",
    "    \n",
    "    def forward (self, x, task, params=None, embeddings=None):\n",
    "        \n",
    "        if params is None:\n",
    "            params = OrderedDict(self.named_parameters())\n",
    "            \n",
    "        x = self.task_net.encoder(x)\n",
    "        encoding = self.task_encoder.encoder(task)\n",
    "        latent = self.lmbd(encoding)\n",
    "        task_rec = self.task_decoder(latent)\n",
    "        \n",
    "        modulation_embeddings = self.modulation_layer(encoding)\n",
    "        modulated_output = self.conditional_layer(x, modulation_embeddings)\n",
    "        output = self.output_layer(modulated_output)\n",
    "        \n",
    "        loss = self.compute_loss(task_rec, task)\n",
    "        \n",
    "        return output, loss\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VWG3APX\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss: tensor(137.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.10034741611175593\n",
      "Test loss: 0.13116203178421104\n",
      "Epoch: 1\n",
      "Train loss: tensor(295.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0950062658504716\n",
      "Test loss: 0.12437941926983323\n",
      "Epoch: 2\n",
      "Train loss: tensor(482.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.08995051254917469\n",
      "Test loss: 0.11784783341359384\n",
      "Epoch: 3\n",
      "Train loss: tensor(101.6671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0850523332311284\n",
      "Test loss: 0.11164504201105326\n",
      "Epoch: 4\n",
      "Train loss: tensor(314.3843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.08016593380875531\n",
      "Test loss: 0.10535934998995007\n",
      "Epoch: 5\n",
      "Train loss: tensor(172.1096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07578379501189504\n",
      "Test loss: 0.09970334620390198\n",
      "Epoch: 6\n",
      "Train loss: tensor(192.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0714958704564543\n",
      "Test loss: 0.09437421117309887\n",
      "Epoch: 7\n",
      "Train loss: tensor(185.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06744974579307295\n",
      "Test loss: 0.08945235333377773\n",
      "Epoch: 8\n",
      "Train loss: tensor(156.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06360351818480663\n",
      "Test loss: 0.08486886798302726\n",
      "Epoch: 9\n",
      "Train loss: tensor(132.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0599403735338932\n",
      "Test loss: 0.08054556601708478\n",
      "Epoch: 10\n",
      "Train loss: tensor(100.6085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05638970510945434\n",
      "Test loss: 0.0764018544687493\n",
      "Epoch: 11\n",
      "Train loss: tensor(346.0202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053163705642024675\n",
      "Test loss: 0.07245693776277032\n",
      "Epoch: 12\n",
      "Train loss: tensor(336.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05043197500386409\n",
      "Test loss: 0.06906854139991325\n",
      "Epoch: 13\n",
      "Train loss: tensor(123.6393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047489809289219836\n",
      "Test loss: 0.06559827626858017\n",
      "Epoch: 14\n",
      "Train loss: tensor(239.4623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044765005854978446\n",
      "Test loss: 0.062288280004764544\n",
      "Epoch: 15\n",
      "Train loss: tensor(287.5816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04230639551367078\n",
      "Test loss: 0.058942569262984364\n",
      "Epoch: 16\n",
      "Train loss: tensor(183.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040159529935391174\n",
      "Test loss: 0.05601058991644347\n",
      "Epoch: 17\n",
      "Train loss: tensor(157.1742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03808971708196969\n",
      "Test loss: 0.05316412829711001\n",
      "Epoch: 18\n",
      "Train loss: tensor(398.6078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036531407953727814\n",
      "Test loss: 0.050924420513507755\n",
      "Epoch: 19\n",
      "Train loss: tensor(152.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03527693345787979\n",
      "Test loss: 0.049059226555694446\n",
      "Epoch: 20\n",
      "Train loss: tensor(129.2989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034368107645284564\n",
      "Test loss: 0.04755076584360092\n",
      "Loss this time: tensor(153.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 21\n",
      "Train loss: tensor(153.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03378704334830954\n",
      "Test loss: 0.046397459730137106\n",
      "Epoch: 22\n",
      "Train loss: tensor(268.8873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03338815727758975\n",
      "Test loss: 0.045466658650058334\n",
      "Epoch: 23\n",
      "Train loss: tensor(203.1446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03314420653152324\n",
      "Test loss: 0.04473819947884519\n",
      "Epoch: 24\n",
      "Train loss: tensor(329.4235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03335834215616896\n",
      "Test loss: 0.04428744050535825\n",
      "Epoch: 25\n",
      "Train loss: tensor(108.3762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03378190052296434\n",
      "Test loss: 0.044123351085230265\n",
      "Epoch: 26\n",
      "Train loss: tensor(146.8238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034370465275077595\n",
      "Test loss: 0.04417239399719061\n",
      "Epoch: 27\n",
      "Train loss: tensor(161.9477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035153488859179474\n",
      "Test loss: 0.0444130817299137\n",
      "Epoch: 28\n",
      "Train loss: tensor(183.4670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03586813638962451\n",
      "Test loss: 0.0446973946314342\n",
      "Epoch: 29\n",
      "Train loss: tensor(164.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03671027742592352\n",
      "Test loss: 0.045104930776696986\n",
      "Epoch: 30\n",
      "Train loss: tensor(272.3246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037508870962829816\n",
      "Test loss: 0.04553206837597755\n",
      "Epoch: 31\n",
      "Train loss: tensor(114.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038146942836188136\n",
      "Test loss: 0.04588163720609823\n",
      "Epoch: 32\n",
      "Train loss: tensor(339.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03910794835981159\n",
      "Test loss: 0.046512431649509633\n",
      "Epoch: 33\n",
      "Train loss: tensor(177.9982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040097299595141696\n",
      "Test loss: 0.04718803084169579\n",
      "Epoch: 34\n",
      "Train loss: tensor(244.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04116911122220613\n",
      "Test loss: 0.047952370920983874\n",
      "Epoch: 35\n",
      "Train loss: tensor(202.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041618491154873656\n",
      "Test loss: 0.04845479645277604\n",
      "Epoch: 36\n",
      "Train loss: tensor(142.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04211437948757694\n",
      "Test loss: 0.048992555496273654\n",
      "Epoch: 37\n",
      "Train loss: tensor(137.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042838766532284876\n",
      "Test loss: 0.0497342012822628\n",
      "Epoch: 38\n",
      "Train loss: tensor(174.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043709412634017925\n",
      "Test loss: 0.05058609214749667\n",
      "Epoch: 39\n",
      "Train loss: tensor(200.6481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04450600233283781\n",
      "Test loss: 0.05138030233285805\n",
      "Epoch: 40\n",
      "Train loss: tensor(210.8820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04473571524556194\n",
      "Test loss: 0.05170573723862077\n",
      "Epoch: 41\n",
      "Train loss: tensor(172.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044783392424384755\n",
      "Test loss: 0.05187416209442781\n",
      "Epoch: 42\n",
      "Train loss: tensor(153.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04498133183057819\n",
      "Test loss: 0.052157798450034445\n",
      "Epoch: 43\n",
      "Train loss: tensor(229.4104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04508586067351557\n",
      "Test loss: 0.05235076308397964\n",
      "Epoch: 44\n",
      "Train loss: tensor(219.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04522858601773069\n",
      "Test loss: 0.05256089831859168\n",
      "Epoch: 45\n",
      "Train loss: tensor(269.3992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045330944630716526\n",
      "Test loss: 0.05271992607429476\n",
      "Epoch: 46\n",
      "Train loss: tensor(220.9249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045378233802815277\n",
      "Test loss: 0.052825257919802526\n",
      "Epoch: 47\n",
      "Train loss: tensor(126.2575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04501520600169897\n",
      "Test loss: 0.052587605607096514\n",
      "Epoch: 48\n",
      "Train loss: tensor(107.8397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04449132880462067\n",
      "Test loss: 0.05220033457078556\n",
      "Epoch: 49\n",
      "Train loss: tensor(204.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04400211271962949\n",
      "Test loss: 0.05183605923511014\n",
      "Epoch: 50\n",
      "Train loss: tensor(109.0330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04350887295745668\n",
      "Test loss: 0.05146510050733491\n",
      "Epoch: 51\n",
      "Train loss: tensor(123.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042799428939109756\n",
      "Test loss: 0.05094139384898809\n",
      "Epoch: 52\n",
      "Train loss: tensor(477.4618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04160842120292641\n",
      "Test loss: 0.049984410737115556\n",
      "Epoch: 53\n",
      "Train loss: tensor(186.5432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040463344078688394\n",
      "Test loss: 0.04906883120241732\n",
      "Epoch: 54\n",
      "Train loss: tensor(174.7465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03941932672723418\n",
      "Test loss: 0.04822798224516434\n",
      "Epoch: 55\n",
      "Train loss: tensor(186.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03853048100357964\n",
      "Test loss: 0.047514462124298114\n",
      "Epoch: 56\n",
      "Train loss: tensor(161.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037561576813459396\n",
      "Test loss: 0.04676075515770676\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(221.5992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03663891919312023\n",
      "Test loss: 0.04607353486710846\n",
      "Loss this time: tensor(310.5414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 58\n",
      "Train loss: tensor(310.5414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03562309459916183\n",
      "Test loss: 0.04537877073456155\n",
      "Epoch: 59\n",
      "Train loss: tensor(119.9283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03486887569583598\n",
      "Test loss: 0.044872102051014356\n",
      "Epoch: 60\n",
      "Train loss: tensor(176.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034412494488060476\n",
      "Test loss: 0.04460362335759224\n",
      "Epoch: 61\n",
      "Train loss: tensor(166.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03401348026735442\n",
      "Test loss: 0.044385007693257074\n",
      "Epoch: 62\n",
      "Train loss: tensor(208.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03404702906097685\n",
      "Test loss: 0.04438117022008294\n",
      "Epoch: 63\n",
      "Train loss: tensor(384.1505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0341565486575876\n",
      "Test loss: 0.04440792526422751\n",
      "Epoch: 64\n",
      "Train loss: tensor(140.8396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034377261543912546\n",
      "Test loss: 0.044513113492417454\n",
      "Epoch: 65\n",
      "Train loss: tensor(172.2409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03454044919815801\n",
      "Test loss: 0.04458362952169805\n",
      "Epoch: 66\n",
      "Train loss: tensor(292.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03441077253470818\n",
      "Test loss: 0.04448683360720625\n",
      "Epoch: 67\n",
      "Train loss: tensor(394.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03420970523286433\n",
      "Test loss: 0.04435162386386701\n",
      "Epoch: 68\n",
      "Train loss: tensor(156.1376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0340569274854802\n",
      "Test loss: 0.04422308764614091\n",
      "Epoch: 69\n",
      "Train loss: tensor(246.7204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03460291941605863\n",
      "Test loss: 0.044549427115091\n",
      "Epoch: 70\n",
      "Train loss: tensor(184.3435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03502797762907687\n",
      "Test loss: 0.04481210412070303\n",
      "Epoch: 71\n",
      "Train loss: tensor(243.9016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035475929045961016\n",
      "Test loss: 0.04512703267507034\n",
      "Epoch: 72\n",
      "Train loss: tensor(189.9184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0360095054798183\n",
      "Test loss: 0.04553344554387697\n",
      "Epoch: 73\n",
      "Train loss: tensor(142.4201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0369413802311534\n",
      "Test loss: 0.04630081823999339\n",
      "Epoch: 74\n",
      "Train loss: tensor(170.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03758242071739265\n",
      "Test loss: 0.046881861744983364\n",
      "Epoch: 75\n",
      "Train loss: tensor(153.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0380137189956648\n",
      "Test loss: 0.047315909942187886\n",
      "Epoch: 76\n",
      "Train loss: tensor(132.5758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038333328990709216\n",
      "Test loss: 0.0476446110054408\n",
      "Epoch: 77\n",
      "Train loss: tensor(176.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03854057669994377\n",
      "Test loss: 0.047878172875630974\n",
      "Epoch: 78\n",
      "Train loss: tensor(142.9522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03859453493995326\n",
      "Test loss: 0.04797887370580494\n",
      "Epoch: 79\n",
      "Train loss: tensor(146.7019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038549849834470525\n",
      "Test loss: 0.04800517755643566\n",
      "Epoch: 80\n",
      "Train loss: tensor(277.7071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0392154877916688\n",
      "Test loss: 0.04861325173094721\n",
      "Epoch: 81\n",
      "Train loss: tensor(336.8323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039393168386249316\n",
      "Test loss: 0.04881192937419556\n",
      "Loss this time: tensor(167.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 82\n",
      "Train loss: tensor(167.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0395060951244973\n",
      "Test loss: 0.04894838046909559\n",
      "Epoch: 83\n",
      "Train loss: tensor(145.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03962155706470921\n",
      "Test loss: 0.04908353638014581\n",
      "Epoch: 84\n",
      "Train loss: tensor(148.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039674167955915135\n",
      "Test loss: 0.04916679231210215\n",
      "Epoch: 85\n",
      "Train loss: tensor(188.4318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03945038976768653\n",
      "Test loss: 0.04897238087314781\n",
      "Epoch: 86\n",
      "Train loss: tensor(329.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039247648293773335\n",
      "Test loss: 0.04878502849046842\n",
      "Epoch: 87\n",
      "Train loss: tensor(156.6774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039110432166074\n",
      "Test loss: 0.04865481010131022\n",
      "Epoch: 88\n",
      "Train loss: tensor(160.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0390019214756432\n",
      "Test loss: 0.04854857085254228\n",
      "Epoch: 89\n",
      "Train loss: tensor(172.2414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03896120776910157\n",
      "Test loss: 0.0484997154130499\n",
      "Epoch: 90\n",
      "Train loss: tensor(311.2364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03898705758509182\n",
      "Test loss: 0.048530132546652074\n",
      "Epoch: 91\n",
      "Train loss: tensor(192.7901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038735867522302125\n",
      "Test loss: 0.048290501662188824\n",
      "Epoch: 92\n",
      "Train loss: tensor(162.1573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03839778084130514\n",
      "Test loss: 0.04798791453352954\n",
      "Epoch: 93\n",
      "Train loss: tensor(154.3385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03838740847117844\n",
      "Test loss: 0.04797109682112932\n",
      "Epoch: 94\n",
      "Train loss: tensor(139.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0382601021833363\n",
      "Test loss: 0.04785913287081046\n",
      "Epoch: 95\n",
      "Train loss: tensor(195.5161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03804806963141475\n",
      "Test loss: 0.04763902192658717\n",
      "Epoch: 96\n",
      "Train loss: tensor(93.3741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037883099133060094\n",
      "Test loss: 0.04745459948472752\n",
      "Epoch: 97\n",
      "Train loss: tensor(290.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03784811613815171\n",
      "Test loss: 0.04741375661906925\n",
      "Epoch: 98\n",
      "Train loss: tensor(162.6655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03775023018852586\n",
      "Test loss: 0.047294004801845195\n",
      "Epoch: 99\n",
      "Train loss: tensor(477.0280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03729629272683745\n",
      "Test loss: 0.046664318069815636\n",
      "Epoch: 100\n",
      "Train loss: tensor(213.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037053402122997105\n",
      "Test loss: 0.04624130523367093\n",
      "Epoch: 101\n",
      "Train loss: tensor(243.9367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03692924814032657\n",
      "Test loss: 0.04598690001386227\n",
      "Epoch: 102\n",
      "Train loss: tensor(145.1892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03682252666247743\n",
      "Test loss: 0.045761401654396315\n",
      "Epoch: 103\n",
      "Train loss: tensor(130.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03661281328116144\n",
      "Test loss: 0.04545491274520017\n",
      "Epoch: 104\n",
      "Train loss: tensor(269.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0368259976751038\n",
      "Test loss: 0.0456146679099391\n",
      "Epoch: 105\n",
      "Train loss: tensor(181.0084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036949008233135655\n",
      "Test loss: 0.0456876383799285\n",
      "Epoch: 106\n",
      "Train loss: tensor(204.1560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0369708051461549\n",
      "Test loss: 0.04567847995659207\n",
      "Epoch: 107\n",
      "Train loss: tensor(304.6962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0370149545282835\n",
      "Test loss: 0.045680795916088736\n",
      "Epoch: 108\n",
      "Train loss: tensor(228.4013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037032362082529635\n",
      "Test loss: 0.04565730082369087\n",
      "Epoch: 109\n",
      "Train loss: tensor(302.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036959652593802836\n",
      "Test loss: 0.04550687236582289\n",
      "Epoch: 110\n",
      "Train loss: tensor(312.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0366715900245167\n",
      "Test loss: 0.04510254022840521\n",
      "Epoch: 111\n",
      "Train loss: tensor(169.5987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036413130731809705\n",
      "Test loss: 0.04472976208360183\n",
      "Epoch: 112\n",
      "Train loss: tensor(108.3201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03616745255532719\n",
      "Test loss: 0.044376497129255\n",
      "Epoch: 113\n",
      "Train loss: tensor(163.6188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03629579453596047\n",
      "Test loss: 0.0444418172361237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114\n",
      "Train loss: tensor(140.8803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03639985510103759\n",
      "Test loss: 0.04447941759619677\n",
      "Epoch: 115\n",
      "Train loss: tensor(172.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03640673548160564\n",
      "Test loss: 0.044413094666998575\n",
      "Epoch: 116\n",
      "Train loss: tensor(264.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03627812550181434\n",
      "Test loss: 0.04418956611932504\n",
      "Epoch: 117\n",
      "Train loss: tensor(125.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03617619339908872\n",
      "Test loss: 0.04401427158846123\n",
      "Epoch: 118\n",
      "Train loss: tensor(288.2826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036167434301404726\n",
      "Test loss: 0.043956309593845125\n",
      "Epoch: 119\n",
      "Train loss: tensor(169.7174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03619150503405503\n",
      "Test loss: 0.04393365814138462\n",
      "Epoch: 120\n",
      "Train loss: tensor(171.6795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036216007669766744\n",
      "Test loss: 0.04391515576787809\n",
      "Epoch: 121\n",
      "Train loss: tensor(171.1015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036379631289413995\n",
      "Test loss: 0.044073846034410565\n",
      "Epoch: 122\n",
      "Train loss: tensor(231.4743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0366577275984344\n",
      "Test loss: 0.04434464723425041\n",
      "Epoch: 123\n",
      "Train loss: tensor(166.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036899216437623616\n",
      "Test loss: 0.044576945871409805\n",
      "Epoch: 124\n",
      "Train loss: tensor(269.0718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037076272593722454\n",
      "Test loss: 0.04474329907852825\n",
      "Epoch: 125\n",
      "Train loss: tensor(126.8336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037264176085591315\n",
      "Test loss: 0.04492520633162839\n",
      "Epoch: 126\n",
      "Train loss: tensor(174.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037574290342274164\n",
      "Test loss: 0.045266880626135535\n",
      "Epoch: 127\n",
      "Train loss: tensor(285.6462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037828970345712844\n",
      "Test loss: 0.04552376867816\n",
      "Epoch: 128\n",
      "Train loss: tensor(209.4146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037842754948706855\n",
      "Test loss: 0.045477403770431434\n",
      "Epoch: 129\n",
      "Train loss: tensor(191.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03785240308692058\n",
      "Test loss: 0.045428541442840406\n",
      "Epoch: 130\n",
      "Train loss: tensor(186.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03786178193099442\n",
      "Test loss: 0.045382380476313655\n",
      "Epoch: 131\n",
      "Train loss: tensor(326.0412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0380298117353093\n",
      "Test loss: 0.04559547394182127\n",
      "Epoch: 132\n",
      "Train loss: tensor(149.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038151024654507634\n",
      "Test loss: 0.04575597053153975\n",
      "Epoch: 133\n",
      "Train loss: tensor(332.0915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038068846834912184\n",
      "Test loss: 0.045639937937185904\n",
      "Epoch: 134\n",
      "Train loss: tensor(195.8554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037992880174091886\n",
      "Test loss: 0.045536636891267676\n",
      "Epoch: 135\n",
      "Train loss: tensor(335.5071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037943723735709985\n",
      "Test loss: 0.04546416975041427\n",
      "Epoch: 136\n",
      "Train loss: tensor(90.7664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03789187051533233\n",
      "Test loss: 0.04538955614155177\n",
      "Epoch: 137\n",
      "Train loss: tensor(226.6993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03823549986063015\n",
      "Test loss: 0.04577551650270672\n",
      "Epoch: 138\n",
      "Train loss: tensor(106.8191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03850128090097791\n",
      "Test loss: 0.04606487780883171\n",
      "Epoch: 139\n",
      "Train loss: tensor(174.2963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038641588762402534\n",
      "Test loss: 0.046203277866807904\n",
      "Epoch: 140\n",
      "Train loss: tensor(145.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03950179863188948\n",
      "Test loss: 0.04707625364460567\n",
      "Epoch: 141\n",
      "Train loss: tensor(382.9386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04026063067749852\n",
      "Test loss: 0.047827179626663135\n",
      "Epoch: 142\n",
      "Train loss: tensor(207.9562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0408348475095062\n",
      "Test loss: 0.048327038341229506\n",
      "Epoch: 143\n",
      "Train loss: tensor(135.1369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04124557144407715\n",
      "Test loss: 0.04867319080351603\n",
      "Epoch: 144\n",
      "Train loss: tensor(138.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041402524754050235\n",
      "Test loss: 0.04877493434613294\n",
      "Epoch: 145\n",
      "Train loss: tensor(549.7784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041448524168559486\n",
      "Test loss: 0.04872654804425074\n",
      "Epoch: 146\n",
      "Train loss: tensor(129.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04137619999902589\n",
      "Test loss: 0.04856190489291554\n",
      "Epoch: 147\n",
      "Train loss: tensor(180.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04110667504192818\n",
      "Test loss: 0.04823825113696627\n",
      "Epoch: 148\n",
      "Train loss: tensor(155.7034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04081375396677426\n",
      "Test loss: 0.04789239366418949\n",
      "Epoch: 149\n",
      "Train loss: tensor(110.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04044125658415613\n",
      "Test loss: 0.04745195240778203\n",
      "Epoch: 150\n",
      "Train loss: tensor(211.9909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040236753172108106\n",
      "Test loss: 0.04721284500037384\n",
      "Epoch: 151\n",
      "Train loss: tensor(127.7911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03992532924527214\n",
      "Test loss: 0.04686739686692115\n",
      "Epoch: 152\n",
      "Train loss: tensor(338.4358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039671106201906996\n",
      "Test loss: 0.04649002004488565\n",
      "Epoch: 153\n",
      "Train loss: tensor(170.3572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039388330724267735\n",
      "Test loss: 0.046106535341996366\n",
      "Epoch: 154\n",
      "Train loss: tensor(202.9368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03904930424122583\n",
      "Test loss: 0.04568288940014226\n",
      "Epoch: 155\n",
      "Train loss: tensor(186.4732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0387420242652297\n",
      "Test loss: 0.04528009135386731\n",
      "Epoch: 156\n",
      "Train loss: tensor(169.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038461955831873985\n",
      "Test loss: 0.044905781875004866\n",
      "Epoch: 157\n",
      "Train loss: tensor(109.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03816467882799251\n",
      "Test loss: 0.04451992979623599\n",
      "Epoch: 158\n",
      "Train loss: tensor(199.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03806063893827654\n",
      "Test loss: 0.04441599923158341\n",
      "Loss this time: tensor(181.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 159\n",
      "Train loss: tensor(181.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0379870153786171\n",
      "Test loss: 0.04434928886297316\n",
      "Epoch: 160\n",
      "Train loss: tensor(289.0793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03798536072884287\n",
      "Test loss: 0.04435820474593651\n",
      "Loss this time: tensor(212.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 161\n",
      "Train loss: tensor(212.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03801840240401881\n",
      "Test loss: 0.044402197805592916\n",
      "Epoch: 162\n",
      "Train loss: tensor(176.7453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03798607420176268\n",
      "Test loss: 0.044377968886332345\n",
      "Epoch: 163\n",
      "Train loss: tensor(161.8128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037943486301671894\n",
      "Test loss: 0.04434004422314096\n",
      "Epoch: 164\n",
      "Train loss: tensor(201.1420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03790498898320255\n",
      "Test loss: 0.04431412400364285\n",
      "Epoch: 165\n",
      "Train loss: tensor(159.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03783325902408077\n",
      "Test loss: 0.04423908867163233\n",
      "Epoch: 166\n",
      "Train loss: tensor(165.5999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03777924423061666\n",
      "Test loss: 0.0441792333996532\n",
      "Epoch: 167\n",
      "Train loss: tensor(135.8117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037699482031166555\n",
      "Test loss: 0.044081393066830565\n",
      "Epoch: 168\n",
      "Train loss: tensor(159.8766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03761907336967332\n",
      "Test loss: 0.04398151039892789\n",
      "Epoch: 169\n",
      "Train loss: tensor(179.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037525714614561625\n",
      "Test loss: 0.04386767136430977\n",
      "Epoch: 170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(136.0705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03735593787970997\n",
      "Test loss: 0.04364245582261298\n",
      "Epoch: 171\n",
      "Train loss: tensor(139.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03731314927516949\n",
      "Test loss: 0.04358037960448182\n",
      "Epoch: 172\n",
      "Train loss: tensor(121.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037276178633882884\n",
      "Test loss: 0.04352693085438839\n",
      "Epoch: 173\n",
      "Train loss: tensor(155.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03724304164449374\n",
      "Test loss: 0.043472202771370955\n",
      "Epoch: 174\n",
      "Train loss: tensor(167.5544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03721808345012721\n",
      "Test loss: 0.0434308761620138\n",
      "Epoch: 175\n",
      "Train loss: tensor(195.0032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03718262483321485\n",
      "Test loss: 0.04340668653350065\n",
      "Epoch: 176\n",
      "Train loss: tensor(319.7758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03715599950935159\n",
      "Test loss: 0.04334225917769836\n",
      "Epoch: 177\n",
      "Train loss: tensor(208.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03719240535228025\n",
      "Test loss: 0.04340448702620988\n",
      "Epoch: 178\n",
      "Train loss: tensor(189.6256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037232138801898275\n",
      "Test loss: 0.04348072825497625\n",
      "Epoch: 179\n",
      "Train loss: tensor(136.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03720873288278069\n",
      "Test loss: 0.043464340112808315\n",
      "Epoch: 180\n",
      "Train loss: tensor(287.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037187254828001774\n",
      "Test loss: 0.04344678069879808\n",
      "Loss this time: tensor(140.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 181\n",
      "Train loss: tensor(140.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037164636763433616\n",
      "Test loss: 0.04353668362750571\n",
      "Epoch: 182\n",
      "Train loss: tensor(286.2602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037384664471305555\n",
      "Test loss: 0.04387073855072555\n",
      "Epoch: 183\n",
      "Train loss: tensor(136.0179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037494605646601745\n",
      "Test loss: 0.044032873567378165\n",
      "Epoch: 184\n",
      "Train loss: tensor(131.8417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037585398661238806\n",
      "Test loss: 0.04416675849052349\n",
      "Epoch: 185\n",
      "Train loss: tensor(326.7303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03763773887462559\n",
      "Test loss: 0.04425948579786437\n",
      "Epoch: 186\n",
      "Train loss: tensor(185.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03765816493403344\n",
      "Test loss: 0.04431044494751656\n",
      "Epoch: 187\n",
      "Train loss: tensor(247.9673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03762588136430298\n",
      "Test loss: 0.044293810991515026\n",
      "Epoch: 188\n",
      "Train loss: tensor(132.8269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03774682737532116\n",
      "Test loss: 0.04446428837162433\n",
      "Epoch: 189\n",
      "Train loss: tensor(338.9532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037777519234943956\n",
      "Test loss: 0.04432473112229664\n",
      "Epoch: 190\n",
      "Train loss: tensor(168.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037806877600295205\n",
      "Test loss: 0.04419499707620333\n",
      "Epoch: 191\n",
      "Train loss: tensor(168.5269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037756321162340185\n",
      "Test loss: 0.04398528910656967\n",
      "Epoch: 192\n",
      "Train loss: tensor(188.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03757772067827838\n",
      "Test loss: 0.04366488419104331\n",
      "Epoch: 193\n",
      "Train loss: tensor(156.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03742342933657623\n",
      "Test loss: 0.0433842599816104\n",
      "Epoch: 194\n",
      "Train loss: tensor(222.3019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03745844595666443\n",
      "Test loss: 0.04332477760750173\n",
      "Epoch: 195\n",
      "Train loss: tensor(193.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03752485001016231\n",
      "Test loss: 0.043318222654928074\n",
      "Epoch: 196\n",
      "Train loss: tensor(156.5711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03755592932658536\n",
      "Test loss: 0.04327853482290365\n",
      "Epoch: 197\n",
      "Train loss: tensor(141.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03777111632128557\n",
      "Test loss: 0.043583529604838626\n",
      "Epoch: 198\n",
      "Train loss: tensor(100.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037950620534164564\n",
      "Test loss: 0.043848289333578976\n",
      "Epoch: 199\n",
      "Train loss: tensor(111.8265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038172891381241025\n",
      "Test loss: 0.044173248914430044\n",
      "Epoch: 200\n",
      "Train loss: tensor(865.7597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0383770977368667\n",
      "Test loss: 0.044478055615310035\n",
      "Epoch: 201\n",
      "Train loss: tensor(186.1527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038471829279192855\n",
      "Test loss: 0.0446500533195858\n",
      "Epoch: 202\n",
      "Train loss: tensor(182.1111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03855165867578415\n",
      "Test loss: 0.044848845054460046\n",
      "Epoch: 203\n",
      "Train loss: tensor(205.9415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03864554011573394\n",
      "Test loss: 0.04505476830434976\n",
      "Epoch: 204\n",
      "Train loss: tensor(242.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03862483505869196\n",
      "Test loss: 0.04505738756149122\n",
      "Epoch: 205\n",
      "Train loss: tensor(193.9379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03891676841747193\n",
      "Test loss: 0.04546507446113789\n",
      "Epoch: 206\n",
      "Train loss: tensor(340.7654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039117124712183364\n",
      "Test loss: 0.04537600661526517\n",
      "Epoch: 207\n",
      "Train loss: tensor(178.7954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03926188299166305\n",
      "Test loss: 0.04524587602861742\n",
      "Epoch: 208\n",
      "Train loss: tensor(124.6507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03942680331390529\n",
      "Test loss: 0.0451593211215764\n",
      "Epoch: 209\n",
      "Train loss: tensor(339.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03942607840789216\n",
      "Test loss: 0.04481181585331365\n",
      "Epoch: 210\n",
      "Train loss: tensor(181.8385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03940658120527154\n",
      "Test loss: 0.044476018997259656\n",
      "Epoch: 211\n",
      "Train loss: tensor(149.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03973194077788364\n",
      "Test loss: 0.04456958992609588\n",
      "Epoch: 212\n",
      "Train loss: tensor(158.5619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04003976152411529\n",
      "Test loss: 0.04466940648853779\n",
      "Epoch: 213\n",
      "Train loss: tensor(152.3163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04041725049416224\n",
      "Test loss: 0.04488469107943301\n",
      "Epoch: 214\n",
      "Train loss: tensor(141.4719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04069612767724764\n",
      "Test loss: 0.04497567952453795\n",
      "Epoch: 215\n",
      "Train loss: tensor(172.0394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04084879904098454\n",
      "Test loss: 0.044931112198472616\n",
      "Epoch: 216\n",
      "Train loss: tensor(165.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04087259254994847\n",
      "Test loss: 0.0447641406945958\n",
      "Epoch: 217\n",
      "Train loss: tensor(226.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040987860712976686\n",
      "Test loss: 0.04474778146953276\n",
      "Epoch: 218\n",
      "Train loss: tensor(327.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04098978692754394\n",
      "Test loss: 0.044448826535798534\n",
      "Epoch: 219\n",
      "Train loss: tensor(144.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04100859696489005\n",
      "Test loss: 0.04419779566365598\n",
      "Epoch: 220\n",
      "Train loss: tensor(180.9334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0409251565645848\n",
      "Test loss: 0.04385630069946003\n",
      "Epoch: 221\n",
      "Train loss: tensor(166.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040937369857870394\n",
      "Test loss: 0.04366394206143842\n",
      "Epoch: 222\n",
      "Train loss: tensor(223.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04093809463970718\n",
      "Test loss: 0.043456541097695284\n",
      "Epoch: 223\n",
      "Train loss: tensor(242.9109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04099346362054348\n",
      "Test loss: 0.04332655453409004\n",
      "Epoch: 224\n",
      "Train loss: tensor(209.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040983227152554765\n",
      "Test loss: 0.04310050679573623\n",
      "Epoch: 225\n",
      "Train loss: tensor(217.4222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04101773246767975\n",
      "Test loss: 0.04292810259220919\n",
      "Epoch: 226\n",
      "Train loss: tensor(442.6181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04065661357627028\n",
      "Test loss: 0.04274295374640439\n",
      "Epoch: 227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(195.2752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04031934079137586\n",
      "Test loss: 0.04254485347704722\n",
      "Epoch: 228\n",
      "Train loss: tensor(134.0855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040005426215274\n",
      "Test loss: 0.04244836732413214\n",
      "Epoch: 229\n",
      "Train loss: tensor(153.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039727457914324034\n",
      "Test loss: 0.042368689349087156\n",
      "Epoch: 230\n",
      "Train loss: tensor(414.7127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03958498726465872\n",
      "Test loss: 0.0423505324870348\n",
      "Epoch: 231\n",
      "Train loss: tensor(135.5213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03947128928488209\n",
      "Test loss: 0.04236232937488815\n",
      "Epoch: 232\n",
      "Train loss: tensor(102.4038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03936531612915652\n",
      "Test loss: 0.04235287004214997\n",
      "Epoch: 233\n",
      "Train loss: tensor(370.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03929427975700015\n",
      "Test loss: 0.042369055285090856\n",
      "Epoch: 234\n",
      "Train loss: tensor(91.2149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03910143634393102\n",
      "Test loss: 0.042361658582888026\n",
      "Epoch: 235\n",
      "Train loss: tensor(166.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03892552675235839\n",
      "Test loss: 0.04233602157766276\n",
      "Epoch: 236\n",
      "Train loss: tensor(211.7614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038824896842596074\n",
      "Test loss: 0.04234536666201778\n",
      "Epoch: 237\n",
      "Train loss: tensor(157.8970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03874405354616188\n",
      "Test loss: 0.04234543576430861\n",
      "Epoch: 238\n",
      "Train loss: tensor(212.4971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03871387859717721\n",
      "Test loss: 0.042377948124736255\n",
      "Epoch: 239\n",
      "Train loss: tensor(127.4231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03870351795284521\n",
      "Test loss: 0.04240494688032287\n",
      "Epoch: 240\n",
      "Train loss: tensor(118.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03872897564655259\n",
      "Test loss: 0.042446225300652556\n",
      "Epoch: 241\n",
      "Train loss: tensor(129.6926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038742745037944545\n",
      "Test loss: 0.042494794289295625\n",
      "Epoch: 242\n",
      "Train loss: tensor(186.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03861736527511052\n",
      "Test loss: 0.04241227937198364\n",
      "Epoch: 243\n",
      "Train loss: tensor(125.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038498814049221224\n",
      "Test loss: 0.042349340278876595\n",
      "Epoch: 244\n",
      "Train loss: tensor(123.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038394166999274774\n",
      "Test loss: 0.04229965970602514\n",
      "Epoch: 245\n",
      "Train loss: tensor(99.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03829013134929396\n",
      "Test loss: 0.042258288015122755\n",
      "Epoch: 246\n",
      "Train loss: tensor(110.3537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03818389634113936\n",
      "Test loss: 0.04222358384234185\n",
      "Epoch: 247\n",
      "Train loss: tensor(415.7885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03820349559010494\n",
      "Test loss: 0.04227418817192464\n",
      "Epoch: 248\n",
      "Train loss: tensor(141.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03824190016658533\n",
      "Test loss: 0.04232015906104652\n",
      "Epoch: 249\n",
      "Train loss: tensor(169.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03829463654685588\n",
      "Test loss: 0.04236878769121843\n",
      "Epoch: 250\n",
      "Train loss: tensor(119.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0383273691027647\n",
      "Test loss: 0.04241151179620387\n",
      "Epoch: 251\n",
      "Train loss: tensor(120.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038386813790670465\n",
      "Test loss: 0.04245991712104123\n",
      "Epoch: 252\n",
      "Train loss: tensor(208.0077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03843335434794426\n",
      "Test loss: 0.042502139893240566\n",
      "Epoch: 253\n",
      "Train loss: tensor(156.3168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03848438302409791\n",
      "Test loss: 0.04254403056134239\n",
      "Epoch: 254\n",
      "Train loss: tensor(191.2039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03832208633068062\n",
      "Test loss: 0.04246937138683135\n",
      "Epoch: 255\n",
      "Train loss: tensor(361.7835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03770191582540671\n",
      "Test loss: 0.04192992563055146\n",
      "Epoch: 256\n",
      "Train loss: tensor(240.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037356490340261235\n",
      "Test loss: 0.04165677634980714\n",
      "Epoch: 257\n",
      "Train loss: tensor(146.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03713387443373601\n",
      "Test loss: 0.04156602861009317\n",
      "Epoch: 258\n",
      "Train loss: tensor(187.7702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03698754387774638\n",
      "Test loss: 0.04162741148162006\n",
      "Epoch: 259\n",
      "Train loss: tensor(173.7821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03692194861138151\n",
      "Test loss: 0.04180993389633327\n",
      "Epoch: 260\n",
      "Train loss: tensor(91.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03691183245252995\n",
      "Test loss: 0.04210262140259147\n",
      "Epoch: 261\n",
      "Train loss: tensor(131.1723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036952571970011505\n",
      "Test loss: 0.042437817864488844\n",
      "Epoch: 262\n",
      "Train loss: tensor(142.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0370148663009916\n",
      "Test loss: 0.04282472148021259\n",
      "Epoch: 263\n",
      "Train loss: tensor(119.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037114484395299636\n",
      "Test loss: 0.04320138332314125\n",
      "Epoch: 264\n",
      "Train loss: tensor(273.1024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0373180250238095\n",
      "Test loss: 0.04384603556061145\n",
      "Epoch: 265\n",
      "Train loss: tensor(99.7679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037572404422930306\n",
      "Test loss: 0.04446567018691561\n",
      "Epoch: 266\n",
      "Train loss: tensor(228.3241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03779541559162594\n",
      "Test loss: 0.04500110805182174\n",
      "Epoch: 267\n",
      "Train loss: tensor(114.4405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038030387159614334\n",
      "Test loss: 0.04553530344020317\n",
      "Epoch: 268\n",
      "Train loss: tensor(206.1059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03829315737599418\n",
      "Test loss: 0.04613972813960644\n",
      "Epoch: 269\n",
      "Train loss: tensor(197.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038494927462722574\n",
      "Test loss: 0.04654742686981612\n",
      "Epoch: 270\n",
      "Train loss: tensor(115.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038661873588959374\n",
      "Test loss: 0.04687206096725889\n",
      "Epoch: 271\n",
      "Train loss: tensor(322.8629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03864148063141675\n",
      "Test loss: 0.046261951216671725\n",
      "Epoch: 272\n",
      "Train loss: tensor(160.4549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03864587115212565\n",
      "Test loss: 0.04561405661193156\n",
      "Epoch: 273\n",
      "Train loss: tensor(194.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03871070449905736\n",
      "Test loss: 0.04510709401773344\n",
      "Epoch: 274\n",
      "Train loss: tensor(166.0533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03881889312927212\n",
      "Test loss: 0.044734896096115064\n",
      "Epoch: 275\n",
      "Train loss: tensor(139.7886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038932772699211325\n",
      "Test loss: 0.04435624343592046\n",
      "Epoch: 276\n",
      "Train loss: tensor(116.5837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03906285204880294\n",
      "Test loss: 0.04405618074469932\n",
      "Epoch: 277\n",
      "Train loss: tensor(137.6511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03920035341843253\n",
      "Test loss: 0.04380636736935023\n",
      "Epoch: 278\n",
      "Train loss: tensor(143.8314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03933365416846105\n",
      "Test loss: 0.04361641050159636\n",
      "Epoch: 279\n",
      "Train loss: tensor(186.6193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03951520752161741\n",
      "Test loss: 0.04362236527670728\n",
      "Epoch: 280\n",
      "Train loss: tensor(135.2691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03967690537905409\n",
      "Test loss: 0.04359763826584757\n",
      "Epoch: 281\n",
      "Train loss: tensor(124.0692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039817808266906514\n",
      "Test loss: 0.04355140563358765\n",
      "Epoch: 282\n",
      "Train loss: tensor(156.6778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039888131920070874\n",
      "Test loss: 0.04366925348629161\n",
      "Epoch: 283\n",
      "Train loss: tensor(115.9710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03998134141521795\n",
      "Test loss: 0.0437904384983058\n",
      "Epoch: 284\n",
      "Train loss: tensor(197.8111, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.04013005609491042\n",
      "Test loss: 0.044219413117533274\n",
      "Epoch: 285\n",
      "Train loss: tensor(177.1803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0402926084275047\n",
      "Test loss: 0.04458517809905628\n",
      "Epoch: 286\n",
      "Train loss: tensor(152.2399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040406783412964574\n",
      "Test loss: 0.044804127601039884\n",
      "Epoch: 287\n",
      "Train loss: tensor(105.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04052024618500755\n",
      "Test loss: 0.04499418751364297\n",
      "Epoch: 288\n",
      "Train loss: tensor(152.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04063409399241209\n",
      "Test loss: 0.04515962959221094\n",
      "Epoch: 289\n",
      "Train loss: tensor(151.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041013307017939434\n",
      "Test loss: 0.04570707596727822\n",
      "Epoch: 290\n",
      "Train loss: tensor(178.2853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04138179559792791\n",
      "Test loss: 0.04621331371588282\n",
      "Epoch: 291\n",
      "Train loss: tensor(480.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041647444736389885\n",
      "Test loss: 0.04636975532711143\n",
      "Epoch: 292\n",
      "Train loss: tensor(428.9070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041923585959843225\n",
      "Test loss: 0.04631388926933898\n",
      "Epoch: 293\n",
      "Train loss: tensor(231.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04219614524571669\n",
      "Test loss: 0.04625805731088218\n",
      "Epoch: 294\n",
      "Train loss: tensor(202.9562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042562837437504816\n",
      "Test loss: 0.04642691083326198\n",
      "Epoch: 295\n",
      "Train loss: tensor(212.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04296563320039284\n",
      "Test loss: 0.046729399167960234\n",
      "Epoch: 296\n",
      "Train loss: tensor(177.8383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04325646361602204\n",
      "Test loss: 0.046889033611163054\n",
      "Epoch: 297\n",
      "Train loss: tensor(188.0589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04357068067682641\n",
      "Test loss: 0.04707566416352102\n",
      "Epoch: 298\n",
      "Train loss: tensor(136.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043849676714411805\n",
      "Test loss: 0.0472867065985309\n",
      "Epoch: 299\n",
      "Train loss: tensor(206.9815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044115649837823144\n",
      "Test loss: 0.047485935400323115\n",
      "Epoch: 300\n",
      "Train loss: tensor(150.5926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04447480558107297\n",
      "Test loss: 0.0478043669816291\n",
      "Epoch: 301\n",
      "Train loss: tensor(160.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0446017461607144\n",
      "Test loss: 0.047876166585500875\n",
      "Epoch: 302\n",
      "Train loss: tensor(178.1158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044766878753545736\n",
      "Test loss: 0.04799980397271638\n",
      "Epoch: 303\n",
      "Train loss: tensor(97.1024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044899354538037665\n",
      "Test loss: 0.04807227929261061\n",
      "Epoch: 304\n",
      "Train loss: tensor(147.4413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044986207463911604\n",
      "Test loss: 0.04809668307921084\n",
      "Epoch: 305\n",
      "Train loss: tensor(132.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045004834092798686\n",
      "Test loss: 0.048039572258101834\n",
      "Epoch: 306\n",
      "Train loss: tensor(223.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04491165798334848\n",
      "Test loss: 0.047873236091420204\n",
      "Epoch: 307\n",
      "Train loss: tensor(300.4119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04470656388217495\n",
      "Test loss: 0.047618860932122364\n",
      "Epoch: 308\n",
      "Train loss: tensor(288.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044519876981420174\n",
      "Test loss: 0.047381134500893034\n",
      "Epoch: 309\n",
      "Train loss: tensor(350.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04422631438466765\n",
      "Test loss: 0.04707513926642956\n",
      "Epoch: 310\n",
      "Train loss: tensor(300.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04393159176799513\n",
      "Test loss: 0.04676650187904292\n",
      "Epoch: 311\n",
      "Train loss: tensor(326.1583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043778311354773385\n",
      "Test loss: 0.046597209288784774\n",
      "Epoch: 312\n",
      "Train loss: tensor(161.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04350322147033044\n",
      "Test loss: 0.04628013860028569\n",
      "Epoch: 313\n",
      "Train loss: tensor(114.8421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04331529459783009\n",
      "Test loss: 0.04608772333600734\n",
      "Epoch: 314\n",
      "Train loss: tensor(170.3464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04291865925881125\n",
      "Test loss: 0.045675435758168154\n",
      "Epoch: 315\n",
      "Train loss: tensor(88.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042667088276218804\n",
      "Test loss: 0.04546957037937228\n",
      "Epoch: 316\n",
      "Train loss: tensor(179.1091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04238935287687041\n",
      "Test loss: 0.04518128461250574\n",
      "Epoch: 317\n",
      "Train loss: tensor(171.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042096430045508205\n",
      "Test loss: 0.044848292927709546\n",
      "Epoch: 318\n",
      "Train loss: tensor(313.4598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04185275604859704\n",
      "Test loss: 0.04459555361346148\n",
      "Epoch: 319\n",
      "Train loss: tensor(213.9554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04167018887542543\n",
      "Test loss: 0.044350525308953656\n",
      "Epoch: 320\n",
      "Train loss: tensor(160.0717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04143828110148509\n",
      "Test loss: 0.044049419112282225\n",
      "Epoch: 321\n",
      "Train loss: tensor(195.7042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04125730767846107\n",
      "Test loss: 0.04380814164950706\n",
      "Epoch: 322\n",
      "Train loss: tensor(337.9693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040879505376021065\n",
      "Test loss: 0.04361236531582504\n",
      "Epoch: 323\n",
      "Train loss: tensor(194.3531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04049491799835648\n",
      "Test loss: 0.04336400228635509\n",
      "Epoch: 324\n",
      "Train loss: tensor(227.9971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040166661294088475\n",
      "Test loss: 0.04314265036863266\n",
      "Epoch: 325\n",
      "Train loss: tensor(197.9615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0399316108297734\n",
      "Test loss: 0.043033032742614795\n",
      "Epoch: 326\n",
      "Train loss: tensor(126.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03968427839378516\n",
      "Test loss: 0.042887133601499663\n",
      "Epoch: 327\n",
      "Train loss: tensor(225.6952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0394658591066088\n",
      "Test loss: 0.04275988632499581\n",
      "Epoch: 328\n",
      "Train loss: tensor(386.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039253988205676986\n",
      "Test loss: 0.04257552322037149\n",
      "Epoch: 329\n",
      "Train loss: tensor(307.3773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0390755924085776\n",
      "Test loss: 0.0424325649008745\n",
      "Epoch: 330\n",
      "Train loss: tensor(207.5700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0389345717217241\n",
      "Test loss: 0.042301876405899476\n",
      "Epoch: 331\n",
      "Train loss: tensor(101.7776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038836453588945524\n",
      "Test loss: 0.04221102726267706\n",
      "Epoch: 332\n",
      "Train loss: tensor(292.8197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03890137526073626\n",
      "Test loss: 0.04221982512586188\n",
      "Epoch: 333\n",
      "Train loss: tensor(87.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038950951406288715\n",
      "Test loss: 0.042338093032710036\n",
      "Epoch: 334\n",
      "Train loss: tensor(190.7469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039013540141639255\n",
      "Test loss: 0.042479836649381285\n",
      "Epoch: 335\n",
      "Train loss: tensor(154.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03912213259332237\n",
      "Test loss: 0.042703323850020916\n",
      "Epoch: 336\n",
      "Train loss: tensor(147.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03917731044902688\n",
      "Test loss: 0.042901013009619\n",
      "Epoch: 337\n",
      "Train loss: tensor(118.0080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03925147328880571\n",
      "Test loss: 0.04309852098548176\n",
      "Epoch: 338\n",
      "Train loss: tensor(215.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03934926784464291\n",
      "Test loss: 0.043321659170681294\n",
      "Epoch: 339\n",
      "Train loss: tensor(135.9562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03944857586175203\n",
      "Test loss: 0.04351781844391976\n",
      "Epoch: 340\n",
      "Train loss: tensor(261.4398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03955514526792935\n",
      "Test loss: 0.04371755341492077\n",
      "Epoch: 341\n",
      "Train loss: tensor(186.5917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03964312095195055\n",
      "Test loss: 0.04388104687159014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 342\n",
      "Train loss: tensor(157.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03961665440528166\n",
      "Test loss: 0.04390900099816004\n",
      "Epoch: 343\n",
      "Train loss: tensor(164.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03959180724230551\n",
      "Test loss: 0.043934597098960144\n",
      "Epoch: 344\n",
      "Train loss: tensor(113.8255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03956882796649422\n",
      "Test loss: 0.04396069404844305\n",
      "Epoch: 345\n",
      "Train loss: tensor(151.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03955440700408958\n",
      "Test loss: 0.0439990039656658\n",
      "Epoch: 346\n",
      "Train loss: tensor(142.5509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03954339169320606\n",
      "Test loss: 0.04403550935780058\n",
      "Epoch: 347\n",
      "Train loss: tensor(95.0402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03951014826695124\n",
      "Test loss: 0.044051324118777074\n",
      "Epoch: 348\n",
      "Train loss: tensor(169.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039418409463195574\n",
      "Test loss: 0.04395414033148548\n",
      "Epoch: 349\n",
      "Train loss: tensor(122.5549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03935086432667006\n",
      "Test loss: 0.043870824130971244\n",
      "Epoch: 350\n",
      "Train loss: tensor(208.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03910948210174129\n",
      "Test loss: 0.04368159918132985\n",
      "Epoch: 351\n",
      "Train loss: tensor(135.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03891765755556879\n",
      "Test loss: 0.04356843494985363\n",
      "Epoch: 352\n",
      "Train loss: tensor(160.7658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038791807900582044\n",
      "Test loss: 0.04350120410101839\n",
      "Epoch: 353\n",
      "Train loss: tensor(118.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03868358567179669\n",
      "Test loss: 0.04345924284604221\n",
      "Epoch: 354\n",
      "Train loss: tensor(130.6229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038601851560885\n",
      "Test loss: 0.043429882560699885\n",
      "Epoch: 355\n",
      "Train loss: tensor(272.4207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03849279943498827\n",
      "Test loss: 0.04336533329385047\n",
      "Epoch: 356\n",
      "Train loss: tensor(133.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0384047440563639\n",
      "Test loss: 0.04332775279584498\n",
      "Epoch: 357\n",
      "Train loss: tensor(191.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038250371742816196\n",
      "Test loss: 0.04323207797242863\n",
      "Epoch: 358\n",
      "Train loss: tensor(352.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0378813666424581\n",
      "Test loss: 0.04289188573487324\n",
      "Epoch: 359\n",
      "Train loss: tensor(169.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03764551594143822\n",
      "Test loss: 0.042759750278131795\n",
      "Epoch: 360\n",
      "Train loss: tensor(159.9405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03771790973842144\n",
      "Test loss: 0.04305301118863396\n",
      "Epoch: 361\n",
      "Train loss: tensor(171.9334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038010946625754945\n",
      "Test loss: 0.043656082298274675\n",
      "Epoch: 362\n",
      "Train loss: tensor(163.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03845834387909798\n",
      "Test loss: 0.04446174989980046\n",
      "Epoch: 363\n",
      "Train loss: tensor(225.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03886940147550333\n",
      "Test loss: 0.04524863923503326\n",
      "Epoch: 364\n",
      "Train loss: tensor(128.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03924784152990296\n",
      "Test loss: 0.04603533334292398\n",
      "Epoch: 365\n",
      "Train loss: tensor(188.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03964909052564984\n",
      "Test loss: 0.0469623150414612\n",
      "Epoch: 366\n",
      "Train loss: tensor(145.5719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04010565611755564\n",
      "Test loss: 0.0479239474262784\n",
      "Epoch: 367\n",
      "Train loss: tensor(117.2494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040566064408492475\n",
      "Test loss: 0.048858882435182535\n",
      "Epoch: 368\n",
      "Train loss: tensor(139.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041035673678630875\n",
      "Test loss: 0.04978078226604969\n",
      "Epoch: 369\n",
      "Train loss: tensor(169.5741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04161012365172307\n",
      "Test loss: 0.05080518369922544\n",
      "Epoch: 370\n",
      "Train loss: tensor(92.0231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042189426578226545\n",
      "Test loss: 0.051814547832133157\n",
      "Epoch: 371\n",
      "Train loss: tensor(136.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04278257514926649\n",
      "Test loss: 0.0527964324349224\n",
      "Epoch: 372\n",
      "Train loss: tensor(312.4903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0429267730563879\n",
      "Test loss: 0.05295219299116052\n",
      "Epoch: 373\n",
      "Train loss: tensor(157.9214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04342694940666358\n",
      "Test loss: 0.05338268756571383\n",
      "Epoch: 374\n",
      "Train loss: tensor(166.1496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04382824704405807\n",
      "Test loss: 0.0537360643340957\n",
      "Epoch: 375\n",
      "Train loss: tensor(377.2839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0439557898967039\n",
      "Test loss: 0.05362745564394068\n",
      "Epoch: 376\n",
      "Train loss: tensor(327.9592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04361149934785707\n",
      "Test loss: 0.05260143639280064\n",
      "Epoch: 377\n",
      "Train loss: tensor(190.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0431655805735361\n",
      "Test loss: 0.05150467896889342\n",
      "Epoch: 378\n",
      "Train loss: tensor(228.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042950331251181306\n",
      "Test loss: 0.050741842449965456\n",
      "Epoch: 379\n",
      "Train loss: tensor(157.0419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042926548501210554\n",
      "Test loss: 0.05031944733887616\n",
      "Epoch: 380\n",
      "Train loss: tensor(294.3010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04393735684099651\n",
      "Test loss: 0.05170674567654877\n",
      "Epoch: 381\n",
      "Train loss: tensor(131.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04470522324776366\n",
      "Test loss: 0.05286330367337064\n",
      "Epoch: 382\n",
      "Train loss: tensor(185.2291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0451820107886479\n",
      "Test loss: 0.05378109547724523\n",
      "Epoch: 383\n",
      "Train loss: tensor(204.6448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04556188570069415\n",
      "Test loss: 0.05457806966202979\n",
      "Epoch: 384\n",
      "Train loss: tensor(168.6820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0458856615193543\n",
      "Test loss: 0.05525356426023611\n",
      "Epoch: 385\n",
      "Train loss: tensor(115.8070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045888361068708555\n",
      "Test loss: 0.05545369164077657\n",
      "Epoch: 386\n",
      "Train loss: tensor(126.7122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04587658727985053\n",
      "Test loss: 0.055634644786172575\n",
      "Epoch: 387\n",
      "Train loss: tensor(122.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04565728652690138\n",
      "Test loss: 0.0555256345207886\n",
      "Epoch: 388\n",
      "Train loss: tensor(924.7067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04529481247244846\n",
      "Test loss: 0.055221856248998405\n",
      "Epoch: 389\n",
      "Train loss: tensor(175.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045076017090607254\n",
      "Test loss: 0.055010535201002464\n",
      "Epoch: 390\n",
      "Train loss: tensor(161.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04488690318983225\n",
      "Test loss: 0.05487546452902036\n",
      "Epoch: 391\n",
      "Train loss: tensor(158.5808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044740832002744785\n",
      "Test loss: 0.054788924025205694\n",
      "Epoch: 392\n",
      "Train loss: tensor(156.8674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04464085942045564\n",
      "Test loss: 0.0547413263783449\n",
      "Epoch: 393\n",
      "Train loss: tensor(332.0588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04382080002909615\n",
      "Test loss: 0.053384722118256706\n",
      "Epoch: 394\n",
      "Train loss: tensor(147.3222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04310381559743768\n",
      "Test loss: 0.052195680023419976\n",
      "Epoch: 395\n",
      "Train loss: tensor(213.3725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04253982806666976\n",
      "Test loss: 0.051211236929982015\n",
      "Epoch: 396\n",
      "Train loss: tensor(228.6806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04200115585256191\n",
      "Test loss: 0.05031514888869064\n",
      "Epoch: 397\n",
      "Train loss: tensor(280.2892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04129765581428295\n",
      "Test loss: 0.04917908765117426\n",
      "Epoch: 398\n",
      "Train loss: tensor(203.0777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040731242511953626\n",
      "Test loss: 0.04821407723028471\n",
      "Epoch: 399\n",
      "Train loss: tensor(246.2691, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.040268139567758356\n",
      "Test loss: 0.04739717423620791\n",
      "Epoch: 400\n",
      "Train loss: tensor(165.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03978956455276126\n",
      "Test loss: 0.04656616388128536\n",
      "Epoch: 401\n",
      "Train loss: tensor(148.8982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039408065516146874\n",
      "Test loss: 0.04586531306699951\n",
      "Epoch: 402\n",
      "Train loss: tensor(125.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039088196657775416\n",
      "Test loss: 0.04527456516234001\n",
      "Epoch: 403\n",
      "Train loss: tensor(301.0201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038749689675335375\n",
      "Test loss: 0.044567319241785766\n",
      "Epoch: 404\n",
      "Train loss: tensor(167.2153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03850422385813934\n",
      "Test loss: 0.04404433000611492\n",
      "Epoch: 405\n",
      "Train loss: tensor(133.5910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03834624546358273\n",
      "Test loss: 0.04368532249833097\n",
      "Epoch: 406\n",
      "Train loss: tensor(114.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03821917862764427\n",
      "Test loss: 0.04336333294205441\n",
      "Epoch: 407\n",
      "Train loss: tensor(185.8979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038110680146408935\n",
      "Test loss: 0.0431131685226418\n",
      "Epoch: 408\n",
      "Train loss: tensor(231.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038129021870415836\n",
      "Test loss: 0.04305251297716162\n",
      "Epoch: 409\n",
      "Train loss: tensor(221.2639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038173038166548524\n",
      "Test loss: 0.04302004245248171\n",
      "Epoch: 410\n",
      "Train loss: tensor(284.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038170394532027696\n",
      "Test loss: 0.042919963653577434\n",
      "Epoch: 411\n",
      "Train loss: tensor(174.8924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03815300146206504\n",
      "Test loss: 0.04281152841072566\n",
      "Epoch: 412\n",
      "Train loss: tensor(186.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038063490497214456\n",
      "Test loss: 0.04264539574263709\n",
      "Epoch: 413\n",
      "Train loss: tensor(223.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03797318850244794\n",
      "Test loss: 0.04248942960385639\n",
      "Epoch: 414\n",
      "Train loss: tensor(172.5909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03790920700079629\n",
      "Test loss: 0.04235482156866848\n",
      "Epoch: 415\n",
      "Train loss: tensor(164.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03788758282150541\n",
      "Test loss: 0.0422483168468617\n",
      "Loss this time: tensor(341.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 416\n",
      "Train loss: tensor(341.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03800582797931773\n",
      "Test loss: 0.04225971592166046\n",
      "Epoch: 417\n",
      "Train loss: tensor(133.1059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03818951528519392\n",
      "Test loss: 0.04230527158383981\n",
      "Epoch: 418\n",
      "Train loss: tensor(184.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03843252197617576\n",
      "Test loss: 0.04239895077662008\n",
      "Epoch: 419\n",
      "Train loss: tensor(261.6181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03882042330556682\n",
      "Test loss: 0.04263309756349219\n",
      "Epoch: 420\n",
      "Train loss: tensor(131.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03917654348271234\n",
      "Test loss: 0.04287718932172007\n",
      "Epoch: 421\n",
      "Train loss: tensor(163.5002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03953139314960156\n",
      "Test loss: 0.043099569520996056\n",
      "Epoch: 422\n",
      "Train loss: tensor(230.4536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04000331394019581\n",
      "Test loss: 0.04346969264494901\n",
      "Epoch: 423\n",
      "Train loss: tensor(173.4116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040364920108446056\n",
      "Test loss: 0.043838331858526064\n",
      "Epoch: 424\n",
      "Train loss: tensor(150.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04072082790413073\n",
      "Test loss: 0.044231250859096204\n",
      "Epoch: 425\n",
      "Train loss: tensor(335.2482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04204256571829319\n",
      "Test loss: 0.04613583215908839\n",
      "Epoch: 426\n",
      "Train loss: tensor(107.9563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04318778005295566\n",
      "Test loss: 0.048069620302112974\n",
      "Epoch: 427\n",
      "Train loss: tensor(189.4555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04476980556334768\n",
      "Test loss: 0.050624650146922856\n",
      "Epoch: 428\n",
      "Train loss: tensor(309.4765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04564302372967913\n",
      "Test loss: 0.05214782517016082\n",
      "Epoch: 429\n",
      "Train loss: tensor(157.9108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04638142023412954\n",
      "Test loss: 0.05353067421105386\n",
      "Epoch: 430\n",
      "Train loss: tensor(280.4518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04714479723146984\n",
      "Test loss: 0.054934851673090514\n",
      "Epoch: 431\n",
      "Train loss: tensor(321.8147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045247999197315605\n",
      "Test loss: 0.052459340939058526\n",
      "Epoch: 432\n",
      "Train loss: tensor(137.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04343167248048953\n",
      "Test loss: 0.050225520465006626\n",
      "Epoch: 433\n",
      "Train loss: tensor(153.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04172957356398304\n",
      "Test loss: 0.0481756532444886\n",
      "Epoch: 434\n",
      "Train loss: tensor(150.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040581048368698074\n",
      "Test loss: 0.0467023779868637\n",
      "Epoch: 435\n",
      "Train loss: tensor(420.5076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039498807423348936\n",
      "Test loss: 0.04479638382903125\n",
      "Epoch: 436\n",
      "Train loss: tensor(156.4319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03870084273761937\n",
      "Test loss: 0.043200253121702385\n",
      "Epoch: 437\n",
      "Train loss: tensor(122.3935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038540033676794594\n",
      "Test loss: 0.0425092343628259\n",
      "Epoch: 438\n",
      "Train loss: tensor(215.8195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0388360985953893\n",
      "Test loss: 0.04261457944971205\n",
      "Epoch: 439\n",
      "Train loss: tensor(188.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03899231820056836\n",
      "Test loss: 0.04264681375963558\n",
      "Epoch: 440\n",
      "Train loss: tensor(301.8046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03923758113135894\n",
      "Test loss: 0.04276668372573239\n",
      "Epoch: 441\n",
      "Train loss: tensor(279.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03931059546413876\n",
      "Test loss: 0.04286077929347163\n",
      "Epoch: 442\n",
      "Train loss: tensor(196.1788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039913731294551065\n",
      "Test loss: 0.043689217298559034\n",
      "Epoch: 443\n",
      "Train loss: tensor(166.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04075034392465438\n",
      "Test loss: 0.04482929780157191\n",
      "Epoch: 444\n",
      "Train loss: tensor(134.5030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04173845900666146\n",
      "Test loss: 0.04625241629004773\n",
      "Epoch: 445\n",
      "Train loss: tensor(141.2928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042868552015473446\n",
      "Test loss: 0.04788985291477477\n",
      "Epoch: 446\n",
      "Train loss: tensor(115.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04386055186568272\n",
      "Test loss: 0.049364943721211786\n",
      "Epoch: 447\n",
      "Train loss: tensor(164.7573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04484530834569817\n",
      "Test loss: 0.050856059998052545\n",
      "Epoch: 448\n",
      "Train loss: tensor(135.9573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04584293008028042\n",
      "Test loss: 0.0523461436410204\n",
      "Epoch: 449\n",
      "Train loss: tensor(120.4367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04690037669081773\n",
      "Test loss: 0.05390042776592297\n",
      "Epoch: 450\n",
      "Train loss: tensor(207.1283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047744404338300225\n",
      "Test loss: 0.05523317238076193\n",
      "Epoch: 451\n",
      "Train loss: tensor(98.6129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0486579626621235\n",
      "Test loss: 0.05666203738771158\n",
      "Epoch: 452\n",
      "Train loss: tensor(137.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0493323190714277\n",
      "Test loss: 0.057727979938730155\n",
      "Epoch: 453\n",
      "Train loss: tensor(211.4747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050016406923532486\n",
      "Test loss: 0.05876358486896399\n",
      "Epoch: 454\n",
      "Train loss: tensor(309.9619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.049567006927515776\n",
      "Test loss: 0.05774136390168183\n",
      "Epoch: 455\n",
      "Train loss: tensor(127.8293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04959521651090611\n",
      "Test loss: 0.05719772314117982\n",
      "Epoch: 456\n",
      "Train loss: tensor(293.0505, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.04934207208986793\n",
      "Test loss: 0.05519266551969075\n",
      "Epoch: 457\n",
      "Train loss: tensor(166.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05024327163007997\n",
      "Test loss: 0.05448391312493546\n",
      "Epoch: 458\n",
      "Train loss: tensor(180.6655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.051876849867403506\n",
      "Test loss: 0.05487874417685636\n",
      "Epoch: 459\n",
      "Train loss: tensor(96.6994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05384481998958758\n",
      "Test loss: 0.05595012792930155\n",
      "Epoch: 460\n",
      "Train loss: tensor(143.6020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05479830023610876\n",
      "Test loss: 0.05644738368026101\n",
      "Epoch: 461\n",
      "Train loss: tensor(211.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05618538760713169\n",
      "Test loss: 0.057515606948054666\n",
      "Epoch: 462\n",
      "Train loss: tensor(129.2929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05650759259504931\n",
      "Test loss: 0.057835259963527764\n",
      "Epoch: 463\n",
      "Train loss: tensor(197.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.057489269164701304\n",
      "Test loss: 0.05899696531567243\n",
      "Epoch: 464\n",
      "Train loss: tensor(533.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05787090790413675\n",
      "Test loss: 0.05964648094729032\n",
      "Epoch: 465\n",
      "Train loss: tensor(213.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05849290161083142\n",
      "Test loss: 0.06054918010636132\n",
      "Epoch: 466\n",
      "Train loss: tensor(125.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.059186386308144955\n",
      "Test loss: 0.06151891287674408\n",
      "Epoch: 467\n",
      "Train loss: tensor(136.4748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05707986606728463\n",
      "Test loss: 0.059820908822561844\n",
      "Epoch: 468\n",
      "Train loss: tensor(115.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05242744096155678\n",
      "Test loss: 0.05568850897990241\n",
      "Epoch: 469\n",
      "Train loss: tensor(134.4940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04556401431383122\n",
      "Test loss: 0.04957552226536935\n",
      "Epoch: 470\n",
      "Train loss: tensor(146.4397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04043976068496704\n",
      "Test loss: 0.04494553618133068\n",
      "Epoch: 471\n",
      "Train loss: tensor(190.1457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03790998340451292\n",
      "Test loss: 0.042370007345729536\n",
      "Epoch: 472\n",
      "Train loss: tensor(159.2274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038361261767290884\n",
      "Test loss: 0.042620169994707156\n",
      "Epoch: 473\n",
      "Train loss: tensor(307.3681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0417152072169951\n",
      "Test loss: 0.04557019656542504\n",
      "Epoch: 474\n",
      "Train loss: tensor(226.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04583781257803951\n",
      "Test loss: 0.04962084813984019\n",
      "Epoch: 475\n",
      "Train loss: tensor(177.8151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04935442377768812\n",
      "Test loss: 0.05310361760456373\n",
      "Epoch: 476\n",
      "Train loss: tensor(137.8053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05265077728600729\n",
      "Test loss: 0.05628606554415851\n",
      "Epoch: 477\n",
      "Train loss: tensor(134.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05722827185832319\n",
      "Test loss: 0.06090272821965489\n",
      "Epoch: 478\n",
      "Train loss: tensor(209.2073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0641579248898086\n",
      "Test loss: 0.06825474044769117\n",
      "Epoch: 479\n",
      "Train loss: tensor(211.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06961253175423258\n",
      "Test loss: 0.07427424842510189\n",
      "Epoch: 480\n",
      "Train loss: tensor(241.5698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0722783093473741\n",
      "Test loss: 0.07703177013093292\n",
      "Epoch: 481\n",
      "Train loss: tensor(182.0462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0701976934536582\n",
      "Test loss: 0.07517994480152236\n",
      "Epoch: 482\n",
      "Train loss: tensor(161.4953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06720803427909101\n",
      "Test loss: 0.07222201078576912\n",
      "Epoch: 483\n",
      "Train loss: tensor(137.2279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06152176054283267\n",
      "Test loss: 0.06667828859558494\n",
      "Epoch: 484\n",
      "Train loss: tensor(191.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05432802540737958\n",
      "Test loss: 0.059445785257116995\n",
      "Epoch: 485\n",
      "Train loss: tensor(143.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04885132997518494\n",
      "Test loss: 0.05370825459479843\n",
      "Epoch: 486\n",
      "Train loss: tensor(248.8832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04453947945010094\n",
      "Test loss: 0.04915024560535013\n",
      "Epoch: 487\n",
      "Train loss: tensor(151.3651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04331856102106117\n",
      "Test loss: 0.04772689710786142\n",
      "Epoch: 488\n",
      "Train loss: tensor(159.4701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04373281944897913\n",
      "Test loss: 0.047928506692889894\n",
      "Epoch: 489\n",
      "Train loss: tensor(91.7586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04462542260686556\n",
      "Test loss: 0.04865670017898083\n",
      "Epoch: 490\n",
      "Train loss: tensor(112.7210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04553264179045246\n",
      "Test loss: 0.04941600120377423\n",
      "Epoch: 491\n",
      "Train loss: tensor(177.6218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045857709051952474\n",
      "Test loss: 0.04970734980473719\n",
      "Epoch: 492\n",
      "Train loss: tensor(297.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04607747848190012\n",
      "Test loss: 0.04996749945907014\n",
      "Epoch: 493\n",
      "Train loss: tensor(272.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04635896751923221\n",
      "Test loss: 0.050260154788594434\n",
      "Epoch: 494\n",
      "Train loss: tensor(96.5675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04657145327932778\n",
      "Test loss: 0.050485897864593135\n",
      "Epoch: 495\n",
      "Train loss: tensor(164.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04508636385379802\n",
      "Test loss: 0.04919956232614742\n",
      "Epoch: 496\n",
      "Train loss: tensor(277.8103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04410505438489573\n",
      "Test loss: 0.048342682338218285\n",
      "Epoch: 497\n",
      "Train loss: tensor(154.7602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04332520128006027\n",
      "Test loss: 0.047748887819228786\n",
      "Epoch: 498\n",
      "Train loss: tensor(229.9112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043409584382815024\n",
      "Test loss: 0.047986820220283354\n",
      "Epoch: 499\n",
      "Train loss: tensor(159.7876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043044340570590325\n",
      "Test loss: 0.04763024714360438\n",
      "Epoch: 500\n",
      "Train loss: tensor(203.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042867162868025756\n",
      "Test loss: 0.04743390401253606\n",
      "Epoch: 501\n",
      "Train loss: tensor(239.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042724032429534764\n",
      "Test loss: 0.04726695659395197\n",
      "Epoch: 502\n",
      "Train loss: tensor(183.1792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044127787241623515\n",
      "Test loss: 0.0489390342782187\n",
      "Epoch: 503\n",
      "Train loss: tensor(156.9470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045686813115718816\n",
      "Test loss: 0.05088936176040385\n",
      "Epoch: 504\n",
      "Train loss: tensor(325.0275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0532662658464341\n",
      "Test loss: 0.06047476647366391\n",
      "Epoch: 505\n",
      "Train loss: tensor(132.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.059101000312893164\n",
      "Test loss: 0.06755962633149754\n",
      "Epoch: 506\n",
      "Train loss: tensor(210.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06345485715816418\n",
      "Test loss: 0.07286741261803868\n",
      "Epoch: 507\n",
      "Train loss: tensor(151.3458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06668250280476752\n",
      "Test loss: 0.07708649143189339\n",
      "Epoch: 508\n",
      "Train loss: tensor(119.2231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06946267314432632\n",
      "Test loss: 0.08079794067243981\n",
      "Epoch: 509\n",
      "Train loss: tensor(315.4070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0680440682962182\n",
      "Test loss: 0.07942736963510956\n",
      "Epoch: 510\n",
      "Train loss: tensor(127.5223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06596033492436011\n",
      "Test loss: 0.0774552634603685\n",
      "Epoch: 511\n",
      "Train loss: tensor(224.5884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06350636776714098\n",
      "Test loss: 0.07476165939565046\n",
      "Epoch: 512\n",
      "Train loss: tensor(143.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.061641685629174825\n",
      "Test loss: 0.07245579964047906\n",
      "Epoch: 513\n",
      "Train loss: tensor(318.9872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05820026567117089\n",
      "Test loss: 0.06744330512857673\n",
      "Epoch: 514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(268.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05543059121285166\n",
      "Test loss: 0.06282180750576577\n",
      "Epoch: 515\n",
      "Train loss: tensor(184.2916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05510608835057134\n",
      "Test loss: 0.06144742571776456\n",
      "Epoch: 516\n",
      "Train loss: tensor(205.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053906197845935824\n",
      "Test loss: 0.05966778401986207\n",
      "Epoch: 517\n",
      "Train loss: tensor(209.8744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.052348540448361916\n",
      "Test loss: 0.0577556390757903\n",
      "Epoch: 518\n",
      "Train loss: tensor(151.1579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050191440459873\n",
      "Test loss: 0.055552092094970223\n",
      "Epoch: 519\n",
      "Train loss: tensor(171.6421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047821112234322796\n",
      "Test loss: 0.05278882889611886\n",
      "Epoch: 520\n",
      "Train loss: tensor(120.6462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04533014642518191\n",
      "Test loss: 0.050187358807883053\n",
      "Epoch: 521\n",
      "Train loss: tensor(128.5395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04354127100003617\n",
      "Test loss: 0.04829083727027225\n",
      "Epoch: 522\n",
      "Train loss: tensor(330.3079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041891271612119106\n",
      "Test loss: 0.046440243960754704\n",
      "Epoch: 523\n",
      "Train loss: tensor(179.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040632689611188\n",
      "Test loss: 0.04503472744127606\n",
      "Epoch: 524\n",
      "Train loss: tensor(121.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03968802572538455\n",
      "Test loss: 0.04400215268430143\n",
      "Epoch: 525\n",
      "Train loss: tensor(111.3464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03890490812205133\n",
      "Test loss: 0.04318781669187074\n",
      "Epoch: 526\n",
      "Train loss: tensor(194.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038215557472514254\n",
      "Test loss: 0.04252683773341746\n",
      "Epoch: 527\n",
      "Train loss: tensor(182.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037683535260813576\n",
      "Test loss: 0.042060495428003296\n",
      "Epoch: 528\n",
      "Train loss: tensor(143.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037229386304638214\n",
      "Test loss: 0.04169431207056093\n",
      "Epoch: 529\n",
      "Train loss: tensor(308.1966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03708297948219946\n",
      "Test loss: 0.04157563623520407\n",
      "Epoch: 530\n",
      "Train loss: tensor(139.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03689897284798679\n",
      "Test loss: 0.041441652029383894\n",
      "Epoch: 531\n",
      "Train loss: tensor(127.2730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036550174697878815\n",
      "Test loss: 0.04121253044704105\n",
      "Epoch: 532\n",
      "Train loss: tensor(159.2044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03625594670219081\n",
      "Test loss: 0.04103041047433225\n",
      "Epoch: 533\n",
      "Train loss: tensor(125.1810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03601675528057274\n",
      "Test loss: 0.04088111137879072\n",
      "Epoch: 534\n",
      "Train loss: tensor(439.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03575582623126961\n",
      "Test loss: 0.04074811782355946\n",
      "Epoch: 535\n",
      "Train loss: tensor(197.7917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0356159053388096\n",
      "Test loss: 0.040688229558786544\n",
      "Epoch: 536\n",
      "Train loss: tensor(133.2404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035503243836796\n",
      "Test loss: 0.040634298770882114\n",
      "Epoch: 537\n",
      "Train loss: tensor(352.3515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035302592317263286\n",
      "Test loss: 0.04053994262646331\n",
      "Epoch: 538\n",
      "Train loss: tensor(182.4026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035112478783620255\n",
      "Test loss: 0.040458994622499043\n",
      "Epoch: 539\n",
      "Train loss: tensor(186.5296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03484911911544346\n",
      "Test loss: 0.04037866438047426\n",
      "Epoch: 540\n",
      "Train loss: tensor(152.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034626780521302\n",
      "Test loss: 0.04045580001086882\n",
      "Epoch: 541\n",
      "Train loss: tensor(337.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03512648310778396\n",
      "Test loss: 0.04130457262370256\n",
      "Epoch: 542\n",
      "Train loss: tensor(124.1994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03628027092310644\n",
      "Test loss: 0.04269466840542189\n",
      "Epoch: 543\n",
      "Train loss: tensor(246.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03657993872073435\n",
      "Test loss: 0.04253510317516209\n",
      "Epoch: 544\n",
      "Train loss: tensor(147.5867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037199838202269304\n",
      "Test loss: 0.042919492164608275\n",
      "Epoch: 545\n",
      "Train loss: tensor(224.2672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03776475830624501\n",
      "Test loss: 0.04323050704332861\n",
      "Epoch: 546\n",
      "Train loss: tensor(169.1942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03838348775392487\n",
      "Test loss: 0.043668233061043345\n",
      "Epoch: 547\n",
      "Train loss: tensor(194.3971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038969323154361475\n",
      "Test loss: 0.04406554416043333\n",
      "Epoch: 548\n",
      "Train loss: tensor(91.8209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03935077525675297\n",
      "Test loss: 0.04417509048955866\n",
      "Epoch: 549\n",
      "Train loss: tensor(106.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03999938163906336\n",
      "Test loss: 0.04460114950664563\n",
      "Epoch: 550\n",
      "Train loss: tensor(137.2116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03910102442439113\n",
      "Test loss: 0.0436990555136068\n",
      "Epoch: 551\n",
      "Train loss: tensor(303.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03953353312043917\n",
      "Test loss: 0.04407820073279119\n",
      "Epoch: 552\n",
      "Train loss: tensor(93.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04181255222786041\n",
      "Test loss: 0.04634537405823127\n",
      "Epoch: 553\n",
      "Train loss: tensor(134.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04384026117622852\n",
      "Test loss: 0.04855680379942797\n",
      "Epoch: 554\n",
      "Train loss: tensor(152.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045362105832568236\n",
      "Test loss: 0.050565639990243584\n",
      "Epoch: 555\n",
      "Train loss: tensor(154.3907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04633552329171271\n",
      "Test loss: 0.05195345003895535\n",
      "Epoch: 556\n",
      "Train loss: tensor(140.0639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04709201982422244\n",
      "Test loss: 0.05326194190742946\n",
      "Epoch: 557\n",
      "Train loss: tensor(132.9360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048714283893683125\n",
      "Test loss: 0.05564409386514142\n",
      "Epoch: 558\n",
      "Train loss: tensor(170.8480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05065572971389407\n",
      "Test loss: 0.05832608772607723\n",
      "Epoch: 559\n",
      "Train loss: tensor(140.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05143039465127956\n",
      "Test loss: 0.05940245863714135\n",
      "Epoch: 560\n",
      "Train loss: tensor(298.2371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05072784809661763\n",
      "Test loss: 0.05852924906971431\n",
      "Epoch: 561\n",
      "Train loss: tensor(223.6126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04922090276543583\n",
      "Test loss: 0.05665170100268604\n",
      "Epoch: 562\n",
      "Train loss: tensor(131.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047760817390822226\n",
      "Test loss: 0.05482537907059535\n",
      "Epoch: 563\n",
      "Train loss: tensor(202.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04598894820859035\n",
      "Test loss: 0.052618995520959395\n",
      "Epoch: 564\n",
      "Train loss: tensor(260.0108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04450168059251848\n",
      "Test loss: 0.05056813175762349\n",
      "Epoch: 565\n",
      "Train loss: tensor(291.2391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043181220304575704\n",
      "Test loss: 0.04854907345321804\n",
      "Epoch: 566\n",
      "Train loss: tensor(110.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042471506996523765\n",
      "Test loss: 0.04726431943881925\n",
      "Epoch: 567\n",
      "Train loss: tensor(124.5216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04216276627211343\n",
      "Test loss: 0.04647777593777616\n",
      "Epoch: 568\n",
      "Train loss: tensor(257.5362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04205368395362582\n",
      "Test loss: 0.04595185857782565\n",
      "Epoch: 569\n",
      "Train loss: tensor(316.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04273884590005591\n",
      "Test loss: 0.04672616998674256\n",
      "Epoch: 570\n",
      "Train loss: tensor(190.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0430522261364829\n",
      "Test loss: 0.04724966774298118\n",
      "Epoch: 571\n",
      "Train loss: tensor(116.4662, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.043355350533411614\n",
      "Test loss: 0.04776946178609782\n",
      "Epoch: 572\n",
      "Train loss: tensor(112.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04400494366529442\n",
      "Test loss: 0.04862026566879289\n",
      "Epoch: 573\n",
      "Train loss: tensor(472.5701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04706795769965365\n",
      "Test loss: 0.053617153685576846\n",
      "Epoch: 574\n",
      "Train loss: tensor(248.2354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04939961831661917\n",
      "Test loss: 0.05738683188758274\n",
      "Epoch: 575\n",
      "Train loss: tensor(141.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.051741032674908635\n",
      "Test loss: 0.06122293021751217\n",
      "Epoch: 576\n",
      "Train loss: tensor(124.4345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054945254636307554\n",
      "Test loss: 0.0659218192155851\n",
      "Epoch: 577\n",
      "Train loss: tensor(135.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058345155803752796\n",
      "Test loss: 0.07057758809832654\n",
      "Epoch: 578\n",
      "Train loss: tensor(193.3671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05856217538849229\n",
      "Test loss: 0.0708459922951637\n",
      "Epoch: 579\n",
      "Train loss: tensor(211.3628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05843839183272351\n",
      "Test loss: 0.07070015213166428\n",
      "Epoch: 580\n",
      "Train loss: tensor(162.0074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05591638343674796\n",
      "Test loss: 0.06729407354009033\n",
      "Epoch: 581\n",
      "Train loss: tensor(205.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054199890845588274\n",
      "Test loss: 0.06477118854291074\n",
      "Epoch: 582\n",
      "Train loss: tensor(343.0900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05204672789910719\n",
      "Test loss: 0.06149925379137887\n",
      "Epoch: 583\n",
      "Train loss: tensor(144.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04982535376967419\n",
      "Test loss: 0.058058701944306935\n",
      "Epoch: 584\n",
      "Train loss: tensor(114.4513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048357664336938236\n",
      "Test loss: 0.055470819824771714\n",
      "Epoch: 585\n",
      "Train loss: tensor(186.4761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047024432702788284\n",
      "Test loss: 0.052929919738654456\n",
      "Epoch: 586\n",
      "Train loss: tensor(176.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04604528709536507\n",
      "Test loss: 0.05102181652247315\n",
      "Epoch: 587\n",
      "Train loss: tensor(126.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04555313971248411\n",
      "Test loss: 0.04981495919499067\n",
      "Epoch: 588\n",
      "Train loss: tensor(171.3007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04472607601256598\n",
      "Test loss: 0.04854529585209814\n",
      "Epoch: 589\n",
      "Train loss: tensor(200.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04350571254534381\n",
      "Test loss: 0.04709825678590206\n",
      "Epoch: 590\n",
      "Train loss: tensor(271.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042454159774240996\n",
      "Test loss: 0.04578890492862994\n",
      "Epoch: 591\n",
      "Train loss: tensor(124.6829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04168916698545218\n",
      "Test loss: 0.04483739673021701\n",
      "Epoch: 592\n",
      "Train loss: tensor(178.8141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04105081726309089\n",
      "Test loss: 0.0440501570609389\n",
      "Epoch: 593\n",
      "Train loss: tensor(221.3181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04055870972751152\n",
      "Test loss: 0.043598741993750675\n",
      "Epoch: 594\n",
      "Train loss: tensor(188.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04009139800355548\n",
      "Test loss: 0.04317734461499027\n",
      "Epoch: 595\n",
      "Train loss: tensor(116.0094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0396945911858763\n",
      "Test loss: 0.04285765622770137\n",
      "Epoch: 596\n",
      "Train loss: tensor(356.1446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039473581003646056\n",
      "Test loss: 0.04279570527706701\n",
      "Epoch: 597\n",
      "Train loss: tensor(165.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03937139246790182\n",
      "Test loss: 0.042800756540186335\n",
      "Epoch: 598\n",
      "Train loss: tensor(279.3635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039759632847493606\n",
      "Test loss: 0.04333037283216225\n",
      "Epoch: 599\n",
      "Train loss: tensor(192.8221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040308374694238105\n",
      "Test loss: 0.04402354783793487\n",
      "Epoch: 600\n",
      "Train loss: tensor(171.7582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04067009901184411\n",
      "Test loss: 0.04452706237166825\n",
      "Epoch: 601\n",
      "Train loss: tensor(197.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0403619659931532\n",
      "Test loss: 0.04437496544940785\n",
      "Epoch: 602\n",
      "Train loss: tensor(88.8013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03913830234447405\n",
      "Test loss: 0.043273264496116945\n",
      "Epoch: 603\n",
      "Train loss: tensor(134.2410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03812150990679151\n",
      "Test loss: 0.04237540287546592\n",
      "Epoch: 604\n",
      "Train loss: tensor(113.9950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03830734519731431\n",
      "Test loss: 0.042556961122346984\n",
      "Epoch: 605\n",
      "Train loss: tensor(145.7378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03927427085914782\n",
      "Test loss: 0.043409839401593306\n",
      "Epoch: 606\n",
      "Train loss: tensor(224.4116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040804498092759225\n",
      "Test loss: 0.044771448331009045\n",
      "Epoch: 607\n",
      "Train loss: tensor(99.9949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0424841563350388\n",
      "Test loss: 0.04623990871085979\n",
      "Epoch: 608\n",
      "Train loss: tensor(126.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04233669865699041\n",
      "Test loss: 0.04614752975504587\n",
      "Epoch: 609\n",
      "Train loss: tensor(144.5850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04101193689164661\n",
      "Test loss: 0.045064808616396224\n",
      "Epoch: 610\n",
      "Train loss: tensor(357.2257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03998433206939981\n",
      "Test loss: 0.04420836218217812\n",
      "Epoch: 611\n",
      "Train loss: tensor(218.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03915544679122312\n",
      "Test loss: 0.04349305896586416\n",
      "Epoch: 612\n",
      "Train loss: tensor(235.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03831421946663232\n",
      "Test loss: 0.042806436778000084\n",
      "Epoch: 613\n",
      "Train loss: tensor(189.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037639898150449706\n",
      "Test loss: 0.042327125833397455\n",
      "Epoch: 614\n",
      "Train loss: tensor(189.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0373514357333382\n",
      "Test loss: 0.042299298818527474\n",
      "Epoch: 615\n",
      "Train loss: tensor(178.1228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0372850264200852\n",
      "Test loss: 0.042563370364432286\n",
      "Epoch: 616\n",
      "Train loss: tensor(230.0861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03729484167304777\n",
      "Test loss: 0.04289645459134095\n",
      "Epoch: 617\n",
      "Train loss: tensor(214.9406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03720582697895311\n",
      "Test loss: 0.043148594396649906\n",
      "Epoch: 618\n",
      "Train loss: tensor(149.2050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03612562114638942\n",
      "Test loss: 0.042505072780174784\n",
      "Epoch: 619\n",
      "Train loss: tensor(151.6160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03582779680423084\n",
      "Test loss: 0.04252201361157516\n",
      "Epoch: 620\n",
      "Train loss: tensor(234.3607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035570767876647764\n",
      "Test loss: 0.04255390196743578\n",
      "Epoch: 621\n",
      "Train loss: tensor(174.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035860368485252064\n",
      "Test loss: 0.04327499968838869\n",
      "Epoch: 622\n",
      "Train loss: tensor(164.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03699660012941985\n",
      "Test loss: 0.045276839516614334\n",
      "Epoch: 623\n",
      "Train loss: tensor(172.1223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037829910449328874\n",
      "Test loss: 0.04682950366583496\n",
      "Epoch: 624\n",
      "Train loss: tensor(186.1966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03894653487950563\n",
      "Test loss: 0.04872330177649118\n",
      "Epoch: 625\n",
      "Train loss: tensor(249.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04013395141810179\n",
      "Test loss: 0.05067167486442198\n",
      "Epoch: 626\n",
      "Train loss: tensor(232.8126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04162556055401053\n",
      "Test loss: 0.052924000381464414\n",
      "Epoch: 627\n",
      "Train loss: tensor(151.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042661122560855885\n",
      "Test loss: 0.05444421457809092\n",
      "Epoch: 628\n",
      "Train loss: tensor(181.6979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04390823606933866\n",
      "Test loss: 0.05614452240158721\n",
      "Epoch: 629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(168.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04421177411540633\n",
      "Test loss: 0.05648014083098952\n",
      "Epoch: 630\n",
      "Train loss: tensor(133.9821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04346287034097172\n",
      "Test loss: 0.05564922193932061\n",
      "Epoch: 631\n",
      "Train loss: tensor(113.3314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0426040715005781\n",
      "Test loss: 0.05460360240523178\n",
      "Epoch: 632\n",
      "Train loss: tensor(163.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04179890822796595\n",
      "Test loss: 0.053614225837927645\n",
      "Epoch: 633\n",
      "Train loss: tensor(175.8529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04116592779755592\n",
      "Test loss: 0.05282118341120163\n",
      "Epoch: 634\n",
      "Train loss: tensor(123.6397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04017519384533876\n",
      "Test loss: 0.05158862826589605\n",
      "Epoch: 635\n",
      "Train loss: tensor(145.5780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03948927421034092\n",
      "Test loss: 0.05063730809321203\n",
      "Epoch: 636\n",
      "Train loss: tensor(95.0261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03917918386203902\n",
      "Test loss: 0.05023870140424754\n",
      "Epoch: 637\n",
      "Train loss: tensor(272.9537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038743910197878165\n",
      "Test loss: 0.04962581032794891\n",
      "Epoch: 638\n",
      "Train loss: tensor(225.2083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03846894828159185\n",
      "Test loss: 0.049521620717305356\n",
      "Epoch: 639\n",
      "Train loss: tensor(151.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03838273073945727\n",
      "Test loss: 0.04952922885739567\n",
      "Epoch: 640\n",
      "Train loss: tensor(120.9606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038303752935358454\n",
      "Test loss: 0.049485829953878825\n",
      "Epoch: 641\n",
      "Train loss: tensor(204.3970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03762221201544716\n",
      "Test loss: 0.04843577230810234\n",
      "Epoch: 642\n",
      "Train loss: tensor(176.5310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03765487948964749\n",
      "Test loss: 0.04814811445551344\n",
      "Epoch: 643\n",
      "Train loss: tensor(131.5239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03722710086121445\n",
      "Test loss: 0.047372636117852564\n",
      "Epoch: 644\n",
      "Train loss: tensor(158.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03736786830815531\n",
      "Test loss: 0.04747179390327765\n",
      "Epoch: 645\n",
      "Train loss: tensor(172.7337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037013896612361784\n",
      "Test loss: 0.04706663334059833\n",
      "Epoch: 646\n",
      "Train loss: tensor(164.2006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03572998369290006\n",
      "Test loss: 0.045733014213861806\n",
      "Epoch: 647\n",
      "Train loss: tensor(164.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03438804513730463\n",
      "Test loss: 0.043982086463434863\n",
      "Epoch: 648\n",
      "Train loss: tensor(159.1763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03326630513405516\n",
      "Test loss: 0.042001351197757344\n",
      "Epoch: 649\n",
      "Train loss: tensor(191.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0330479342446086\n",
      "Test loss: 0.041094894940494606\n",
      "Epoch: 650\n",
      "Train loss: tensor(155.4300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03344371296199305\n",
      "Test loss: 0.040945804037043065\n",
      "Epoch: 651\n",
      "Train loss: tensor(144.2216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03411514687218836\n",
      "Test loss: 0.04122328695997891\n",
      "Epoch: 652\n",
      "Train loss: tensor(115.8509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03485087573616987\n",
      "Test loss: 0.041726699758247277\n",
      "Epoch: 653\n",
      "Train loss: tensor(212.2118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03461278657916756\n",
      "Test loss: 0.04135447877486891\n",
      "Epoch: 654\n",
      "Train loss: tensor(231.0518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03420613238233186\n",
      "Test loss: 0.04085536225523689\n",
      "Epoch: 655\n",
      "Train loss: tensor(231.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03411076527887157\n",
      "Test loss: 0.04050300067917693\n",
      "Epoch: 656\n",
      "Train loss: tensor(148.5813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0334345808430087\n",
      "Test loss: 0.0396680884745599\n",
      "Epoch: 657\n",
      "Train loss: tensor(169.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03298437935078428\n",
      "Test loss: 0.039126009412921305\n",
      "Epoch: 658\n",
      "Train loss: tensor(87.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03299585681053854\n",
      "Test loss: 0.03894643888504493\n",
      "Loss this time: tensor(133.5601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 659\n",
      "Train loss: tensor(133.5601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03352223068387026\n",
      "Test loss: 0.039179620821729745\n",
      "Epoch: 660\n",
      "Train loss: tensor(199.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034927294820192314\n",
      "Test loss: 0.040063267785797614\n",
      "Epoch: 661\n",
      "Train loss: tensor(235.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036842054412478495\n",
      "Test loss: 0.04154148618552354\n",
      "Epoch: 662\n",
      "Train loss: tensor(139.9457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03811886782447497\n",
      "Test loss: 0.042607304750766496\n",
      "Epoch: 663\n",
      "Train loss: tensor(143.5049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0395451379319032\n",
      "Test loss: 0.04400316069806271\n",
      "Epoch: 664\n",
      "Train loss: tensor(188.7172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04093787357033718\n",
      "Test loss: 0.04550115894157403\n",
      "Epoch: 665\n",
      "Train loss: tensor(209.5729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04234935487842276\n",
      "Test loss: 0.047140749779963256\n",
      "Epoch: 666\n",
      "Train loss: tensor(275.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0435074558925061\n",
      "Test loss: 0.04838870887155875\n",
      "Epoch: 667\n",
      "Train loss: tensor(370.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044546671256068204\n",
      "Test loss: 0.049502501430192795\n",
      "Epoch: 668\n",
      "Train loss: tensor(165.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04575782803197702\n",
      "Test loss: 0.05099115844373361\n",
      "Epoch: 669\n",
      "Train loss: tensor(356.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04533586773489203\n",
      "Test loss: 0.05097288867034534\n",
      "Epoch: 670\n",
      "Train loss: tensor(209.7551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04490065439825966\n",
      "Test loss: 0.0508367475491054\n",
      "Epoch: 671\n",
      "Train loss: tensor(161.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042371923644982636\n",
      "Test loss: 0.04859739273675893\n",
      "Epoch: 672\n",
      "Train loss: tensor(145.1655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03943071379548027\n",
      "Test loss: 0.045959728908273254\n",
      "Epoch: 673\n",
      "Train loss: tensor(141.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036838397410299095\n",
      "Test loss: 0.043816497374215335\n",
      "Epoch: 674\n",
      "Train loss: tensor(133.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03485979268416053\n",
      "Test loss: 0.042368740673259936\n",
      "Epoch: 675\n",
      "Train loss: tensor(177.4923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03330791715887331\n",
      "Test loss: 0.041268199673014705\n",
      "Epoch: 676\n",
      "Train loss: tensor(212.8775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03245493674739486\n",
      "Test loss: 0.04070666839949565\n",
      "Epoch: 677\n",
      "Train loss: tensor(174.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03190591485638704\n",
      "Test loss: 0.04029045057584449\n",
      "Epoch: 678\n",
      "Train loss: tensor(168.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03182900598538774\n",
      "Test loss: 0.04018440646220847\n",
      "Epoch: 679\n",
      "Train loss: tensor(235.6770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03219793229142115\n",
      "Test loss: 0.0404650798380965\n",
      "Epoch: 680\n",
      "Train loss: tensor(183.8636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03285346085294372\n",
      "Test loss: 0.0410453775842296\n",
      "Epoch: 681\n",
      "Train loss: tensor(97.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03365089048498443\n",
      "Test loss: 0.041690866734906296\n",
      "Epoch: 682\n",
      "Train loss: tensor(132.2758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03458639317236486\n",
      "Test loss: 0.042454565045340814\n",
      "Epoch: 683\n",
      "Train loss: tensor(107.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03564371649796764\n",
      "Test loss: 0.04334715390485702\n",
      "Epoch: 684\n",
      "Train loss: tensor(175.6022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035565090316924314\n",
      "Test loss: 0.04334291917188923\n",
      "Epoch: 685\n",
      "Train loss: tensor(264.3660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035306759874912955\n",
      "Test loss: 0.0431767819117349\n",
      "Epoch: 686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(257.8187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03507273590546988\n",
      "Test loss: 0.04302179602684804\n",
      "Epoch: 687\n",
      "Train loss: tensor(113.3709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03286233931513769\n",
      "Test loss: 0.041449558271076714\n",
      "Epoch: 688\n",
      "Train loss: tensor(115.4537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0318569338924828\n",
      "Test loss: 0.04106530408826795\n",
      "Epoch: 689\n",
      "Train loss: tensor(250.4100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03199880528928978\n",
      "Test loss: 0.04110140901169564\n",
      "Epoch: 690\n",
      "Train loss: tensor(187.3189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03285712767835884\n",
      "Test loss: 0.04156873342903829\n",
      "Epoch: 691\n",
      "Train loss: tensor(331.1923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03413455748841876\n",
      "Test loss: 0.042340883524111\n",
      "Epoch: 692\n",
      "Train loss: tensor(134.8426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03484702784390677\n",
      "Test loss: 0.04261927816574231\n",
      "Epoch: 693\n",
      "Train loss: tensor(158.2232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035255488150176546\n",
      "Test loss: 0.04232460083347736\n",
      "Epoch: 694\n",
      "Train loss: tensor(192.2986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0353421959848631\n",
      "Test loss: 0.0418510337793591\n",
      "Epoch: 695\n",
      "Train loss: tensor(127.4124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035586285759650525\n",
      "Test loss: 0.041578021370759694\n",
      "Loss this time: tensor(148.0652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 696\n",
      "Train loss: tensor(148.0652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035143669464048885\n",
      "Test loss: 0.04078883158577846\n",
      "Epoch: 697\n",
      "Train loss: tensor(419.5990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03492665272206068\n",
      "Test loss: 0.040265328020300015\n",
      "Epoch: 698\n",
      "Train loss: tensor(142.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035006891359530744\n",
      "Test loss: 0.04002778368568657\n",
      "Epoch: 699\n",
      "Train loss: tensor(166.5286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03521952165202016\n",
      "Test loss: 0.03997027733833483\n",
      "Epoch: 700\n",
      "Train loss: tensor(353.6494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03560376640941416\n",
      "Test loss: 0.04006093187202321\n",
      "Epoch: 701\n",
      "Train loss: tensor(177.8600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035832790830837825\n",
      "Test loss: 0.04021930072161526\n",
      "Epoch: 702\n",
      "Train loss: tensor(112.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03634350030195145\n",
      "Test loss: 0.04074312998258536\n",
      "Epoch: 703\n",
      "Train loss: tensor(124.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03722536603787115\n",
      "Test loss: 0.041619892499529486\n",
      "Epoch: 704\n",
      "Train loss: tensor(157.5239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03772130653350836\n",
      "Test loss: 0.04192730039358139\n",
      "Epoch: 705\n",
      "Train loss: tensor(239.1212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0407080995717219\n",
      "Test loss: 0.04453475484716715\n",
      "Epoch: 706\n",
      "Train loss: tensor(334.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04178073242129315\n",
      "Test loss: 0.04544044553422102\n",
      "Epoch: 707\n",
      "Train loss: tensor(338.5058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04092103531584144\n",
      "Test loss: 0.04462998629649087\n",
      "Epoch: 708\n",
      "Train loss: tensor(276.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03952595668711833\n",
      "Test loss: 0.04332864231955592\n",
      "Epoch: 709\n",
      "Train loss: tensor(230.8802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04143432435091762\n",
      "Test loss: 0.04520029130179693\n",
      "Epoch: 710\n",
      "Train loss: tensor(918.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0435934702200549\n",
      "Test loss: 0.04721465517794437\n",
      "Epoch: 711\n",
      "Train loss: tensor(221.1842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04430818904989532\n",
      "Test loss: 0.047832640524179036\n",
      "Epoch: 712\n",
      "Train loss: tensor(161.5573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04510540621177781\n",
      "Test loss: 0.04871478780071334\n",
      "Epoch: 713\n",
      "Train loss: tensor(129.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04581508863096436\n",
      "Test loss: 0.04949772088687018\n",
      "Epoch: 714\n",
      "Train loss: tensor(180.7954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04637631708756089\n",
      "Test loss: 0.05000320740855566\n",
      "Epoch: 715\n",
      "Train loss: tensor(137.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04686359085940889\n",
      "Test loss: 0.050330367372693995\n",
      "Epoch: 716\n",
      "Train loss: tensor(149.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04747537912446118\n",
      "Test loss: 0.0503055250991394\n",
      "Epoch: 717\n",
      "Train loss: tensor(127.0670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048635043762624265\n",
      "Test loss: 0.05075764775940097\n",
      "Epoch: 718\n",
      "Train loss: tensor(110.4457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0514357622801548\n",
      "Test loss: 0.052204791972837825\n",
      "Epoch: 719\n",
      "Train loss: tensor(249.0536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.057955031877472286\n",
      "Test loss: 0.05729965729140999\n",
      "Epoch: 720\n",
      "Train loss: tensor(94.0731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06498856943632875\n",
      "Test loss: 0.06363480973361742\n",
      "Epoch: 721\n",
      "Train loss: tensor(163.6586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0717358014501986\n",
      "Test loss: 0.069887965751609\n",
      "Epoch: 722\n",
      "Train loss: tensor(156.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07816590570090783\n",
      "Test loss: 0.07588596378296318\n",
      "Epoch: 723\n",
      "Train loss: tensor(317.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.08377321954107\n",
      "Test loss: 0.0810771612727111\n",
      "Epoch: 724\n",
      "Train loss: tensor(111.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.08882225782033942\n",
      "Test loss: 0.08586895419745752\n",
      "Epoch: 725\n",
      "Train loss: tensor(199.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0935076852816911\n",
      "Test loss: 0.09051804384677717\n",
      "Epoch: 726\n",
      "Train loss: tensor(115.7577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.09389017966708967\n",
      "Test loss: 0.09113939313015135\n",
      "Epoch: 727\n",
      "Train loss: tensor(173.1751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0879640367148178\n",
      "Test loss: 0.08555843516962953\n",
      "Epoch: 728\n",
      "Train loss: tensor(145.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.08274644003027962\n",
      "Test loss: 0.08068893652519968\n",
      "Epoch: 729\n",
      "Train loss: tensor(145.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07553537874704315\n",
      "Test loss: 0.07393964787594753\n",
      "Epoch: 730\n",
      "Train loss: tensor(299.1391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06986052863122452\n",
      "Test loss: 0.0687448840477679\n",
      "Epoch: 731\n",
      "Train loss: tensor(209.3378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06530136187516508\n",
      "Test loss: 0.06484590105638646\n",
      "Epoch: 732\n",
      "Train loss: tensor(161.7760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06086330507837591\n",
      "Test loss: 0.06071557410725272\n",
      "Epoch: 733\n",
      "Train loss: tensor(426.1568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05655347222373599\n",
      "Test loss: 0.05636418671669936\n",
      "Epoch: 734\n",
      "Train loss: tensor(227.8560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053269506183763346\n",
      "Test loss: 0.05322033659287608\n",
      "Epoch: 735\n",
      "Train loss: tensor(335.8482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05042838247581607\n",
      "Test loss: 0.05054418139602288\n",
      "Epoch: 736\n",
      "Train loss: tensor(173.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04789393855524915\n",
      "Test loss: 0.04808063689840607\n",
      "Epoch: 737\n",
      "Train loss: tensor(275.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045892124463404925\n",
      "Test loss: 0.046195571209387026\n",
      "Epoch: 738\n",
      "Train loss: tensor(156.8700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044341133322034564\n",
      "Test loss: 0.04473788130770225\n",
      "Epoch: 739\n",
      "Train loss: tensor(177.7551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04286540207408723\n",
      "Test loss: 0.04342008998045827\n",
      "Epoch: 740\n",
      "Train loss: tensor(148.6647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041813159911405474\n",
      "Test loss: 0.04245319725521425\n",
      "Epoch: 741\n",
      "Train loss: tensor(167.6968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04109110427754266\n",
      "Test loss: 0.04173667345306661\n",
      "Epoch: 742\n",
      "Train loss: tensor(108.7972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0407433876989498\n",
      "Test loss: 0.04138320909425764\n",
      "Epoch: 743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(307.5513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03986873787251257\n",
      "Test loss: 0.04047514469648647\n",
      "Epoch: 744\n",
      "Train loss: tensor(86.9870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03916115074285439\n",
      "Test loss: 0.039894440312786855\n",
      "Epoch: 745\n",
      "Train loss: tensor(267.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038562737831047605\n",
      "Test loss: 0.03955470063345562\n",
      "Epoch: 746\n",
      "Train loss: tensor(181.3783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03804748225957155\n",
      "Test loss: 0.039406965145527724\n",
      "Epoch: 747\n",
      "Train loss: tensor(312.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03769530248606489\n",
      "Test loss: 0.03947657438013518\n",
      "Epoch: 748\n",
      "Train loss: tensor(126.7562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0374637406141985\n",
      "Test loss: 0.039722302965451\n",
      "Epoch: 749\n",
      "Train loss: tensor(196.1792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03731788723241715\n",
      "Test loss: 0.040262615972078676\n",
      "Epoch: 750\n",
      "Train loss: tensor(171.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037329294177747906\n",
      "Test loss: 0.0409742009521711\n",
      "Epoch: 751\n",
      "Train loss: tensor(354.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03816371060730446\n",
      "Test loss: 0.044778624549508095\n",
      "Epoch: 752\n",
      "Train loss: tensor(161.9232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04105864346825651\n",
      "Test loss: 0.050633342927414005\n",
      "Epoch: 753\n",
      "Train loss: tensor(146.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04495438363935266\n",
      "Test loss: 0.056965734417743906\n",
      "Loss this time: tensor(132.6026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 754\n",
      "Train loss: tensor(132.6026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05033276496188981\n",
      "Test loss: 0.06438572774871741\n",
      "Epoch: 755\n",
      "Train loss: tensor(172.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05418839518512998\n",
      "Test loss: 0.07001261332874546\n",
      "Epoch: 756\n",
      "Train loss: tensor(172.1932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.057322639271262146\n",
      "Test loss: 0.07467030402789317\n",
      "Epoch: 757\n",
      "Train loss: tensor(151.9676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058142815264207975\n",
      "Test loss: 0.07622939170255225\n",
      "Epoch: 758\n",
      "Train loss: tensor(384.3367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053828893247104825\n",
      "Test loss: 0.07079677058771106\n",
      "Epoch: 759\n",
      "Train loss: tensor(154.6175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04950663742298881\n",
      "Test loss: 0.0654562965293627\n",
      "Epoch: 760\n",
      "Train loss: tensor(195.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04572650046043453\n",
      "Test loss: 0.06058008942089164\n",
      "Epoch: 761\n",
      "Train loss: tensor(176.3167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042722339546751406\n",
      "Test loss: 0.05629984569265553\n",
      "Epoch: 762\n",
      "Train loss: tensor(168.5250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04013361963665202\n",
      "Test loss: 0.05200090620777394\n",
      "Epoch: 763\n",
      "Train loss: tensor(200.2242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03876312346242013\n",
      "Test loss: 0.0490620367892898\n",
      "Epoch: 764\n",
      "Train loss: tensor(153.7860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03810699754172847\n",
      "Test loss: 0.04613128069345609\n",
      "Epoch: 765\n",
      "Train loss: tensor(136.2497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03845070648406233\n",
      "Test loss: 0.04446313254959365\n",
      "Epoch: 766\n",
      "Train loss: tensor(172.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03918158320177879\n",
      "Test loss: 0.04422423862713841\n",
      "Epoch: 767\n",
      "Train loss: tensor(204.4048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04023547028856618\n",
      "Test loss: 0.04429126790918336\n",
      "Epoch: 768\n",
      "Train loss: tensor(138.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04211194519219654\n",
      "Test loss: 0.045010214219662815\n",
      "Epoch: 769\n",
      "Train loss: tensor(181.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04309919232591277\n",
      "Test loss: 0.04537425118286421\n",
      "Epoch: 770\n",
      "Train loss: tensor(149.7350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04444394952928026\n",
      "Test loss: 0.046383026019107584\n",
      "Epoch: 771\n",
      "Train loss: tensor(148.1766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04518955384070675\n",
      "Test loss: 0.04696595381097038\n",
      "Epoch: 772\n",
      "Train loss: tensor(151.5897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04522403254218045\n",
      "Test loss: 0.04683580996450221\n",
      "Epoch: 773\n",
      "Train loss: tensor(129.2663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045446104543017486\n",
      "Test loss: 0.04696630327824024\n",
      "Epoch: 774\n",
      "Train loss: tensor(171.1083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04432799406349659\n",
      "Test loss: 0.04574619428632726\n",
      "Epoch: 775\n",
      "Train loss: tensor(153.6410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04335535245814494\n",
      "Test loss: 0.04472271731068002\n",
      "Epoch: 776\n",
      "Train loss: tensor(217.8399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04256218376436404\n",
      "Test loss: 0.043895316863487854\n",
      "Epoch: 777\n",
      "Train loss: tensor(194.8810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040927300380454175\n",
      "Test loss: 0.04245745812054023\n",
      "Epoch: 778\n",
      "Train loss: tensor(183.8244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03990834071522667\n",
      "Test loss: 0.04186796835891091\n",
      "Epoch: 779\n",
      "Train loss: tensor(188.9035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039086419264120716\n",
      "Test loss: 0.04153393989078479\n",
      "Epoch: 780\n",
      "Train loss: tensor(241.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03861192482124482\n",
      "Test loss: 0.04164549763692488\n",
      "Epoch: 781\n",
      "Train loss: tensor(115.2320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03836653340785276\n",
      "Test loss: 0.042051316764537654\n",
      "Epoch: 782\n",
      "Train loss: tensor(344.5832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038299420591266384\n",
      "Test loss: 0.0427869824729491\n",
      "Epoch: 783\n",
      "Train loss: tensor(286.9055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038417910846571125\n",
      "Test loss: 0.04241793071574504\n",
      "Epoch: 784\n",
      "Train loss: tensor(322.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03912336062639952\n",
      "Test loss: 0.04127997517733291\n",
      "Epoch: 785\n",
      "Train loss: tensor(175.5861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040170930915822585\n",
      "Test loss: 0.04160049506970266\n",
      "Epoch: 786\n",
      "Train loss: tensor(110.1546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04141960214557392\n",
      "Test loss: 0.04267119336873293\n",
      "Epoch: 787\n",
      "Train loss: tensor(144.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04290104962087103\n",
      "Test loss: 0.044391711740431807\n",
      "Epoch: 788\n",
      "Train loss: tensor(91.3681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04457598084672576\n",
      "Test loss: 0.0464218616633132\n",
      "Epoch: 789\n",
      "Train loss: tensor(149.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.046798157709695046\n",
      "Test loss: 0.04920615706740335\n",
      "Epoch: 790\n",
      "Train loss: tensor(145.6882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04917753300230418\n",
      "Test loss: 0.0522065491848948\n",
      "Epoch: 791\n",
      "Train loss: tensor(233.5062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050041180072973174\n",
      "Test loss: 0.05338582532056192\n",
      "Epoch: 792\n",
      "Train loss: tensor(231.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04989987983856173\n",
      "Test loss: 0.05342699111540719\n",
      "Epoch: 793\n",
      "Train loss: tensor(162.3038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05005686753207729\n",
      "Test loss: 0.053779494072688686\n",
      "Epoch: 794\n",
      "Train loss: tensor(188.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.049459407620486756\n",
      "Test loss: 0.053024134958291995\n",
      "Epoch: 795\n",
      "Train loss: tensor(129.0768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0493153194142949\n",
      "Test loss: 0.05285625737898125\n",
      "Epoch: 796\n",
      "Train loss: tensor(147.6928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.049057415194277254\n",
      "Test loss: 0.05238296221572869\n",
      "Epoch: 797\n",
      "Train loss: tensor(159.9433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04924683090121973\n",
      "Test loss: 0.05231381381059637\n",
      "Epoch: 798\n",
      "Train loss: tensor(172.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04958278654764096\n",
      "Test loss: 0.0525632102300625\n",
      "Epoch: 799\n",
      "Train loss: tensor(276.2576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048896256665743536\n",
      "Test loss: 0.050976162942329255\n",
      "Epoch: 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(136.3475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.049438364129690895\n",
      "Test loss: 0.05036281332336735\n",
      "Epoch: 801\n",
      "Train loss: tensor(150.5218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05050768314727715\n",
      "Test loss: 0.050410006518042325\n",
      "Epoch: 802\n",
      "Train loss: tensor(311.8834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05202392275844302\n",
      "Test loss: 0.0511518466738191\n",
      "Epoch: 803\n",
      "Train loss: tensor(133.8638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053622217467498214\n",
      "Test loss: 0.05208735630875177\n",
      "Epoch: 804\n",
      "Train loss: tensor(168.8337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05269839514401697\n",
      "Test loss: 0.05111917017931395\n",
      "Epoch: 805\n",
      "Train loss: tensor(253.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.052087682716193656\n",
      "Test loss: 0.05062079674905479\n",
      "Epoch: 806\n",
      "Train loss: tensor(209.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05163515563167277\n",
      "Test loss: 0.050479398855921065\n",
      "Epoch: 807\n",
      "Train loss: tensor(130.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04965284246773947\n",
      "Test loss: 0.04901859068339414\n",
      "Epoch: 808\n",
      "Train loss: tensor(113.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048015344905711355\n",
      "Test loss: 0.047989319106287294\n",
      "Epoch: 809\n",
      "Train loss: tensor(106.7718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0466097888137613\n",
      "Test loss: 0.047104658153240046\n",
      "Epoch: 810\n",
      "Train loss: tensor(144.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04543954360165766\n",
      "Test loss: 0.04646242794460884\n",
      "Epoch: 811\n",
      "Train loss: tensor(151.5306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043700920191726514\n",
      "Test loss: 0.045285533219207044\n",
      "Epoch: 812\n",
      "Train loss: tensor(141.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04187741695592801\n",
      "Test loss: 0.044043071116182476\n",
      "Epoch: 813\n",
      "Train loss: tensor(278.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04068834446370602\n",
      "Test loss: 0.042687761818639716\n",
      "Epoch: 814\n",
      "Train loss: tensor(333.3205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040270494483411315\n",
      "Test loss: 0.04271382142300948\n",
      "Epoch: 815\n",
      "Train loss: tensor(112.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040130326994473026\n",
      "Test loss: 0.042928064232784335\n",
      "Epoch: 816\n",
      "Train loss: tensor(154.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0400584408658601\n",
      "Test loss: 0.043174639408762504\n",
      "Epoch: 817\n",
      "Train loss: tensor(170.9507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039959668168532\n",
      "Test loss: 0.043510772679738775\n",
      "Epoch: 818\n",
      "Train loss: tensor(112.1828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040071048339207965\n",
      "Test loss: 0.044040817495361706\n",
      "Epoch: 819\n",
      "Train loss: tensor(160.2928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0400523705274931\n",
      "Test loss: 0.044423071400142546\n",
      "Epoch: 820\n",
      "Train loss: tensor(85.1463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040189441045125326\n",
      "Test loss: 0.04490755609522509\n",
      "Epoch: 821\n",
      "Train loss: tensor(132.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040413375722155684\n",
      "Test loss: 0.04534831202340008\n",
      "Epoch: 822\n",
      "Train loss: tensor(131.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039757386994149005\n",
      "Test loss: 0.044922012480731945\n",
      "Epoch: 823\n",
      "Train loss: tensor(629.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03924370562835108\n",
      "Test loss: 0.04450976923753572\n",
      "Epoch: 824\n",
      "Train loss: tensor(124.9337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038474776631309875\n",
      "Test loss: 0.04378578752869427\n",
      "Epoch: 825\n",
      "Train loss: tensor(420.3647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038215352599287315\n",
      "Test loss: 0.042901725886334285\n",
      "Epoch: 826\n",
      "Train loss: tensor(242.1598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038460779886337976\n",
      "Test loss: 0.042163214332765285\n",
      "Epoch: 827\n",
      "Train loss: tensor(133.8539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038765520815338406\n",
      "Test loss: 0.041677320339154486\n",
      "Epoch: 828\n",
      "Train loss: tensor(232.1663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039204556965047405\n",
      "Test loss: 0.04120282644387519\n",
      "Epoch: 829\n",
      "Train loss: tensor(151.5818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04000740326674921\n",
      "Test loss: 0.04133183443642194\n",
      "Epoch: 830\n",
      "Train loss: tensor(210.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04052899471439776\n",
      "Test loss: 0.0414884571852808\n",
      "Epoch: 831\n",
      "Train loss: tensor(172.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04098685366057214\n",
      "Test loss: 0.0417288645161408\n",
      "Epoch: 832\n",
      "Train loss: tensor(312.1963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04106339682337074\n",
      "Test loss: 0.04204273116913172\n",
      "Epoch: 833\n",
      "Train loss: tensor(157.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041773445979647696\n",
      "Test loss: 0.043194156988422466\n",
      "Epoch: 834\n",
      "Train loss: tensor(230.9415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04164553179095189\n",
      "Test loss: 0.04392928886457835\n",
      "Epoch: 835\n",
      "Train loss: tensor(125.1542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04150992497979175\n",
      "Test loss: 0.044780501219822036\n",
      "Epoch: 836\n",
      "Train loss: tensor(69.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041606072886359126\n",
      "Test loss: 0.045876499246990325\n",
      "Epoch: 837\n",
      "Train loss: tensor(184.2973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041775402648463134\n",
      "Test loss: 0.04698273010256857\n",
      "Epoch: 838\n",
      "Train loss: tensor(145.9317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04228867022764115\n",
      "Test loss: 0.04844559542834759\n",
      "Epoch: 839\n",
      "Train loss: tensor(296.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04283844048068637\n",
      "Test loss: 0.04938918324464028\n",
      "Epoch: 840\n",
      "Train loss: tensor(224.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043523133865424564\n",
      "Test loss: 0.05044564851882434\n",
      "Epoch: 841\n",
      "Train loss: tensor(271.9776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043398558942689784\n",
      "Test loss: 0.047650163163348\n",
      "Loss this time: tensor(132.7421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 842\n",
      "Train loss: tensor(132.7421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044160145742907414\n",
      "Test loss: 0.046322352096143334\n",
      "Epoch: 843\n",
      "Train loss: tensor(208.1975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045631433473456474\n",
      "Test loss: 0.044829160860269376\n",
      "Epoch: 844\n",
      "Train loss: tensor(192.6894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047330370634084656\n",
      "Test loss: 0.04606197589989936\n",
      "Epoch: 845\n",
      "Train loss: tensor(242.1122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05059878698860606\n",
      "Test loss: 0.049886603332539595\n",
      "Epoch: 846\n",
      "Train loss: tensor(146.8300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.055052320947427125\n",
      "Test loss: 0.05535047459831037\n",
      "Epoch: 847\n",
      "Train loss: tensor(176.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06035445981792041\n",
      "Test loss: 0.06181058484028176\n",
      "Epoch: 848\n",
      "Train loss: tensor(136.1941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06563911561277651\n",
      "Test loss: 0.06786843818049915\n",
      "Epoch: 849\n",
      "Train loss: tensor(109.9151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07061431984018002\n",
      "Test loss: 0.07366329247113501\n",
      "Epoch: 850\n",
      "Train loss: tensor(127.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07525486644978324\n",
      "Test loss: 0.07909359472185963\n",
      "Epoch: 851\n",
      "Train loss: tensor(174.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07745657930860207\n",
      "Test loss: 0.08172369397955366\n",
      "Epoch: 852\n",
      "Train loss: tensor(128.1804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07941167157232051\n",
      "Test loss: 0.08407643212392779\n",
      "Epoch: 853\n",
      "Train loss: tensor(306.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07571813928939047\n",
      "Test loss: 0.0791629689773268\n",
      "Epoch: 854\n",
      "Train loss: tensor(256.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07317432691564872\n",
      "Test loss: 0.07533983106143993\n",
      "Epoch: 855\n",
      "Train loss: tensor(97.0890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.07160012003566538\n",
      "Test loss: 0.07266381849525588\n",
      "Epoch: 856\n",
      "Train loss: tensor(178.1858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06803535590214389\n",
      "Test loss: 0.06747476431992974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 857\n",
      "Train loss: tensor(132.1761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06553995784017302\n",
      "Test loss: 0.06374476642559955\n",
      "Epoch: 858\n",
      "Train loss: tensor(146.1129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06309294511697122\n",
      "Test loss: 0.06059093236701914\n",
      "Epoch: 859\n",
      "Train loss: tensor(201.0119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05918707615208058\n",
      "Test loss: 0.05612042083377295\n",
      "Epoch: 860\n",
      "Train loss: tensor(377.6759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.056026840963888734\n",
      "Test loss: 0.05483721541517442\n",
      "Epoch: 861\n",
      "Train loss: tensor(108.4982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05563222783662024\n",
      "Test loss: 0.059615434940424886\n",
      "Epoch: 862\n",
      "Train loss: tensor(137.5091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05694316691674647\n",
      "Test loss: 0.0666897456290772\n",
      "Epoch: 863\n",
      "Train loss: tensor(154.7204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05750635916455871\n",
      "Test loss: 0.07241715044520869\n",
      "Epoch: 864\n",
      "Train loss: tensor(116.1689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0575630974201929\n",
      "Test loss: 0.07632500126884126\n",
      "Epoch: 865\n",
      "Train loss: tensor(195.3886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05834444136846633\n",
      "Test loss: 0.08012095378656493\n",
      "Epoch: 866\n",
      "Train loss: tensor(295.5290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05810224637389183\n",
      "Test loss: 0.08182609810650644\n",
      "Epoch: 867\n",
      "Train loss: tensor(434.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.055544225059981855\n",
      "Test loss: 0.08024840975309362\n",
      "Epoch: 868\n",
      "Train loss: tensor(120.1878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054497260232234286\n",
      "Test loss: 0.08014903678604872\n",
      "Epoch: 869\n",
      "Train loss: tensor(180.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05455399310393702\n",
      "Test loss: 0.08096731493323303\n",
      "Epoch: 870\n",
      "Train loss: tensor(195.2091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.055285711107509475\n",
      "Test loss: 0.08221346304041914\n",
      "Epoch: 871\n",
      "Train loss: tensor(201.7675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05076048732513473\n",
      "Test loss: 0.07431417867762617\n",
      "Epoch: 872\n",
      "Train loss: tensor(141.2170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0488683427550963\n",
      "Test loss: 0.06817918389777441\n",
      "Epoch: 873\n",
      "Train loss: tensor(168.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04886448744329668\n",
      "Test loss: 0.06370791063487234\n",
      "Epoch: 874\n",
      "Train loss: tensor(286.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05006592190336613\n",
      "Test loss: 0.05980935429066125\n",
      "Epoch: 875\n",
      "Train loss: tensor(112.7263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050972801562221275\n",
      "Test loss: 0.05696950371533927\n",
      "Epoch: 876\n",
      "Train loss: tensor(250.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05303012091843855\n",
      "Test loss: 0.05665013366517159\n",
      "Epoch: 877\n",
      "Train loss: tensor(95.8614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050327591682296426\n",
      "Test loss: 0.05284360881968595\n",
      "Epoch: 878\n",
      "Train loss: tensor(175.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04748653216908375\n",
      "Test loss: 0.04957400507634819\n",
      "Epoch: 879\n",
      "Train loss: tensor(138.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0451470712510248\n",
      "Test loss: 0.04691243952711915\n",
      "Epoch: 880\n",
      "Train loss: tensor(238.1921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04344128661655954\n",
      "Test loss: 0.044719584470633233\n",
      "Epoch: 881\n",
      "Train loss: tensor(280.0689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04132764187331001\n",
      "Test loss: 0.04223847516471207\n",
      "Epoch: 882\n",
      "Train loss: tensor(161.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039949693304619616\n",
      "Test loss: 0.04023274579223725\n",
      "Epoch: 883\n",
      "Train loss: tensor(170.3484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040355620382442364\n",
      "Test loss: 0.04006572274288329\n",
      "Epoch: 884\n",
      "Train loss: tensor(295.7515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043093822829957516\n",
      "Test loss: 0.04159711997513429\n",
      "Epoch: 885\n",
      "Train loss: tensor(124.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04623702062027795\n",
      "Test loss: 0.043871705927471125\n",
      "Epoch: 886\n",
      "Train loss: tensor(113.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04940622651151248\n",
      "Test loss: 0.046456820174756615\n",
      "Epoch: 887\n",
      "Train loss: tensor(152.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05264889038212243\n",
      "Test loss: 0.049260737309877824\n",
      "Epoch: 888\n",
      "Train loss: tensor(151.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05534694641828537\n",
      "Test loss: 0.05166854716763638\n",
      "Epoch: 889\n",
      "Train loss: tensor(165.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05808079517668202\n",
      "Test loss: 0.05415072476509774\n",
      "Epoch: 890\n",
      "Train loss: tensor(159.6770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06075534672432002\n",
      "Test loss: 0.05662837735202053\n",
      "Epoch: 891\n",
      "Train loss: tensor(189.3338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06251923095967088\n",
      "Test loss: 0.058215332448039905\n",
      "Epoch: 892\n",
      "Train loss: tensor(161.8227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06406587101519108\n",
      "Test loss: 0.059559619220176545\n",
      "Epoch: 893\n",
      "Train loss: tensor(213.9317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06465484920356955\n",
      "Test loss: 0.06000080800587588\n",
      "Epoch: 894\n",
      "Train loss: tensor(134.2518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06405312047295628\n",
      "Test loss: 0.059447721218561185\n",
      "Epoch: 895\n",
      "Train loss: tensor(186.8649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06255659453038659\n",
      "Test loss: 0.05801992592318814\n",
      "Epoch: 896\n",
      "Train loss: tensor(253.7863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.061282571786571115\n",
      "Test loss: 0.05678245270311242\n",
      "Epoch: 897\n",
      "Train loss: tensor(183.4177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06048135010614281\n",
      "Test loss: 0.05598722112429614\n",
      "Epoch: 898\n",
      "Train loss: tensor(286.9253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05899968686557951\n",
      "Test loss: 0.054496121270084144\n",
      "Epoch: 899\n",
      "Train loss: tensor(161.5923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05690214864554859\n",
      "Test loss: 0.05253980976372662\n",
      "Epoch: 900\n",
      "Train loss: tensor(146.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054695883375548184\n",
      "Test loss: 0.05064629842665526\n",
      "Epoch: 901\n",
      "Train loss: tensor(129.9328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0526119894481131\n",
      "Test loss: 0.04900673106497172\n",
      "Epoch: 902\n",
      "Train loss: tensor(146.5614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05068692595121407\n",
      "Test loss: 0.04771818374606347\n",
      "Epoch: 903\n",
      "Train loss: tensor(64.5380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04896115270398912\n",
      "Test loss: 0.04684664648358185\n",
      "Epoch: 904\n",
      "Train loss: tensor(178.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0480102753577133\n",
      "Test loss: 0.04656016295499141\n",
      "Epoch: 905\n",
      "Train loss: tensor(108.7726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04766610187611409\n",
      "Test loss: 0.04660399249837835\n",
      "Epoch: 906\n",
      "Train loss: tensor(140.4646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04738114228294719\n",
      "Test loss: 0.046559384756601686\n",
      "Epoch: 907\n",
      "Train loss: tensor(106.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04534761703440121\n",
      "Test loss: 0.045321475944970505\n",
      "Epoch: 908\n",
      "Train loss: tensor(68.1078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043786720088904815\n",
      "Test loss: 0.044515418276043224\n",
      "Epoch: 909\n",
      "Train loss: tensor(145.4940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04315671734511852\n",
      "Test loss: 0.04443263066102668\n",
      "Epoch: 910\n",
      "Train loss: tensor(199.6388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04189257843508607\n",
      "Test loss: 0.044006978502810594\n",
      "Epoch: 911\n",
      "Train loss: tensor(171.7027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04086045341654902\n",
      "Test loss: 0.04370939157128629\n",
      "Epoch: 912\n",
      "Train loss: tensor(121.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04006938968031179\n",
      "Test loss: 0.043526768168010335\n",
      "Epoch: 913\n",
      "Train loss: tensor(185.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03899974997731901\n",
      "Test loss: 0.042871677501145566\n",
      "Epoch: 914\n",
      "Train loss: tensor(111.4101, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.037936936576096786\n",
      "Test loss: 0.04247696449666625\n",
      "Epoch: 915\n",
      "Train loss: tensor(154.2199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037178042872498436\n",
      "Test loss: 0.04246770933565527\n",
      "Epoch: 916\n",
      "Train loss: tensor(247.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03676426246584881\n",
      "Test loss: 0.04321462827006189\n",
      "Epoch: 917\n",
      "Train loss: tensor(126.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036678019245820384\n",
      "Test loss: 0.04433682885500464\n",
      "Epoch: 918\n",
      "Train loss: tensor(173.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03676638271925705\n",
      "Test loss: 0.045585637331230215\n",
      "Epoch: 919\n",
      "Train loss: tensor(241.4435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03674475318264393\n",
      "Test loss: 0.04615781591781\n",
      "Epoch: 920\n",
      "Train loss: tensor(139.3104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03676518847988475\n",
      "Test loss: 0.04670824804850439\n",
      "Epoch: 921\n",
      "Train loss: tensor(383.1798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03668788034646284\n",
      "Test loss: 0.04687794668618405\n",
      "Epoch: 922\n",
      "Train loss: tensor(224.7085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03650648793471711\n",
      "Test loss: 0.04643612938684107\n",
      "Epoch: 923\n",
      "Train loss: tensor(215.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03645920713121693\n",
      "Test loss: 0.04646573012860695\n",
      "Epoch: 924\n",
      "Train loss: tensor(144.3617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036499525389323634\n",
      "Test loss: 0.04652340356076118\n",
      "Epoch: 925\n",
      "Train loss: tensor(153.1359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03648511916842489\n",
      "Test loss: 0.04660906322706159\n",
      "Epoch: 926\n",
      "Train loss: tensor(119.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03637501335303698\n",
      "Test loss: 0.046572060278146574\n",
      "Epoch: 927\n",
      "Train loss: tensor(97.9105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03643188647748459\n",
      "Test loss: 0.04665532037800196\n",
      "Epoch: 928\n",
      "Train loss: tensor(766.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03622814674551288\n",
      "Test loss: 0.045818527109257066\n",
      "Epoch: 929\n",
      "Train loss: tensor(120.6298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036576251206653455\n",
      "Test loss: 0.04556812887255213\n",
      "Epoch: 930\n",
      "Train loss: tensor(153.8628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036951132930283036\n",
      "Test loss: 0.04553600265137335\n",
      "Epoch: 931\n",
      "Train loss: tensor(134.3447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03717748764015379\n",
      "Test loss: 0.045392836379532765\n",
      "Epoch: 932\n",
      "Train loss: tensor(132.4422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03715333492007284\n",
      "Test loss: 0.0451679513559188\n",
      "Epoch: 933\n",
      "Train loss: tensor(176.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037167239450805245\n",
      "Test loss: 0.045088724380746334\n",
      "Epoch: 934\n",
      "Train loss: tensor(129.7934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03642886780379784\n",
      "Test loss: 0.042886274912864855\n",
      "Epoch: 935\n",
      "Train loss: tensor(102.0789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03573887352166431\n",
      "Test loss: 0.04120886203196674\n",
      "Epoch: 936\n",
      "Train loss: tensor(222.9286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03548041762606729\n",
      "Test loss: 0.040243955448933756\n",
      "Epoch: 937\n",
      "Train loss: tensor(74.9184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03512633357729231\n",
      "Test loss: 0.039539315101533835\n",
      "Epoch: 938\n",
      "Train loss: tensor(123.2555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0348733824722114\n",
      "Test loss: 0.039181708404333285\n",
      "Epoch: 939\n",
      "Train loss: tensor(98.8747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03480151428264521\n",
      "Test loss: 0.03918999690783791\n",
      "Epoch: 940\n",
      "Train loss: tensor(210.8868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034752829310794674\n",
      "Test loss: 0.039386858361413576\n",
      "Epoch: 941\n",
      "Train loss: tensor(90.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034950896237222924\n",
      "Test loss: 0.03965469490330998\n",
      "Loss this time: tensor(86.5365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 942\n",
      "Train loss: tensor(86.5365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035503941388534646\n",
      "Test loss: 0.039764387745152015\n",
      "Epoch: 943\n",
      "Train loss: tensor(211.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03617123994266703\n",
      "Test loss: 0.04007830577764181\n",
      "Epoch: 944\n",
      "Train loss: tensor(275.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03688057953314412\n",
      "Test loss: 0.04054652768565287\n",
      "Epoch: 945\n",
      "Train loss: tensor(283.1765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03849197241167227\n",
      "Test loss: 0.041652330935075144\n",
      "Epoch: 946\n",
      "Train loss: tensor(114.1227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04035502697030703\n",
      "Test loss: 0.04312067197654212\n",
      "Epoch: 947\n",
      "Train loss: tensor(120.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042394997427860896\n",
      "Test loss: 0.04490626142314165\n",
      "Epoch: 948\n",
      "Train loss: tensor(188.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04580862720807393\n",
      "Test loss: 0.04799710855920716\n",
      "Epoch: 949\n",
      "Train loss: tensor(191.2045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04882203998665015\n",
      "Test loss: 0.05082482674924454\n",
      "Epoch: 950\n",
      "Train loss: tensor(131.2990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05205326447529452\n",
      "Test loss: 0.05379654253178304\n",
      "Epoch: 951\n",
      "Train loss: tensor(237.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05511883030689898\n",
      "Test loss: 0.056681626024517685\n",
      "Epoch: 952\n",
      "Train loss: tensor(124.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05815916062288341\n",
      "Test loss: 0.059631460337060516\n",
      "Epoch: 953\n",
      "Train loss: tensor(95.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06099675108811685\n",
      "Test loss: 0.06243936652963114\n",
      "Epoch: 954\n",
      "Train loss: tensor(220.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06409318129576388\n",
      "Test loss: 0.06567172822311963\n",
      "Epoch: 955\n",
      "Train loss: tensor(105.1917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06689512552249999\n",
      "Test loss: 0.06874575735171243\n",
      "Epoch: 956\n",
      "Train loss: tensor(121.8752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06866713441198781\n",
      "Test loss: 0.07084039917750524\n",
      "Epoch: 957\n",
      "Train loss: tensor(112.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06982971373058501\n",
      "Test loss: 0.07242487319330178\n",
      "Epoch: 958\n",
      "Train loss: tensor(74.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06831369989862045\n",
      "Test loss: 0.07168499289984161\n",
      "Epoch: 959\n",
      "Train loss: tensor(191.0425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0669998120605236\n",
      "Test loss: 0.07109695995724437\n",
      "Epoch: 960\n",
      "Train loss: tensor(79.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06580171389948754\n",
      "Test loss: 0.07065731342328657\n",
      "Epoch: 961\n",
      "Train loss: tensor(96.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06529949020949148\n",
      "Test loss: 0.07071524382670327\n",
      "Epoch: 962\n",
      "Train loss: tensor(111.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06488380784257537\n",
      "Test loss: 0.07086759837030775\n",
      "Epoch: 963\n",
      "Train loss: tensor(84.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06434134831208559\n",
      "Test loss: 0.07104991857737007\n",
      "Epoch: 964\n",
      "Train loss: tensor(105.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0636099494816292\n",
      "Test loss: 0.07114325433342468\n",
      "Epoch: 965\n",
      "Train loss: tensor(102.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06292593762988136\n",
      "Test loss: 0.07130158307159891\n",
      "Epoch: 966\n",
      "Train loss: tensor(116.3238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.06119671942932265\n",
      "Test loss: 0.06980144535882933\n",
      "Loss this time: tensor(270.0913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 967\n",
      "Train loss: tensor(270.0913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05689930447510311\n",
      "Test loss: 0.06434476345150482\n",
      "Epoch: 968\n",
      "Train loss: tensor(359.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050502415338442436\n",
      "Test loss: 0.05549017152758223\n",
      "Epoch: 969\n",
      "Train loss: tensor(152.7232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04549649161331001\n",
      "Test loss: 0.04876038738258994\n",
      "Epoch: 970\n",
      "Train loss: tensor(104.8511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04152100217040806\n",
      "Test loss: 0.04406025440496678\n",
      "Epoch: 971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(102.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03887636817636944\n",
      "Test loss: 0.041392345562355944\n",
      "Epoch: 972\n",
      "Train loss: tensor(84.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037178118114492724\n",
      "Test loss: 0.04012817482805193\n",
      "Epoch: 973\n",
      "Train loss: tensor(135.9507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036323460643844944\n",
      "Test loss: 0.040111570646709734\n",
      "Epoch: 974\n",
      "Train loss: tensor(137.1736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03603758893552281\n",
      "Test loss: 0.041005612046706795\n",
      "Epoch: 975\n",
      "Train loss: tensor(81.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03618470661874328\n",
      "Test loss: 0.042416969692279205\n",
      "Epoch: 976\n",
      "Train loss: tensor(164.7600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036731000741322836\n",
      "Test loss: 0.044044853105108334\n",
      "Epoch: 977\n",
      "Train loss: tensor(148.6965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03755048770634901\n",
      "Test loss: 0.04592189129146904\n",
      "Epoch: 978\n",
      "Train loss: tensor(231.4252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03828889232661043\n",
      "Test loss: 0.04757234184901313\n",
      "Epoch: 979\n",
      "Train loss: tensor(257.2452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03852413645280259\n",
      "Test loss: 0.04810336944969869\n",
      "Epoch: 980\n",
      "Train loss: tensor(102.7102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03870973536478622\n",
      "Test loss: 0.048561843988107575\n",
      "Epoch: 981\n",
      "Train loss: tensor(81.9566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03887434519295182\n",
      "Test loss: 0.04898094785132325\n",
      "Epoch: 982\n",
      "Train loss: tensor(99.6333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03900626707999479\n",
      "Test loss: 0.04938847305124054\n",
      "Epoch: 983\n",
      "Train loss: tensor(91.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03911964043620087\n",
      "Test loss: 0.04973949235633458\n",
      "Epoch: 984\n",
      "Train loss: tensor(128.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039222843962765874\n",
      "Test loss: 0.04995842624713879\n",
      "Epoch: 985\n",
      "Train loss: tensor(184.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03937629569942753\n",
      "Test loss: 0.05030971812545368\n",
      "Epoch: 986\n",
      "Train loss: tensor(139.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039512104168534276\n",
      "Test loss: 0.05062128449467444\n",
      "Epoch: 987\n",
      "Train loss: tensor(156.4747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03937616878676982\n",
      "Test loss: 0.05063297437264187\n",
      "Epoch: 988\n",
      "Train loss: tensor(141.2895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039281245028334\n",
      "Test loss: 0.050244214446606615\n",
      "Epoch: 989\n",
      "Train loss: tensor(60.6463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039411670643658865\n",
      "Test loss: 0.05005982861217886\n",
      "Epoch: 990\n",
      "Train loss: tensor(191.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03973694712455784\n",
      "Test loss: 0.05008643491212094\n",
      "Epoch: 991\n",
      "Train loss: tensor(378.4535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04020968403312422\n",
      "Test loss: 0.05026944175288819\n",
      "Epoch: 992\n",
      "Train loss: tensor(88.5105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04065035951013366\n",
      "Test loss: 0.05044496451310887\n",
      "Epoch: 993\n",
      "Train loss: tensor(194.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04099073776354392\n",
      "Test loss: 0.05044460508714218\n",
      "Epoch: 994\n",
      "Train loss: tensor(178.7110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04291846881664935\n",
      "Test loss: 0.052107837696624276\n",
      "Epoch: 995\n",
      "Train loss: tensor(229.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044521602314142955\n",
      "Test loss: 0.05333481296564978\n",
      "Epoch: 996\n",
      "Train loss: tensor(107.5622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04619408535460631\n",
      "Test loss: 0.05480007466740242\n",
      "Epoch: 997\n",
      "Train loss: tensor(155.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04709474626218989\n",
      "Test loss: 0.05546860871744333\n",
      "Epoch: 998\n",
      "Train loss: tensor(84.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04793643174426896\n",
      "Test loss: 0.05612594395470206\n",
      "Epoch: 999\n",
      "Train loss: tensor(103.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.049154339987962016\n",
      "Test loss: 0.05728648400100151\n",
      "Epoch: 1000\n",
      "Train loss: tensor(68.9462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05063111630401441\n",
      "Test loss: 0.05879299734525456\n",
      "Epoch: 1001\n",
      "Train loss: tensor(138.8351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05197845221984954\n",
      "Test loss: 0.0601094057506854\n",
      "Epoch: 1002\n",
      "Train loss: tensor(155.7470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053128509693557306\n",
      "Test loss: 0.06121853464236944\n",
      "Epoch: 1003\n",
      "Train loss: tensor(143.5259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05398040541580745\n",
      "Test loss: 0.06181960693090269\n",
      "Epoch: 1004\n",
      "Train loss: tensor(146.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054773910458953606\n",
      "Test loss: 0.06239429199238225\n",
      "Epoch: 1005\n",
      "Train loss: tensor(69.8112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.053419419351433\n",
      "Test loss: 0.06059349958996962\n",
      "Epoch: 1006\n",
      "Train loss: tensor(892.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0518369331335028\n",
      "Test loss: 0.05873214685828379\n",
      "Epoch: 1007\n",
      "Train loss: tensor(275.9566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050142115620630125\n",
      "Test loss: 0.05644481621756412\n",
      "Epoch: 1008\n",
      "Train loss: tensor(208.7501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04870685349617686\n",
      "Test loss: 0.05458925353676671\n",
      "Epoch: 1009\n",
      "Train loss: tensor(273.6694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.046212094658542244\n",
      "Test loss: 0.05174560157010461\n",
      "Epoch: 1010\n",
      "Train loss: tensor(194.3097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04395186427448477\n",
      "Test loss: 0.04910439770152368\n",
      "Epoch: 1011\n",
      "Train loss: tensor(1339.8180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0421329161240941\n",
      "Test loss: 0.0471625529266525\n",
      "Epoch: 1012\n",
      "Train loss: tensor(266.7923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04057665560394526\n",
      "Test loss: 0.04545903527685026\n",
      "Epoch: 1013\n",
      "Train loss: tensor(164.8437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03928259254122774\n",
      "Test loss: 0.04408592745514199\n",
      "Epoch: 1014\n",
      "Train loss: tensor(117.8481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037913729756006175\n",
      "Test loss: 0.04273413086660428\n",
      "Epoch: 1015\n",
      "Train loss: tensor(233.9065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036792938087490346\n",
      "Test loss: 0.041708364584805944\n",
      "Epoch: 1016\n",
      "Train loss: tensor(102.0267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03610607599396081\n",
      "Test loss: 0.040963607526725475\n",
      "Epoch: 1017\n",
      "Train loss: tensor(131.5883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035801121162339335\n",
      "Test loss: 0.04075290644449173\n",
      "Epoch: 1018\n",
      "Train loss: tensor(192.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035619808547198775\n",
      "Test loss: 0.04073288825589536\n",
      "Epoch: 1019\n",
      "Train loss: tensor(207.1884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03602425034290978\n",
      "Test loss: 0.04133724306922148\n",
      "Epoch: 1020\n",
      "Train loss: tensor(171.6840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03669332487153865\n",
      "Test loss: 0.04229598711844128\n",
      "Epoch: 1021\n",
      "Train loss: tensor(78.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03750312350956457\n",
      "Test loss: 0.04344135747835188\n",
      "Epoch: 1022\n",
      "Train loss: tensor(134.2354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03834912824400124\n",
      "Test loss: 0.044676417715404884\n",
      "Epoch: 1023\n",
      "Train loss: tensor(115.9248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039221603263701714\n",
      "Test loss: 0.045923665958908524\n",
      "Epoch: 1024\n",
      "Train loss: tensor(176.9481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04032320617919877\n",
      "Test loss: 0.04750743806177732\n",
      "Epoch: 1025\n",
      "Train loss: tensor(170.3646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04139477310790902\n",
      "Test loss: 0.04910477148461165\n",
      "Epoch: 1026\n",
      "Train loss: tensor(89.5637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04248291511709491\n",
      "Test loss: 0.05077040437977798\n",
      "Epoch: 1027\n",
      "Train loss: tensor(127.3191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04324191841962082\n",
      "Test loss: 0.05202665692656347\n",
      "Epoch: 1028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(114.1294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04392529354829874\n",
      "Test loss: 0.05311348258821976\n",
      "Epoch: 1029\n",
      "Train loss: tensor(103.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04459130797269089\n",
      "Test loss: 0.05415673028806796\n",
      "Epoch: 1030\n",
      "Train loss: tensor(173.0328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04513948524282092\n",
      "Test loss: 0.05503135601906936\n",
      "Epoch: 1031\n",
      "Train loss: tensor(100.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045618767672706215\n",
      "Test loss: 0.05578588552791441\n",
      "Epoch: 1032\n",
      "Train loss: tensor(155.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04600502414894955\n",
      "Test loss: 0.0564221119978419\n",
      "Epoch: 1033\n",
      "Train loss: tensor(115.3237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04624696109621298\n",
      "Test loss: 0.0568208885609661\n",
      "Epoch: 1034\n",
      "Train loss: tensor(182.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.046397573394434795\n",
      "Test loss: 0.05710712618812328\n",
      "Epoch: 1035\n",
      "Train loss: tensor(78.1687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.046448247467300724\n",
      "Test loss: 0.057151582765180876\n",
      "Epoch: 1036\n",
      "Train loss: tensor(110.7255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04644296913008605\n",
      "Test loss: 0.05711388322386411\n",
      "Epoch: 1037\n",
      "Train loss: tensor(156.3447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04703903018629977\n",
      "Test loss: 0.057826918734255994\n",
      "Epoch: 1038\n",
      "Train loss: tensor(127.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04770900822643723\n",
      "Test loss: 0.05861109701713713\n",
      "Epoch: 1039\n",
      "Train loss: tensor(162.3874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047529513983144644\n",
      "Test loss: 0.05809821495509679\n",
      "Epoch: 1040\n",
      "Train loss: tensor(144.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04741885803994678\n",
      "Test loss: 0.057697272721198525\n",
      "Epoch: 1041\n",
      "Train loss: tensor(176.9097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.047273363696322554\n",
      "Test loss: 0.05727771179990308\n",
      "Epoch: 1042\n",
      "Train loss: tensor(141.1967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04636033336587605\n",
      "Test loss: 0.05571136630075698\n",
      "Epoch: 1043\n",
      "Train loss: tensor(248.6144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04562701272024285\n",
      "Test loss: 0.054431681069407135\n",
      "Epoch: 1044\n",
      "Train loss: tensor(79.1449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.044975513361749195\n",
      "Test loss: 0.0532982154832323\n",
      "Epoch: 1045\n",
      "Train loss: tensor(158.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04442295496839853\n",
      "Test loss: 0.05228463201645282\n",
      "Epoch: 1046\n",
      "Train loss: tensor(224.7809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042917479663377715\n",
      "Test loss: 0.04983214860652933\n",
      "Epoch: 1047\n",
      "Train loss: tensor(112.9387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04142822320351289\n",
      "Test loss: 0.047708859925370405\n",
      "Epoch: 1048\n",
      "Train loss: tensor(132.0639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04017155042716435\n",
      "Test loss: 0.045897625266841734\n",
      "Epoch: 1049\n",
      "Train loss: tensor(139.4653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03978035587462641\n",
      "Test loss: 0.045416584736344835\n",
      "Loss this time: tensor(167.8228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1050\n",
      "Train loss: tensor(167.8228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0393355387263\n",
      "Test loss: 0.0448814265079575\n",
      "Epoch: 1051\n",
      "Train loss: tensor(160.0741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03792351610248997\n",
      "Test loss: 0.04292313943589383\n",
      "Epoch: 1052\n",
      "Train loss: tensor(270.8214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0367157550750389\n",
      "Test loss: 0.041439830989457006\n",
      "Epoch: 1053\n",
      "Train loss: tensor(200.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035635426072847275\n",
      "Test loss: 0.040272172706404534\n",
      "Epoch: 1054\n",
      "Train loss: tensor(107.2668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0350969476669672\n",
      "Test loss: 0.03969167257742126\n",
      "Epoch: 1055\n",
      "Train loss: tensor(152.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03486777763547642\n",
      "Test loss: 0.03952374510319516\n",
      "Epoch: 1056\n",
      "Train loss: tensor(100.1578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03483638017482701\n",
      "Test loss: 0.0396664504810135\n",
      "Epoch: 1057\n",
      "Train loss: tensor(102.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03476825689098665\n",
      "Test loss: 0.03987400454127848\n",
      "Epoch: 1058\n",
      "Train loss: tensor(140.8821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03477506608746591\n",
      "Test loss: 0.040125525104674965\n",
      "Epoch: 1059\n",
      "Train loss: tensor(128.9664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03482439666099492\n",
      "Test loss: 0.040415682544064996\n",
      "Epoch: 1060\n",
      "Train loss: tensor(190.7610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03485847602465323\n",
      "Test loss: 0.04012553543221242\n",
      "Epoch: 1061\n",
      "Train loss: tensor(151.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03491462780872271\n",
      "Test loss: 0.039954581528459446\n",
      "Epoch: 1062\n",
      "Train loss: tensor(79.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034675875993534215\n",
      "Test loss: 0.03959630355054494\n",
      "Epoch: 1063\n",
      "Train loss: tensor(199.0504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03456433588816296\n",
      "Test loss: 0.0393161162328307\n",
      "Epoch: 1064\n",
      "Train loss: tensor(99.8034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034485655734759\n",
      "Test loss: 0.03916455709403104\n",
      "Epoch: 1065\n",
      "Train loss: tensor(103.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03447050491259212\n",
      "Test loss: 0.03911978921087662\n",
      "Epoch: 1066\n",
      "Train loss: tensor(121.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03454459282081752\n",
      "Test loss: 0.039186875861470065\n",
      "Epoch: 1067\n",
      "Train loss: tensor(162.8962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034426233119198256\n",
      "Test loss: 0.03914540311745783\n",
      "Epoch: 1068\n",
      "Train loss: tensor(127.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03433383967106541\n",
      "Test loss: 0.03912164429479306\n",
      "Epoch: 1069\n",
      "Train loss: tensor(174.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034231760716509255\n",
      "Test loss: 0.039089676029611345\n",
      "Loss this time: tensor(205.8527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1070\n",
      "Train loss: tensor(205.8527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03399358973173158\n",
      "Test loss: 0.03889970065527918\n",
      "Epoch: 1071\n",
      "Train loss: tensor(283.7439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03371090547492107\n",
      "Test loss: 0.03870510327454546\n",
      "Epoch: 1072\n",
      "Train loss: tensor(877.4056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03361169923806474\n",
      "Test loss: 0.03862594476541375\n",
      "Epoch: 1073\n",
      "Train loss: tensor(196.4051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03352903754760821\n",
      "Test loss: 0.03861863497128286\n",
      "Epoch: 1074\n",
      "Train loss: tensor(152.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03347397152600544\n",
      "Test loss: 0.03876765797117559\n",
      "Epoch: 1075\n",
      "Train loss: tensor(130.2639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033499370905615035\n",
      "Test loss: 0.039054385091334874\n",
      "Epoch: 1076\n",
      "Train loss: tensor(127.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033557649156344786\n",
      "Test loss: 0.03927112237946822\n",
      "Epoch: 1077\n",
      "Train loss: tensor(132.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03362086339898053\n",
      "Test loss: 0.03949373704150762\n",
      "Epoch: 1078\n",
      "Train loss: tensor(131.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03368780863515678\n",
      "Test loss: 0.039718580376910104\n",
      "Epoch: 1079\n",
      "Train loss: tensor(123.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03348505205164353\n",
      "Test loss: 0.03974721638836188\n",
      "Epoch: 1080\n",
      "Train loss: tensor(164.2172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033364332418534016\n",
      "Test loss: 0.03998713264481561\n",
      "Epoch: 1081\n",
      "Train loss: tensor(170.3676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033289655271385395\n",
      "Test loss: 0.040264727473996655\n",
      "Epoch: 1082\n",
      "Train loss: tensor(122.6409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033187920329648825\n",
      "Test loss: 0.040533561499254536\n",
      "Epoch: 1083\n",
      "Train loss: tensor(61.0286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033188239644680706\n",
      "Test loss: 0.04087466103863893\n",
      "Epoch: 1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(141.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03320638170199735\n",
      "Test loss: 0.04117023262499583\n",
      "Epoch: 1085\n",
      "Train loss: tensor(112.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03322957643263397\n",
      "Test loss: 0.0414604811772409\n",
      "Epoch: 1086\n",
      "Train loss: tensor(106.8832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03325852613363947\n",
      "Test loss: 0.041663083542912906\n",
      "Epoch: 1087\n",
      "Train loss: tensor(138.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03329423602138247\n",
      "Test loss: 0.04186061368609714\n",
      "Epoch: 1088\n",
      "Train loss: tensor(80.6877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03334335251933052\n",
      "Test loss: 0.04205815640674664\n",
      "Epoch: 1089\n",
      "Train loss: tensor(234.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033382322940798036\n",
      "Test loss: 0.042116974148493594\n",
      "Epoch: 1090\n",
      "Train loss: tensor(163.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03332910395803906\n",
      "Test loss: 0.04181583968940938\n",
      "Epoch: 1091\n",
      "Train loss: tensor(114.3796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03330746478445473\n",
      "Test loss: 0.041545209041473886\n",
      "Epoch: 1092\n",
      "Train loss: tensor(207.2269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033155612824928196\n",
      "Test loss: 0.04049310582404089\n",
      "Epoch: 1093\n",
      "Train loss: tensor(160.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03310558290353843\n",
      "Test loss: 0.039810340630240956\n",
      "Epoch: 1094\n",
      "Train loss: tensor(129.7261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03314468671700784\n",
      "Test loss: 0.03928153542340687\n",
      "Epoch: 1095\n",
      "Train loss: tensor(89.9415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03325678850745871\n",
      "Test loss: 0.038910833353379574\n",
      "Epoch: 1096\n",
      "Train loss: tensor(198.0951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0333811178359957\n",
      "Test loss: 0.038693557733135056\n",
      "Epoch: 1097\n",
      "Train loss: tensor(140.9699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.033482883435984455\n",
      "Test loss: 0.03860848811962227\n",
      "Epoch: 1098\n",
      "Train loss: tensor(116.3073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03362931158571016\n",
      "Test loss: 0.0385211636911672\n",
      "Epoch: 1099\n",
      "Train loss: tensor(179.2830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03403613545177948\n",
      "Test loss: 0.03853165693949945\n",
      "Epoch: 1100\n",
      "Train loss: tensor(223.6755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.034766880644574054\n",
      "Test loss: 0.038791832670864494\n",
      "Epoch: 1101\n",
      "Train loss: tensor(123.1693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03561951292767411\n",
      "Test loss: 0.03924643702915694\n",
      "Epoch: 1102\n",
      "Train loss: tensor(153.9651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03647763659024522\n",
      "Test loss: 0.039826618793355945\n",
      "Epoch: 1103\n",
      "Train loss: tensor(180.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03732504905866725\n",
      "Test loss: 0.040438702754159964\n",
      "Epoch: 1104\n",
      "Train loss: tensor(114.0953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03823195620927782\n",
      "Test loss: 0.04112480568819412\n",
      "Epoch: 1105\n",
      "Train loss: tensor(215.7693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039268456856232314\n",
      "Test loss: 0.041926941566980715\n",
      "Epoch: 1106\n",
      "Train loss: tensor(172.4103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040185492831681456\n",
      "Test loss: 0.04265596761856929\n",
      "Epoch: 1107\n",
      "Train loss: tensor(92.6324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04122852699919825\n",
      "Test loss: 0.04348560721419825\n",
      "Epoch: 1108\n",
      "Train loss: tensor(141.1948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04215449498345455\n",
      "Test loss: 0.04424335766989406\n",
      "Epoch: 1109\n",
      "Train loss: tensor(230.4052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04241737056346167\n",
      "Test loss: 0.04439960509575534\n",
      "Epoch: 1110\n",
      "Train loss: tensor(147.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042786467882494135\n",
      "Test loss: 0.04467929341821092\n",
      "Epoch: 1111\n",
      "Train loss: tensor(87.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04318404333399875\n",
      "Test loss: 0.04499760307002776\n",
      "Epoch: 1112\n",
      "Train loss: tensor(228.2152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04335542278630393\n",
      "Test loss: 0.04513385546126283\n",
      "Epoch: 1113\n",
      "Train loss: tensor(125.7448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04379785221424841\n",
      "Test loss: 0.04556570879856844\n",
      "Epoch: 1114\n",
      "Train loss: tensor(225.8869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04639529356112083\n",
      "Test loss: 0.04935974739307519\n",
      "Epoch: 1115\n",
      "Train loss: tensor(260.6841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04852663506531999\n",
      "Test loss: 0.05301932276844388\n",
      "Epoch: 1116\n",
      "Train loss: tensor(140.8180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05034727017794337\n",
      "Test loss: 0.05654158007980573\n",
      "Epoch: 1117\n",
      "Train loss: tensor(115.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05252803458521763\n",
      "Test loss: 0.06043416491276262\n",
      "Epoch: 1118\n",
      "Train loss: tensor(141.1330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054546359332189674\n",
      "Test loss: 0.06416086809211734\n",
      "Epoch: 1119\n",
      "Train loss: tensor(144.5396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05593784672341177\n",
      "Test loss: 0.0667873387695244\n",
      "Epoch: 1120\n",
      "Train loss: tensor(112.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05735738650851306\n",
      "Test loss: 0.06939805871668724\n",
      "Epoch: 1121\n",
      "Train loss: tensor(92.7449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0584810894248741\n",
      "Test loss: 0.07166237095463099\n",
      "Epoch: 1122\n",
      "Train loss: tensor(187.2591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058821863796384564\n",
      "Test loss: 0.07302892008925428\n",
      "Epoch: 1123\n",
      "Train loss: tensor(115.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058867535784485794\n",
      "Test loss: 0.07413355341310253\n",
      "Epoch: 1124\n",
      "Train loss: tensor(178.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05912409320118881\n",
      "Test loss: 0.07525419968521536\n",
      "Epoch: 1125\n",
      "Train loss: tensor(111.1908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05870387861061664\n",
      "Test loss: 0.07506542487789204\n",
      "Epoch: 1126\n",
      "Train loss: tensor(68.1994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05870815886273271\n",
      "Test loss: 0.07513115825223746\n",
      "Epoch: 1127\n",
      "Train loss: tensor(110.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058675730813826835\n",
      "Test loss: 0.07515035229412341\n",
      "Epoch: 1128\n",
      "Train loss: tensor(122.7785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058788181522062846\n",
      "Test loss: 0.07523723292431914\n",
      "Epoch: 1129\n",
      "Train loss: tensor(190.2720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.058139426695803804\n",
      "Test loss: 0.07414155328037715\n",
      "Epoch: 1130\n",
      "Train loss: tensor(74.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.057223555818200114\n",
      "Test loss: 0.07291957320147517\n",
      "Epoch: 1131\n",
      "Train loss: tensor(122.5279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.056173596903681754\n",
      "Test loss: 0.07151772977212573\n",
      "Epoch: 1132\n",
      "Train loss: tensor(149.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.054323274934930464\n",
      "Test loss: 0.06815910241612703\n",
      "Epoch: 1133\n",
      "Train loss: tensor(135.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05244885681285744\n",
      "Test loss: 0.06440034967911716\n",
      "Epoch: 1134\n",
      "Train loss: tensor(147.1373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.05030936250197036\n",
      "Test loss: 0.060155131005783485\n",
      "Epoch: 1135\n",
      "Train loss: tensor(190.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04836860370068323\n",
      "Test loss: 0.0559658728134219\n",
      "Epoch: 1136\n",
      "Train loss: tensor(235.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04641711897261086\n",
      "Test loss: 0.051930457676327466\n",
      "Epoch: 1137\n",
      "Train loss: tensor(87.2581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04492009243972245\n",
      "Test loss: 0.04895483881308891\n",
      "Epoch: 1138\n",
      "Train loss: tensor(119.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043763249411824204\n",
      "Test loss: 0.04677445428575029\n",
      "Epoch: 1139\n",
      "Train loss: tensor(169.8080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04291497028122346\n",
      "Test loss: 0.045305571860015985\n",
      "Epoch: 1140\n",
      "Train loss: tensor(218.3916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04241325198894455\n",
      "Test loss: 0.04450013060675989\n",
      "Epoch: 1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(116.9268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04200302161985919\n",
      "Test loss: 0.0440331534067593\n",
      "Epoch: 1142\n",
      "Train loss: tensor(95.8792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04173658966485943\n",
      "Test loss: 0.04386467709768527\n",
      "Epoch: 1143\n",
      "Train loss: tensor(153.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041568864385286966\n",
      "Test loss: 0.0439077050305239\n",
      "Epoch: 1144\n",
      "Train loss: tensor(177.1392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04147814735770226\n",
      "Test loss: 0.04409953214154385\n",
      "Epoch: 1145\n",
      "Train loss: tensor(113.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04100426319277003\n",
      "Test loss: 0.044045060688611304\n",
      "Epoch: 1146\n",
      "Train loss: tensor(97.0428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040404238268023446\n",
      "Test loss: 0.04394354392765182\n",
      "Epoch: 1147\n",
      "Train loss: tensor(181.5651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03988999838807753\n",
      "Test loss: 0.04390185041408433\n",
      "Epoch: 1148\n",
      "Train loss: tensor(95.2664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0394062622317246\n",
      "Test loss: 0.04387084248079227\n",
      "Epoch: 1149\n",
      "Train loss: tensor(123.4474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03904960728915674\n",
      "Test loss: 0.04393326946635648\n",
      "Epoch: 1150\n",
      "Train loss: tensor(138.8937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03854409317885126\n",
      "Test loss: 0.04384099997321863\n",
      "Epoch: 1151\n",
      "Train loss: tensor(74.2907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03830260561690444\n",
      "Test loss: 0.04397655560607367\n",
      "Epoch: 1152\n",
      "Train loss: tensor(136.3409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03823327264260678\n",
      "Test loss: 0.04422695961513436\n",
      "Epoch: 1153\n",
      "Train loss: tensor(134.2774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038304514899140316\n",
      "Test loss: 0.044598521941369124\n",
      "Epoch: 1154\n",
      "Train loss: tensor(158.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03847033729155858\n",
      "Test loss: 0.045039387521251\n",
      "Epoch: 1155\n",
      "Train loss: tensor(119.5227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038683184795081614\n",
      "Test loss: 0.04548981470415498\n",
      "Epoch: 1156\n",
      "Train loss: tensor(144.2619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03886471661251216\n",
      "Test loss: 0.045844693797280886\n",
      "Epoch: 1157\n",
      "Train loss: tensor(121.8074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039022013553906054\n",
      "Test loss: 0.04607009317836549\n",
      "Epoch: 1158\n",
      "Train loss: tensor(100.0343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03923696311456817\n",
      "Test loss: 0.04629843603672072\n",
      "Epoch: 1159\n",
      "Train loss: tensor(109.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03925436796354396\n",
      "Test loss: 0.04634558813332921\n",
      "Epoch: 1160\n",
      "Train loss: tensor(113.1337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03920482289755628\n",
      "Test loss: 0.046317467078714085\n",
      "Epoch: 1161\n",
      "Train loss: tensor(160.3331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03906573062496526\n",
      "Test loss: 0.04605309955665086\n",
      "Epoch: 1162\n",
      "Train loss: tensor(106.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03875239918984118\n",
      "Test loss: 0.04553539277340221\n",
      "Epoch: 1163\n",
      "Train loss: tensor(192.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03848791163237322\n",
      "Test loss: 0.04510521434136842\n",
      "Epoch: 1164\n",
      "Train loss: tensor(98.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03813254622121652\n",
      "Test loss: 0.04463270444902453\n",
      "Epoch: 1165\n",
      "Train loss: tensor(152.1694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037851434626749586\n",
      "Test loss: 0.044279883375926185\n",
      "Epoch: 1166\n",
      "Train loss: tensor(104.3509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03763528360674779\n",
      "Test loss: 0.043976227780527406\n",
      "Epoch: 1167\n",
      "Train loss: tensor(181.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037431951567885424\n",
      "Test loss: 0.0436636505205885\n",
      "Epoch: 1168\n",
      "Train loss: tensor(185.9027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037218216540558\n",
      "Test loss: 0.043222539117652004\n",
      "Epoch: 1169\n",
      "Train loss: tensor(73.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037056260006058786\n",
      "Test loss: 0.042847867225213804\n",
      "Epoch: 1170\n",
      "Train loss: tensor(120.2103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03724079913504067\n",
      "Test loss: 0.04284331269820433\n",
      "Epoch: 1171\n",
      "Train loss: tensor(73.7243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037481286177145585\n",
      "Test loss: 0.042926198194301365\n",
      "Epoch: 1172\n",
      "Train loss: tensor(166.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03772491465455719\n",
      "Test loss: 0.042224465030254704\n",
      "Epoch: 1173\n",
      "Train loss: tensor(103.1361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038245166470074934\n",
      "Test loss: 0.04222286618914049\n",
      "Epoch: 1174\n",
      "Train loss: tensor(110.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03888850337603972\n",
      "Test loss: 0.04267255662211982\n",
      "Epoch: 1175\n",
      "Train loss: tensor(124.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03893429998840604\n",
      "Test loss: 0.04274453038331306\n",
      "Epoch: 1176\n",
      "Train loss: tensor(154.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03908030352156077\n",
      "Test loss: 0.043064857833087444\n",
      "Epoch: 1177\n",
      "Train loss: tensor(143.5831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0398155246861279\n",
      "Test loss: 0.044422386831945125\n",
      "Epoch: 1178\n",
      "Train loss: tensor(209.5606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04051817465307457\n",
      "Test loss: 0.045986771389915804\n",
      "Epoch: 1179\n",
      "Train loss: tensor(167.5493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041192558904488884\n",
      "Test loss: 0.04765802334145744\n",
      "Epoch: 1180\n",
      "Train loss: tensor(133.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04171766351376261\n",
      "Test loss: 0.04916604919967675\n",
      "Epoch: 1181\n",
      "Train loss: tensor(95.6409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04094635504076169\n",
      "Test loss: 0.04928261891818873\n",
      "Epoch: 1182\n",
      "Train loss: tensor(123.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04005617500681962\n",
      "Test loss: 0.04873343842048751\n",
      "Epoch: 1183\n",
      "Train loss: tensor(133.5534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039598116801962964\n",
      "Test loss: 0.0485764023857099\n",
      "Epoch: 1184\n",
      "Train loss: tensor(140.6040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03950810689656507\n",
      "Test loss: 0.04873804549806484\n",
      "Epoch: 1185\n",
      "Train loss: tensor(133.3154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03928997082014878\n",
      "Test loss: 0.048314069047348925\n",
      "Epoch: 1186\n",
      "Train loss: tensor(72.7000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03948496774814668\n",
      "Test loss: 0.04820056736358617\n",
      "Epoch: 1187\n",
      "Train loss: tensor(119.4039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039980770616481705\n",
      "Test loss: 0.04833954119925747\n",
      "Epoch: 1188\n",
      "Train loss: tensor(239.6197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0406591321829529\n",
      "Test loss: 0.04864445479937119\n",
      "Epoch: 1189\n",
      "Train loss: tensor(135.6305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041339132101053284\n",
      "Test loss: 0.04875170981677452\n",
      "Epoch: 1190\n",
      "Train loss: tensor(135.4103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04198984119242855\n",
      "Test loss: 0.04879605253734211\n",
      "Epoch: 1191\n",
      "Train loss: tensor(174.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042129836493127404\n",
      "Test loss: 0.048515735350844295\n",
      "Epoch: 1192\n",
      "Train loss: tensor(146.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042339038915399994\n",
      "Test loss: 0.04838666145569912\n",
      "Epoch: 1193\n",
      "Train loss: tensor(102.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0425318907103723\n",
      "Test loss: 0.048152375772669176\n",
      "Epoch: 1194\n",
      "Train loss: tensor(352.2989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04221723238449721\n",
      "Test loss: 0.04676118041250375\n",
      "Epoch: 1195\n",
      "Train loss: tensor(238.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04194111330878167\n",
      "Test loss: 0.04551272165251545\n",
      "Epoch: 1196\n",
      "Train loss: tensor(235.3021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04203949918349584\n",
      "Test loss: 0.04531586089051596\n",
      "Epoch: 1197\n",
      "Train loss: tensor(869.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042431725366484555\n",
      "Test loss: 0.04624742200358374\n",
      "Epoch: 1198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(100.6280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042320693559235054\n",
      "Test loss: 0.047111540396541064\n",
      "Epoch: 1199\n",
      "Train loss: tensor(141.9197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04247785845682735\n",
      "Test loss: 0.048536561789120185\n",
      "Epoch: 1200\n",
      "Train loss: tensor(108.1413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04296723545661994\n",
      "Test loss: 0.050506753745571814\n",
      "Epoch: 1201\n",
      "Train loss: tensor(122.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04316389815260967\n",
      "Test loss: 0.05188675748534722\n",
      "Epoch: 1202\n",
      "Train loss: tensor(229.4144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04350161512515375\n",
      "Test loss: 0.05334641830534628\n",
      "Epoch: 1203\n",
      "Train loss: tensor(308.8396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04323709596480642\n",
      "Test loss: 0.053551264448404905\n",
      "Epoch: 1204\n",
      "Train loss: tensor(91.5394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04263866753982646\n",
      "Test loss: 0.053476972662207516\n",
      "Epoch: 1205\n",
      "Train loss: tensor(103.1020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042390841352088114\n",
      "Test loss: 0.053672511868252615\n",
      "Epoch: 1206\n",
      "Train loss: tensor(170.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04229227480079446\n",
      "Test loss: 0.0539287842837817\n",
      "Epoch: 1207\n",
      "Train loss: tensor(149.1331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0418805299681567\n",
      "Test loss: 0.053591440514762806\n",
      "Epoch: 1208\n",
      "Train loss: tensor(211.1605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04070580586170157\n",
      "Test loss: 0.051643096039643385\n",
      "Epoch: 1209\n",
      "Train loss: tensor(123.8146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039148896089976744\n",
      "Test loss: 0.04883431189573637\n",
      "Epoch: 1210\n",
      "Train loss: tensor(180.4183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03795814002376227\n",
      "Test loss: 0.04654775023239084\n",
      "Epoch: 1211\n",
      "Train loss: tensor(116.8029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036975137108848206\n",
      "Test loss: 0.0444017733622453\n",
      "Epoch: 1212\n",
      "Train loss: tensor(252.9064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03616814755258106\n",
      "Test loss: 0.042772773312091235\n",
      "Epoch: 1213\n",
      "Train loss: tensor(90.5817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03573526990200792\n",
      "Test loss: 0.04177154932576831\n",
      "Epoch: 1214\n",
      "Train loss: tensor(122.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03547801093774892\n",
      "Test loss: 0.0410623481165212\n",
      "Epoch: 1215\n",
      "Train loss: tensor(177.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035235069474826256\n",
      "Test loss: 0.040264565442310704\n",
      "Epoch: 1216\n",
      "Train loss: tensor(167.2856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03527495392731258\n",
      "Test loss: 0.03989055071321159\n",
      "Epoch: 1217\n",
      "Train loss: tensor(105.2279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03587414491478176\n",
      "Test loss: 0.040581076830109156\n",
      "Epoch: 1218\n",
      "Train loss: tensor(123.4260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036849579246093826\n",
      "Test loss: 0.04200828158398076\n",
      "Epoch: 1219\n",
      "Train loss: tensor(144.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03796638683637693\n",
      "Test loss: 0.043928486479464735\n",
      "Epoch: 1220\n",
      "Train loss: tensor(96.7608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039188335623059956\n",
      "Test loss: 0.046217074737616694\n",
      "Epoch: 1221\n",
      "Train loss: tensor(148.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040174545250123456\n",
      "Test loss: 0.04817192902843846\n",
      "Epoch: 1222\n",
      "Train loss: tensor(227.5753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04109243658326921\n",
      "Test loss: 0.049979581045779854\n",
      "Epoch: 1223\n",
      "Train loss: tensor(104.2571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04169443885219239\n",
      "Test loss: 0.051293302152195186\n",
      "Epoch: 1224\n",
      "Train loss: tensor(86.6126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04190240217638867\n",
      "Test loss: 0.05209268252411396\n",
      "Epoch: 1225\n",
      "Train loss: tensor(113.8832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04185137212986038\n",
      "Test loss: 0.05242252780474944\n",
      "Epoch: 1226\n",
      "Train loss: tensor(171.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04185513921436809\n",
      "Test loss: 0.05280530401090584\n",
      "Epoch: 1227\n",
      "Train loss: tensor(160.9567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04194113574922085\n",
      "Test loss: 0.05325445316104901\n",
      "Epoch: 1228\n",
      "Train loss: tensor(155.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041898744606545996\n",
      "Test loss: 0.05317530176132032\n",
      "Epoch: 1229\n",
      "Train loss: tensor(113.3187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041929144882375285\n",
      "Test loss: 0.0531954828483781\n",
      "Epoch: 1230\n",
      "Train loss: tensor(167.6457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04194312117816437\n",
      "Test loss: 0.053192339026101744\n",
      "Epoch: 1231\n",
      "Train loss: tensor(181.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04184727117951427\n",
      "Test loss: 0.053135867544108685\n",
      "Epoch: 1232\n",
      "Train loss: tensor(109.4786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041793997887344586\n",
      "Test loss: 0.053093961513794884\n",
      "Epoch: 1233\n",
      "Train loss: tensor(193.4305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04183036313347873\n",
      "Test loss: 0.053078207122807454\n",
      "Epoch: 1234\n",
      "Train loss: tensor(153.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04193262667616918\n",
      "Test loss: 0.053130448675981844\n",
      "Epoch: 1235\n",
      "Train loss: tensor(182.5154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04214201625436544\n",
      "Test loss: 0.05325177424393668\n",
      "Epoch: 1236\n",
      "Train loss: tensor(109.8116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04235810284014969\n",
      "Test loss: 0.053369224126828776\n",
      "Epoch: 1237\n",
      "Train loss: tensor(191.5002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04257958425829808\n",
      "Test loss: 0.0534968289205491\n",
      "Epoch: 1238\n",
      "Train loss: tensor(241.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04214932061731815\n",
      "Test loss: 0.0519537701649536\n",
      "Epoch: 1239\n",
      "Train loss: tensor(173.6170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04151493278997285\n",
      "Test loss: 0.04988628274549057\n",
      "Epoch: 1240\n",
      "Train loss: tensor(137.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040878203555586794\n",
      "Test loss: 0.04812693298047427\n",
      "Epoch: 1241\n",
      "Train loss: tensor(139.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040250326081046034\n",
      "Test loss: 0.04663210042226728\n",
      "Epoch: 1242\n",
      "Train loss: tensor(147.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03987490203054178\n",
      "Test loss: 0.04550984819963722\n",
      "Epoch: 1243\n",
      "Train loss: tensor(124.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03945129926183394\n",
      "Test loss: 0.0443713170024428\n",
      "Epoch: 1244\n",
      "Train loss: tensor(165.7721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039226161058814754\n",
      "Test loss: 0.04381355780665532\n",
      "Epoch: 1245\n",
      "Train loss: tensor(196.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03904925419815949\n",
      "Test loss: 0.043384026357959404\n",
      "Epoch: 1246\n",
      "Train loss: tensor(200.6344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038710666359180496\n",
      "Test loss: 0.04288645457513261\n",
      "Epoch: 1247\n",
      "Train loss: tensor(108.4992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038376056615795406\n",
      "Test loss: 0.0424435632211147\n",
      "Epoch: 1248\n",
      "Train loss: tensor(143.7170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03806039812486796\n",
      "Test loss: 0.04208063179313546\n",
      "Epoch: 1249\n",
      "Train loss: tensor(168.8440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03754715884015674\n",
      "Test loss: 0.04160285623061775\n",
      "Epoch: 1250\n",
      "Train loss: tensor(148.1072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037118324473322854\n",
      "Test loss: 0.04122023180237796\n",
      "Epoch: 1251\n",
      "Train loss: tensor(111.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036773163315263535\n",
      "Test loss: 0.04092716139805789\n",
      "Epoch: 1252\n",
      "Train loss: tensor(183.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036454445389764646\n",
      "Test loss: 0.040677359844050784\n",
      "Epoch: 1253\n",
      "Train loss: tensor(78.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03610241659695194\n",
      "Test loss: 0.04042494069268503\n",
      "Epoch: 1254\n",
      "Train loss: tensor(124.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0358460935719666\n",
      "Test loss: 0.04025918975619987\n",
      "Epoch: 1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(100.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03565854748622293\n",
      "Test loss: 0.0401513943596199\n",
      "Epoch: 1256\n",
      "Train loss: tensor(92.1087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03565754362692435\n",
      "Test loss: 0.040189533125572274\n",
      "Epoch: 1257\n",
      "Train loss: tensor(146.4283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035756811543944333\n",
      "Test loss: 0.04024729015545385\n",
      "Epoch: 1258\n",
      "Train loss: tensor(121.9091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.035861807830986525\n",
      "Test loss: 0.04033230771633363\n",
      "Epoch: 1259\n",
      "Train loss: tensor(165.3030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03596144053375437\n",
      "Test loss: 0.04043161951116111\n",
      "Epoch: 1260\n",
      "Train loss: tensor(130.8772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0361132047893036\n",
      "Test loss: 0.04059530009912087\n",
      "Epoch: 1261\n",
      "Train loss: tensor(104.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03635473532513494\n",
      "Test loss: 0.04094191836100994\n",
      "Epoch: 1262\n",
      "Train loss: tensor(218.6430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036523791704149475\n",
      "Test loss: 0.04114106623916933\n",
      "Epoch: 1263\n",
      "Train loss: tensor(151.1315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03706931322813034\n",
      "Test loss: 0.04227375193950859\n",
      "Epoch: 1264\n",
      "Train loss: tensor(143.0272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037658126111186685\n",
      "Test loss: 0.04376050388200743\n",
      "Epoch: 1265\n",
      "Train loss: tensor(108.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038441132993570395\n",
      "Test loss: 0.04564834957813273\n",
      "Epoch: 1266\n",
      "Train loss: tensor(401.3678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03940572820249058\n",
      "Test loss: 0.04781109610074522\n",
      "Epoch: 1267\n",
      "Train loss: tensor(242.7836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039984727952451934\n",
      "Test loss: 0.048628700482151885\n",
      "Epoch: 1268\n",
      "Train loss: tensor(118.1451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04074738886916921\n",
      "Test loss: 0.049646821988764966\n",
      "Epoch: 1269\n",
      "Train loss: tensor(150.9540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041057975820842245\n",
      "Test loss: 0.049251197994050415\n",
      "Epoch: 1270\n",
      "Train loss: tensor(198.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04179169785763536\n",
      "Test loss: 0.050047109502893275\n",
      "Epoch: 1271\n",
      "Train loss: tensor(127.2486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0419412708442126\n",
      "Test loss: 0.04923244448618429\n",
      "Epoch: 1272\n",
      "Train loss: tensor(172.5178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042003126034424416\n",
      "Test loss: 0.04835210081263639\n",
      "Epoch: 1273\n",
      "Train loss: tensor(110.5878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.042152276023158006\n",
      "Test loss: 0.04782626607298556\n",
      "Epoch: 1274\n",
      "Train loss: tensor(158.3685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04231115196432386\n",
      "Test loss: 0.04745552712811692\n",
      "Epoch: 1275\n",
      "Train loss: tensor(174.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04267846892720887\n",
      "Test loss: 0.04743067914675368\n",
      "Epoch: 1276\n",
      "Train loss: tensor(431.9018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04196143094450235\n",
      "Test loss: 0.046457547178067785\n",
      "Epoch: 1277\n",
      "Train loss: tensor(272.1830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041404580440194835\n",
      "Test loss: 0.04573082441630045\n",
      "Epoch: 1278\n",
      "Train loss: tensor(191.1639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04101699949020431\n",
      "Test loss: 0.04526937304820755\n",
      "Epoch: 1279\n",
      "Train loss: tensor(151.3919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040210578546282794\n",
      "Test loss: 0.044389928986161654\n",
      "Epoch: 1280\n",
      "Train loss: tensor(76.1613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038932340423620884\n",
      "Test loss: 0.04301356786105892\n",
      "Epoch: 1281\n",
      "Train loss: tensor(183.8395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03830409629181737\n",
      "Test loss: 0.04230972916109137\n",
      "Epoch: 1282\n",
      "Train loss: tensor(97.5325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03810964534502654\n",
      "Test loss: 0.042022694068232384\n",
      "Epoch: 1283\n",
      "Train loss: tensor(274.6287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038136866289590086\n",
      "Test loss: 0.04195764099275417\n",
      "Epoch: 1284\n",
      "Train loss: tensor(133.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038523905112275054\n",
      "Test loss: 0.042212771814279626\n",
      "Epoch: 1285\n",
      "Train loss: tensor(206.6802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03919683785310813\n",
      "Test loss: 0.04269581565651858\n",
      "Epoch: 1286\n",
      "Train loss: tensor(114.9777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03996472407487177\n",
      "Test loss: 0.04327012619722893\n",
      "Epoch: 1287\n",
      "Train loss: tensor(75.4911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040430607478178684\n",
      "Test loss: 0.04365593008697033\n",
      "Epoch: 1288\n",
      "Train loss: tensor(201.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040907242690168676\n",
      "Test loss: 0.044142562075342874\n",
      "Epoch: 1289\n",
      "Train loss: tensor(187.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04130485695565031\n",
      "Test loss: 0.044530513853129776\n",
      "Epoch: 1290\n",
      "Train loss: tensor(288.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041056805059668564\n",
      "Test loss: 0.0444770985568809\n",
      "Epoch: 1291\n",
      "Train loss: tensor(133.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041226544089260554\n",
      "Test loss: 0.04476958192368545\n",
      "Epoch: 1292\n",
      "Train loss: tensor(105.4679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04028336415510802\n",
      "Test loss: 0.04419435676888074\n",
      "Epoch: 1293\n",
      "Train loss: tensor(108.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03954981460812546\n",
      "Test loss: 0.04382839887449057\n",
      "Epoch: 1294\n",
      "Train loss: tensor(150.8620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03898129328375771\n",
      "Test loss: 0.04360624535544084\n",
      "Epoch: 1295\n",
      "Train loss: tensor(144.4769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.038701558423539\n",
      "Test loss: 0.04377038301070138\n",
      "Epoch: 1296\n",
      "Train loss: tensor(326.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03858058046372164\n",
      "Test loss: 0.044224876845900964\n",
      "Epoch: 1297\n",
      "Train loss: tensor(260.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03893936510596956\n",
      "Test loss: 0.04516216171075507\n",
      "Epoch: 1298\n",
      "Train loss: tensor(169.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03953622074886447\n",
      "Test loss: 0.04703548940654734\n",
      "Epoch: 1299\n",
      "Train loss: tensor(179.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04000145005328315\n",
      "Test loss: 0.04870174894349115\n",
      "Epoch: 1300\n",
      "Train loss: tensor(228.5257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040887521025502964\n",
      "Test loss: 0.05128322011505318\n",
      "Epoch: 1301\n",
      "Train loss: tensor(129.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041272949210057655\n",
      "Test loss: 0.0524980760741942\n",
      "Epoch: 1302\n",
      "Train loss: tensor(119.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041786908509121055\n",
      "Test loss: 0.053701243123574424\n",
      "Epoch: 1303\n",
      "Train loss: tensor(172.7259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04230351695524795\n",
      "Test loss: 0.05478054434429891\n",
      "Epoch: 1304\n",
      "Train loss: tensor(83.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04277335200458765\n",
      "Test loss: 0.05576888551142546\n",
      "Epoch: 1305\n",
      "Train loss: tensor(79.3016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04333426845925195\n",
      "Test loss: 0.056665806394844954\n",
      "Epoch: 1306\n",
      "Train loss: tensor(252.4977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043277436893965515\n",
      "Test loss: 0.05688431012527187\n",
      "Epoch: 1307\n",
      "Train loss: tensor(83.9571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043241064108553384\n",
      "Test loss: 0.05708895389470133\n",
      "Epoch: 1308\n",
      "Train loss: tensor(230.6354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04320306849355499\n",
      "Test loss: 0.05725366418425104\n",
      "Epoch: 1309\n",
      "Train loss: tensor(118.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043117474760150626\n",
      "Test loss: 0.057421133871937154\n",
      "Epoch: 1310\n",
      "Train loss: tensor(111.6928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04312526469695426\n",
      "Test loss: 0.05757947835960601\n",
      "Epoch: 1311\n",
      "Train loss: tensor(170.8529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04308780533749433\n",
      "Test loss: 0.057659960803714126\n",
      "Epoch: 1312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: tensor(134.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.043143001216508096\n",
      "Test loss: 0.058034076097209265\n",
      "Epoch: 1313\n",
      "Train loss: tensor(200.8562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04317661349972089\n",
      "Test loss: 0.0583052527491409\n",
      "Epoch: 1314\n",
      "Train loss: tensor(117.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04372162003336208\n",
      "Test loss: 0.05907366010775365\n",
      "Epoch: 1315\n",
      "Train loss: tensor(143.8589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04441666678924646\n",
      "Test loss: 0.059991395386802676\n",
      "Epoch: 1316\n",
      "Train loss: tensor(184.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04520418963262013\n",
      "Test loss: 0.06087295004710703\n",
      "Epoch: 1317\n",
      "Train loss: tensor(126.1533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04568420754124721\n",
      "Test loss: 0.0609609828063167\n",
      "Epoch: 1318\n",
      "Train loss: tensor(103.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.046034530142233486\n",
      "Test loss: 0.0610608532471527\n",
      "Epoch: 1319\n",
      "Train loss: tensor(135.6380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04663453230723029\n",
      "Test loss: 0.061283434676651906\n",
      "Epoch: 1320\n",
      "Train loss: tensor(85.1711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04768670220815\n",
      "Test loss: 0.06158467928076734\n",
      "Epoch: 1321\n",
      "Train loss: tensor(110.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04836610037656058\n",
      "Test loss: 0.06168044740241943\n",
      "Epoch: 1322\n",
      "Train loss: tensor(355.4800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04828515094483182\n",
      "Test loss: 0.060927710431342076\n",
      "Epoch: 1323\n",
      "Train loss: tensor(111.6073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048104607234043736\n",
      "Test loss: 0.06008011539752531\n",
      "Epoch: 1324\n",
      "Train loss: tensor(81.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048844725070964726\n",
      "Test loss: 0.05986712459880527\n",
      "Epoch: 1325\n",
      "Train loss: tensor(147.6935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04951756647122758\n",
      "Test loss: 0.059717077429931945\n",
      "Epoch: 1326\n",
      "Train loss: tensor(244.2047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.050235184521547384\n",
      "Test loss: 0.05971315593486375\n",
      "Epoch: 1327\n",
      "Train loss: tensor(70.1197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.049726525259514646\n",
      "Test loss: 0.058847743169506\n",
      "Epoch: 1328\n",
      "Train loss: tensor(143.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04911825621411914\n",
      "Test loss: 0.058034587384081716\n",
      "Epoch: 1329\n",
      "Train loss: tensor(211.5682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.048312887975147795\n",
      "Test loss: 0.05652707310780735\n",
      "Epoch: 1330\n",
      "Train loss: tensor(107.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04749148393138534\n",
      "Test loss: 0.05509257138623755\n",
      "Epoch: 1331\n",
      "Train loss: tensor(75.7815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04676904072541566\n",
      "Test loss: 0.053833307578495825\n",
      "Epoch: 1332\n",
      "Train loss: tensor(113.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04608114990627482\n",
      "Test loss: 0.05271802982776472\n",
      "Epoch: 1333\n",
      "Train loss: tensor(130.7782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.045366430646252065\n",
      "Test loss: 0.05112177537440663\n",
      "Loss this time: tensor(437.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch: 1334\n",
      "Train loss: tensor(437.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04504005346624624\n",
      "Test loss: 0.05035664854884738\n",
      "Epoch: 1335\n",
      "Train loss: tensor(90.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04448408757646879\n",
      "Test loss: 0.04952463900467547\n",
      "Epoch: 1336\n",
      "Train loss: tensor(167.4156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04393678994938022\n",
      "Test loss: 0.04875262620130388\n",
      "Epoch: 1337\n",
      "Train loss: tensor(153.6341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04338530143279405\n",
      "Test loss: 0.047567529862027357\n",
      "Epoch: 1338\n",
      "Train loss: tensor(120.4261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04307994814146133\n",
      "Test loss: 0.04670876560566744\n",
      "Epoch: 1339\n",
      "Train loss: tensor(107.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04286724287306978\n",
      "Test loss: 0.04605677335679826\n",
      "Epoch: 1340\n",
      "Train loss: tensor(204.9422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04257528992990653\n",
      "Test loss: 0.04536713423705337\n",
      "Epoch: 1341\n",
      "Train loss: tensor(150.2534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04222159583476328\n",
      "Test loss: 0.04478446205174274\n",
      "Epoch: 1342\n",
      "Train loss: tensor(171.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.041899415770811695\n",
      "Test loss: 0.044347855714288086\n",
      "Epoch: 1343\n",
      "Train loss: tensor(119.9072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0413079368039256\n",
      "Test loss: 0.04380114933494294\n",
      "Epoch: 1344\n",
      "Train loss: tensor(81.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.04081080234831288\n",
      "Test loss: 0.043385958926069855\n",
      "Epoch: 1345\n",
      "Train loss: tensor(109.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.040109507739543915\n",
      "Test loss: 0.04287941854373358\n",
      "Epoch: 1346\n",
      "Train loss: tensor(158.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03953282913813989\n",
      "Test loss: 0.04251128386263505\n",
      "Epoch: 1347\n",
      "Train loss: tensor(127.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.039051207811349915\n",
      "Test loss: 0.042234766896408385\n",
      "Epoch: 1348\n",
      "Train loss: tensor(103.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03856726563757374\n",
      "Test loss: 0.04197421703155678\n",
      "Epoch: 1349\n",
      "Train loss: tensor(129.6119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03810015277316173\n",
      "Test loss: 0.041724952232867187\n",
      "Epoch: 1350\n",
      "Train loss: tensor(215.6662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03775494045444897\n",
      "Test loss: 0.04154464471531977\n",
      "Epoch: 1351\n",
      "Train loss: tensor(119.2582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03745483409258581\n",
      "Test loss: 0.04141578770768229\n",
      "Epoch: 1352\n",
      "Train loss: tensor(180.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03727536529657387\n",
      "Test loss: 0.04136427349899665\n",
      "Epoch: 1353\n",
      "Train loss: tensor(170.9324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03713594337127039\n",
      "Test loss: 0.04134836501561769\n",
      "Epoch: 1354\n",
      "Train loss: tensor(143.7045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.0370185996450129\n",
      "Test loss: 0.041348689032884516\n",
      "Epoch: 1355\n",
      "Train loss: tensor(148.7493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036880776494564046\n",
      "Test loss: 0.041200327631639375\n",
      "Epoch: 1356\n",
      "Train loss: tensor(95.9944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03678457781317688\n",
      "Test loss: 0.04108686107994601\n",
      "Epoch: 1357\n",
      "Train loss: tensor(82.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036751911877876235\n",
      "Test loss: 0.041000918872506904\n",
      "Epoch: 1358\n",
      "Train loss: tensor(211.1485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03674078703015333\n",
      "Test loss: 0.04093015135846811\n",
      "Epoch: 1359\n",
      "Train loss: tensor(125.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03674425339503657\n",
      "Test loss: 0.0408915300014438\n",
      "Epoch: 1360\n",
      "Train loss: tensor(164.4468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036748969967343975\n",
      "Test loss: 0.04086776679879663\n",
      "Epoch: 1361\n",
      "Train loss: tensor(190.4024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03675496382638812\n",
      "Test loss: 0.04088484494956118\n",
      "Epoch: 1362\n",
      "Train loss: tensor(120.4803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036772564536936225\n",
      "Test loss: 0.040888720625402906\n",
      "Epoch: 1363\n",
      "Train loss: tensor(134.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03678996115479441\n",
      "Test loss: 0.04090567391439535\n",
      "Epoch: 1364\n",
      "Train loss: tensor(104.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03678107980550045\n",
      "Test loss: 0.04087484824369744\n",
      "Epoch: 1365\n",
      "Train loss: tensor(105.8106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03678751771914817\n",
      "Test loss: 0.04085336925259026\n",
      "Epoch: 1366\n",
      "Train loss: tensor(274.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03687040899835882\n",
      "Test loss: 0.04082129005859099\n",
      "Epoch: 1367\n",
      "Train loss: tensor(80.6913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03703866751775855\n",
      "Test loss: 0.04084490144643748\n",
      "Epoch: 1368\n",
      "Train loss: tensor(177.6488, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.037202263215468045\n",
      "Test loss: 0.04090518404794211\n",
      "Epoch: 1369\n",
      "Train loss: tensor(155.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03735608903336383\n",
      "Test loss: 0.04097887727035449\n",
      "Epoch: 1370\n",
      "Train loss: tensor(123.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03743214545594085\n",
      "Test loss: 0.04101269911642712\n",
      "Epoch: 1371\n",
      "Train loss: tensor(212.4946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037367932906463036\n",
      "Test loss: 0.04095564580679235\n",
      "Epoch: 1372\n",
      "Train loss: tensor(96.1999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037313932677110036\n",
      "Test loss: 0.04089472344200505\n",
      "Epoch: 1373\n",
      "Train loss: tensor(122.0696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03725649596058896\n",
      "Test loss: 0.04084625653922558\n",
      "Epoch: 1374\n",
      "Train loss: tensor(238.6281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036948890199086495\n",
      "Test loss: 0.04065575584363524\n",
      "Epoch: 1375\n",
      "Train loss: tensor(69.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03665582894658049\n",
      "Test loss: 0.040505291829531144\n",
      "Epoch: 1376\n",
      "Train loss: tensor(123.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.036814120296566256\n",
      "Test loss: 0.04065156048440402\n",
      "Epoch: 1377\n",
      "Train loss: tensor(138.2619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03698466235239591\n",
      "Test loss: 0.04076643810967113\n",
      "Epoch: 1378\n",
      "Train loss: tensor(91.1477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.037242716910051446\n",
      "Test loss: 0.04093730315971788\n",
      "Epoch: 1379\n",
      "Train loss: tensor(112.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03750191910990647\n",
      "Test loss: 0.04110205154128299\n",
      "Epoch: 1380\n",
      "Train loss: tensor(141.6822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03779026839349951\n",
      "Test loss: 0.04129447094579734\n",
      "Epoch: 1381\n",
      "Train loss: tensor(178.5106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03803228101737442\n",
      "Test loss: 0.0414635416876414\n",
      "Epoch: 1382\n",
      "Train loss: tensor(165.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Val loss: 0.03817945277052266\n",
      "Test loss: 0.041617635868047134\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2056 is out of bounds for dimension 0 with size 2056",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dc1dd645a46b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m#or task_id in range(total_tasks-1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtask_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2056 is out of bounds for dimension 0 with size 2056"
     ]
    }
   ],
   "source": [
    "def test(data_ML, multimodal_learner, loss_fn):\n",
    "    \n",
    "    total_tasks, task_size, window_size, input_dim = data_ML.x.shape\n",
    "    \n",
    "    task_data = torch.FloatTensor(get_task_encoder_input(data_ML))\n",
    "    x_tensor = torch.FloatTensor(data_ML.x)\n",
    "    y_tensor = torch.FloatTensor(data_ML.y) \n",
    "\n",
    "    count = 0.0\n",
    "    accum_loss = 0.0\n",
    "    \n",
    "    for task_id in range(0, total_tasks, total_tasks//100):\n",
    "        \n",
    "        task =task_data[task_id:task_id+1].cuda()\n",
    "        x = x_tensor[task_id+1].cuda()\n",
    "        y = y_tensor[task_id+1].cuda()\n",
    "\n",
    "        y_pred, (vrae_loss, kl_loss, rec_loss) = multimodal_learner(x, task)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        accum_loss += loss.cpu().detach().numpy()\n",
    "        count +=1\n",
    "        \n",
    "    return accum_loss/count\n",
    "        \n",
    "\n",
    "\n",
    "task_net = LSTMModel(batch_size=batch_size, \n",
    "                       seq_len = window_size, \n",
    "                       input_dim = input_dim_task_net, \n",
    "                       n_layers = n_layers_task_net, \n",
    "                       hidden_dim = hidden_dim_task_net, \n",
    "                       output_dim = output_dim_task_net)\n",
    "\n",
    "task_encoder = LSTMModel(batch_size=batch_size, \n",
    "                         seq_len = task_size, \n",
    "                         input_dim = input_dim_task_encoder, \n",
    "                         n_layers = n_layers_task_encoder, \n",
    "                         hidden_dim = hidden_dim_encoder, \n",
    "                         output_dim =1)\n",
    "\n",
    "task_decoder = LSTMDecoder(batch_size = 1, \n",
    "                           n_layers = n_layers_task_decoder , \n",
    "                           seq_len = task_size, \n",
    "                           output_dim = output_dim_task_decoder, \n",
    "                           hidden_dim = hidden_dim_encoder, \n",
    "                           latent_dim = hidden_dim_decoder, \n",
    "                           device = device)\n",
    "\n",
    "lmbd = Lambda(hidden_dim_encoder, hidden_dim_task_net)\n",
    "\n",
    "multimodal_learner = MultimodalLearner(task_net, task_encoder, task_decoder, lmbd)\n",
    "multimodal_learner.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(multimodal_learner.parameters(), lr = 0.0001)\n",
    "\n",
    "task_data = torch.FloatTensor(get_task_encoder_input(train_data_ML))\n",
    "x_tensor = torch.FloatTensor(train_data_ML.x)\n",
    "y_tensor = torch.FloatTensor(train_data_ML.y)\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "loss_fn = nn.SmoothL1Loss(size_average=False)\n",
    "#loss_fn = mae\n",
    "\n",
    "val_loss_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    multimodal_learner.train()\n",
    "    \n",
    "    task_id = np.random.randint(0, total_tasks)\n",
    "    #or task_id in range(total_tasks-1):\n",
    "    task =task_data[task_id:task_id+1].cuda()\n",
    "    x = x_tensor[task_id+1].cuda()\n",
    "    y = y_tensor[task_id+1].cuda()\n",
    "\n",
    "    y_pred, (vrae_loss, kl_loss, rec_loss) = multimodal_learner(x, task)\n",
    "\n",
    "    loss = loss_fn(y_pred, y) + vrae_loss\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    opt.step()\n",
    "\n",
    "    if task_id %100 == 0:\n",
    "\n",
    "        print(\"Loss this time:\", loss)\n",
    "    \n",
    "    multimodal_learner.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = test(validation_data_ML, multimodal_learner, mae)\n",
    "        test_loss = test(test_data_ML, multimodal_learner, mae)\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    print(\"Train loss:\",loss)\n",
    "    print(\"Val loss:\", val_loss)\n",
    "    print(\"Test loss:\", test_loss)\n",
    "    \n",
    "    val_loss_hist.append(val_loss)\n",
    "    test_loss_hist.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2137e78ad48>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_hist)\n",
    "plt.plot(test_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(val_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03182900598538774"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(val_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04018440646220847"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_hist[678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
