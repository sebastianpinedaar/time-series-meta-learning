{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn2learn as l2l\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "from run_MAML_04 import test2 as test_maml\n",
    "\n",
    "\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "from ts_dataset import TSDataset\n",
    "from base_models import LSTMModel, FCN\n",
    "from metrics import torch_mae as mae\n",
    "import copy\n",
    "from pytorchtools import EarlyStopping, to_torch\n",
    "from eval_base_models import test, train, freeze_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ts_dataset import DomainTSDataset, SimpleDataset\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning MAML vs LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = {\"POLLUTION\": [5, 50, 14],\n",
    "             \"HR\": [32, 50, 13],\n",
    "             \"BATTERY\": [20, 50, 3] }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_directory = \"output/\"\n",
    "horizon = 10\n",
    "output_dim = 1\n",
    "\n",
    "dataset_name = \"HR\"\n",
    "save_model_file = \"model6.pt\"\n",
    "load_model_file = \"model6.pt\"\n",
    "lower_trial = 0\n",
    "upper_trial = 3\n",
    "learning_rate = 0.01\n",
    "meta_learning_rate = 0.005\n",
    "adaptation_steps = 10\n",
    "batch_size = 20\n",
    "model_name = \"LSTM\"\n",
    "is_test = 1\n",
    "patience_stopping = 20\n",
    "epochs = 1000\n",
    "noise_level = 0.0\n",
    "noise_type = \"additive\"\n",
    "\n",
    "params = {'batch_size': batch_size,\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0}\n",
    "\n",
    "assert model_name in (\"FCN\", \"LSTM\"), \"Model was not correctly specified\"\n",
    "assert dataset_name in (\"POLLUTION\", \"HR\", \"BATTERY\")\n",
    "\n",
    "window_size, task_size, input_dim = meta_info[dataset_name]\n",
    "grid = [0., noise_level]\n",
    "\n",
    "train_data = pickle.load(  open( \"../../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "train_data_ML = pickle.load( open( \"../../Data/TRAIN-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "validation_data = pickle.load( open( \"../../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "validation_data_ML = pickle.load( open( \"../../Data/VAL-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )\n",
    "test_data = pickle.load( open( \"../../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-NOML.pickle\", \"rb\" ) )\n",
    "test_data_ML = pickle.load( open( \"../../Data/TEST-\"+dataset_name+\"-W\"+str(window_size)+\"-T\"+str(task_size)+\"-ML.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_ML = train_data_ML\n",
    "\n",
    "trial = 0\n",
    "output_directory = \"../../Models/\"+dataset_name+\"_\"+model_name+\"_MAML/\"+str(trial)+\"/\"\n",
    "\n",
    "save_model_file_ = output_directory + \"encoder_\"+save_model_file\n",
    "save_model_file_2 = output_directory + save_model_file\n",
    "load_model_file_ = output_directory + load_model_file\n",
    "\n",
    "model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n",
    "model2 = nn.Linear(120, 1)\n",
    "\n",
    "model.cuda()\n",
    "model2.cuda()\n",
    "\n",
    "maml = l2l.algorithms.MAML(model2, lr=learning_rate, first_order=False)\n",
    "model.load_state_dict(torch.load(save_model_file_))\n",
    "maml.load_state_dict(torch.load(save_model_file_2))\n",
    "\n",
    "\n",
    "total_tasks_test = len(test_data_ML)\n",
    "error_list =  []\n",
    "parameters_list = []\n",
    "domain_list = []\n",
    "error_mean = []\n",
    "activations_list = []\n",
    "\n",
    "learner = maml.clone()  # Creates a clone of model\n",
    "learner.cuda()\n",
    "accum_error = 0.0\n",
    "accum_std = 0.0\n",
    "count = 0.0\n",
    "grid = [0., noise_level]\n",
    "\n",
    "input_dim = test_data_ML.x.shape[-1]\n",
    "window_size = test_data_ML.x.shape[-2]\n",
    "output_dim = test_data_ML.y.shape[-1]\n",
    "\n",
    "if is_test:\n",
    "    step = total_tasks_test//100\n",
    "\n",
    "else:\n",
    "    step = 1\n",
    "\n",
    "step = 1 if step == 0 else step\n",
    "max_tasks = (total_tasks_test-horizon-1)\n",
    "#step = 1\n",
    "#max_tasks = 2\n",
    "\n",
    "temp_params = []\n",
    "for params in maml.parameters():\n",
    "\n",
    "    temp_params.append(params.cpu().detach().numpy()[0])\n",
    "params = np.concatenate([temp_params[0], np.array([temp_params[1]])])\n",
    "parameters_list.append(list(params))\n",
    "domain_list.append(test_data_ML.file_idx[-1])\n",
    "\n",
    "for task in range(0,max_tasks , step):\n",
    "\n",
    "    temp_file_idx = test_data_ML.file_idx[task:task+horizon+1]\n",
    "    if(len(np.unique(temp_file_idx))>1):\n",
    "        continue\n",
    "\n",
    "    if model_name == \"LSTM\":\n",
    "        model2 = LSTMModel( batch_size=None, seq_len = None, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n",
    "    elif model_name == \"FCN\":\n",
    "        kernels = [8,5,3] if window_size != 5 else [4,2,1]\n",
    "        model2 = FCN(time_steps = window_size,  channels=[input_dim, 128, 128, 128] , kernels=kernels)\n",
    "\n",
    "\n",
    "    #model2.cuda()\n",
    "    #model2.load_state_dict(copy.deepcopy(maml.module.state_dict()))\n",
    "    #opt2 = optim.Adam(model2.parameters(), lr=learning_rate)\n",
    "    learner = maml.clone() \n",
    "\n",
    "    x_spt, y_spt = test_data_ML[task]\n",
    "    x_qry = test_data_ML.x[(task+1):(task+1+horizon)].reshape(-1, window_size, input_dim)\n",
    "    y_qry = test_data_ML.y[(task+1):(task+1+horizon)].reshape(-1, output_dim)\n",
    "    #x_qry = test_data_ML.x[(task+1)].reshape(-1, window_size, input_dim)\n",
    "    #y_qry = test_data_ML.y[(task+1)].reshape(-1, output_dim)\n",
    "\n",
    "    if model_name == \"FCN\":\n",
    "        x_qry = np.transpose(x_qry, [0,2,1])\n",
    "        x_spt = np.transpose(x_spt, [0,2,1])\n",
    "\n",
    "    x_spt, y_spt = to_torch(x_spt), to_torch(y_spt)\n",
    "    x_qry = to_torch(x_qry)\n",
    "    y_qry = to_torch(y_qry)\n",
    "\n",
    "\n",
    "    epsilon = grid[np.random.randint(0,len(grid))]\n",
    "\n",
    "    if noise_type == \"additive\":\n",
    "        y_spt = y_spt+epsilon\n",
    "        y_qry = y_qry+epsilon\n",
    "\n",
    "    else:\n",
    "        y_spt = y_spt*(1+epsilon)\n",
    "        y_qry = y_qry*(1+epsilon)\n",
    "\n",
    "\n",
    "    #learner.module.train()\n",
    "    #model2.eval()\n",
    "    for step in range(adaptation_steps):\n",
    "\n",
    "        #model2.train()\n",
    "        pred = learner(model.encoder(x_spt))\n",
    "        error = mae(pred, y_spt)\n",
    "\n",
    "        #opt2.zero_grad()\n",
    "        #error.backward()\n",
    "\n",
    "        learner.adapt(error)\n",
    "        #opt2.step()\n",
    "\n",
    "    error_mean.append(np.mean(error.cpu().detach().numpy()))\n",
    "    temp_params = []\n",
    "    for params in maml.parameters():\n",
    "\n",
    "        temp_params.append(params.cpu().detach().numpy()[0])\n",
    "    params = np.concatenate([temp_params[0], np.array([temp_params[1]])])\n",
    "    parameters_list.append(list(params))\n",
    "    domain_list.append(test_data_ML.file_idx[task])\n",
    "    activations_list.append(model.encoder(x_spt).cpu().detach().numpy()[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 50, 120)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = np.concatenate(activations_list)\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 2.53704941e+02,  5.28356218e+00,  4.04668045e+00,  4.58983719e-01,\n",
      "        3.62976313e-01,  1.38164446e-01,  1.18722156e-01,  6.29261732e-02,\n",
      "        5.12754284e-02,  2.67189108e-02,  2.27418169e-02,  1.74104217e-02,\n",
      "        1.44330738e-02,  8.66021868e-03,  7.21610943e-03,  5.54806786e-03,\n",
      "        5.02766529e-03,  3.15695931e-03,  3.08503630e-03,  2.47809407e-03,\n",
      "        1.84557412e-03,  1.45926746e-03,  1.19898829e-03,  1.03858998e-03,\n",
      "        8.42827372e-04,  6.00140949e-04,  5.45575167e-04,  4.35619673e-04,\n",
      "        3.90051777e-04,  3.46488348e-04,  2.88105104e-04,  2.08540208e-04,\n",
      "        1.52258508e-04,  1.35059716e-04,  1.16363066e-04,  1.05403298e-04,\n",
      "        7.66273588e-05,  7.06773499e-05,  5.73541438e-05,  4.76287169e-05,\n",
      "        3.15969628e-05,  2.25456915e-05,  1.81276882e-05,  1.37219076e-05,\n",
      "        1.02753174e-05, -5.91242269e-06,  7.17545709e-06,  6.39129530e-06,\n",
      "        5.90902982e-06, -4.58692239e-06,  3.79480093e-06,  3.05705248e-06,\n",
      "       -2.72647708e-06,  2.86747741e-06,  2.37884251e-06, -2.23767620e-06,\n",
      "        1.76111223e-06, -1.61194623e-06,  1.55921077e-06, -1.31744969e-06,\n",
      "       -9.31368390e-07,  1.09439236e-06,  9.98625865e-07,  9.12783094e-07,\n",
      "       -7.05827006e-07, -6.19892319e-07,  7.88563739e-07,  7.12486496e-07,\n",
      "        6.85365194e-07, -4.91822277e-07, -4.58449676e-07,  5.14135138e-07,\n",
      "        4.70471065e-07,  3.67061034e-07, -3.87493714e-07, -3.76384691e-07,\n",
      "       -3.32905046e-07,  3.18131185e-07,  3.01782819e-07, -2.60374378e-07,\n",
      "        2.35860426e-07,  2.14948656e-07, -2.27696432e-07, -2.03694228e-07,\n",
      "       -1.78725955e-07,  1.82085415e-07,  1.68013813e-07, -1.50980497e-07,\n",
      "        1.46115511e-07,  1.26158966e-07,  8.99906354e-08,  7.43229336e-08,\n",
      "       -1.11890508e-07, -9.63327125e-08, -8.71622632e-08, -6.92773980e-08,\n",
      "        6.02424990e-08, -6.48881837e-08, -6.07368236e-08,  4.61001299e-08,\n",
      "       -4.24831157e-08, -3.52609497e-08,  3.20458859e-08,  2.73913994e-08,\n",
      "       -2.24568506e-08, -2.10538573e-08,  1.94166851e-08,  1.43653232e-08,\n",
      "        2.34372539e-08, -1.48996495e-08,  1.18172450e-08,  9.90848648e-09,\n",
      "        5.74446624e-09,  4.96180830e-09,  2.42314147e-09,  9.70076353e-10,\n",
      "       -2.11791473e-09, -1.09910765e-08, -8.79601636e-09, -9.72420544e-09],\n",
      "      dtype=float32), array([[-0.04072091,  0.09886069,  0.06755448, ...,  0.06991853,\n",
      "        -0.03387867, -0.03333312],\n",
      "       [-0.03618453, -0.0636776 ,  0.00844403, ..., -0.08289669,\n",
      "        -0.06449199,  0.06620087],\n",
      "       [ 0.0123781 , -0.02743687,  0.08037209, ..., -0.03627324,\n",
      "        -0.02743377,  0.15732363],\n",
      "       ...,\n",
      "       [-0.00762849,  0.07590649, -0.15612468, ..., -0.01422098,\n",
      "         0.06721969, -0.01847726],\n",
      "       [-0.1428529 ,  0.01119134,  0.20992108, ...,  0.01813971,\n",
      "        -0.00594699,  0.01343549],\n",
      "       [-0.02490673, -0.04588256,  0.13651586, ..., -0.11945985,\n",
      "        -0.05361825,  0.06943792]], dtype=float32))\n",
      "(array([ 2.43280350e+02,  8.78436938e-02,  2.15186235e-02,  9.42663010e-03,\n",
      "        3.96185275e-03,  1.80650805e-03,  9.94686969e-04,  3.33304808e-04,\n",
      "        1.72346714e-04,  1.03410952e-04,  8.87975912e-05,  7.35441863e-05,\n",
      "        5.50552722e-05,  3.15062061e-05,  2.82846013e-05, -9.82405436e-06,\n",
      "        1.25039205e-05,  1.16628371e-05,  1.06519947e-05,  7.87753015e-06,\n",
      "        6.52946437e-06, -5.80931192e-06, -4.57684791e-06,  5.56061696e-06,\n",
      "        4.89376953e-06,  4.18383661e-06,  3.80091910e-06,  3.23730501e-06,\n",
      "        3.28216333e-06, -2.87302873e-06, -2.64312416e-06,  2.83538429e-06,\n",
      "       -2.22402991e-06,  2.42338137e-06,  2.02526348e-06, -1.76192623e-06,\n",
      "       -1.53706264e-06,  1.68628537e-06,  1.45306865e-06, -1.14718569e-06,\n",
      "        1.32686409e-06, -9.65288564e-07,  1.16017918e-06,  1.01860803e-06,\n",
      "        1.03464470e-06, -7.32189619e-07,  8.96264282e-07,  8.26660653e-07,\n",
      "       -5.94456026e-07,  7.36650350e-07,  6.30838997e-07,  6.45793932e-07,\n",
      "        5.54221060e-07, -4.77732897e-07, -4.70020467e-07,  5.02032719e-07,\n",
      "       -4.37144507e-07,  4.57058405e-07,  4.31971074e-07, -3.64810376e-07,\n",
      "        4.03566759e-07, -2.99724519e-07,  3.28389376e-07, -2.77278843e-07,\n",
      "        3.35468854e-07, -2.16279645e-07,  2.91124394e-07,  2.71531775e-07,\n",
      "       -1.93206859e-07,  2.46752762e-07,  2.27624525e-07, -1.56393128e-07,\n",
      "       -1.51696625e-07, -1.24523964e-07,  1.94110200e-07,  1.77398434e-07,\n",
      "        1.72196380e-07,  1.41175818e-07,  1.20400799e-07, -8.93901770e-08,\n",
      "       -8.23097039e-08, -7.21793967e-08,  1.06520638e-07,  9.91582780e-08,\n",
      "        9.11136198e-08,  7.89368144e-08,  7.30990735e-08, -5.16135046e-08,\n",
      "        6.22211616e-08, -4.89320051e-08, -4.20102566e-08, -3.93666859e-08,\n",
      "        5.40697194e-08,  4.98934760e-08, -2.62744528e-08, -2.37348488e-08,\n",
      "        4.38335555e-08,  3.96174933e-08,  3.34748229e-08,  3.03428891e-08,\n",
      "       -2.09886881e-08, -1.19933050e-08,  2.40704754e-08, -9.17732823e-09,\n",
      "       -8.12040124e-09, -6.50943743e-09,  2.02818207e-08,  1.88092830e-08,\n",
      "        1.71890608e-08,  1.44379966e-08,  1.30541666e-08, -3.38847195e-09,\n",
      "       -5.76264869e-10,  1.17609950e-10,  8.89289442e-09,  1.69254566e-09,\n",
      "        4.36561942e-09,  7.07142256e-09,  5.36804245e-09,  6.46416964e-09],\n",
      "      dtype=float32), array([[-0.03478633,  0.12346843,  0.00180078, ...,  0.06346407,\n",
      "         0.00863763, -0.00291575],\n",
      "       [-0.03178607, -0.17440832,  0.0016648 , ...,  0.03958625,\n",
      "         0.01264866,  0.04331393],\n",
      "       [ 0.0167495 ,  0.03126989,  0.05463844, ..., -0.01872823,\n",
      "        -0.1153203 ,  0.10753407],\n",
      "       ...,\n",
      "       [-0.01818856, -0.01622038, -0.12766747, ..., -0.09696911,\n",
      "         0.16419756,  0.08966876],\n",
      "       [-0.12110221,  0.18708333,  0.04030078, ...,  0.00372583,\n",
      "         0.00412735,  0.02015942],\n",
      "       [-0.01354912,  0.08442213, -0.05079819, ..., -0.16940324,\n",
      "         0.08874977,  0.01204026]], dtype=float32))\n",
      "(array([ 2.4423425e+02,  1.2198809e-01,  1.7619163e-02,  1.1916032e-02,\n",
      "        1.0032812e-02,  2.4200114e-03,  1.0511577e-03,  6.6038093e-04,\n",
      "        3.9777881e-04,  1.8042278e-04,  1.5016664e-04,  9.9744480e-05,\n",
      "        5.6061501e-05,  4.0555780e-05,  3.5852321e-05,  2.5131914e-05,\n",
      "        2.3787441e-05,  1.9901629e-05,  1.5361285e-05, -8.9147006e-06,\n",
      "        8.2460037e-06,  7.5693374e-06,  6.9908319e-06, -5.4768643e-06,\n",
      "        5.0030299e-06,  4.6531595e-06, -3.6475885e-06,  3.9101387e-06,\n",
      "       -3.3664817e-06, -3.0707199e-06,  3.5328260e-06,  3.4257753e-06,\n",
      "        2.9090736e-06,  2.6084469e-06, -2.1185099e-06, -1.8228976e-06,\n",
      "        2.1238363e-06, -1.4722302e-06,  1.7986216e-06,  1.5643534e-06,\n",
      "        1.6206762e-06, -1.1773894e-06,  1.2682985e-06,  1.2489591e-06,\n",
      "       -8.7315675e-07,  1.0673550e-06,  9.7511531e-07, -7.6952807e-07,\n",
      "       -6.6264397e-07,  8.3499310e-07,  7.5070346e-07,  6.7962930e-07,\n",
      "       -5.1331193e-07,  6.0389436e-07,  5.2885082e-07,  4.7176999e-07,\n",
      "        4.5520443e-07, -4.0032165e-07, -3.9284916e-07,  3.8808608e-07,\n",
      "       -3.4216151e-07, -2.9046976e-07, -2.5613454e-07, -2.3263163e-07,\n",
      "        3.5675589e-07,  3.3151821e-07,  3.0601905e-07,  2.8289776e-07,\n",
      "        2.3989793e-07, -1.8464878e-07, -1.6652309e-07,  2.2141116e-07,\n",
      "        2.1299729e-07, -1.3114683e-07,  1.8878991e-07,  1.7106365e-07,\n",
      "        1.6511378e-07,  1.3849824e-07, -1.0811678e-07,  1.2704865e-07,\n",
      "       -8.7653056e-08,  1.0357770e-07,  1.0614161e-07, -7.8966984e-08,\n",
      "        9.5891082e-08, -6.5097190e-08, -6.1745972e-08,  8.3364213e-08,\n",
      "        6.7014199e-08,  6.0718719e-08,  5.8491445e-08, -4.4688356e-08,\n",
      "       -3.6732331e-08,  5.2400047e-08,  4.8724683e-08,  4.2299764e-08,\n",
      "       -3.0576206e-08,  3.6678923e-08, -2.2095598e-08, -2.0809560e-08,\n",
      "        3.2559619e-08,  2.6621501e-08,  2.3622809e-08, -1.6579026e-08,\n",
      "       -1.4856055e-08, -1.0777805e-08,  2.0380766e-08,  1.5812898e-08,\n",
      "       -7.3229742e-09, -4.5406923e-09, -7.7462614e-09,  1.3273918e-08,\n",
      "       -7.5580031e-10,  1.1147277e-08,  1.3174780e-09,  9.4559365e-09,\n",
      "        7.7749860e-09,  5.9565517e-09,  2.4650746e-09,  3.3856558e-09],\n",
      "      dtype=float32), array([[-0.0360734 ,  0.13037099,  0.10811447, ..., -0.08849757,\n",
      "        -0.03135889,  0.0281401 ],\n",
      "       [-0.03097064, -0.17136577, -0.02958623, ..., -0.04613704,\n",
      "        -0.09614467,  0.02238955],\n",
      "       [ 0.01732652,  0.04151472, -0.02231321, ..., -0.02883581,\n",
      "        -0.18483844, -0.00398754],\n",
      "       ...,\n",
      "       [-0.02153597, -0.03075292,  0.1597726 , ...,  0.01811437,\n",
      "         0.08337124, -0.0685681 ],\n",
      "       [-0.12152167,  0.18402325, -0.07845185, ...,  0.03344726,\n",
      "         0.00240961,  0.02036793],\n",
      "       [-0.01325732,  0.08075103,  0.05716857, ...,  0.05985553,\n",
      "         0.08255379, -0.04511752]], dtype=float32))\n",
      "(array([ 2.47193146e+02,  8.55543613e-02,  1.06876148e-02,  9.99719184e-03,\n",
      "        1.02156878e-03,  6.19489758e-04,  5.20334404e-04,  1.39022319e-04,\n",
      "        8.02586437e-05,  5.44951217e-05,  2.55398209e-05,  1.92060488e-05,\n",
      "        1.70050444e-05,  1.21364519e-05,  1.18361795e-05, -7.62331774e-06,\n",
      "       -6.82409473e-06,  7.53181848e-06,  6.63231140e-06, -5.29487761e-06,\n",
      "        4.84422208e-06,  4.71802741e-06,  3.70699604e-06, -3.11166468e-06,\n",
      "        3.14266777e-06, -2.69635007e-06,  2.90616299e-06,  2.70498185e-06,\n",
      "       -2.12589725e-06,  2.22391100e-06, -1.66670338e-06,  1.98527414e-06,\n",
      "        1.92603466e-06,  1.75556193e-06, -1.53816109e-06,  1.61030528e-06,\n",
      "        1.51845347e-06, -1.37492714e-06,  1.23996301e-06,  1.19841980e-06,\n",
      "        1.00348370e-06, -9.90837407e-07, -8.98656538e-07, -7.35198000e-07,\n",
      "       -7.22944606e-07,  8.46166074e-07,  7.68614939e-07,  7.18869842e-07,\n",
      "        6.63776802e-07,  5.80661776e-07, -4.82991254e-07, -4.34740116e-07,\n",
      "       -3.92106955e-07,  4.77620858e-07,  4.57632353e-07, -3.56420458e-07,\n",
      "       -3.45678956e-07,  4.15876428e-07,  4.04219804e-07, -3.07417508e-07,\n",
      "       -2.43408664e-07,  3.47391364e-07,  3.19818497e-07,  2.99178510e-07,\n",
      "        2.68039742e-07,  2.27510228e-07, -2.02238041e-07, -1.73666734e-07,\n",
      "       -1.45435209e-07, -1.36878512e-07,  2.12169482e-07,  1.65691731e-07,\n",
      "        1.72992273e-07,  1.89645874e-07,  1.35933334e-07, -1.07134476e-07,\n",
      "        1.20626723e-07,  1.09492866e-07, -8.50583675e-08, -7.98777720e-08,\n",
      "        9.66857883e-08,  8.94699568e-08, -6.67043096e-08, -6.02800370e-08,\n",
      "       -4.71763677e-08,  7.60394485e-08,  7.37323589e-08,  6.36007869e-08,\n",
      "        6.14809608e-08, -3.91707751e-08, -3.41775639e-08,  5.16674952e-08,\n",
      "       -2.75213967e-08,  4.59735148e-08,  4.49306263e-08,  3.56411256e-08,\n",
      "       -2.06833466e-08,  2.89989597e-08, -1.69802945e-08,  2.42962201e-08,\n",
      "        2.22415348e-08, -1.09408580e-08,  1.78389783e-08,  1.67060978e-08,\n",
      "       -9.85019621e-09, -6.66209443e-09, -2.55998200e-09, -4.96263697e-09,\n",
      "       -4.38720704e-09,  4.82817075e-09,  2.81349055e-09, -3.34816813e-10,\n",
      "        1.47806301e-08,  1.34579823e-08,  7.87921672e-10,  7.27701954e-10,\n",
      "        1.10400409e-08,  8.36822167e-09,  7.66741604e-09,  9.62187041e-09],\n",
      "      dtype=float32), array([[-0.03562173, -0.11225597, -0.13250704, ..., -0.09403392,\n",
      "         0.01071856, -0.00409744],\n",
      "       [-0.02988861,  0.16587359,  0.07474411, ...,  0.05125441,\n",
      "         0.01417762, -0.00988183],\n",
      "       [ 0.0190684 , -0.0413461 ,  0.10033012, ...,  0.13495693,\n",
      "        -0.08924064,  0.03815341],\n",
      "       ...,\n",
      "       [-0.02617167,  0.03608871, -0.09177545, ...,  0.0012557 ,\n",
      "        -0.01303465, -0.03211954],\n",
      "       [-0.12234896, -0.18265906,  0.01993638, ...,  0.01140988,\n",
      "         0.00098806, -0.01138578],\n",
      "       [-0.01135729, -0.07872504, -0.03876145, ..., -0.12179665,\n",
      "        -0.04744868, -0.0922171 ]], dtype=float32))\n",
      "(array([ 2.52034409e+02,  9.98641551e-02,  1.02343243e-02,  6.09642128e-03,\n",
      "        7.89981277e-04,  4.86284029e-04,  2.17606590e-04,  1.43673155e-04,\n",
      "        1.18527198e-04,  6.53349198e-05,  4.80711460e-05,  2.28599365e-05,\n",
      "        1.94835084e-05,  1.86776015e-05, -1.05167437e-05,  1.15376406e-05,\n",
      "        9.64565425e-06, -7.48645743e-06,  6.90875549e-06, -5.48722028e-06,\n",
      "        6.49754338e-06,  5.75972581e-06,  5.47883246e-06,  5.04389118e-06,\n",
      "       -4.41428983e-06, -4.01643229e-06,  3.86129977e-06, -2.83671852e-06,\n",
      "       -2.68054350e-06,  3.07980758e-06,  2.97054726e-06,  2.50261814e-06,\n",
      "        1.96463202e-06,  1.84189923e-06, -1.70937244e-06,  1.33820163e-06,\n",
      "        1.19452739e-06, -1.16164108e-06, -1.04607523e-06, -9.15082467e-07,\n",
      "       -7.66231494e-07,  1.07096719e-06,  1.04425374e-06,  9.17555553e-07,\n",
      "        8.61334854e-07,  8.17998853e-07, -6.41446945e-07,  7.09698952e-07,\n",
      "        6.26449435e-07, -6.00117346e-07, -5.18848367e-07,  5.10028372e-07,\n",
      "       -4.81763038e-07, -3.98736688e-07,  4.32379125e-07,  3.85286455e-07,\n",
      "       -3.24980050e-07,  3.50315077e-07,  3.13502596e-07, -2.84006745e-07,\n",
      "       -2.47976999e-07,  2.91134995e-07,  3.00646690e-07, -2.09906545e-07,\n",
      "        2.25406936e-07, -1.79566058e-07,  2.08958511e-07,  1.89282645e-07,\n",
      "       -1.50791493e-07, -1.21345124e-07,  1.58745479e-07,  1.57131211e-07,\n",
      "        1.43209135e-07,  1.31333337e-07, -1.03382988e-07, -9.08691717e-08,\n",
      "       -9.20580874e-08, -7.12440311e-08,  1.13037416e-07,  9.82881261e-08,\n",
      "        9.73236283e-08,  8.96343337e-08,  8.64278533e-08,  7.25412406e-08,\n",
      "       -5.54341533e-08, -5.02517885e-08, -4.62842031e-08, -3.87498673e-08,\n",
      "        5.57074173e-08,  5.35513323e-08,  5.13874170e-08, -2.75741954e-08,\n",
      "        4.23499991e-08,  4.07852205e-08,  3.81741394e-08,  3.53099061e-08,\n",
      "       -2.44896636e-08, -1.72995538e-08, -1.46066812e-08,  2.72732468e-08,\n",
      "        2.32532020e-08,  2.11540669e-08,  1.93391827e-08, -1.11270921e-08,\n",
      "       -8.12297962e-09, -6.99397251e-09,  1.50896486e-08,  1.61060196e-08,\n",
      "        1.18832633e-08, -4.71349892e-09, -3.73031783e-09,  1.08434985e-08,\n",
      "        9.04292730e-09,  7.28399829e-09,  5.11248111e-09, -1.38340706e-09,\n",
      "        4.61163677e-11,  9.54733848e-10,  2.53112131e-09,  1.89938931e-09],\n",
      "      dtype=float32), array([[-0.03695925,  0.10019516,  0.15417205, ...,  0.04154454,\n",
      "         0.01041025,  0.0011992 ],\n",
      "       [-0.02869006, -0.162592  , -0.07492574, ...,  0.089434  ,\n",
      "        -0.05062152,  0.02472923],\n",
      "       [ 0.02158604,  0.04450667, -0.0849995 , ...,  0.1200028 ,\n",
      "        -0.0419531 ,  0.01157   ],\n",
      "       ...,\n",
      "       [-0.03250861, -0.04810011,  0.04321859, ...,  0.01587567,\n",
      "         0.00085265, -0.04205256],\n",
      "       [-0.12350066,  0.17355643, -0.01103768, ..., -0.0079649 ,\n",
      "        -0.00232852,  0.00460851],\n",
      "       [-0.01038847,  0.07829352,  0.04969032, ..., -0.10584915,\n",
      "         0.34891587,  0.23443635]], dtype=float32))\n",
      "(array([ 2.5486906e+02,  9.0359375e-02,  8.1465207e-03,  4.5990054e-03,\n",
      "        1.1301662e-03,  2.9628963e-04,  1.8973849e-04,  1.2394183e-04,\n",
      "        6.7150439e-05,  4.8758167e-05,  2.4932660e-05,  1.7356057e-05,\n",
      "        1.4367443e-05, -9.3994695e-06,  1.1294937e-05,  1.0477935e-05,\n",
      "       -7.7068435e-06,  9.0739013e-06,  7.9353358e-06, -5.3525091e-06,\n",
      "        5.3979261e-06,  4.7769986e-06, -3.7034451e-06,  3.7831721e-06,\n",
      "       -2.5632698e-06,  3.4064169e-06,  3.1095954e-06,  2.9994142e-06,\n",
      "        2.3790349e-06, -2.1422331e-06,  1.8925336e-06, -1.7973521e-06,\n",
      "        1.7198448e-06, -1.4927402e-06, -1.3286823e-06,  1.4308333e-06,\n",
      "        1.3525607e-06,  1.3121540e-06, -1.0010992e-06,  1.0557609e-06,\n",
      "        9.6341307e-07, -9.2144745e-07, -8.8172970e-07,  8.0218194e-07,\n",
      "        7.1837945e-07,  6.5424547e-07, -6.1606562e-07, -6.0055783e-07,\n",
      "       -5.2228353e-07, -4.5956850e-07,  5.5614487e-07,  4.8277349e-07,\n",
      "        4.4982639e-07, -3.4144881e-07, -3.2353117e-07,  3.8960863e-07,\n",
      "        3.6329783e-07,  3.3796965e-07,  3.0757602e-07, -2.4895073e-07,\n",
      "       -2.2349353e-07, -2.0810339e-07,  2.5971585e-07,  2.5201996e-07,\n",
      "        2.3699948e-07,  2.2426217e-07,  2.0726328e-07, -1.8213498e-07,\n",
      "       -1.6723034e-07, -1.5473914e-07, -1.3659739e-07, -1.0772909e-07,\n",
      "        1.6403257e-07,  1.5311748e-07,  1.3096344e-07,  1.2023331e-07,\n",
      "        1.0927706e-07, -7.5445904e-08,  9.9268163e-08,  8.1215738e-08,\n",
      "       -5.8433589e-08, -5.1301754e-08,  7.9063717e-08, -4.3936364e-08,\n",
      "        6.9549536e-08,  6.5284063e-08,  5.9912253e-08,  5.4668231e-08,\n",
      "       -3.7705863e-08,  4.3005119e-08, -3.4673779e-08, -3.0738921e-08,\n",
      "        4.0004018e-08, -2.6615840e-08,  3.6285080e-08,  3.3837612e-08,\n",
      "        3.1031487e-08,  2.7897070e-08, -1.9056086e-08,  2.4177901e-08,\n",
      "       -1.4896750e-08,  2.3652333e-08,  1.8483458e-08, -1.1225008e-08,\n",
      "        1.6486290e-08,  1.3788372e-08, -7.7724511e-09,  1.0359732e-08,\n",
      "        8.4774454e-09,  6.4535861e-09, -5.0304330e-09, -2.9399261e-09,\n",
      "       -4.0388066e-09,  5.8570548e-09, -1.6045721e-09, -1.1382519e-09,\n",
      "        2.9644216e-09,  4.3428865e-09,  1.8061467e-09,  1.4338060e-09],\n",
      "      dtype=float32), array([[-0.03803863,  0.10708332, -0.14704473, ..., -0.01366317,\n",
      "        -0.00464856,  0.02013564],\n",
      "       [-0.02789645, -0.16601443,  0.07513212, ...,  0.04066437,\n",
      "        -0.06585455, -0.03118353],\n",
      "       [ 0.02295862,  0.04500757,  0.07781371, ..., -0.08807544,\n",
      "         0.06656453,  0.0185935 ],\n",
      "       ...,\n",
      "       [-0.03554066, -0.05442994, -0.01747596, ...,  0.07753795,\n",
      "        -0.04341462, -0.05427728],\n",
      "       [-0.12394389,  0.17526849,  0.01994662, ...,  0.01455643,\n",
      "        -0.01320255, -0.00319903],\n",
      "       [-0.00977822,  0.07900755, -0.04299127, ...,  0.05515694,\n",
      "        -0.0669985 ,  0.04399084]], dtype=float32))\n",
      "(array([ 2.56493866e+02,  9.48168114e-02,  9.43767559e-03,  6.46079797e-03,\n",
      "        1.61406444e-03,  5.97073406e-04,  4.13022179e-04,  1.82087533e-04,\n",
      "        9.76027659e-05,  7.15731076e-05,  4.89502272e-05,  3.13867677e-05,\n",
      "        1.86529160e-05,  1.55301495e-05,  1.33219673e-05, -1.19739407e-05,\n",
      "        8.81123106e-06, -6.82842528e-06,  7.52213782e-06,  6.78995730e-06,\n",
      "       -5.10105747e-06,  5.58972670e-06, -3.74053548e-06,  4.78658239e-06,\n",
      "        4.11788142e-06,  3.86718148e-06,  3.67087500e-06, -2.76933019e-06,\n",
      "        2.77051868e-06, -1.91894401e-06,  2.32788398e-06,  2.12460031e-06,\n",
      "        1.89974185e-06, -1.42915565e-06, -1.38312043e-06,  1.65990105e-06,\n",
      "       -1.18711307e-06,  1.42098338e-06,  1.27232317e-06, -9.26310520e-07,\n",
      "        1.12955854e-06,  1.09310099e-06,  9.58570013e-07, -8.21685319e-07,\n",
      "       -7.34231151e-07,  8.34924492e-07,  7.34342336e-07, -5.99634859e-07,\n",
      "        6.09893448e-07, -5.02676244e-07,  4.74054815e-07, -3.78116169e-07,\n",
      "       -3.48201411e-07,  4.36960732e-07,  4.33283191e-07,  4.13923232e-07,\n",
      "        3.97849334e-07,  3.49697672e-07, -2.88459432e-07, -2.55059774e-07,\n",
      "       -2.37555511e-07,  2.91175155e-07,  2.84754805e-07,  2.83830161e-07,\n",
      "        2.39650149e-07, -2.00097773e-07,  2.09082032e-07, -1.87306696e-07,\n",
      "       -1.56434524e-07, -1.51672836e-07, -1.16313025e-07,  1.80937889e-07,\n",
      "        1.65406405e-07,  1.61805730e-07,  1.43959667e-07,  1.26432795e-07,\n",
      "       -9.87932722e-08,  1.12218707e-07, -9.53305843e-08,  1.07947415e-07,\n",
      "        1.00258255e-07, -6.37961222e-08, -6.04478245e-08, -5.56916113e-08,\n",
      "        8.43114165e-08,  7.46185904e-08,  7.01190999e-08,  6.06702955e-08,\n",
      "        5.25482022e-08,  4.73574282e-08, -4.09559213e-08, -3.70405466e-08,\n",
      "       -3.38964057e-08, -1.95101180e-08,  3.89273538e-08,  3.48568427e-08,\n",
      "        3.27225855e-08,  3.04958228e-08, -1.79372819e-08,  2.39636044e-08,\n",
      "       -1.62024669e-08,  2.08340012e-08, -1.15168977e-08, -9.02969877e-09,\n",
      "        1.84282989e-08,  1.63904552e-08,  1.41226240e-08,  1.26837696e-08,\n",
      "       -5.89629190e-09, -5.25933830e-09,  9.93280747e-09, -3.40700268e-09,\n",
      "       -1.40054224e-09,  7.65050778e-09,  2.44140264e-10,  1.44155921e-09,\n",
      "        4.47431070e-09,  5.85023363e-09,  2.98365199e-09,  3.92823551e-09],\n",
      "      dtype=float32), array([[-0.03949618,  0.10230507, -0.12729591, ..., -0.01985416,\n",
      "        -0.0075128 , -0.00523035],\n",
      "       [-0.02739397, -0.1658157 ,  0.04492139, ...,  0.0088505 ,\n",
      "         0.04508718,  0.00537237],\n",
      "       [ 0.02361823,  0.04495345,  0.08026095, ...,  0.02332747,\n",
      "         0.0101904 ,  0.07435185],\n",
      "       ...,\n",
      "       [-0.03696908, -0.05481872, -0.07827897, ...,  0.01954596,\n",
      "         0.0687516 , -0.01397969],\n",
      "       [-0.12350545,  0.17490761,  0.03777901, ...,  0.00064656,\n",
      "        -0.00476522, -0.00147248],\n",
      "       [-0.00962282,  0.08069266, -0.06537572, ...,  0.23999104,\n",
      "        -0.11786919, -0.11883728]], dtype=float32))\n",
      "(array([ 2.5814890e+02,  2.3800385e-01,  3.1930842e-02,  1.6458485e-02,\n",
      "        9.4097517e-03,  6.7170309e-03,  2.4565021e-03,  1.2423886e-03,\n",
      "        6.7624910e-04,  5.3129339e-04,  2.4241210e-04,  1.8228374e-04,\n",
      "        1.5044142e-04,  7.2266244e-05,  6.6959619e-05,  4.3696386e-05,\n",
      "        3.0197314e-05,  2.0913983e-05,  1.6441245e-05,  1.3631080e-05,\n",
      "        1.0953747e-05, -9.5531750e-06,  8.1693743e-06,  7.9936544e-06,\n",
      "       -5.7163156e-06,  6.6419880e-06,  6.0558914e-06,  5.1817979e-06,\n",
      "        4.7560702e-06,  4.5306842e-06,  3.7201935e-06, -3.0597732e-06,\n",
      "        3.0891806e-06, -2.6086379e-06, -2.3850459e-06,  2.8153988e-06,\n",
      "       -2.1443907e-06,  2.1907413e-06,  2.0898792e-06, -1.4609948e-06,\n",
      "       -1.3575363e-06,  1.7702971e-06,  1.6268555e-06,  1.3807912e-06,\n",
      "        1.3483115e-06,  1.1174861e-06, -9.6611484e-07, -9.1273904e-07,\n",
      "        9.5232832e-07,  8.7879295e-07,  7.8005462e-07, -6.1161694e-07,\n",
      "        6.6094151e-07,  6.1667669e-07, -5.5538362e-07,  5.6380043e-07,\n",
      "       -4.1371453e-07,  5.2676000e-07, -3.6818244e-07,  4.7427764e-07,\n",
      "        4.5370638e-07,  3.9094081e-07, -3.4996938e-07, -3.0463528e-07,\n",
      "        3.1106600e-07,  3.0362227e-07, -2.4731358e-07,  2.7275109e-07,\n",
      "        2.3611786e-07, -1.9426817e-07,  1.9689413e-07, -1.8288949e-07,\n",
      "       -1.7327309e-07, -1.5338209e-07, -1.4524764e-07,  1.7889161e-07,\n",
      "        1.6080681e-07,  1.4847257e-07,  1.3484291e-07,  1.2191349e-07,\n",
      "       -1.0167614e-07, -9.1556927e-08, -7.0267539e-08,  1.1584972e-07,\n",
      "        1.1297757e-07,  9.0758682e-08,  8.4174545e-08,  8.0745806e-08,\n",
      "       -6.2671631e-08,  7.1094263e-08, -5.2150362e-08, -4.6469545e-08,\n",
      "        6.1447885e-08,  5.9056408e-08, -3.7046277e-08, -3.1632890e-08,\n",
      "        4.3035886e-08,  4.6589786e-08,  3.6354134e-08, -2.2996904e-08,\n",
      "       -2.0210424e-08, -1.4994541e-08,  2.9778043e-08,  2.7359299e-08,\n",
      "       -1.1240623e-08, -8.1010576e-09,  2.1678375e-08,  1.8790676e-08,\n",
      "        1.5588212e-08, -4.7294266e-09,  1.2091320e-08, -2.3251374e-09,\n",
      "        1.0589443e-08, -6.1208309e-11,  6.6928840e-10,  7.2637021e-09,\n",
      "        2.9594869e-09,  3.9758339e-09,  5.6534728e-09,  5.9922511e-09],\n",
      "      dtype=float32), array([[-0.04111852, -0.11791103, -0.01804355, ...,  0.01328788,\n",
      "        -0.02800381,  0.02267371],\n",
      "       [-0.02724569,  0.15688999,  0.01424359, ...,  0.02104302,\n",
      "        -0.0117645 , -0.02737031],\n",
      "       [ 0.02275755, -0.04481851,  0.1344754 , ...,  0.0135348 ,\n",
      "         0.02592591,  0.00459212],\n",
      "       ...,\n",
      "       [-0.03545333,  0.05894277, -0.32171974, ..., -0.043623  ,\n",
      "        -0.03803157,  0.04784851],\n",
      "       [-0.12284128, -0.18657559, -0.18505195, ...,  0.00123625,\n",
      "         0.00547493,  0.005244  ],\n",
      "       [-0.00987282, -0.09603892,  0.06345743, ...,  0.22965547,\n",
      "         0.13382271,  0.04132124]], dtype=float32))\n",
      "(array([ 2.45889236e+02,  8.25193107e-01,  3.46963555e-01,  2.73663163e-01,\n",
      "        2.17211068e-01,  4.18695100e-02,  2.03327499e-02,  1.60761718e-02,\n",
      "        1.22062899e-02,  7.70557858e-03,  5.14751440e-03,  3.10706347e-03,\n",
      "        1.58931990e-03,  1.09246047e-03,  8.96842277e-04,  5.90108102e-04,\n",
      "        5.11523976e-04,  4.23764228e-04,  3.64041858e-04,  3.17459402e-04,\n",
      "        2.62104062e-04,  1.95613669e-04,  1.64092795e-04,  1.39656986e-04,\n",
      "        1.17118281e-04,  1.08802036e-04,  7.53777713e-05,  6.21146974e-05,\n",
      "        4.84441080e-05,  4.15181603e-05,  3.80526471e-05,  3.25328729e-05,\n",
      "        2.81599314e-05,  1.91074123e-05,  1.51910017e-05,  1.24425715e-05,\n",
      "        9.78555636e-06, -8.18969329e-06,  8.49871412e-06,  7.76055003e-06,\n",
      "        6.22249536e-06,  4.49219078e-06, -3.56539590e-06,  3.59270211e-06,\n",
      "       -3.29700606e-06, -2.82283349e-06,  3.29471914e-06,  3.01636851e-06,\n",
      "       -2.24045880e-06,  2.57058878e-06,  2.36593087e-06,  2.09105860e-06,\n",
      "       -1.59399565e-06,  1.77223092e-06,  1.61081357e-06,  1.47714957e-06,\n",
      "        1.35937682e-06, -1.13216879e-06, -8.39620725e-07,  1.03570926e-06,\n",
      "        9.74083832e-07, -6.58738941e-07,  7.44997465e-07,  7.04755792e-07,\n",
      "        5.94134349e-07, -5.80666438e-07, -5.32044169e-07, -5.00141823e-07,\n",
      "       -3.68751301e-07,  4.84172801e-07,  4.67898985e-07,  4.12408497e-07,\n",
      "       -2.93919101e-07,  3.63121359e-07,  3.06316394e-07, -2.58718330e-07,\n",
      "        2.86410653e-07, -2.15127159e-07,  2.59683901e-07,  2.47544904e-07,\n",
      "        2.34287185e-07, -1.72401030e-07, -1.58087317e-07, -1.49185581e-07,\n",
      "        1.51338767e-07, -1.20698857e-07,  1.35824394e-07, -1.10309394e-07,\n",
      "        1.25426865e-07,  1.12315760e-07, -8.89279832e-08, -7.34176027e-08,\n",
      "        9.41899145e-08,  6.74626222e-08,  7.81061331e-08, -5.31190452e-08,\n",
      "        5.26141051e-08, -5.05853102e-08,  4.45024035e-08, -2.83454060e-08,\n",
      "       -2.94976985e-08,  3.56073109e-08,  3.08990238e-08, -2.21947278e-08,\n",
      "       -2.02169907e-08,  2.48359395e-08,  2.66259725e-08,  1.98430605e-08,\n",
      "       -1.47226000e-08, -7.84422305e-09, -4.72373296e-09,  4.54981697e-09,\n",
      "        2.72580780e-09, -2.08002104e-09, -6.19231888e-10, -1.02141717e-08,\n",
      "       -9.80941639e-09,  1.44518664e-08,  9.21187038e-09,  1.17030883e-08],\n",
      "      dtype=float32), array([[ 0.02856061, -0.11261968, -0.24775523, ...,  0.05900563,\n",
      "        -0.04093197,  0.02996022],\n",
      "       [ 0.0355523 ,  0.11329804,  0.05026614, ...,  0.10793931,\n",
      "         0.07341016,  0.05729686],\n",
      "       [-0.0151257 ,  0.02348265, -0.00592501, ...,  0.09280362,\n",
      "        -0.05801359, -0.12410254],\n",
      "       ...,\n",
      "       [ 0.01316869, -0.11914573, -0.1474301 , ..., -0.1567537 ,\n",
      "         0.04941998, -0.02792729],\n",
      "       [ 0.13065512,  0.05738596,  0.09490623, ..., -0.00696021,\n",
      "         0.00838958, -0.02466062],\n",
      "       [ 0.01715915,  0.05251616, -0.08929832, ...,  0.18172696,\n",
      "         0.16992721,  0.1596407 ]], dtype=float32))\n",
      "(array([ 2.18979492e+02,  1.65389389e-01,  6.94952384e-02,  1.89818703e-02,\n",
      "        1.63560882e-02,  9.67795122e-03,  6.50468096e-03,  4.71599307e-03,\n",
      "        3.21777351e-03,  2.27595889e-03,  1.62512658e-03,  8.76225880e-04,\n",
      "        7.36861373e-04,  5.75559738e-04,  2.92941288e-04,  2.97947874e-04,\n",
      "        2.18927045e-04,  1.68913582e-04,  1.35959577e-04,  8.18202534e-05,\n",
      "        7.59665272e-05,  6.67355416e-05,  4.87583238e-05,  4.11417568e-05,\n",
      "        3.40384686e-05,  2.94707552e-05,  2.80363056e-05,  2.38976645e-05,\n",
      "        1.84656856e-05,  1.60862819e-05,  1.29997716e-05,  1.11163945e-05,\n",
      "       -6.66856113e-06,  8.37724838e-06,  7.36945958e-06,  6.63598894e-06,\n",
      "        5.85336466e-06,  5.23801327e-06, -4.58715431e-06,  5.10957852e-06,\n",
      "        4.46080276e-06,  4.05757964e-06,  3.77493075e-06,  3.26769577e-06,\n",
      "       -2.57809938e-06, -1.95829762e-06,  2.75938987e-06,  2.56928865e-06,\n",
      "        2.37601466e-06,  2.17766251e-06, -1.74714035e-06, -1.38605606e-06,\n",
      "        1.80960035e-06,  1.61759385e-06,  1.56842339e-06,  1.46170180e-06,\n",
      "        1.29640205e-06, -1.21619678e-06, -1.17414038e-06, -1.05708671e-06,\n",
      "        1.05436129e-06, -8.38627841e-07,  9.23670484e-07, -7.64053425e-07,\n",
      "        7.94435948e-07, -6.42378836e-07,  7.29541284e-07,  6.69367637e-07,\n",
      "       -5.54371866e-07, -4.98143038e-07, -4.25878369e-07, -4.16066854e-07,\n",
      "        5.96836173e-07,  5.62857451e-07,  5.30734269e-07,  4.43790128e-07,\n",
      "        4.31012353e-07, -3.00021838e-07, -3.23547653e-07,  3.58758143e-07,\n",
      "        3.29317317e-07, -2.48718919e-07, -2.34232218e-07, -1.96531602e-07,\n",
      "        2.99253628e-07,  2.67764648e-07,  2.54379444e-07,  2.19862443e-07,\n",
      "        1.98512566e-07, -1.28861032e-07, -1.33582432e-07,  1.67191573e-07,\n",
      "       -1.11390023e-07, -8.51334150e-08,  1.48598303e-07,  1.23356372e-07,\n",
      "        1.07031930e-07, -6.95984141e-08,  8.66565912e-08,  8.42713206e-08,\n",
      "       -4.02862419e-08, -4.52903635e-08, -2.32925945e-08,  5.96755854e-08,\n",
      "        5.28031450e-08,  4.83780198e-08, -1.80729138e-08, -1.22237385e-08,\n",
      "        2.56468056e-08,  3.74316933e-08,  3.58748871e-08, -6.93155133e-09,\n",
      "       -3.32002092e-09,  1.90498639e-08, -2.66530613e-12,  2.02202699e-09,\n",
      "        3.26999006e-09,  1.54942388e-08,  1.15141416e-08,  9.18854326e-09],\n",
      "      dtype=float32), array([[-0.02126802, -0.13934895, -0.01592782, ..., -0.02196003,\n",
      "        -0.00149723,  0.00089559],\n",
      "       [-0.04562427,  0.16274501, -0.05829064, ..., -0.03134701,\n",
      "         0.05169801, -0.03836701],\n",
      "       [-0.00350477, -0.07043722,  0.05660237, ..., -0.14842725,\n",
      "         0.10482088,  0.19316338],\n",
      "       ...,\n",
      "       [ 0.02556126, -0.01634731, -0.0067011 , ...,  0.05954937,\n",
      "         0.04559127,  0.08018302],\n",
      "       [-0.15036336, -0.16355698,  0.00092303, ...,  0.01038184,\n",
      "        -0.00954686, -0.02518138],\n",
      "       [-0.0424379 , -0.05261239,  0.05269494, ..., -0.04973209,\n",
      "        -0.11575008, -0.03182248]], dtype=float32))\n",
      "(array([ 2.71405060e+02,  4.41068029e+00,  1.13054216e+00,  1.02946281e+00,\n",
      "        2.65491486e-01,  8.59001279e-02,  8.23596492e-02,  5.62619641e-02,\n",
      "        4.39883210e-02,  2.62872949e-02,  2.30296459e-02,  1.89304706e-02,\n",
      "        1.29863145e-02,  1.01333018e-02,  7.96930306e-03,  6.05999911e-03,\n",
      "        5.16578322e-03,  3.85393691e-03,  2.87218625e-03,  2.41884240e-03,\n",
      "        1.93928415e-03,  1.57342863e-03,  1.40595064e-03,  1.26278447e-03,\n",
      "        1.02714135e-03,  9.65021783e-04,  8.12412589e-04,  6.58079749e-04,\n",
      "        5.54101542e-04,  4.86682809e-04,  4.09631233e-04,  3.42357933e-04,\n",
      "        3.34308424e-04,  2.61383131e-04,  2.11640450e-04,  1.83383600e-04,\n",
      "        1.77556591e-04,  1.69626554e-04,  1.17874464e-04,  1.06901389e-04,\n",
      "        1.00960147e-04,  7.73233696e-05,  6.31322182e-05,  5.71024793e-05,\n",
      "        4.35993716e-05,  3.77205033e-05,  2.95011687e-05,  2.54930073e-05,\n",
      "        1.84466498e-05,  1.69210325e-05, -8.77487946e-06,  5.77827859e-06,\n",
      "       -4.50708694e-06,  3.56991131e-06, -3.46728962e-06, -3.09202369e-06,\n",
      "        2.37844029e-06,  2.27889677e-06, -1.56246165e-06,  1.84109058e-06,\n",
      "        1.70900159e-06,  1.50811206e-06,  1.42186570e-06, -1.35093057e-06,\n",
      "       -1.18350511e-06, -9.30600606e-07,  9.45158092e-07, -8.08952166e-07,\n",
      "        8.24923745e-07,  7.39330289e-07,  6.14892372e-07,  6.36631000e-07,\n",
      "       -7.01514580e-07, -6.30748104e-07, -6.04299657e-07,  4.61109806e-07,\n",
      "        4.44066984e-07,  3.68637302e-07, -4.72763048e-07, -4.41786852e-07,\n",
      "       -4.17869899e-07, -3.84267452e-07, -3.37444618e-07,  3.14357663e-07,\n",
      "       -2.79786917e-07,  2.76977630e-07, -2.42869163e-07, -2.09054591e-07,\n",
      "       -1.77614751e-07,  1.69727727e-07,  1.63182193e-07,  1.53004564e-07,\n",
      "       -1.47338326e-07, -1.36107374e-07,  1.22019799e-07, -1.04999572e-07,\n",
      "        9.96521621e-08, -7.52745919e-08,  8.40279952e-08,  7.06143908e-08,\n",
      "        6.61955184e-08, -6.30061692e-08, -5.83546047e-08, -5.25448556e-08,\n",
      "        5.16514653e-08,  4.20006323e-08, -3.12324957e-08,  3.64550949e-08,\n",
      "       -2.02524468e-08, -2.36379538e-08,  2.02217603e-08,  2.26456880e-08,\n",
      "       -1.31133886e-08, -7.19271886e-09,  4.96582198e-09,  1.04391775e-08,\n",
      "       -1.86446639e-11, -3.18942317e-09,  7.98007616e-09,  1.05848308e-08],\n",
      "      dtype=float32), array([[-0.03279963, -0.09855373,  0.02284175, ..., -0.00372706,\n",
      "        -0.01916367,  0.00463642],\n",
      "       [-0.04691117, -0.00192779,  0.03883719, ..., -0.03078716,\n",
      "        -0.0039056 , -0.03616787],\n",
      "       [-0.00196275,  0.04019037,  0.08626442, ..., -0.01035467,\n",
      "        -0.01096036,  0.09130193],\n",
      "       ...,\n",
      "       [ 0.02366625, -0.09412219, -0.15812618, ..., -0.15310752,\n",
      "         0.03747543,  0.13739602],\n",
      "       [-0.16647916, -0.0063618 ,  0.17766252, ...,  0.0011184 ,\n",
      "        -0.02068193, -0.00032836],\n",
      "       [-0.04614282,  0.05497815,  0.09453734, ..., -0.06187777,\n",
      "        -0.01525748, -0.01405809]], dtype=float32))\n",
      "(array([ 2.95188629e+02,  3.87140369e+00,  1.43913710e+00,  4.76199448e-01,\n",
      "        1.54439121e-01,  1.20534159e-01,  6.23347349e-02,  3.30114402e-02,\n",
      "        3.20093185e-02,  2.58170310e-02,  1.83574613e-02,  1.53650623e-02,\n",
      "        1.26301171e-02,  8.67692009e-03,  5.03779482e-03,  4.24787262e-03,\n",
      "        3.64182238e-03,  3.12507781e-03,  2.60864012e-03,  2.30310671e-03,\n",
      "        1.98953669e-03,  1.74159335e-03,  1.35058630e-03,  1.18651672e-03,\n",
      "        1.15825306e-03,  9.25601227e-04,  7.35161360e-04,  6.23131113e-04,\n",
      "        5.33994345e-04,  4.28309606e-04,  3.47831170e-04,  3.21502943e-04,\n",
      "        2.71637749e-04,  2.35970365e-04,  1.99272050e-04,  1.86934485e-04,\n",
      "        1.54991605e-04,  1.35203038e-04,  1.07067892e-04,  8.83249013e-05,\n",
      "        7.49443716e-05,  5.58513711e-05,  6.19086131e-05,  4.67912614e-05,\n",
      "        4.14983660e-05,  2.83340287e-05,  2.35814205e-05,  2.17241777e-05,\n",
      "        1.96193596e-05,  1.54790905e-05,  7.49530363e-06, -5.26603844e-06,\n",
      "        4.34078356e-06, -4.55355485e-06, -3.60203853e-06,  2.69841871e-06,\n",
      "        2.55227110e-06,  2.10553389e-06, -2.71840076e-06, -2.34670779e-06,\n",
      "       -2.21372261e-06, -1.98264502e-06, -1.61960247e-06,  1.89446416e-06,\n",
      "        1.68933150e-06,  1.53297935e-06, -1.33344020e-06,  1.20089567e-06,\n",
      "        1.13501312e-06, -1.06444554e-06,  8.96629558e-07, -8.87459407e-07,\n",
      "       -9.22188690e-07,  7.44379292e-07,  6.80852168e-07, -7.05191837e-07,\n",
      "       -6.46056321e-07,  5.66198707e-07,  5.46757576e-07, -4.66587892e-07,\n",
      "        4.75983711e-07, -4.12616487e-07,  3.78316599e-07, -3.81361190e-07,\n",
      "       -3.68270520e-07, -3.02097618e-07,  3.21875007e-07,  2.82836595e-07,\n",
      "        2.39927232e-07,  1.97799253e-07, -2.49596042e-07, -2.20357961e-07,\n",
      "       -1.99286106e-07, -1.80605980e-07,  1.65391000e-07, -1.48724112e-07,\n",
      "        1.55369548e-07,  1.35493138e-07, -1.07834346e-07, -1.03084041e-07,\n",
      "        1.08786615e-07,  1.04410105e-07,  8.52624567e-08, -7.68484085e-08,\n",
      "        7.54059926e-08,  5.71810652e-08, -5.56638113e-08, -4.90125771e-08,\n",
      "       -3.68457549e-08,  4.17076400e-08,  3.28438290e-08, -2.69454024e-08,\n",
      "       -1.98544363e-08,  1.72100343e-08, -1.27234436e-08, -4.61720395e-09,\n",
      "       -2.54305266e-09,  2.84424195e-09,  1.10250991e-08,  9.47536805e-09],\n",
      "      dtype=float32), array([[-0.03121663,  0.11306974,  0.08903428, ...,  0.06093055,\n",
      "        -0.05181026, -0.00967587],\n",
      "       [-0.04618774,  0.03023984, -0.15682365, ..., -0.02494188,\n",
      "         0.06261014,  0.02989142],\n",
      "       [-0.01245008, -0.03801092,  0.07677267, ...,  0.16538337,\n",
      "        -0.07367415,  0.1178278 ],\n",
      "       ...,\n",
      "       [ 0.04164781,  0.05910134,  0.07475747, ...,  0.05584314,\n",
      "         0.04245262, -0.05093774],\n",
      "       [-0.18097125,  0.02030206,  0.10947098, ..., -0.00645903,\n",
      "        -0.00603112, -0.03586814],\n",
      "       [-0.05989967, -0.04567958,  0.04311033, ...,  0.01404326,\n",
      "        -0.04810685,  0.13678402]], dtype=float32))\n",
      "(array([ 2.35867493e+02,  1.46922994e+00,  9.73079264e-01,  4.13808912e-01,\n",
      "        2.47601181e-01,  9.76095051e-02,  6.04142696e-02,  4.40879129e-02,\n",
      "        3.72457132e-02,  2.71907598e-02,  2.04198156e-02,  1.78940762e-02,\n",
      "        1.29481852e-02,  7.44171534e-03,  6.36972673e-03,  6.42322795e-03,\n",
      "        4.38197609e-03,  4.01478028e-03,  2.99550476e-03,  2.30055302e-03,\n",
      "        2.12417240e-03,  1.87371450e-03,  1.66939641e-03,  1.23233965e-03,\n",
      "        9.96531569e-04,  8.97634134e-04,  6.90585002e-04,  5.96722355e-04,\n",
      "        4.71312000e-04,  4.36981849e-04,  3.16969585e-04,  3.12330114e-04,\n",
      "        2.15916283e-04,  2.08422658e-04,  1.32649380e-04,  1.38286006e-04,\n",
      "        1.01029895e-04,  8.07343458e-05,  7.43062192e-05,  4.91481260e-05,\n",
      "        4.51326669e-05,  4.17418705e-05,  3.73021212e-05,  2.89658474e-05,\n",
      "        2.70668279e-05,  1.92239277e-05,  1.86559755e-05,  1.56747119e-05,\n",
      "        1.04020173e-05,  6.60980641e-06, -4.97733572e-06,  3.24769280e-06,\n",
      "        3.00150259e-06,  2.82712517e-06, -2.43003819e-06, -2.30737851e-06,\n",
      "       -2.12866144e-06, -1.44397313e-06,  1.71425825e-06,  1.55067880e-06,\n",
      "        1.47559660e-06,  1.21649441e-06, -1.26241287e-06, -1.11514044e-06,\n",
      "       -1.07635844e-06,  9.85246629e-07, -8.17070259e-07,  8.34679270e-07,\n",
      "        7.74076454e-07, -6.37429594e-07,  7.11600535e-07,  6.36232585e-07,\n",
      "        5.82580356e-07, -5.49203094e-07, -5.62255707e-07, -4.45527832e-07,\n",
      "        4.64619887e-07,  4.09202300e-07,  3.65565512e-07,  3.57158655e-07,\n",
      "        2.91782442e-07, -3.56858862e-07, -3.28553313e-07, -3.13482701e-07,\n",
      "       -2.61721596e-07,  2.04639633e-07, -1.92574660e-07,  1.85480189e-07,\n",
      "       -1.73484949e-07, -1.60345664e-07,  1.46388857e-07,  1.22490206e-07,\n",
      "       -1.17588812e-07, -1.00258468e-07,  9.72371978e-08,  8.54442987e-08,\n",
      "       -9.12460862e-08, -7.55816956e-08,  6.38565325e-08, -5.91183351e-08,\n",
      "        5.81226764e-08, -4.78271431e-08,  5.23398533e-08,  4.38542465e-08,\n",
      "       -4.38911201e-08, -3.54626835e-08, -2.01935569e-11,  3.84332246e-08,\n",
      "        3.15394786e-08, -2.79181478e-08,  2.12736797e-08,  1.61106346e-08,\n",
      "        1.08922702e-08,  8.44029557e-09,  1.95741512e-09, -1.62639360e-08,\n",
      "       -1.27564750e-08, -1.02240101e-08, -5.34090860e-09, -4.96932140e-09],\n",
      "      dtype=float32), array([[ 0.02970866, -0.06441453,  0.1328681 , ...,  0.00199549,\n",
      "         0.06986329,  0.02278613],\n",
      "       [ 0.04536151,  0.0261884 ,  0.05991355, ...,  0.03285685,\n",
      "        -0.00717457,  0.00746771],\n",
      "       [ 0.00495525,  0.04970902, -0.10498686, ..., -0.06862833,\n",
      "         0.06257682, -0.13205086],\n",
      "       ...,\n",
      "       [-0.02891812, -0.12763989,  0.06572319, ..., -0.0335329 ,\n",
      "        -0.22360216, -0.02214672],\n",
      "       [ 0.15447529, -0.11719312, -0.17384663, ..., -0.00674047,\n",
      "         0.01166403,  0.02014375],\n",
      "       [ 0.0436815 ,  0.00045736, -0.15024218, ..., -0.0620208 ,\n",
      "        -0.03963835, -0.06783775]], dtype=float32))\n",
      "(array([ 2.2255336e+02,  3.8008084e+00,  9.1306078e-01,  3.3952400e-01,\n",
      "        1.8570724e-01,  1.0763762e-01,  7.9728879e-02,  3.4534529e-02,\n",
      "        2.6483499e-02,  2.0159081e-02,  1.7036784e-02,  1.2445321e-02,\n",
      "        9.5787868e-03,  7.1838661e-03,  5.4259384e-03,  4.5294981e-03,\n",
      "        4.0293676e-03,  2.2392985e-03,  1.8502675e-03,  1.7177259e-03,\n",
      "        1.4145181e-03,  7.7941804e-04,  6.4454658e-04,  5.7897234e-04,\n",
      "        5.0951517e-04,  4.5119159e-04,  4.2328343e-04,  4.0362688e-04,\n",
      "        3.1804631e-04,  2.7732720e-04,  2.4187125e-04,  1.9613183e-04,\n",
      "        1.7522612e-04,  1.6039313e-04,  1.3681356e-04,  8.8865352e-05,\n",
      "        7.5918993e-05,  6.7889167e-05,  5.8360802e-05,  4.8106176e-05,\n",
      "        4.2911015e-05,  3.6015033e-05,  3.2429245e-05,  2.5812513e-05,\n",
      "        2.1454116e-05,  2.0495794e-05,  1.6898959e-05,  1.1048831e-05,\n",
      "        8.2125071e-06, -6.3753250e-06,  6.8674121e-06,  5.3375206e-06,\n",
      "        3.0853855e-06, -2.8579686e-06,  2.6714276e-06,  2.3044436e-06,\n",
      "       -2.3975031e-06, -1.7469565e-06, -1.6420472e-06,  1.6829031e-06,\n",
      "        1.3905028e-06,  1.0992956e-06, -1.1244940e-06, -1.0109368e-06,\n",
      "       -7.9763902e-07, -7.1409909e-07,  8.1618123e-07,  7.3654638e-07,\n",
      "        6.9583496e-07,  6.3292413e-07,  6.0198221e-07, -5.8619327e-07,\n",
      "       -5.4445218e-07, -5.1182911e-07,  4.9476614e-07,  4.1022625e-07,\n",
      "       -4.1198817e-07, -3.9353733e-07, -3.6501771e-07,  3.2550605e-07,\n",
      "        3.0345325e-07, -2.8457214e-07,  2.9105146e-07,  2.5624249e-07,\n",
      "       -2.4437830e-07, -2.0513073e-07, -1.8900414e-07,  2.0543136e-07,\n",
      "        1.8568802e-07,  1.7343214e-07, -1.6094016e-07, -1.2973962e-07,\n",
      "       -1.1810306e-07,  1.2129243e-07,  1.1310615e-07,  1.0747656e-07,\n",
      "       -9.7705332e-08,  8.1415394e-08, -7.2523150e-08,  6.6468537e-08,\n",
      "       -5.0613934e-08, -4.8039269e-08,  4.8350653e-08,  4.1567169e-08,\n",
      "       -3.6015795e-08,  2.8311311e-08, -3.2660317e-08,  2.0921444e-08,\n",
      "       -2.0881956e-08, -1.6793646e-08, -1.4072668e-08,  1.5158685e-08,\n",
      "        1.2134061e-08,  1.2072917e-08, -6.3080678e-09, -6.9949491e-10,\n",
      "        3.2023806e-09,  5.8480962e-09, -5.5617320e-09, -9.9036690e-09],\n",
      "      dtype=float32), array([[-0.0189249 , -0.16050676,  0.14367643, ..., -0.01113796,\n",
      "        -0.00351968,  0.00941831],\n",
      "       [-0.05083495, -0.00593223, -0.1844206 , ..., -0.01374058,\n",
      "        -0.01234791,  0.13541101],\n",
      "       [-0.00840198,  0.02892517,  0.07281201, ..., -0.0693972 ,\n",
      "        -0.15158452, -0.12081322],\n",
      "       ...,\n",
      "       [ 0.03848958, -0.05027984,  0.0139357 , ...,  0.01418874,\n",
      "        -0.06250799,  0.05487094],\n",
      "       [-0.15296039, -0.00911134,  0.16781314, ...,  0.02577338,\n",
      "        -0.00978825, -0.01404943],\n",
      "       [-0.0433732 ,  0.0254567 ,  0.09622747, ..., -0.00830981,\n",
      "         0.10283781,  0.02997125]], dtype=float32))\n",
      "(array([ 1.93320801e+02,  1.65231252e+00,  6.00561559e-01,  2.80232131e-01,\n",
      "        6.09023720e-02,  4.20320928e-02,  3.23644057e-02,  2.26525534e-02,\n",
      "        1.51531305e-02,  1.02433423e-02,  8.25256016e-03,  7.04996753e-03,\n",
      "        5.69547107e-03,  3.97429802e-03,  2.92989193e-03,  2.24289624e-03,\n",
      "        1.78399635e-03,  1.56129024e-03,  1.11858966e-03,  7.11925328e-04,\n",
      "        6.28728129e-04,  5.43353322e-04,  4.64117358e-04,  3.99871118e-04,\n",
      "        3.12389224e-04,  2.86444993e-04,  2.37007451e-04,  1.93195883e-04,\n",
      "        1.81674768e-04,  1.37489333e-04,  1.35059439e-04,  1.26157291e-04,\n",
      "        8.72489836e-05,  7.74319269e-05,  7.07085564e-05,  6.42499872e-05,\n",
      "        4.53187095e-05,  3.83653387e-05,  3.30441144e-05,  2.94061301e-05,\n",
      "        2.62651811e-05,  1.80751722e-05,  1.64257854e-05,  1.35028513e-05,\n",
      "        1.18560292e-05,  1.11522859e-05,  8.57573013e-06,  7.66446192e-06,\n",
      "        6.01808597e-06,  5.27807970e-06,  3.74005367e-06, -3.17562353e-06,\n",
      "       -2.90986554e-06,  2.86989894e-06,  2.15805653e-06, -1.88219747e-06,\n",
      "       -1.69637451e-06,  1.44682394e-06,  1.25403062e-06,  1.06018285e-06,\n",
      "       -1.23465338e-06, -1.11411259e-06, -9.59984050e-07, -8.86635178e-07,\n",
      "        8.49770345e-07,  7.67399911e-07, -6.97696748e-07,  6.82879090e-07,\n",
      "       -6.24312861e-07, -6.02722992e-07,  5.88106900e-07, -4.87588693e-07,\n",
      "        4.99660700e-07, -3.93257977e-07,  4.49982480e-07,  4.32831655e-07,\n",
      "        3.82292541e-07, -3.47870071e-07,  2.86731733e-07, -2.71003131e-07,\n",
      "       -2.56413358e-07,  2.67228017e-07,  2.38740427e-07, -2.23804946e-07,\n",
      "       -2.01056864e-07,  2.19028180e-07,  1.86030562e-07,  1.63883499e-07,\n",
      "       -1.74979533e-07, -1.61258015e-07,  1.33303132e-07,  1.40359830e-07,\n",
      "       -1.29196678e-07, -1.20583849e-07, -1.11340718e-07,  1.01518516e-07,\n",
      "       -9.03253508e-08,  8.71237091e-08, -8.71302248e-08, -7.92701087e-08,\n",
      "        7.71315598e-08, -5.12751797e-08, -4.07483931e-08,  6.28643875e-08,\n",
      "        5.79685100e-08,  5.21439141e-08,  3.92213018e-08, -3.53170364e-08,\n",
      "        2.29137918e-08, -2.61671378e-08,  1.83959834e-08,  1.33670923e-08,\n",
      "        1.11562297e-08,  1.48242818e-09,  6.70963785e-10, -3.78815423e-09,\n",
      "       -8.89760798e-09, -7.30822647e-09, -2.05819930e-08, -1.51897748e-08],\n",
      "      dtype=float32), array([[-0.00075857,  0.05253549, -0.16641389, ..., -0.01973134,\n",
      "         0.01881101,  0.0287987 ],\n",
      "       [-0.05271783,  0.05319019,  0.1728331 , ..., -0.06459041,\n",
      "         0.00475727, -0.01702464],\n",
      "       [-0.01222283, -0.02104179, -0.08004232, ...,  0.1634184 ,\n",
      "         0.17265655,  0.04414111],\n",
      "       ...,\n",
      "       [ 0.04581615,  0.04638446,  0.00287643, ..., -0.02040772,\n",
      "         0.05278664,  0.06273506],\n",
      "       [-0.15413521,  0.02268918, -0.18609738, ...,  0.03936812,\n",
      "        -0.03207418,  0.00649128],\n",
      "       [-0.04397285, -0.03783219, -0.11816924, ..., -0.09545276,\n",
      "         0.08188466,  0.0637048 ]], dtype=float32))\n",
      "(array([ 3.26184845e+02,  4.91789341e+00,  1.32770777e+00,  9.28214550e-01,\n",
      "        1.30847231e-01,  7.93555900e-02,  7.16985166e-02,  4.84953634e-02,\n",
      "        3.29060331e-02,  2.48772949e-02,  2.20177583e-02,  1.39379073e-02,\n",
      "        1.06221624e-02,  1.02695609e-02,  5.53060602e-03,  5.15677361e-03,\n",
      "        4.97067999e-03,  3.44555173e-03,  2.66928691e-03,  2.47327611e-03,\n",
      "        2.19293358e-03,  1.54799712e-03,  1.11879618e-03,  9.38981830e-04,\n",
      "        9.14421573e-04,  8.37862433e-04,  6.90093555e-04,  6.21860148e-04,\n",
      "        5.83328307e-04,  4.94170934e-04,  3.65252869e-04,  2.87766859e-04,\n",
      "        2.58231652e-04,  2.41637084e-04,  1.95069137e-04,  1.76855217e-04,\n",
      "        1.69936684e-04,  1.45900180e-04,  1.22536905e-04,  1.08771099e-04,\n",
      "        7.36700313e-05,  6.25055836e-05,  5.23406925e-05,  3.99548699e-05,\n",
      "        3.69202608e-05,  2.98777741e-05,  1.96522924e-05,  1.91083855e-05,\n",
      "        1.46060174e-05,  1.19876013e-05, -7.16307477e-06, -6.21888330e-06,\n",
      "        6.02933869e-06,  4.90384582e-06, -4.39242194e-06,  3.85361363e-06,\n",
      "        2.97886731e-06,  2.56292992e-06, -2.25098302e-06, -2.02798947e-06,\n",
      "        1.97740997e-06,  1.82248777e-06, -1.81494909e-06, -1.56726276e-06,\n",
      "        1.38710345e-06,  1.17889329e-06, -1.34996753e-06, -1.18525656e-06,\n",
      "        1.05783090e-06, -8.90698516e-07, -7.37643234e-07,  8.59279169e-07,\n",
      "        7.30943668e-07, -6.54426174e-07, -6.10775203e-07,  5.73553905e-07,\n",
      "        5.99014470e-07, -4.92543904e-07,  5.11529151e-07,  4.44356630e-07,\n",
      "       -4.24792603e-07, -3.81934768e-07,  3.49317901e-07, -3.14455889e-07,\n",
      "        3.20556410e-07,  2.58782819e-07,  2.03424491e-07, -2.53411855e-07,\n",
      "       -2.35170788e-07, -1.99908015e-07, -1.91598787e-07,  1.82247405e-07,\n",
      "        1.47306082e-07, -1.28580680e-07, -1.23122831e-07, -1.01402932e-07,\n",
      "        1.27209148e-07,  1.09242826e-07,  9.31713942e-08,  8.43571826e-08,\n",
      "       -8.10299099e-08, -7.40643173e-08,  6.53132943e-08, -6.19971985e-08,\n",
      "        5.71548711e-08, -4.15291517e-08, -3.83328462e-08,  4.32595222e-08,\n",
      "        3.15802495e-08,  2.74827947e-08, -2.27321131e-08, -1.67736598e-08,\n",
      "        1.27214976e-08, -1.09352349e-08,  8.09373990e-09,  6.95515734e-09,\n",
      "       -1.64490621e-09,  1.84587778e-09, -5.72672398e-09, -7.55749774e-09],\n",
      "      dtype=float32), array([[-0.03445957, -0.1610355 ,  0.10399748, ..., -0.00967286,\n",
      "        -0.01913073, -0.01026367],\n",
      "       [-0.05118741,  0.0434953 , -0.10551164, ...,  0.01355731,\n",
      "         0.01884776,  0.06421468],\n",
      "       [-0.00812397,  0.00311106,  0.04329738, ..., -0.06913413,\n",
      "        -0.33585468, -0.00724261],\n",
      "       ...,\n",
      "       [ 0.03436144, -0.03724996, -0.04680602, ...,  0.02103057,\n",
      "         0.0179801 ,  0.00576843],\n",
      "       [-0.15925805, -0.10087661,  0.15736955, ..., -0.00078083,\n",
      "         0.00088776, -0.01496286],\n",
      "       [-0.04398267, -0.01944945,  0.09009817, ...,  0.0028832 ,\n",
      "        -0.02524171,  0.08714656]], dtype=float32))\n",
      "(array([ 4.58668243e+02,  6.31998873e+00,  1.08491910e+00,  4.49843824e-01,\n",
      "        2.33962461e-01,  1.26501560e-01,  9.67721120e-02,  5.59462346e-02,\n",
      "        4.78371978e-02,  2.58493144e-02,  1.84978489e-02,  1.69787686e-02,\n",
      "        1.32250655e-02,  9.90564004e-03,  7.63525860e-03,  6.55620405e-03,\n",
      "        5.26791951e-03,  4.67223255e-03,  3.34919826e-03,  2.59228586e-03,\n",
      "        2.15804228e-03,  1.52570929e-03,  1.34874822e-03,  1.17614446e-03,\n",
      "        9.67445550e-04,  7.91788334e-04,  6.63981831e-04,  5.95959020e-04,\n",
      "        5.57623629e-04,  4.16659605e-04,  3.55270662e-04,  3.28824361e-04,\n",
      "        2.51184858e-04,  2.04110300e-04,  1.65976875e-04,  1.48458465e-04,\n",
      "        1.14566545e-04,  9.50074173e-05,  8.88123614e-05,  7.21422984e-05,\n",
      "        5.57904787e-05,  4.60881492e-05,  4.21060577e-05,  2.76921328e-05,\n",
      "        2.29670841e-05,  1.69914892e-05,  1.10543433e-05, -7.80752816e-06,\n",
      "       -6.07828724e-06,  6.52139488e-06,  6.16628131e-06, -4.85099008e-06,\n",
      "        5.47067430e-06,  4.81426059e-06, -4.22677840e-06, -3.09255711e-06,\n",
      "       -2.79472897e-06,  3.18750563e-06,  2.84865337e-06,  2.53868279e-06,\n",
      "       -1.98249290e-06, -1.66999337e-06, -1.41313228e-06,  1.65561789e-06,\n",
      "        1.60222589e-06,  1.41318958e-06,  1.16437513e-06, -1.07699896e-06,\n",
      "       -1.01095043e-06,  9.65527420e-07, -8.67310803e-07,  8.64430660e-07,\n",
      "        7.93823119e-07, -7.25034170e-07,  7.08911955e-07, -5.92814672e-07,\n",
      "        6.06103015e-07, -4.90747368e-07,  4.91393621e-07,  4.52759053e-07,\n",
      "        4.33218446e-07,  3.30660953e-07, -3.66688710e-07, -3.80254846e-07,\n",
      "       -3.06421867e-07,  2.60425367e-07,  2.44576768e-07, -2.36114104e-07,\n",
      "       -2.28042438e-07,  2.17675648e-07,  1.89106359e-07, -1.41076285e-07,\n",
      "        1.62061866e-07,  1.40601742e-07, -1.14149579e-07, -9.70400009e-08,\n",
      "       -1.04113241e-07,  8.63584262e-08, -8.18566406e-08, -7.26246725e-08,\n",
      "        6.68725448e-08,  5.46516432e-08,  4.83010609e-08, -5.13109981e-08,\n",
      "       -4.35521201e-08,  3.80327805e-08, -2.99241663e-08, -2.90866637e-08,\n",
      "        2.96469018e-08,  2.05501536e-08, -5.06361175e-09,  2.87512281e-09,\n",
      "        2.92036645e-10, -2.22910801e-09,  1.69782783e-08, -1.35256091e-08,\n",
      "       -1.16228627e-08, -8.19640178e-09,  1.28058941e-08,  8.46084358e-09],\n",
      "      dtype=float32), array([[-0.04891131, -0.1288054 ,  0.09020317, ..., -0.01187724,\n",
      "         0.0330067 , -0.03142016],\n",
      "       [-0.06041668,  0.00210906, -0.20695084, ..., -0.01381624,\n",
      "        -0.07511232, -0.02971524],\n",
      "       [-0.00396508,  0.01648121,  0.05429925, ...,  0.09791555,\n",
      "        -0.16750363, -0.0182205 ],\n",
      "       ...,\n",
      "       [ 0.02446985, -0.05632874,  0.02938341, ...,  0.02805805,\n",
      "        -0.05942213,  0.01781646],\n",
      "       [-0.15568283, -0.06566938,  0.07450535, ...,  0.02356534,\n",
      "         0.01056621, -0.0045104 ],\n",
      "       [-0.03785311, -0.00304689,  0.057139  , ..., -0.02454293,\n",
      "         0.08944869,  0.00445404]], dtype=float32))\n",
      "(array([ 5.83193359e+02,  5.07589757e-01,  3.69927526e-01,  2.58546263e-01,\n",
      "        7.29245842e-02,  4.34333645e-02,  3.37505713e-02,  2.06181854e-02,\n",
      "        1.70911215e-02,  1.30219022e-02,  9.00712796e-03,  6.07945118e-03,\n",
      "        3.95712582e-03,  3.67147522e-03,  2.47914507e-03,  1.97913102e-03,\n",
      "        1.72766414e-03,  1.42676081e-03,  1.13609259e-03,  1.05601340e-03,\n",
      "        7.60503230e-04,  5.35860425e-04,  4.68914892e-04,  3.47515772e-04,\n",
      "        2.48774071e-04,  2.24044372e-04,  2.05007891e-04,  1.78814371e-04,\n",
      "        1.63834673e-04,  1.22903934e-04,  1.10246059e-04,  1.07875312e-04,\n",
      "        7.58218011e-05,  6.92086469e-05,  5.63795584e-05,  4.54289184e-05,\n",
      "        3.81832870e-05,  3.75698291e-05,  2.66362422e-05,  2.31327977e-05,\n",
      "        1.99196293e-05,  1.80571224e-05, -1.38930500e-05, -1.14583409e-05,\n",
      "        1.62996403e-05,  1.56298665e-05,  1.28174852e-05,  1.04154378e-05,\n",
      "       -8.11990594e-06, -6.62296725e-06,  8.31872421e-06,  7.10504992e-06,\n",
      "        6.65352945e-06, -5.46646834e-06, -4.19151456e-06,  5.77045603e-06,\n",
      "        5.31951309e-06,  4.63422157e-06,  4.21219420e-06,  3.63757135e-06,\n",
      "       -2.47169032e-06,  3.15325497e-06,  2.44125522e-06,  2.36221422e-06,\n",
      "       -2.03823220e-06,  1.89882769e-06, -1.62951562e-06, -1.54477425e-06,\n",
      "       -1.46414357e-06,  1.48009337e-06,  1.25647296e-06, -1.14228601e-06,\n",
      "        1.07770393e-06,  9.15604744e-07,  9.27338363e-07, -7.60291243e-07,\n",
      "        7.49424316e-07, -6.71584701e-07,  6.54348696e-07, -5.42365001e-07,\n",
      "        5.30451302e-07,  4.86193812e-07, -4.89987315e-07,  3.86050687e-07,\n",
      "       -4.17103593e-07, -3.47327301e-07, -3.17316193e-07,  2.59923809e-07,\n",
      "        2.53557204e-07, -2.21701825e-07,  2.04138757e-07, -1.94440162e-07,\n",
      "       -1.79251060e-07,  1.84954516e-07,  1.51799384e-07, -1.48979566e-07,\n",
      "       -1.33351335e-07,  1.14010845e-07, -8.73766908e-08, -7.14193646e-08,\n",
      "       -5.70979140e-08,  7.66862200e-08,  7.76370470e-08,  5.40026335e-08,\n",
      "        4.45786306e-08,  3.30284209e-08, -3.77499134e-08, -3.23515899e-08,\n",
      "       -2.51046846e-08,  1.91517451e-08, -1.84482030e-08, -1.06532623e-08,\n",
      "        1.27877060e-08,  8.87889495e-09,  7.98180988e-09, -4.26245439e-09,\n",
      "       -1.42608925e-09,  4.16986140e-10,  3.07306425e-09,  2.32267516e-09],\n",
      "      dtype=float32), array([[-0.04123441, -0.14110525,  0.06363555, ...,  0.0283084 ,\n",
      "        -0.08339052,  0.00888383],\n",
      "       [-0.06553421,  0.20184354,  0.11738291, ...,  0.00939136,\n",
      "         0.01084872,  0.03241016],\n",
      "       [-0.00138763, -0.03353028, -0.04079384, ...,  0.2767012 ,\n",
      "         0.08529682, -0.2386567 ],\n",
      "       ...,\n",
      "       [ 0.01726699, -0.06573941,  0.14000462, ...,  0.10227843,\n",
      "        -0.07141401,  0.07216219],\n",
      "       [-0.15490536, -0.12973808,  0.16966741, ..., -0.01882159,\n",
      "         0.01887884, -0.00901758],\n",
      "       [-0.03637092, -0.02920685, -0.02502465, ..., -0.00351654,\n",
      "        -0.03440208,  0.06338298]], dtype=float32))\n",
      "(array([ 4.90740143e+02,  4.00655627e-01,  2.69472927e-01,  1.63421541e-01,\n",
      "        1.07243732e-01,  9.17028412e-02,  4.56932597e-02,  3.09313759e-02,\n",
      "        1.41855404e-02,  1.09566543e-02,  1.03151249e-02,  7.21980399e-03,\n",
      "        5.21660736e-03,  4.42150934e-03,  2.48281052e-03,  1.78598659e-03,\n",
      "        1.50277698e-03,  1.05165213e-03,  1.00365246e-03,  7.35500420e-04,\n",
      "        6.31790492e-04,  5.24723728e-04,  4.51234955e-04,  3.94162256e-04,\n",
      "        2.53392936e-04,  2.35394968e-04,  2.19926296e-04,  1.90109815e-04,\n",
      "        1.53629037e-04,  1.45404003e-04,  1.26644358e-04,  8.90859155e-05,\n",
      "        7.16091745e-05,  6.12028089e-05,  4.98566769e-05,  4.64141558e-05,\n",
      "        3.83933439e-05,  3.38096688e-05,  2.99429266e-05,  2.71745921e-05,\n",
      "        2.42113947e-05,  2.05312863e-05,  1.64961584e-05,  1.42276631e-05,\n",
      "       -1.16754236e-05, -1.03357988e-05, -9.42286533e-06,  1.21832800e-05,\n",
      "        1.13799770e-05,  1.02308359e-05,  8.35481205e-06, -5.95275969e-06,\n",
      "        6.15520912e-06,  5.44925069e-06, -4.40593112e-06,  4.14841907e-06,\n",
      "        3.56917394e-06, -3.18797584e-06, -2.91908100e-06,  3.09827783e-06,\n",
      "       -2.40700115e-06,  2.61046125e-06,  2.24062774e-06,  2.08638312e-06,\n",
      "       -1.66370853e-06, -1.43662146e-06,  1.60672346e-06,  1.56659951e-06,\n",
      "        1.34905076e-06,  1.26622444e-06,  1.05103777e-06, -1.12825364e-06,\n",
      "       -1.14616137e-06, -1.05660683e-06,  8.05857496e-07, -8.09745700e-07,\n",
      "       -7.21429558e-07,  7.09967196e-07, -5.89694992e-07,  4.94263361e-07,\n",
      "        4.45342806e-07,  4.11020835e-07, -4.73622862e-07, -3.96274913e-07,\n",
      "       -3.77297937e-07,  3.15384113e-07, -2.75279092e-07,  2.68558409e-07,\n",
      "       -2.46487247e-07, -1.91149354e-07, -1.64809791e-07,  2.11887127e-07,\n",
      "        1.93730315e-07,  1.59079264e-07,  1.40912746e-07, -1.26100630e-07,\n",
      "        1.06065649e-07, -1.00177957e-07, -9.34803026e-08, -7.68467601e-08,\n",
      "        8.65075762e-08,  8.23932993e-08,  6.69736124e-08,  5.40780150e-08,\n",
      "        3.90735764e-08, -5.81858401e-08, -5.62270692e-08, -3.59054297e-08,\n",
      "        3.16472750e-08, -3.06253156e-08, -2.53563694e-08,  2.27327757e-08,\n",
      "        1.60166724e-08, -1.65330523e-08, -1.37282896e-08,  1.14580745e-08,\n",
      "        5.96679506e-09,  5.21089449e-10, -7.88543186e-09, -3.47261642e-09],\n",
      "      dtype=float32), array([[-0.0305094 , -0.12699258, -0.10759754, ..., -0.02050396,\n",
      "        -0.03234183,  0.01601288],\n",
      "       [-0.06583457, -0.03858466,  0.290127  , ...,  0.01329051,\n",
      "         0.01729878, -0.01526706],\n",
      "       [ 0.00040367, -0.01212477, -0.07626123, ...,  0.2828866 ,\n",
      "        -0.18996961, -0.08367063],\n",
      "       ...,\n",
      "       [ 0.01246765,  0.02484787,  0.04893924, ..., -0.01245943,\n",
      "        -0.05264788, -0.02923718],\n",
      "       [-0.15764888, -0.00228997, -0.05331669, ...,  0.00238388,\n",
      "         0.0062683 ,  0.01114379],\n",
      "       [-0.03529023, -0.01522891, -0.07152019, ...,  0.04319701,\n",
      "         0.10958438,  0.07495772]], dtype=float32))\n",
      "(array([ 5.42823059e+02,  1.15008748e+00,  3.61030996e-01,  2.64770031e-01,\n",
      "        1.35457098e-01,  8.81104544e-02,  5.13247326e-02,  3.36040705e-02,\n",
      "        1.95576940e-02,  1.25861792e-02,  1.02636022e-02,  8.19198415e-03,\n",
      "        7.82302395e-03,  5.61490282e-03,  3.99619620e-03,  2.82524968e-03,\n",
      "        2.08904431e-03,  1.82341470e-03,  1.25272095e-03,  1.03668810e-03,\n",
      "        8.12532904e-04,  6.18175487e-04,  5.01390605e-04,  4.89754719e-04,\n",
      "        3.49951733e-04,  3.28816677e-04,  2.47472752e-04,  1.98209120e-04,\n",
      "        1.79084993e-04,  1.71443739e-04,  1.40233678e-04,  1.02266415e-04,\n",
      "        9.44211642e-05,  7.62282871e-05,  7.16044888e-05,  4.67859463e-05,\n",
      "        4.49249565e-05,  3.83218430e-05,  3.52648385e-05,  2.93769135e-05,\n",
      "        2.62038520e-05,  2.31831964e-05,  1.88532103e-05,  1.77907841e-05,\n",
      "       -1.16686815e-05,  1.47425926e-05,  1.36619574e-05,  1.25656388e-05,\n",
      "        1.00746747e-05, -8.12480903e-06, -7.19375930e-06,  8.82757195e-06,\n",
      "       -6.15492218e-06,  7.33182742e-06,  6.96162670e-06,  5.90994159e-06,\n",
      "       -4.46052036e-06,  4.94260121e-06, -3.65030337e-06,  4.14281430e-06,\n",
      "        3.56950295e-06, -2.42930696e-06, -2.30337946e-06, -2.09620134e-06,\n",
      "        2.30494493e-06,  2.10065923e-06,  1.84076771e-06, -1.48061542e-06,\n",
      "        1.52333735e-06, -1.33307310e-06,  1.32496359e-06, -1.17906359e-06,\n",
      "       -1.00101624e-06,  9.49424987e-07, -7.31808484e-07,  9.18039063e-07,\n",
      "        7.44571992e-07,  7.10857648e-07, -6.00949136e-07,  5.23012659e-07,\n",
      "       -4.87801515e-07,  5.00876354e-07,  4.31410626e-07, -3.79955708e-07,\n",
      "        3.82389544e-07, -2.97616964e-07,  2.90681783e-07, -2.61850772e-07,\n",
      "       -2.17540986e-07, -2.16039410e-07,  2.57989740e-07,  2.29525796e-07,\n",
      "        1.91619478e-07,  1.85376280e-07, -1.62939429e-07,  1.15858192e-07,\n",
      "       -1.12496700e-07, -1.05538049e-07,  9.98570400e-08, -8.31047942e-08,\n",
      "        6.81184602e-08,  6.04589800e-08,  5.02499482e-08, -6.63437447e-08,\n",
      "       -5.56162725e-08, -4.79713016e-08, -5.07352702e-08,  3.76806852e-08,\n",
      "       -2.93674152e-08,  3.57651366e-08,  2.86083068e-08,  1.80121251e-08,\n",
      "       -1.50568340e-08, -1.16553904e-08, -7.00022795e-09, -8.45467518e-09,\n",
      "        4.41835180e-10,  4.03174960e-09,  7.87783172e-09,  6.70045708e-09],\n",
      "      dtype=float32), array([[ 0.03631649, -0.17173153, -0.07610527, ..., -0.0436383 ,\n",
      "        -0.00360665,  0.02529323],\n",
      "       [ 0.06419107,  0.16639689, -0.16187085, ..., -0.01014696,\n",
      "        -0.01614946, -0.04281168],\n",
      "       [ 0.00122947, -0.03581095,  0.01897866, ..., -0.26062232,\n",
      "        -0.0768491 ,  0.05689455],\n",
      "       ...,\n",
      "       [-0.01518669,  0.00245093, -0.01357102, ..., -0.0473771 ,\n",
      "        -0.01226483,  0.10955072],\n",
      "       [ 0.15783986, -0.13787928, -0.06284469, ..., -0.00082716,\n",
      "        -0.00195288, -0.00359258],\n",
      "       [ 0.03626162, -0.04880429,  0.0372727 , ...,  0.09423634,\n",
      "         0.0280382 , -0.02218494]], dtype=float32))\n",
      "(array([ 5.63950378e+02,  8.06351960e-01,  5.57282805e-01,  4.20604140e-01,\n",
      "        1.41246989e-01,  8.11468214e-02,  7.60315806e-02,  4.26657163e-02,\n",
      "        1.60043407e-02,  1.44216688e-02,  1.29921930e-02,  9.24026035e-03,\n",
      "        7.38728559e-03,  5.67946397e-03,  4.34568338e-03,  3.21266823e-03,\n",
      "        2.91524990e-03,  2.43469886e-03,  1.74520211e-03,  1.59518083e-03,\n",
      "        1.12642872e-03,  8.32206162e-04,  6.65762520e-04,  6.33264834e-04,\n",
      "        5.61574707e-04,  4.35270893e-04,  3.07319249e-04,  2.37905275e-04,\n",
      "        2.17317749e-04,  1.83289085e-04,  1.56353562e-04,  1.43478828e-04,\n",
      "        9.24749256e-05,  8.42490699e-05,  6.27899353e-05,  5.88847506e-05,\n",
      "        4.74188782e-05,  4.06600884e-05,  3.72273535e-05,  3.55019947e-05,\n",
      "        2.52286954e-05,  2.35357202e-05,  2.18870500e-05, -1.55059806e-05,\n",
      "        1.85191930e-05,  1.52600642e-05,  1.38447313e-05, -9.66949028e-06,\n",
      "        1.05358913e-05,  9.54913685e-06, -7.41239137e-06, -6.31321154e-06,\n",
      "        6.23347296e-06,  6.17700516e-06,  5.25978339e-06, -3.79860558e-06,\n",
      "        4.45342630e-06,  3.99875671e-06, -3.36003586e-06,  3.68692304e-06,\n",
      "        3.26832037e-06, -2.73295427e-06, -2.62557364e-06, -2.12888472e-06,\n",
      "        2.59487956e-06,  2.21466416e-06,  1.96180304e-06, -1.68563213e-06,\n",
      "        1.83644693e-06,  1.36905737e-06,  1.25169754e-06, -1.19479967e-06,\n",
      "       -1.03442915e-06,  1.00913223e-06,  9.12337214e-07, -7.73408260e-07,\n",
      "        7.82807888e-07, -6.20501112e-07,  6.70907866e-07, -5.82100824e-07,\n",
      "       -5.18312845e-07, -4.75302414e-07,  5.54506300e-07,  5.09028609e-07,\n",
      "        4.64752816e-07, -3.61122119e-07, -3.26562201e-07,  3.62741218e-07,\n",
      "        3.13544632e-07,  2.55093028e-07, -2.34045785e-07,  2.18717290e-07,\n",
      "        2.05396901e-07, -2.13531095e-07, -1.89886123e-07, -1.59297201e-07,\n",
      "        1.32684036e-07, -1.34451099e-07,  1.58317050e-07,  1.03234171e-07,\n",
      "       -7.66166863e-08,  7.57756311e-08,  6.15357010e-08,  5.65941498e-08,\n",
      "       -5.63928744e-08, -4.78329163e-08,  3.32579404e-08, -3.49111495e-08,\n",
      "        2.80369417e-08, -2.75499694e-08, -1.92948217e-08,  1.35769387e-08,\n",
      "       -1.31520013e-08,  1.08900018e-08,  7.03676006e-09,  3.57420982e-09,\n",
      "        1.10096904e-10, -4.04700895e-09, -8.06180900e-09, -6.73743772e-09],\n",
      "      dtype=float32), array([[-0.03867311, -0.07584449,  0.20905994, ...,  0.03874462,\n",
      "        -0.00724752, -0.02254507],\n",
      "       [-0.06250599,  0.17664006,  0.05900216, ...,  0.00101628,\n",
      "         0.01729931,  0.00310383],\n",
      "       [-0.0010734 , -0.04122723,  0.00429055, ..., -0.03098081,\n",
      "         0.02929722, -0.02299557],\n",
      "       ...,\n",
      "       [ 0.01403867,  0.02223425, -0.03582323, ...,  0.10114871,\n",
      "        -0.06847107,  0.13378777],\n",
      "       [-0.16163726, -0.08586734,  0.08488768, ...,  0.00537774,\n",
      "         0.01779295,  0.01208479],\n",
      "       [-0.03676704, -0.03911492,  0.05746501, ...,  0.06536712,\n",
      "        -0.0947911 ,  0.03613782]], dtype=float32))\n",
      "(array([ 4.32092712e+02,  3.10364389e+00,  5.98058343e-01,  5.72797768e-02,\n",
      "        5.63715249e-02,  3.46531421e-02,  2.86606718e-02,  1.93847045e-02,\n",
      "        1.42117813e-02,  9.70606692e-03,  7.57460389e-03,  5.73804835e-03,\n",
      "        3.84264113e-03,  3.08266538e-03,  2.04011472e-03,  1.77005294e-03,\n",
      "        1.25912670e-03,  9.46844462e-04,  8.14623025e-04,  7.01308134e-04,\n",
      "        5.36645122e-04,  4.50119231e-04,  3.87577253e-04,  3.37994017e-04,\n",
      "        2.53696635e-04,  2.38119377e-04,  1.78885268e-04,  1.67445120e-04,\n",
      "        1.54444904e-04,  9.85036313e-05,  8.88382419e-05,  8.13517981e-05,\n",
      "        6.96525822e-05,  5.31002770e-05,  4.77033536e-05,  3.80797792e-05,\n",
      "        3.62651335e-05,  2.98132563e-05,  2.47949538e-05,  2.44085804e-05,\n",
      "        2.11730203e-05,  1.81905380e-05, -9.04016815e-06,  1.21777366e-05,\n",
      "        1.09072889e-05,  1.01031037e-05,  9.21202172e-06, -6.73732984e-06,\n",
      "        7.02878151e-06,  6.61180138e-06, -5.27093107e-06, -5.01148179e-06,\n",
      "        5.68017595e-06,  5.06670995e-06, -4.45690375e-06, -3.45907756e-06,\n",
      "        3.99845658e-06,  3.34904576e-06,  2.94574875e-06,  2.56768794e-06,\n",
      "       -2.25815552e-06,  2.42228498e-06,  2.23836946e-06, -1.72539058e-06,\n",
      "        1.83486259e-06, -1.58458522e-06,  1.46060779e-06,  1.32358559e-06,\n",
      "       -1.34869254e-06, -1.29618638e-06, -1.06154732e-06, -9.34260129e-07,\n",
      "        1.09674295e-06,  1.01155797e-06,  8.69211362e-07,  8.09556923e-07,\n",
      "       -6.83978897e-07,  6.76915874e-07,  5.88216267e-07, -6.09496396e-07,\n",
      "        4.65165073e-07, -5.04261209e-07, -4.63386215e-07,  4.44392072e-07,\n",
      "       -3.50550238e-07, -3.38747270e-07,  2.87829323e-07, -2.59275538e-07,\n",
      "        2.47536462e-07, -2.31588672e-07,  2.02265554e-07, -1.70052630e-07,\n",
      "       -1.43979790e-07, -1.48305659e-07,  1.46371931e-07,  1.28992369e-07,\n",
      "        1.18570696e-07,  9.80690587e-08, -8.86725573e-08, -7.77012943e-08,\n",
      "        7.13547479e-08,  6.18308391e-08,  6.07800246e-08, -6.07586585e-08,\n",
      "       -4.37159002e-08, -4.00583566e-08,  3.53011025e-08, -3.02250065e-08,\n",
      "        2.69658678e-08,  1.97641423e-08, -1.91355909e-08,  1.33197187e-08,\n",
      "       -1.30141213e-08, -8.49303206e-09,  6.67697320e-09, -5.00767250e-09,\n",
      "       -1.71546655e-09,  5.05680742e-09,  3.18260773e-09,  3.50760282e-10],\n",
      "      dtype=float32), array([[ 0.04116178,  0.0359093 , -0.10554703, ..., -0.01339578,\n",
      "        -0.06227541,  0.0021387 ],\n",
      "       [ 0.05670768, -0.0130259 ,  0.20293948, ..., -0.02394856,\n",
      "         0.03899092,  0.0024211 ],\n",
      "       [ 0.00308679, -0.01502664, -0.06327292, ..., -0.26214945,\n",
      "         0.09874414, -0.22214574],\n",
      "       ...,\n",
      "       [-0.02061971,  0.05960866, -0.02032471, ...,  0.0026828 ,\n",
      "         0.07729074, -0.04051451],\n",
      "       [ 0.1597283 ,  0.06010763, -0.10411053, ..., -0.00630923,\n",
      "         0.00863162, -0.00940723],\n",
      "       [ 0.04009834, -0.01685217, -0.06290177, ...,  0.10926875,\n",
      "        -0.10012438, -0.04690723]], dtype=float32))\n",
      "(array([ 4.0275589e+02,  5.1092825e+00,  8.8008893e-01,  1.6659322e-01,\n",
      "        1.4061704e-01,  7.1989112e-02,  3.6270641e-02,  3.0681083e-02,\n",
      "        2.4787361e-02,  2.0503491e-02,  1.2550545e-02,  8.8247117e-03,\n",
      "        7.0936917e-03,  5.8778520e-03,  4.0081888e-03,  2.9996755e-03,\n",
      "        2.4245544e-03,  1.9906254e-03,  1.6894755e-03,  1.4581232e-03,\n",
      "        1.3535444e-03,  9.6257706e-04,  7.6102238e-04,  6.0658687e-04,\n",
      "        5.3245929e-04,  4.4656469e-04,  3.6919166e-04,  3.5625859e-04,\n",
      "        3.3142482e-04,  2.5160334e-04,  2.0976709e-04,  1.9994612e-04,\n",
      "        1.4835043e-04,  1.2317744e-04,  1.3461310e-04,  1.0787459e-04,\n",
      "        1.0365966e-04,  7.1270246e-05,  6.8990114e-05,  5.4745698e-05,\n",
      "        5.1461866e-05,  3.9011382e-05,  3.4013683e-05,  2.9299261e-05,\n",
      "        2.4741394e-05,  2.0702761e-05,  1.7268960e-05,  1.4641029e-05,\n",
      "       -1.0369497e-05,  1.2128613e-05, -8.6526998e-06,  8.0529844e-06,\n",
      "       -6.5631461e-06,  6.5368267e-06,  5.5621394e-06,  4.8788875e-06,\n",
      "       -4.0915279e-06,  3.2578978e-06, -2.9285618e-06,  2.5615495e-06,\n",
      "        2.3514563e-06, -2.7477522e-06, -2.4544468e-06, -1.8983864e-06,\n",
      "       -1.6822065e-06,  1.5931241e-06,  1.4812842e-06, -1.4395340e-06,\n",
      "        1.3039923e-06, -1.2075943e-06,  1.0268348e-06, -1.0815538e-06,\n",
      "       -9.1230669e-07, -8.5821642e-07,  8.5297143e-07,  8.0559028e-07,\n",
      "        6.6918267e-07, -6.4502404e-07, -5.6369703e-07,  5.5756232e-07,\n",
      "       -4.9729539e-07,  4.6634418e-07,  4.0206709e-07, -3.9026759e-07,\n",
      "       -3.6161546e-07, -2.6674681e-07,  2.9598445e-07,  2.9053359e-07,\n",
      "        2.3704682e-07, -2.4334724e-07, -2.3098340e-07,  2.0056903e-07,\n",
      "       -2.0067165e-07, -1.7080720e-07, -1.4558503e-07,  1.5310584e-07,\n",
      "        1.3745611e-07,  1.2482711e-07,  1.0499107e-07,  7.8453184e-08,\n",
      "       -7.6333194e-08, -5.9844815e-08, -5.3392057e-08,  5.4873954e-08,\n",
      "       -3.8174232e-08, -3.0846405e-08,  4.5184958e-08,  4.0423117e-08,\n",
      "        3.4576278e-08,  2.2119258e-08, -2.2894840e-08, -1.7748425e-08,\n",
      "        1.5750510e-08,  9.0735153e-09, -1.1000619e-08, -8.9815000e-09,\n",
      "       -4.0331498e-09,  3.2228369e-09, -4.6342585e-10,  1.1913538e-09],\n",
      "      dtype=float32), array([[-0.04531721,  0.08895316,  0.04589729, ...,  0.03525414,\n",
      "         0.01298612, -0.00516815],\n",
      "       [-0.05060881, -0.01938349, -0.2086971 , ..., -0.02218282,\n",
      "         0.0240286 , -0.00394616],\n",
      "       [-0.00047398, -0.04320092,  0.05707456, ...,  0.04052659,\n",
      "         0.13413252,  0.07540479],\n",
      "       ...,\n",
      "       [ 0.01142891,  0.11934754, -0.00433126, ...,  0.03918373,\n",
      "        -0.03588036, -0.0069762 ],\n",
      "       [-0.16702048,  0.00372626,  0.11376211, ...,  0.0157064 ,\n",
      "         0.00316905, -0.00177005],\n",
      "       [-0.03917288, -0.05989618,  0.0829375 , ...,  0.00997512,\n",
      "        -0.02757257, -0.04546079]], dtype=float32))\n",
      "(array([ 4.51330200e+02,  2.81044340e+00,  5.93026102e-01,  4.58939880e-01,\n",
      "        1.52666330e-01,  7.68278986e-02,  6.56194240e-02,  5.32563068e-02,\n",
      "        2.83781309e-02,  1.76497865e-02,  1.22177675e-02,  9.57125798e-03,\n",
      "        6.94022374e-03,  5.62231336e-03,  5.25044603e-03,  3.63022648e-03,\n",
      "        2.76144641e-03,  2.24124710e-03,  1.70058105e-03,  1.59599772e-03,\n",
      "        1.23650220e-03,  9.55079391e-04,  9.18339880e-04,  6.58984354e-04,\n",
      "        5.82792331e-04,  5.15987689e-04,  4.50555788e-04,  3.51762370e-04,\n",
      "        3.34842742e-04,  2.68829725e-04,  2.40034176e-04,  2.04149634e-04,\n",
      "        1.69857696e-04,  1.37333409e-04,  1.26591898e-04,  1.04908941e-04,\n",
      "        1.00471771e-04,  8.17640830e-05,  6.65522894e-05,  6.18099803e-05,\n",
      "        5.16663240e-05,  4.83645854e-05,  4.40561271e-05,  3.21719308e-05,\n",
      "        2.62100966e-05,  2.11153438e-05,  1.74714078e-05,  1.33106050e-05,\n",
      "       -9.83965492e-06,  1.10090341e-05,  9.01889416e-06,  8.09471658e-06,\n",
      "        6.95078234e-06, -6.73195109e-06, -6.31279681e-06, -4.55251165e-06,\n",
      "        4.37154858e-06,  3.60484000e-06,  3.42816907e-06, -3.33148159e-06,\n",
      "        2.77020285e-06, -2.51206848e-06, -2.29665943e-06, -2.10243206e-06,\n",
      "        2.29086481e-06, -1.76365268e-06,  1.87367380e-06,  1.75058165e-06,\n",
      "        1.40182101e-06, -1.39108715e-06, -1.23770974e-06, -1.11374550e-06,\n",
      "        1.05941535e-06,  1.04162723e-06, -1.04535934e-06, -8.58534349e-07,\n",
      "       -7.93235472e-07, -6.80337507e-07,  7.77939533e-07,  7.15353110e-07,\n",
      "       -4.24828301e-07,  4.89920808e-07,  5.05262562e-07,  3.93160207e-07,\n",
      "       -3.30264982e-07, -3.10873531e-07, -2.64674355e-07,  3.19375943e-07,\n",
      "        2.97872788e-07, -1.61413880e-07,  2.46826318e-07,  2.10245261e-07,\n",
      "        1.88462735e-07, -1.47895619e-07, -1.28354785e-07,  1.32967131e-07,\n",
      "        1.19328746e-07, -1.11349344e-07,  1.05077504e-07,  8.34842595e-08,\n",
      "       -9.16940195e-08, -8.49914912e-08,  6.33986659e-08,  5.69696503e-08,\n",
      "       -5.33995959e-08, -4.20208366e-08, -3.74513576e-08,  3.38782975e-08,\n",
      "       -2.61211550e-08,  2.28739712e-08,  2.30521877e-08,  1.75063004e-08,\n",
      "        9.85013582e-09, -1.56139883e-08,  3.86790999e-09, -1.24394237e-08,\n",
      "        8.04190159e-10, -2.31329378e-09, -7.37296713e-09, -5.61792790e-09],\n",
      "      dtype=float32), array([[ 0.04478575,  0.12897189,  0.2219373 , ...,  0.00457576,\n",
      "         0.0183241 , -0.00822063],\n",
      "       [ 0.0535582 ,  0.01395624,  0.09045448, ..., -0.03929589,\n",
      "         0.00541818,  0.02275836],\n",
      "       [ 0.00157631, -0.03493341,  0.01528468, ..., -0.01209699,\n",
      "         0.00464737,  0.06378138],\n",
      "       ...,\n",
      "       [-0.01674286,  0.08869682, -0.10534677, ..., -0.01974273,\n",
      "         0.12941888,  0.03384966],\n",
      "       [ 0.16839062,  0.01608036,  0.07165351, ...,  0.00690136,\n",
      "        -0.00886865, -0.01011833],\n",
      "       [ 0.03998735, -0.05837489,  0.05275565, ...,  0.03396266,\n",
      "         0.04692115,  0.00511396]], dtype=float32))\n",
      "(array([ 4.5081708e+02,  3.7283001e+00,  1.1363646e+00,  4.6089548e-01,\n",
      "        1.4013244e-01,  9.5901258e-02,  5.8740072e-02,  3.6008622e-02,\n",
      "        3.3023547e-02,  2.1031588e-02,  1.4097676e-02,  1.2751920e-02,\n",
      "        8.2218330e-03,  6.5525789e-03,  4.9711582e-03,  4.0649450e-03,\n",
      "        3.4805932e-03,  2.8912185e-03,  2.4722922e-03,  1.8688433e-03,\n",
      "        1.7206082e-03,  1.3387107e-03,  1.1016929e-03,  8.3707320e-04,\n",
      "        7.8160432e-04,  7.3510350e-04,  4.5562620e-04,  4.1495796e-04,\n",
      "        3.3032958e-04,  2.4200183e-04,  1.9377869e-04,  1.6412479e-04,\n",
      "        1.5105524e-04,  1.4088658e-04,  1.0959816e-04,  8.8484674e-05,\n",
      "        7.4364609e-05,  6.4113265e-05,  5.4604945e-05,  5.2175881e-05,\n",
      "        4.6332792e-05,  4.1146737e-05,  3.6532565e-05,  2.9334848e-05,\n",
      "        2.6312659e-05,  1.9757910e-05,  1.7733824e-05,  1.0907024e-05,\n",
      "        1.0388972e-05,  8.8342358e-06, -7.5188746e-06,  7.5003650e-06,\n",
      "        6.9444591e-06, -5.9131294e-06,  5.1860984e-06, -4.6433279e-06,\n",
      "       -4.0651898e-06, -3.4143347e-06,  3.5308910e-06,  3.2549351e-06,\n",
      "        2.9236903e-06, -2.7296571e-06, -2.2262686e-06,  2.0501182e-06,\n",
      "        1.8711921e-06, -1.6892856e-06, -1.4597348e-06, -1.2678306e-06,\n",
      "        1.4029648e-06,  1.3188101e-06, -1.0409368e-06,  1.0231023e-06,\n",
      "        9.5779023e-07, -8.8207412e-07, -7.9659031e-07,  8.5850400e-07,\n",
      "        8.4093904e-07, -6.5150283e-07, -6.1165701e-07,  5.9073943e-07,\n",
      "        5.7208734e-07, -4.8518717e-07,  4.7019799e-07,  4.2547313e-07,\n",
      "       -4.2256727e-07, -3.3902393e-07, -3.2498261e-07,  3.5091722e-07,\n",
      "        3.0095464e-07, -2.6785730e-07,  2.3978882e-07, -2.1172157e-07,\n",
      "        2.0689885e-07,  1.6980627e-07, -1.9469788e-07, -1.6469195e-07,\n",
      "       -1.3570033e-07,  1.1835813e-07,  1.2485339e-07,  1.0573550e-07,\n",
      "       -9.9846524e-08,  7.3239946e-08,  5.4961372e-08, -8.2919058e-08,\n",
      "       -6.9779084e-08,  3.5486476e-08,  2.9568023e-08, -4.5175025e-08,\n",
      "       -3.9461806e-08, -1.7393001e-08, -1.9253090e-08, -1.4594245e-08,\n",
      "        1.1729025e-08, -7.6175617e-09, -4.5104098e-09,  9.2132311e-09,\n",
      "        7.9949709e-09,  2.7298637e-09,  2.0429844e-09, -8.2008694e-10],\n",
      "      dtype=float32), array([[ 0.05050067, -0.10368126, -0.0165924 , ...,  0.02560012,\n",
      "        -0.03345364,  0.0061071 ],\n",
      "       [ 0.05200264, -0.02112812, -0.21686637, ...,  0.04873626,\n",
      "        -0.02314598,  0.02282217],\n",
      "       [ 0.00269352,  0.03641075,  0.03317682, ..., -0.00144956,\n",
      "        -0.06766257,  0.04227497],\n",
      "       ...,\n",
      "       [-0.01755486, -0.10052955,  0.04377623, ..., -0.05212833,\n",
      "        -0.00478256, -0.04974741],\n",
      "       [ 0.16936181,  0.02233635,  0.10191689, ..., -0.00108088,\n",
      "        -0.00280385,  0.01056792],\n",
      "       [ 0.04178001,  0.07349925,  0.0635636 , ...,  0.03813287,\n",
      "         0.00585283, -0.04786243]], dtype=float32))\n",
      "(array([ 4.91565735e+02,  1.42453849e+00,  6.44977987e-01,  2.70995170e-01,\n",
      "        1.38426036e-01,  7.41261318e-02,  6.13582768e-02,  3.47419344e-02,\n",
      "        3.23647112e-02,  1.78361703e-02,  1.22811655e-02,  9.03054513e-03,\n",
      "        6.33874536e-03,  4.70764469e-03,  3.96851683e-03,  3.55196162e-03,\n",
      "        2.84190406e-03,  2.16666725e-03,  1.75974087e-03,  1.46316085e-03,\n",
      "        1.29073928e-03,  1.01612031e-03,  8.05018644e-04,  5.76946186e-04,\n",
      "        4.31075663e-04,  3.83032719e-04,  3.59650177e-04,  2.99312262e-04,\n",
      "        2.65804527e-04,  2.33105951e-04,  2.19877169e-04,  1.73608656e-04,\n",
      "        1.64672223e-04,  1.46773760e-04,  1.29682914e-04,  1.07930595e-04,\n",
      "        9.64268693e-05,  8.25242314e-05,  7.51214320e-05,  5.77164537e-05,\n",
      "        5.13066152e-05,  5.16822292e-05,  3.35149525e-05,  2.97980278e-05,\n",
      "        2.85911301e-05,  2.12102477e-05,  1.39180829e-05,  1.29067430e-05,\n",
      "        1.21224284e-05, -8.98359031e-06, -8.14532632e-06,  9.55051019e-06,\n",
      "       -6.47964862e-06,  7.74586351e-06,  6.63129049e-06,  6.02330829e-06,\n",
      "       -4.70132045e-06,  4.77848425e-06,  4.30316595e-06, -3.67344092e-06,\n",
      "        3.50199707e-06, -3.13469991e-06,  2.40617055e-06,  2.13735734e-06,\n",
      "       -2.17384309e-06, -1.97802410e-06, -1.92671860e-06, -1.55126281e-06,\n",
      "        1.71099578e-06,  1.37061181e-06,  1.22083691e-06, -1.07914025e-06,\n",
      "       -1.03476498e-06,  1.06102163e-06,  9.56515350e-07, -8.48184015e-07,\n",
      "        7.43844794e-07,  7.02686066e-07,  5.38972813e-07, -6.06598462e-07,\n",
      "       -5.85390808e-07, -5.36588118e-07, -4.47098785e-07,  4.13624349e-07,\n",
      "        3.80428872e-07,  3.51873354e-07, -3.59855420e-07, -3.11945996e-07,\n",
      "        2.69299420e-07,  2.50995015e-07, -2.71771455e-07, -2.56881634e-07,\n",
      "       -2.15779707e-07,  2.05967993e-07, -1.55511330e-07, -1.27023867e-07,\n",
      "        1.43190064e-07,  1.14114108e-07,  8.14504162e-08, -8.68882353e-08,\n",
      "       -7.66744606e-08,  7.59792016e-08,  6.44093845e-08,  5.69189709e-08,\n",
      "       -4.80295341e-08, -3.70579372e-08,  4.01813161e-08, -3.08370360e-08,\n",
      "        3.39021398e-08,  2.69651128e-08,  1.89678602e-08,  1.53872346e-08,\n",
      "       -1.69395697e-08, -1.19385382e-08,  8.63400640e-09,  5.65095881e-09,\n",
      "       -8.58208260e-09, -4.88662222e-09, -1.34750677e-09, -5.66046321e-10],\n",
      "      dtype=float32), array([[ 4.6245724e-02,  3.0941546e-01,  9.0041809e-02, ...,\n",
      "        -3.8733937e-02,  1.3569625e-02,  1.8342821e-03],\n",
      "       [ 5.3940624e-02,  5.5265840e-02, -2.1045379e-01, ...,\n",
      "         1.7793929e-03, -4.3849602e-02, -1.9631272e-02],\n",
      "       [-2.3284099e-05,  4.2291251e-03,  2.1978376e-02, ...,\n",
      "         1.9357689e-01,  1.3870569e-02,  8.2058951e-02],\n",
      "       ...,\n",
      "       [-1.2720050e-02, -5.1834751e-02,  1.8600313e-02, ...,\n",
      "         9.1747353e-03, -8.3468288e-02,  1.7326631e-03],\n",
      "       [ 1.6099620e-01, -9.4693648e-03,  1.4045820e-01, ...,\n",
      "         9.5415171e-03,  7.9909954e-03,  3.9786678e-03],\n",
      "       [ 3.4071356e-02, -5.5425768e-03,  6.1653718e-02, ...,\n",
      "         5.2078113e-02, -4.0508762e-02,  3.4455772e-02]], dtype=float32))\n",
      "(array([ 3.00941589e+02,  1.58575668e+01,  5.84457445e+00,  1.98250628e+00,\n",
      "        2.87429631e-01,  1.72526270e-01,  1.33340076e-01,  7.24928677e-02,\n",
      "        5.45403324e-02,  2.68234462e-02,  2.04264764e-02,  1.55842435e-02,\n",
      "        1.08626196e-02,  1.03381714e-02,  9.02968366e-03,  7.34645827e-03,\n",
      "        6.49292581e-03,  4.31685895e-03,  3.20597435e-03,  2.84558395e-03,\n",
      "        2.42520473e-03,  2.03754613e-03,  1.54792320e-03,  1.16489618e-03,\n",
      "        8.87869857e-04,  7.89997634e-04,  5.72195160e-04,  5.49930206e-04,\n",
      "        4.82635980e-04,  4.35985974e-04,  3.10513540e-04,  2.61724053e-04,\n",
      "        2.30560996e-04,  1.93412634e-04,  1.28770349e-04,  1.21444267e-04,\n",
      "        8.88347276e-05,  8.33624872e-05,  6.75162009e-05,  5.90977688e-05,\n",
      "        3.67706380e-05,  2.89748587e-05,  2.68105287e-05,  1.56504466e-05,\n",
      "        1.40978373e-05,  1.31239758e-05,  1.27438370e-05,  7.90536978e-06,\n",
      "       -7.02666921e-06,  6.79468303e-06,  6.20434912e-06, -5.88461626e-06,\n",
      "        4.50597690e-06, -4.59155581e-06, -3.92385709e-06, -3.31915840e-06,\n",
      "       -2.72384705e-06,  3.15452485e-06,  2.77853701e-06,  2.40084864e-06,\n",
      "        2.19923368e-06, -1.91847084e-06, -1.55970679e-06,  1.93570440e-06,\n",
      "        1.82636120e-06,  1.71939075e-06, -1.44217211e-06,  1.41187593e-06,\n",
      "        1.28331510e-06, -1.19560264e-06, -1.02390970e-06, -9.14484247e-07,\n",
      "        8.81907454e-07,  8.72429894e-07,  7.03401327e-07, -8.16455668e-07,\n",
      "       -7.46646833e-07, -6.91939931e-07, -5.70973612e-07,  5.47140644e-07,\n",
      "        5.24171469e-07,  4.63967496e-07, -4.44175953e-07, -4.02139335e-07,\n",
      "        3.72463859e-07,  3.36488597e-07, -3.68277881e-07, -3.04139746e-07,\n",
      "        2.50720433e-07,  2.15688942e-07, -2.34056031e-07, -2.44309092e-07,\n",
      "       -1.97365708e-07, -1.64159829e-07, -1.41189204e-07,  1.74704340e-07,\n",
      "        1.68205972e-07,  1.49113220e-07,  1.16897475e-07,  8.99358383e-08,\n",
      "       -9.25730816e-08, -8.41078815e-08,  7.77783384e-08,  5.98112848e-08,\n",
      "        4.89520176e-08, -5.25958868e-08, -4.84576326e-08, -4.33114096e-08,\n",
      "        3.56021026e-08,  3.15379474e-08, -3.02696002e-08,  2.45356038e-08,\n",
      "        1.28930928e-08,  1.15710268e-08, -1.79653483e-08, -1.44848888e-08,\n",
      "       -9.13201514e-09,  5.61153346e-09, -1.81418247e-09, -1.52787158e-11],\n",
      "      dtype=float32), array([[-0.0435449 , -0.080407  , -0.13148333, ..., -0.04686802,\n",
      "         0.05169404,  0.03184349],\n",
      "       [-0.05204045, -0.02085624,  0.01312194, ...,  0.02744655,\n",
      "         0.02390435,  0.05017886],\n",
      "       [-0.01208176,  0.03142669, -0.03056026, ...,  0.20450613,\n",
      "        -0.09710085, -0.01277664],\n",
      "       ...,\n",
      "       [ 0.03825649, -0.04201927,  0.00522423, ...,  0.00760237,\n",
      "         0.08017473,  0.03078703],\n",
      "       [-0.17637528, -0.03611116, -0.1192863 , ..., -0.00186147,\n",
      "        -0.00049811, -0.00389069],\n",
      "       [-0.06289081,  0.04020426, -0.08117408, ...,  0.03752514,\n",
      "         0.00535956, -0.00657379]], dtype=float32))\n",
      "(array([ 2.35214844e+02,  1.35214663e+01,  1.48834181e+00,  2.29966819e-01,\n",
      "        1.50388807e-01,  1.29672810e-01,  3.13311815e-02,  2.18910910e-02,\n",
      "        1.54363094e-02,  1.47622833e-02,  1.36124864e-02,  8.80182721e-03,\n",
      "        5.44801634e-03,  4.69207717e-03,  3.88293201e-03,  3.04349279e-03,\n",
      "        2.39747553e-03,  1.96113833e-03,  1.78119296e-03,  1.45961263e-03,\n",
      "        1.09151681e-03,  1.00180961e-03,  7.60337221e-04,  6.17000507e-04,\n",
      "        4.62702446e-04,  3.93172813e-04,  3.80738056e-04,  2.64750532e-04,\n",
      "        2.42483729e-04,  1.82585063e-04,  1.51920962e-04,  1.17804884e-04,\n",
      "        1.05959836e-04,  8.06536627e-05,  7.06740393e-05,  6.43953390e-05,\n",
      "        5.18780107e-05,  4.44282668e-05,  3.53198920e-05,  3.24689172e-05,\n",
      "        2.94405909e-05,  2.66200823e-05,  1.57708255e-05,  1.50545493e-05,\n",
      "        1.13577144e-05,  9.14689372e-06,  8.75054775e-06, -5.17212447e-06,\n",
      "        5.51664561e-06,  4.73114869e-06,  3.83814904e-06, -3.31642013e-06,\n",
      "       -2.83820827e-06,  3.11840290e-06, -2.60349270e-06,  2.45926299e-06,\n",
      "       -2.20494962e-06, -2.02158230e-06,  2.20392235e-06,  2.12334771e-06,\n",
      "        1.90382707e-06,  1.72156524e-06, -1.52731639e-06, -1.48113668e-06,\n",
      "       -1.42225633e-06,  1.55755333e-06,  1.31627030e-06,  1.17784816e-06,\n",
      "        1.12536588e-06, -1.13865178e-06, -1.07062408e-06,  1.00396926e-06,\n",
      "       -9.84103281e-07, -8.48925026e-07, -7.96631468e-07,  8.60177579e-07,\n",
      "       -6.77623746e-07, -6.16039017e-07,  7.41873691e-07,  6.46865146e-07,\n",
      "        7.75853323e-07, -4.89160755e-07, -4.58832574e-07,  5.23732467e-07,\n",
      "        5.16646992e-07,  4.57152055e-07,  3.57611270e-07,  3.36838440e-07,\n",
      "        2.73931761e-07, -3.41306134e-07, -2.96930693e-07, -2.62527521e-07,\n",
      "       -2.46018971e-07, -2.25738773e-07,  2.17072923e-07,  1.95360784e-07,\n",
      "        1.52508079e-07, -1.52142476e-07, -1.26587096e-07,  1.23027235e-07,\n",
      "       -1.02776021e-07, -9.63690141e-08,  1.05576589e-07,  9.94706326e-08,\n",
      "       -6.85635371e-08,  7.08501986e-08,  5.74944181e-08,  4.09575023e-08,\n",
      "       -4.88818301e-08, -4.26916706e-08, -3.08278736e-08, -2.53293084e-08,\n",
      "        2.28348895e-08, -1.46675712e-08,  1.67980421e-08, -6.84019374e-09,\n",
      "       -4.98661690e-09,  6.12391415e-10,  5.40871969e-09,  1.04069571e-08],\n",
      "      dtype=float32), array([[-0.03532707,  0.15198265,  0.12443297, ...,  0.01883974,\n",
      "         0.01173364, -0.01570519],\n",
      "       [-0.04499378,  0.02749123, -0.1279244 , ...,  0.09240154,\n",
      "         0.00275605,  0.03903428],\n",
      "       [-0.02283644, -0.02164719,  0.07006893, ...,  0.09613005,\n",
      "        -0.1625907 ,  0.09356335],\n",
      "       ...,\n",
      "       [ 0.04982236,  0.02265703,  0.0902098 , ..., -0.04423154,\n",
      "         0.04439832, -0.07704363],\n",
      "       [-0.16981211,  0.11440352,  0.11362968, ..., -0.01009181,\n",
      "         0.04528053, -0.00510418],\n",
      "       [-0.07553748, -0.00717024,  0.02888991, ...,  0.00411699,\n",
      "         0.00535733,  0.00160123]], dtype=float32))\n",
      "(array([ 3.13776428e+02,  1.76671925e+01,  1.42139840e+00,  3.79300714e-01,\n",
      "        2.11291164e-01,  1.01991944e-01,  6.47760481e-02,  3.47046107e-02,\n",
      "        2.88356543e-02,  2.29891464e-02,  1.46710202e-02,  1.14055891e-02,\n",
      "        7.58466357e-03,  6.37533888e-03,  4.33405163e-03,  3.80367180e-03,\n",
      "        3.28952144e-03,  2.80217058e-03,  2.15221778e-03,  1.86047063e-03,\n",
      "        1.61732349e-03,  1.45864196e-03,  1.13976758e-03,  8.75997648e-04,\n",
      "        6.69167086e-04,  5.98537503e-04,  4.78416216e-04,  4.39168391e-04,\n",
      "        3.99342272e-04,  3.50810209e-04,  3.05220252e-04,  2.36861975e-04,\n",
      "        1.75819354e-04,  1.47890169e-04,  1.12976923e-04,  1.09881417e-04,\n",
      "        9.67996311e-05,  8.89682342e-05,  6.60423029e-05,  5.93540426e-05,\n",
      "        4.92098479e-05,  4.08107153e-05,  3.29956565e-05,  2.88727388e-05,\n",
      "        2.32864477e-05,  1.94364675e-05,  1.74851830e-05,  1.29663586e-05,\n",
      "        8.41519250e-06, -7.27209954e-06, -6.06579897e-06,  6.17701198e-06,\n",
      "        5.55053794e-06, -4.48559649e-06,  4.47718958e-06, -3.56887176e-06,\n",
      "       -3.27233897e-06,  3.28473448e-06, -2.46488617e-06, -2.04421212e-06,\n",
      "        2.38255461e-06,  2.06396999e-06,  2.02475303e-06, -1.80764198e-06,\n",
      "        1.80917561e-06,  1.71229749e-06, -1.62580488e-06, -1.36453673e-06,\n",
      "       -1.26853058e-06,  1.37024506e-06,  1.27418878e-06,  1.18653236e-06,\n",
      "        1.03977254e-06, -9.71954819e-07, -1.00352020e-06,  9.68060704e-07,\n",
      "       -8.39117604e-07, -7.47389663e-07,  7.45642296e-07,  6.70270708e-07,\n",
      "       -6.47305455e-07, -6.20619630e-07,  5.84233533e-07,  5.47531045e-07,\n",
      "       -4.72470191e-07, -4.35333305e-07,  4.55056977e-07,  4.20275683e-07,\n",
      "       -3.98470348e-07, -3.35640152e-07, -3.08780244e-07,  3.71627834e-07,\n",
      "        3.00391434e-07,  2.72311041e-07, -2.42091687e-07,  2.19641748e-07,\n",
      "       -1.96475895e-07, -1.68378065e-07, -1.62171773e-07,  1.66865718e-07,\n",
      "        1.33706621e-07,  1.28174136e-07, -1.09949546e-07, -8.55812203e-08,\n",
      "        9.85435804e-08,  6.53614549e-08, -7.15765083e-08, -4.78527475e-08,\n",
      "        4.23690558e-08,  3.55557503e-08, -2.45307543e-08, -2.08828208e-08,\n",
      "       -1.68850161e-08,  1.99884003e-08,  1.80580493e-08, -8.26396374e-09,\n",
      "       -3.57582097e-09,  1.23794726e-08,  3.82426135e-09,  6.98999747e-09],\n",
      "      dtype=float32), array([[-0.05187653,  0.13414414, -0.11129317, ..., -0.01466733,\n",
      "         0.00254209, -0.02804978],\n",
      "       [-0.04979246,  0.01572617,  0.13458517, ..., -0.0862522 ,\n",
      "         0.01270063,  0.042281  ],\n",
      "       [-0.01864425, -0.02547807, -0.06213555, ...,  0.10896941,\n",
      "         0.04338551, -0.08386594],\n",
      "       ...,\n",
      "       [ 0.05102108,  0.03225917, -0.09074284, ...,  0.01880411,\n",
      "         0.06601329,  0.01262217],\n",
      "       [-0.18513589,  0.06166326, -0.09564091, ..., -0.02484201,\n",
      "        -0.00577393, -0.01059708],\n",
      "       [-0.07364053, -0.01531525, -0.02486012, ..., -0.04808699,\n",
      "         0.07269995,  0.03981886]], dtype=float32))\n",
      "(array([ 1.6107484e+02,  2.5857403e+00,  1.0790212e+00,  2.2258067e-01,\n",
      "        7.2804220e-02,  5.4770179e-02,  2.6646154e-02,  2.5361026e-02,\n",
      "        1.5081652e-02,  9.5131900e-03,  6.2700971e-03,  4.4388426e-03,\n",
      "        4.1536801e-03,  2.6568489e-03,  2.1463190e-03,  1.6003224e-03,\n",
      "        1.4609173e-03,  1.2794404e-03,  1.2370717e-03,  9.0567180e-04,\n",
      "        7.6485117e-04,  6.1347196e-04,  5.0739956e-04,  4.4051892e-04,\n",
      "        3.3971321e-04,  2.8419466e-04,  2.5668344e-04,  2.0895868e-04,\n",
      "        1.9220423e-04,  1.3200026e-04,  1.1288408e-04,  9.5974247e-05,\n",
      "        9.1285910e-05,  8.0284066e-05,  7.3940457e-05,  6.3830237e-05,\n",
      "        5.7617694e-05,  5.2513886e-05,  4.1783234e-05,  3.3333414e-05,\n",
      "        3.0527252e-05,  2.6283102e-05,  1.9784657e-05,  1.6340173e-05,\n",
      "        1.5619869e-05,  9.4427314e-06,  8.8168363e-06,  6.8805875e-06,\n",
      "        5.4138022e-06,  4.9017553e-06, -3.0289377e-06,  2.5899853e-06,\n",
      "        2.3199516e-06, -1.9521419e-06, -1.7290974e-06, -1.7015159e-06,\n",
      "        1.6044489e-06,  1.3142181e-06, -1.3487295e-06, -1.1778732e-06,\n",
      "        1.1638430e-06,  1.0990840e-06,  9.9553597e-07, -1.0640140e-06,\n",
      "       -9.8427017e-07, -8.2900965e-07, -7.6553857e-07,  8.0534892e-07,\n",
      "        7.6720045e-07,  7.1235240e-07, -6.8776041e-07, -6.3488596e-07,\n",
      "        6.2764394e-07, -6.0578139e-07,  5.3794679e-07, -5.1431584e-07,\n",
      "       -4.4399789e-07, -4.1254216e-07, -3.6959187e-07,  4.4697248e-07,\n",
      "        4.4015755e-07,  3.7267375e-07,  3.9688334e-07,  3.5814463e-07,\n",
      "       -3.0797506e-07,  2.8472434e-07, -2.6632333e-07, -2.5573587e-07,\n",
      "        2.3562815e-07,  2.0420192e-07, -1.8995028e-07,  1.8939768e-07,\n",
      "       -1.7533337e-07, -1.5806830e-07, -1.2396352e-07,  1.3193994e-07,\n",
      "        1.0913078e-07, -1.0946650e-07, -8.8319815e-08,  9.5419630e-08,\n",
      "        9.3527873e-08, -6.8373851e-08,  7.0442525e-08,  6.5588210e-08,\n",
      "        4.5078121e-08,  3.3435878e-08, -4.4380410e-08, -4.0559488e-08,\n",
      "       -3.6473057e-08,  2.5111818e-08, -2.6346957e-08,  1.7703227e-08,\n",
      "        1.2345684e-08,  6.9813035e-09,  2.1772733e-09, -1.5332379e-08,\n",
      "       -1.3137309e-08, -3.0563039e-09, -5.1136944e-09, -7.0708972e-09],\n",
      "      dtype=float32), array([[-0.0112034 ,  0.1736472 , -0.0432898 , ...,  0.02619954,\n",
      "         0.02622817, -0.01592341],\n",
      "       [-0.03655908, -0.02332451,  0.14972743, ..., -0.13572232,\n",
      "        -0.00716937,  0.11375193],\n",
      "       [-0.02767208,  0.03307573, -0.07758383, ...,  0.03227963,\n",
      "         0.11693212, -0.04051623],\n",
      "       ...,\n",
      "       [ 0.06044764,  0.04019945, -0.0687974 , ..., -0.05339608,\n",
      "         0.0806326 ,  0.0501246 ],\n",
      "       [-0.13885218,  0.22357729, -0.07718103, ...,  0.02117774,\n",
      "        -0.00611967, -0.01908673],\n",
      "       [-0.07319851,  0.01553614, -0.03717551, ...,  0.06082863,\n",
      "        -0.00547348,  0.00684523]], dtype=float32))\n",
      "(array([ 7.77536316e+02,  8.84199524e+00,  1.03932071e+00,  5.61915636e-01,\n",
      "        3.45433742e-01,  1.74910635e-01,  1.01876646e-01,  4.62604351e-02,\n",
      "        3.48789804e-02,  2.35401765e-02,  1.79829970e-02,  1.35108782e-02,\n",
      "        1.23319319e-02,  1.03581920e-02,  8.71561002e-03,  5.82287321e-03,\n",
      "        4.65013226e-03,  4.77313390e-03,  3.18186148e-03,  2.45668110e-03,\n",
      "        2.29181279e-03,  2.03587743e-03,  1.35864643e-03,  1.20783050e-03,\n",
      "        1.15276116e-03,  8.93182762e-04,  6.77961798e-04,  6.17731363e-04,\n",
      "        5.99011371e-04,  5.20674686e-04,  4.02818870e-04,  3.42990039e-04,\n",
      "        2.74464866e-04,  2.30490958e-04,  1.78119401e-04,  1.56454233e-04,\n",
      "        1.40805423e-04,  1.06473155e-04,  9.59888202e-05,  8.04339506e-05,\n",
      "        6.67187924e-05,  5.65289592e-05,  4.72867396e-05,  4.78317124e-05,\n",
      "        3.27935340e-05,  3.06427246e-05,  2.16406588e-05, -1.74131947e-05,\n",
      "        1.88788890e-05,  1.76980284e-05,  1.26100504e-05, -1.10044866e-05,\n",
      "       -9.44001476e-06, -7.55489054e-06,  9.09277242e-06,  8.29964029e-06,\n",
      "       -6.61257127e-06,  7.20260823e-06, -5.55274573e-06,  6.15801810e-06,\n",
      "        5.41242662e-06,  5.13138139e-06, -4.03272907e-06, -3.92991797e-06,\n",
      "        4.06026766e-06,  3.84013356e-06, -3.24199573e-06, -2.88371461e-06,\n",
      "        2.81213624e-06, -2.42660212e-06,  2.33870992e-06, -2.10707731e-06,\n",
      "        1.73089302e-06, -1.55648797e-06, -1.39007352e-06,  1.51931181e-06,\n",
      "        1.41176974e-06,  1.39985264e-06, -1.22564131e-06, -1.11539021e-06,\n",
      "       -8.93116749e-07,  1.14997829e-06,  9.39570327e-07,  1.00157945e-06,\n",
      "        8.31655939e-07, -7.54604969e-07, -6.46641297e-07,  5.34544881e-07,\n",
      "       -5.05439516e-07,  4.72506116e-07,  4.51829749e-07, -4.80463939e-07,\n",
      "        3.35088316e-07, -3.90625814e-07, -3.19337687e-07,  2.89658971e-07,\n",
      "       -2.35730880e-07,  2.16857742e-07, -2.05018821e-07, -1.49591969e-07,\n",
      "        1.46874697e-07,  1.31363947e-07, -1.13798215e-07, -1.00007121e-07,\n",
      "        1.05990473e-07,  9.39953111e-08,  4.98914048e-08, -6.01465970e-08,\n",
      "       -6.20478957e-08, -5.53264599e-08,  3.17075255e-08, -3.18638094e-08,\n",
      "        2.34716797e-08, -1.45313486e-08,  1.46485801e-08,  8.00167665e-09,\n",
      "       -5.83064219e-09, -4.71692641e-09, -2.29842326e-10,  3.00368730e-09],\n",
      "      dtype=float32), array([[-0.10450753, -0.14893669, -0.16848956, ...,  0.02370211,\n",
      "         0.02252122,  0.01384747],\n",
      "       [-0.06596447, -0.0411613 , -0.16623814, ...,  0.01541214,\n",
      "        -0.00951276,  0.00116069],\n",
      "       [-0.00654256,  0.03754058,  0.02578727, ..., -0.00812566,\n",
      "        -0.08122721, -0.12547706],\n",
      "       ...,\n",
      "       [ 0.037448  , -0.0113602 ,  0.09803584, ..., -0.01005191,\n",
      "         0.00088478, -0.03421637],\n",
      "       [-0.1839731 ,  0.00991289,  0.10281686, ..., -0.00254418,\n",
      "         0.00437687,  0.0108932 ],\n",
      "       [-0.0666829 ,  0.03497817, -0.01965769, ...,  0.02031652,\n",
      "        -0.0015445 , -0.01724573]], dtype=float32))\n",
      "(array([ 1.01341125e+03,  1.68513656e+00,  6.73331082e-01,  2.18029007e-01,\n",
      "        1.55300021e-01,  3.09247244e-02,  2.79545188e-02,  2.17403676e-02,\n",
      "        1.81766134e-02,  1.63327269e-02,  6.64804736e-03,  5.50479908e-03,\n",
      "        4.63844370e-03,  3.54711921e-03,  3.37656355e-03,  2.15510814e-03,\n",
      "        1.78483699e-03,  1.59946876e-03,  1.37802726e-03,  1.14920340e-03,\n",
      "        7.77778681e-04,  6.90142100e-04,  6.14058517e-04,  5.30884485e-04,\n",
      "        4.00056888e-04,  3.44313303e-04,  3.08118731e-04,  2.79053085e-04,\n",
      "        2.35937419e-04,  2.03979434e-04,  1.66649203e-04,  1.33887093e-04,\n",
      "        1.17186122e-04,  1.04280327e-04,  8.76984996e-05,  6.72027672e-05,\n",
      "        6.39774080e-05,  5.08673184e-05,  4.75912384e-05,  4.28416861e-05,\n",
      "        3.58867546e-05, -2.16256885e-05,  3.06623297e-05,  2.73294991e-05,\n",
      "        2.55359209e-05,  2.35507396e-05,  2.17574998e-05, -1.85321187e-05,\n",
      "       -1.49843563e-05,  1.77818256e-05,  1.62259403e-05,  1.32388095e-05,\n",
      "       -1.14741742e-05,  1.12208181e-05,  1.09527664e-05, -9.84914550e-06,\n",
      "       -9.31844716e-06,  9.37131881e-06,  8.04509000e-06, -8.11697464e-06,\n",
      "        6.90723482e-06, -6.89236322e-06, -6.61222521e-06, -5.57319254e-06,\n",
      "        6.18087188e-06,  5.73555508e-06, -4.10528946e-06,  4.82028781e-06,\n",
      "       -3.64743710e-06, -3.13386272e-06, -2.73480646e-06,  3.89790557e-06,\n",
      "        3.34847368e-06,  3.05763047e-06,  2.74815852e-06, -2.09111249e-06,\n",
      "        2.05798506e-06, -1.55890245e-06,  1.78502569e-06,  1.52119310e-06,\n",
      "       -1.09391431e-06,  1.19873914e-06,  1.11470138e-06, -9.62271315e-07,\n",
      "        9.92762125e-07, -8.56798806e-07, -6.72500562e-07, -5.87497993e-07,\n",
      "        7.64119875e-07,  6.91964317e-07,  5.85294742e-07, -5.25507630e-07,\n",
      "        4.04817740e-07, -4.25673335e-07,  3.15960420e-07,  2.43758080e-07,\n",
      "       -3.64473692e-07, -3.56132716e-07, -2.84841491e-07, -2.02677668e-07,\n",
      "        1.96072293e-07,  1.39979235e-07, -1.46126538e-07,  1.18488742e-07,\n",
      "       -9.56181054e-08,  8.21738908e-08,  6.31881534e-08, -5.66608200e-08,\n",
      "       -4.34799219e-08,  3.62551198e-08, -3.48818538e-08,  2.43781653e-08,\n",
      "       -1.32914764e-08,  1.14041887e-08,  1.20756365e-08,  3.00301584e-09,\n",
      "       -4.10629974e-09, -2.41730214e-09,  6.48525400e-10, -8.58800531e-11],\n",
      "      dtype=float32), array([[-1.2173062e-01, -1.6328435e-01, -4.1512851e-02, ...,\n",
      "         4.7306479e-03, -5.4765143e-03, -1.2921008e-03],\n",
      "       [-7.1271643e-02, -1.2035301e-01, -1.7614837e-01, ...,\n",
      "         1.3737146e-02, -2.9619770e-05,  7.7769733e-03],\n",
      "       [-4.3119565e-03,  3.8806070e-02,  2.4633832e-02, ...,\n",
      "        -1.6141465e-02, -1.5534295e-01, -3.8699482e-02],\n",
      "       ...,\n",
      "       [ 4.0012691e-02,  2.7938306e-02,  7.8701735e-02, ...,\n",
      "        -1.1276773e-02, -1.9910058e-02, -1.1547209e-02],\n",
      "       [-1.7967573e-01,  7.9542339e-02, -1.9860255e-02, ...,\n",
      "        -4.2806943e-03, -4.4643538e-04,  1.5784912e-03],\n",
      "       [-6.6906407e-02,  1.0041568e-02,  6.4010737e-03, ...,\n",
      "        -1.0693425e-02, -3.5953915e-03, -2.1285431e-02]], dtype=float32))\n",
      "(array([ 6.06245728e+02,  2.52569523e+01,  3.65893912e+00,  1.79278183e+00,\n",
      "        3.61424088e-01,  2.77153045e-01,  2.31337741e-01,  8.03244784e-02,\n",
      "        6.54092282e-02,  4.63386364e-02,  3.40832844e-02,  3.07361204e-02,\n",
      "        1.93080399e-02,  1.77352335e-02,  1.39520522e-02,  1.10502057e-02,\n",
      "        8.86100996e-03,  6.90072309e-03,  6.00054720e-03,  5.03246719e-03,\n",
      "        3.61706037e-03,  3.23802605e-03,  2.91163451e-03,  2.51151761e-03,\n",
      "        1.53273193e-03,  1.42709434e-03,  1.18263101e-03,  1.14916114e-03,\n",
      "        9.89899621e-04,  7.23119651e-04,  6.58901641e-04,  5.60492917e-04,\n",
      "        5.13457344e-04,  4.69559163e-04,  4.09981556e-04,  3.27099144e-04,\n",
      "        2.93577439e-04,  2.52186874e-04,  2.30138307e-04,  1.96007706e-04,\n",
      "        1.70870349e-04,  1.31659297e-04,  1.23926584e-04,  1.09044828e-04,\n",
      "        6.49914437e-05,  6.03332082e-05,  4.55423105e-05,  3.71850983e-05,\n",
      "        2.76425653e-05,  2.09192622e-05,  1.18414055e-05, -1.06023872e-05,\n",
      "       -7.54133316e-06,  7.43681221e-06, -6.39340533e-06,  6.40155895e-06,\n",
      "        5.37969163e-06, -5.06955030e-06, -4.45352634e-06, -4.01070611e-06,\n",
      "        4.01217767e-06,  3.79547214e-06, -3.41545342e-06,  3.02818171e-06,\n",
      "       -3.01733894e-06, -2.53340977e-06,  2.58231489e-06,  2.35220568e-06,\n",
      "        1.96395558e-06, -1.88392551e-06, -1.66930556e-06, -1.61129935e-06,\n",
      "        1.68499923e-06, -1.44065052e-06, -1.19109040e-06,  1.55955297e-06,\n",
      "        1.41121632e-06,  1.29459204e-06, -1.05342201e-06, -9.07180834e-07,\n",
      "       -7.07336085e-07, -6.11720964e-07,  8.73259296e-07,  7.72562203e-07,\n",
      "        9.01209262e-07,  6.19450532e-07,  5.76173989e-07,  4.92699485e-07,\n",
      "       -4.67637051e-07,  4.32074984e-07,  3.39863476e-07, -4.08217176e-07,\n",
      "       -3.80699532e-07, -3.58669354e-07, -2.39403619e-07, -2.19683443e-07,\n",
      "        2.48961499e-07,  2.05175539e-07,  1.85002207e-07, -1.80541392e-07,\n",
      "       -1.18437477e-07,  1.26950539e-07,  1.04855708e-07, -1.01410173e-07,\n",
      "        8.52214299e-08, -7.48222746e-08, -4.71025423e-08,  5.91343827e-08,\n",
      "        5.37631344e-08, -3.48609426e-08,  3.18299165e-08,  2.81324510e-08,\n",
      "       -2.48342005e-08, -1.97851335e-08, -1.30458151e-08, -2.32026331e-09,\n",
      "       -5.06480236e-09,  4.41664927e-09,  9.99742600e-09,  9.25222832e-09],\n",
      "      dtype=float32), array([[ 0.08431902,  0.0364716 , -0.17543177, ..., -0.00530518,\n",
      "        -0.00197997,  0.00204379],\n",
      "       [ 0.06192354,  0.00517146, -0.10650358, ..., -0.00771648,\n",
      "        -0.04575642, -0.0339269 ],\n",
      "       [ 0.00843834, -0.03329862,  0.02070804, ..., -0.04712252,\n",
      "         0.03220167, -0.02348308],\n",
      "       ...,\n",
      "       [-0.03489909,  0.03292191,  0.05740769, ...,  0.03936584,\n",
      "        -0.04704188,  0.01204512],\n",
      "       [ 0.18877196, -0.03798966,  0.02161693, ..., -0.01069656,\n",
      "        -0.00341258, -0.01397644],\n",
      "       [ 0.06243056, -0.04086038, -0.03469879, ..., -0.02023785,\n",
      "         0.08605552,  0.06528715]], dtype=float32))\n",
      "(array([ 6.82463562e+02,  1.73157287e+00,  7.15250671e-01,  3.86820942e-01,\n",
      "        2.46480018e-01,  1.64128706e-01,  1.10507116e-01,  6.77860305e-02,\n",
      "        4.93045822e-02,  3.48177515e-02,  1.74875446e-02,  1.22848004e-02,\n",
      "        1.01563055e-02,  8.44860263e-03,  6.29821047e-03,  6.02330873e-03,\n",
      "        4.55564819e-03,  3.34659498e-03,  2.86154496e-03,  2.09755311e-03,\n",
      "        1.58623292e-03,  1.33278023e-03,  1.18725817e-03,  1.04450807e-03,\n",
      "        9.06974485e-04,  8.12872080e-04,  6.37754099e-04,  5.92736003e-04,\n",
      "        4.91623592e-04,  4.08845866e-04,  2.96436396e-04,  2.74764607e-04,\n",
      "        2.23451425e-04,  1.86795209e-04,  1.57617222e-04,  1.39163152e-04,\n",
      "        1.08584798e-04,  8.98708968e-05,  8.70251388e-05,  6.62099701e-05,\n",
      "        5.80679152e-05,  5.12344777e-05,  4.82455107e-05,  3.88572844e-05,\n",
      "        3.00741485e-05,  2.13089588e-05,  1.65121855e-05, -1.45163531e-05,\n",
      "        1.39291524e-05, -1.32629548e-05, -1.13533370e-05,  1.15170405e-05,\n",
      "        1.04735891e-05,  9.66766856e-06, -8.41716883e-06,  7.31335786e-06,\n",
      "       -6.33122636e-06, -5.42269208e-06,  5.53931477e-06,  5.03092315e-06,\n",
      "       -3.97251506e-06,  4.49981235e-06,  4.03013473e-06, -3.55518227e-06,\n",
      "       -3.27844077e-06,  3.03806451e-06,  2.89910486e-06,  2.53026678e-06,\n",
      "       -2.35893322e-06, -2.12804798e-06,  1.94418749e-06,  1.65052143e-06,\n",
      "       -1.77465222e-06,  1.32507751e-06, -1.52655298e-06, -1.29312991e-06,\n",
      "       -1.21129176e-06,  1.07141852e-06,  8.51145217e-07, -7.87853992e-07,\n",
      "        7.28020837e-07, -6.38873303e-07,  6.03614922e-07, -5.49726337e-07,\n",
      "        5.33315131e-07, -4.89365391e-07,  4.36193858e-07, -4.56385209e-07,\n",
      "        3.97801898e-07, -3.29232222e-07, -2.66492066e-07,  2.82606578e-07,\n",
      "        3.38511114e-07,  2.39917625e-07, -1.85509208e-07,  1.92872847e-07,\n",
      "       -1.40559081e-07,  1.40509584e-07,  1.08306018e-07,  1.00777164e-07,\n",
      "       -8.67294787e-08, -7.88641401e-08,  6.42408082e-08, -5.90941625e-08,\n",
      "       -4.41813732e-08,  5.19828198e-08,  4.95517476e-08,  3.90866539e-08,\n",
      "        3.06010293e-08, -2.79365953e-08, -2.35453985e-08,  2.32872193e-08,\n",
      "       -1.58359548e-08, -1.15520455e-08, -4.12901091e-09, -2.51031262e-09,\n",
      "       -8.47458215e-10,  8.00598610e-09,  4.91204499e-09,  2.14409912e-09],\n",
      "      dtype=float32), array([[ 6.5741301e-02, -2.4434254e-01, -3.6039770e-02, ...,\n",
      "        -1.9953448e-02, -3.6283657e-02, -2.1273273e-03],\n",
      "       [ 5.8634251e-02, -4.8354488e-02,  1.6789006e-01, ...,\n",
      "         1.2681098e-02,  8.5534099e-03,  2.3830242e-03],\n",
      "       [ 1.8862485e-03, -6.5365680e-03, -6.6894390e-02, ...,\n",
      "        -7.2576299e-02,  5.7333592e-02,  1.5507458e-01],\n",
      "       ...,\n",
      "       [-1.3302601e-02,  7.4364848e-02,  1.2955796e-02, ...,\n",
      "        -8.8270999e-02, -1.6968761e-02,  7.4619278e-02],\n",
      "       [ 1.7294456e-01, -1.8687310e-02, -8.6641923e-02, ...,\n",
      "         5.8353580e-05, -1.3954944e-03,  3.8195066e-03],\n",
      "       [ 4.2474583e-02, -2.0170158e-02, -1.2236255e-01, ...,\n",
      "        -5.4020505e-02, -2.8366283e-02, -8.9638811e-03]], dtype=float32))\n",
      "(array([ 6.08344360e+02,  4.24736118e+00,  1.48091364e+00,  7.91127622e-01,\n",
      "        2.63469994e-01,  1.78750306e-01,  1.42034829e-01,  8.79694223e-02,\n",
      "        4.96687107e-02,  4.29716893e-02,  3.25693563e-02,  2.54261475e-02,\n",
      "        1.79860126e-02,  1.73029322e-02,  1.20533705e-02,  9.19602998e-03,\n",
      "        9.46102198e-03,  5.76077262e-03,  5.46777109e-03,  5.06137218e-03,\n",
      "        4.19404497e-03,  3.29402415e-03,  2.81942589e-03,  2.17055436e-03,\n",
      "        1.80402235e-03,  1.61143800e-03,  1.35356758e-03,  1.21817319e-03,\n",
      "        1.12440984e-03,  9.63916420e-04,  8.35313404e-04,  6.34907803e-04,\n",
      "        5.52696933e-04,  4.72077489e-04,  4.43284400e-04,  3.50643822e-04,\n",
      "        3.19046783e-04,  2.61627923e-04,  2.31902479e-04,  2.17607914e-04,\n",
      "        1.99008864e-04,  1.67320715e-04,  1.38393865e-04,  1.20385805e-04,\n",
      "        9.62595150e-05,  8.39358618e-05,  5.69390104e-05,  5.21362563e-05,\n",
      "        4.26385122e-05,  3.01825094e-05, -1.33580397e-05, -1.16095935e-05,\n",
      "        1.28206020e-05,  1.07178630e-05, -7.03113210e-06,  8.11314931e-06,\n",
      "        6.70399959e-06, -5.08220819e-06,  4.99746147e-06,  5.43138822e-06,\n",
      "       -3.92810898e-06, -3.57643967e-06,  3.27671887e-06,  3.24046960e-06,\n",
      "       -3.06717584e-06, -2.78762877e-06,  2.27352393e-06, -2.43387376e-06,\n",
      "       -1.99131205e-06,  1.96612586e-06, -1.74189097e-06, -1.39285828e-06,\n",
      "        1.51123049e-06,  1.44372086e-06, -1.26206351e-06,  1.32521745e-06,\n",
      "        1.08677727e-06,  8.43995394e-07, -8.74306977e-07, -7.08359664e-07,\n",
      "       -6.49070728e-07, -6.02739703e-07,  6.24084123e-07,  5.96846121e-07,\n",
      "        4.70239257e-07,  4.17129030e-07, -3.24027724e-07, -2.76787546e-07,\n",
      "       -4.03465066e-07, -4.14302804e-07,  3.28604273e-07,  2.69984866e-07,\n",
      "        2.33169388e-07, -1.93146050e-07, -1.77242043e-07,  1.92479163e-07,\n",
      "        1.55711916e-07, -1.31055259e-07, -1.04938756e-07,  1.41997262e-07,\n",
      "        1.16958368e-07, -8.31680893e-08,  9.36313640e-08,  5.80622057e-08,\n",
      "       -5.00668413e-08, -3.88681443e-08,  2.05250235e-08,  1.20117871e-08,\n",
      "        3.96240623e-08,  4.03498639e-08, -2.59088413e-08,  2.50156411e-08,\n",
      "       -1.64533205e-08, -1.31279307e-08, -7.46871809e-09, -2.73920997e-09,\n",
      "       -6.90146051e-10,  3.52823659e-09,  5.62627367e-09,  6.75654155e-09],\n",
      "      dtype=float32), array([[ 0.06808797, -0.14659446, -0.03473673, ...,  0.01573711,\n",
      "         0.0152757 ,  0.0025472 ],\n",
      "       [ 0.05762197, -0.04735706,  0.21019943, ..., -0.00490112,\n",
      "        -0.0109884 ,  0.00368247],\n",
      "       [ 0.00227478,  0.01905531, -0.0174787 , ..., -0.02088368,\n",
      "        -0.00572803, -0.01093444],\n",
      "       ...,\n",
      "       [-0.01435906, -0.03797526, -0.09237384, ...,  0.00274877,\n",
      "        -0.00277586,  0.04509002],\n",
      "       [ 0.17335682, -0.0201877 , -0.03918507, ..., -0.00889827,\n",
      "        -0.00553587,  0.01633064],\n",
      "       [ 0.04268972,  0.04616475, -0.00592983, ..., -0.01612247,\n",
      "        -0.00769277,  0.05535777]], dtype=float32))\n",
      "(array([ 7.90672791e+02,  2.38461351e+00,  1.01019859e+00,  3.76124978e-01,\n",
      "        2.84450233e-01,  7.03776330e-02,  4.91050594e-02,  4.05968912e-02,\n",
      "        2.59078201e-02,  1.76826715e-02,  1.53561635e-02,  1.12803504e-02,\n",
      "        7.51367491e-03,  6.07332448e-03,  5.75952092e-03,  5.32713672e-03,\n",
      "        3.63668986e-03,  3.20647191e-03,  2.86698178e-03,  2.39698589e-03,\n",
      "        1.77631131e-03,  1.46349031e-03,  1.15482544e-03,  9.40353086e-04,\n",
      "        8.70903546e-04,  7.05520157e-04,  5.22508461e-04,  4.11229907e-04,\n",
      "        3.33915552e-04,  2.93948222e-04,  2.79562722e-04,  2.40341877e-04,\n",
      "        1.96234119e-04,  1.83104552e-04,  1.44998528e-04,  1.28910033e-04,\n",
      "        1.10177643e-04,  1.01366022e-04,  9.65352738e-05,  6.65340049e-05,\n",
      "        4.95401546e-05,  4.16930307e-05,  3.83760598e-05, -2.08824931e-05,\n",
      "        2.96678227e-05,  2.73708811e-05,  2.49011136e-05,  2.09255923e-05,\n",
      "       -1.62972574e-05, -1.50086871e-05,  1.84092933e-05,  1.60260261e-05,\n",
      "        1.35166438e-05, -9.76141200e-06,  1.05103400e-05,  9.10178915e-06,\n",
      "        8.13318820e-06, -6.25300663e-06,  6.43830072e-06,  5.71398959e-06,\n",
      "        5.20483036e-06, -4.59888633e-06, -4.10412304e-06,  4.13665975e-06,\n",
      "       -3.33712637e-06,  3.43103602e-06, -2.72268358e-06, -2.53639337e-06,\n",
      "        2.97993870e-06,  2.82128576e-06, -2.08456208e-06,  2.04080970e-06,\n",
      "       -1.79701817e-06, -1.57723127e-06,  1.47601384e-06, -1.30018009e-06,\n",
      "        1.37969027e-06,  1.29308728e-06, -1.07974768e-06, -8.88956095e-07,\n",
      "        8.69092673e-07,  8.45184388e-07, -7.99696409e-07, -7.45981879e-07,\n",
      "        6.58855299e-07,  6.88729529e-07, -5.67475922e-07, -4.32680395e-07,\n",
      "        5.08346659e-07,  4.57314371e-07, -3.15459772e-07,  3.29964450e-07,\n",
      "        3.06634774e-07,  2.40116094e-07, -2.32513088e-07,  2.06688014e-07,\n",
      "       -1.92663052e-07,  1.68296168e-07,  1.16196695e-07,  9.72961871e-08,\n",
      "       -1.51950147e-07, -1.34791676e-07, -1.25187142e-07, -7.98211417e-08,\n",
      "       -6.82238550e-08,  5.10252605e-08,  4.82811942e-08,  4.19068371e-08,\n",
      "        1.96607317e-08, -3.39462005e-08, -2.69583538e-08, -2.23952554e-08,\n",
      "        1.57726561e-08, -1.38800962e-08, -7.62566366e-09,  6.98350400e-09,\n",
      "        5.23474597e-09, -1.36413950e-10, -2.95513236e-09, -2.08172590e-09],\n",
      "      dtype=float32), array([[ 0.07077488,  0.19114402, -0.2294548 , ...,  0.00802131,\n",
      "         0.0084526 , -0.00102728],\n",
      "       [ 0.06618782,  0.14208637,  0.14113453, ...,  0.01158875,\n",
      "        -0.00693882,  0.00427522],\n",
      "       [ 0.00234768, -0.01108704, -0.0518028 , ...,  0.11013556,\n",
      "        -0.03830185, -0.02521399],\n",
      "       ...,\n",
      "       [-0.01745703, -0.05042994,  0.00677396, ...,  0.001506  ,\n",
      "        -0.05313115,  0.05879012],\n",
      "       [ 0.17259099, -0.00117562, -0.08535728, ..., -0.00120712,\n",
      "         0.00743186,  0.00255119],\n",
      "       [ 0.04280646,  0.00137371, -0.10851163, ..., -0.00162479,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.02079989, -0.0051428 ]], dtype=float32))\n",
      "(array([ 7.93220642e+02,  1.26887500e+00,  7.33940959e-01,  3.91011894e-01,\n",
      "        2.12641001e-01,  1.14876419e-01,  6.12955429e-02,  4.36157025e-02,\n",
      "        3.55418883e-02,  2.53589358e-02,  1.35252438e-02,  1.01994220e-02,\n",
      "        1.03019914e-02,  7.45483208e-03,  5.81450574e-03,  4.28581750e-03,\n",
      "        2.98120803e-03,  2.49880739e-03,  2.38054758e-03,  1.89346704e-03,\n",
      "        1.59229338e-03,  1.37917895e-03,  1.17250939e-03,  1.00392534e-03,\n",
      "        8.43693444e-04,  7.69155624e-04,  5.87274611e-04,  5.31179481e-04,\n",
      "        4.29881329e-04,  4.00048797e-04,  3.64750042e-04,  2.69669632e-04,\n",
      "        2.48260738e-04,  2.05020246e-04,  1.82106625e-04,  1.51733897e-04,\n",
      "        1.27958701e-04,  1.07446933e-04,  8.83533721e-05,  7.73165011e-05,\n",
      "        7.08615116e-05,  5.55362603e-05,  5.16315704e-05,  4.12891350e-05,\n",
      "       -2.33784322e-05,  3.18095772e-05,  2.83514364e-05,  2.57998909e-05,\n",
      "        2.07881531e-05, -1.50661726e-05,  1.81432188e-05, -1.33835983e-05,\n",
      "       -1.10447572e-05,  1.36124390e-05,  1.20215100e-05, -7.12607789e-06,\n",
      "        9.50296635e-06,  9.00825580e-06,  8.16313695e-06,  7.02165880e-06,\n",
      "        5.82449638e-06, -5.30839770e-06, -4.90105685e-06,  4.25934877e-06,\n",
      "        3.65442315e-06, -3.65346614e-06, -3.31534943e-06, -2.74407716e-06,\n",
      "        2.91150900e-06,  2.51264942e-06, -2.13405019e-06, -1.72178579e-06,\n",
      "        2.09160976e-06,  1.62263495e-06,  1.69500777e-06, -1.43423074e-06,\n",
      "        1.39357451e-06,  1.12570319e-06, -1.17133550e-06, -1.02324771e-06,\n",
      "       -8.35424601e-07,  7.52812809e-07,  6.83564849e-07,  5.96242614e-07,\n",
      "       -6.70493591e-07, -5.68887231e-07, -5.19435673e-07,  4.42336415e-07,\n",
      "        3.74028787e-07, -4.13097609e-07, -3.00792749e-07,  2.67802733e-07,\n",
      "       -2.52469761e-07,  1.93583404e-07,  1.69199765e-07, -1.76309314e-07,\n",
      "       -1.56380750e-07,  1.36670252e-07, -9.63572688e-08,  1.06758364e-07,\n",
      "        8.25860198e-08, -7.51239497e-08,  7.68776403e-08, -6.07697785e-08,\n",
      "        5.50545849e-08, -5.08968512e-08,  4.16668762e-08,  6.39692344e-09,\n",
      "        2.46475201e-10, -1.54023028e-09,  3.31445307e-08,  1.60930860e-08,\n",
      "        7.02776815e-09, -2.68009503e-09, -9.94403671e-09, -1.44112500e-08,\n",
      "       -3.39516824e-08, -3.13030526e-08, -2.13906297e-08,  2.28403430e-08],\n",
      "      dtype=float32), array([[-6.51477650e-02, -9.33836550e-02, -2.88116843e-01, ...,\n",
      "        -1.69591848e-02,  5.26735233e-03, -5.96440816e-03],\n",
      "       [-6.90492094e-02, -1.91961676e-01,  8.17583278e-02, ...,\n",
      "        -5.11822924e-02, -6.55987812e-03, -3.46067846e-02],\n",
      "       [-1.49354653e-03,  4.12484519e-02, -2.93057878e-02, ...,\n",
      "        -4.43358511e-01,  9.66741331e-03, -1.93015218e-01],\n",
      "       ...,\n",
      "       [ 1.36467349e-02, -1.16717070e-04, -2.63042320e-02, ...,\n",
      "        -1.38517513e-04,  1.09949842e-01, -2.69373469e-02],\n",
      "       [-1.70956314e-01,  1.63851231e-02, -1.02835514e-01, ...,\n",
      "        -2.59147631e-03,  1.84408557e-02, -1.32136922e-02],\n",
      "       [-3.94445993e-02,  6.97355121e-02, -9.66643728e-03, ...,\n",
      "        -1.00317344e-01,  5.47126234e-02,  2.84757819e-02]], dtype=float32))\n",
      "(array([ 6.58803101e+02,  2.98308849e+00,  1.39773250e+00,  7.25417376e-01,\n",
      "        2.85850406e-01,  1.42901659e-01,  8.08385611e-02,  4.75771911e-02,\n",
      "        3.99489664e-02,  2.60520652e-02,  1.89384390e-02,  1.45300627e-02,\n",
      "        1.19700748e-02,  9.64550953e-03,  8.22104793e-03,  7.58029753e-03,\n",
      "        5.75319771e-03,  4.21079108e-03,  3.57323186e-03,  3.12738144e-03,\n",
      "        2.52558407e-03,  2.01864098e-03,  1.77894090e-03,  1.39630516e-03,\n",
      "        1.15608261e-03,  9.59245663e-04,  9.06775531e-04,  6.06132264e-04,\n",
      "        5.20036323e-04,  4.44623118e-04,  3.84840299e-04,  3.34625074e-04,\n",
      "        3.14709847e-04,  2.79034692e-04,  2.22264149e-04,  1.82787669e-04,\n",
      "        1.32802335e-04,  1.30581539e-04,  1.11205620e-04,  9.44655840e-05,\n",
      "        9.01118183e-05,  7.88005709e-05,  5.13576197e-05,  4.43834724e-05,\n",
      "        2.88151932e-05, -1.72647888e-05,  2.29773359e-05,  2.14946922e-05,\n",
      "        1.79703966e-05,  1.43032639e-05, -9.29888665e-06,  1.13228316e-05,\n",
      "        1.05280078e-05, -7.48524781e-06, -6.57169539e-06, -6.16156285e-06,\n",
      "        8.32932619e-06,  7.89821752e-06,  6.05379819e-06,  5.66667677e-06,\n",
      "       -4.37052313e-06,  4.78237189e-06,  4.57911892e-06,  3.43597094e-06,\n",
      "        3.28748933e-06, -2.86565387e-06,  2.99663611e-06, -2.72037732e-06,\n",
      "       -2.40767486e-06,  2.42561623e-06,  2.14726765e-06, -1.87984483e-06,\n",
      "       -1.80275481e-06, -1.58943101e-06, -1.20108803e-06,  1.27072099e-06,\n",
      "        1.20759694e-06, -1.10818610e-06, -9.59283852e-07,  8.56230031e-07,\n",
      "        7.87654187e-07,  6.53815903e-07,  5.96290647e-07, -6.85808118e-07,\n",
      "       -7.82275038e-07, -5.70830593e-07, -5.07545110e-07, -4.09965196e-07,\n",
      "        4.63743277e-07,  4.35865047e-07,  4.11899634e-07,  3.44350440e-07,\n",
      "       -2.98521741e-07,  2.56898943e-07, -2.49089169e-07, -1.89047057e-07,\n",
      "        1.44400985e-07,  1.62179035e-07,  1.73402171e-07, -1.30187757e-07,\n",
      "       -1.49106526e-07,  1.12050316e-07,  8.09194773e-08, -7.07647629e-08,\n",
      "       -6.21314697e-08,  4.71563482e-08,  4.00021563e-08, -4.56474680e-08,\n",
      "       -3.78795519e-08, -2.69072267e-08, -2.28009149e-08,  2.55870241e-08,\n",
      "       -1.27919977e-08, -7.77250531e-09, -3.65966280e-09, -5.37307247e-11,\n",
      "        1.94546690e-09,  6.26325392e-09,  1.01871196e-08,  1.72081958e-08],\n",
      "      dtype=float32), array([[ 0.06854546,  0.13651511, -0.12091839, ...,  0.02254817,\n",
      "        -0.0152581 , -0.00736805],\n",
      "       [ 0.05644181,  0.14881678,  0.15886053, ..., -0.00997786,\n",
      "         0.02047138,  0.07644475],\n",
      "       [ 0.00339404, -0.03771705, -0.01863397, ...,  0.14733648,\n",
      "        -0.26476   , -0.21107386],\n",
      "       ...,\n",
      "       [-0.01971545,  0.02257869, -0.11429607, ...,  0.03303408,\n",
      "         0.00102659, -0.05189144],\n",
      "       [ 0.17781997, -0.04820564, -0.02729011, ...,  0.00432123,\n",
      "        -0.01370141, -0.01241233],\n",
      "       [ 0.04522139, -0.07074674,  0.00053042, ...,  0.02793782,\n",
      "        -0.03297115, -0.02019945]], dtype=float32))\n",
      "(array([ 5.64944763e+02,  3.31251097e+00,  1.95122898e+00,  1.17753494e+00,\n",
      "        2.20336437e-01,  1.30851671e-01,  1.03248656e-01,  5.37028424e-02,\n",
      "        2.94532906e-02,  2.39866730e-02,  1.85783170e-02,  1.34533523e-02,\n",
      "        1.09413657e-02,  9.11432784e-03,  7.46255321e-03,  5.78478724e-03,\n",
      "        4.24210681e-03,  3.71843833e-03,  2.72084121e-03,  2.13097059e-03,\n",
      "        1.98282953e-03,  1.57044886e-03,  1.44053635e-03,  1.03412545e-03,\n",
      "        1.01890287e-03,  7.58632086e-04,  6.23402768e-04,  5.97766659e-04,\n",
      "        5.66935341e-04,  4.28569940e-04,  3.92424379e-04,  3.36413650e-04,\n",
      "        3.28790076e-04,  2.34257561e-04,  2.40413225e-04,  2.02381532e-04,\n",
      "        1.71652748e-04,  1.35738286e-04,  1.24733371e-04,  1.01914316e-04,\n",
      "        9.92837813e-05,  7.50890613e-05,  6.60766818e-05,  5.19761852e-05,\n",
      "        4.30909204e-05,  3.16037585e-05,  2.11498864e-05,  1.88346348e-05,\n",
      "       -1.32173454e-05,  1.49360521e-05,  1.16445344e-05,  9.91183606e-06,\n",
      "       -8.53254369e-06,  6.52919289e-06, -6.49807407e-06, -5.57523663e-06,\n",
      "       -4.77665890e-06, -4.23524807e-06,  5.07794448e-06,  4.15870454e-06,\n",
      "        3.95590496e-06, -3.06716902e-06,  3.37596771e-06,  3.17749004e-06,\n",
      "        2.28301542e-06, -2.66496727e-06, -2.57864622e-06, -2.30012324e-06,\n",
      "       -2.05939364e-06, -1.71663112e-06,  1.89172908e-06,  1.93832875e-06,\n",
      "        1.52604389e-06,  1.30632691e-06, -1.28252282e-06, -1.06217158e-06,\n",
      "        1.09918028e-06,  9.27591771e-07, -8.65579466e-07,  7.65982350e-07,\n",
      "       -6.98432189e-07, -5.80199696e-07,  5.93885318e-07,  5.35155436e-07,\n",
      "        4.89098113e-07, -4.91744061e-07, -4.26629896e-07,  3.88402981e-07,\n",
      "        3.42578630e-07, -3.14787030e-07, -3.51559464e-07, -2.78380980e-07,\n",
      "        2.50396226e-07,  2.33207359e-07, -2.27039664e-07,  1.72043443e-07,\n",
      "       -1.71252211e-07, -1.33999066e-07, -1.22182499e-07,  1.23054249e-07,\n",
      "        1.10730291e-07,  1.02023279e-07, -7.46574713e-08,  6.13136137e-08,\n",
      "       -5.80929544e-08,  4.87152256e-08, -4.37566428e-08,  3.44800277e-08,\n",
      "       -2.80826544e-08, -2.25168932e-08,  1.96967882e-08,  1.80575341e-08,\n",
      "        1.17082397e-08, -1.32528006e-08,  4.87962692e-09, -9.67428804e-09,\n",
      "        2.00563255e-09, -8.82963924e-10, -6.58738974e-09, -4.24089786e-09],\n",
      "      dtype=float32), array([[ 0.06138782,  0.18223345,  0.05928627, ..., -0.01155777,\n",
      "         0.02505743, -0.00300044],\n",
      "       [ 0.05272243,  0.02310432, -0.19389871, ..., -0.03389819,\n",
      "         0.00475172,  0.02766135],\n",
      "       [ 0.00566821, -0.01531944,  0.05480184, ..., -0.01370727,\n",
      "         0.07840478, -0.43864512],\n",
      "       ...,\n",
      "       [-0.02578748,  0.00823446,  0.06114828, ...,  0.08382045,\n",
      "        -0.00602963, -0.09293699],\n",
      "       [ 0.17980208,  0.0153014 ,  0.07904111, ...,  0.00081122,\n",
      "         0.0074412 , -0.00727207],\n",
      "       [ 0.05125856, -0.01526687,  0.03982345, ...,  0.03611935,\n",
      "        -0.01339273, -0.0026764 ]], dtype=float32))\n",
      "(array([ 7.99047180e+02,  1.84035265e+00,  1.40192747e+00,  7.64218986e-01,\n",
      "        2.46355176e-01,  1.59388393e-01,  1.02761090e-01,  8.07437003e-02,\n",
      "        4.70335968e-02,  3.70322838e-02,  2.67538596e-02,  2.11218782e-02,\n",
      "        1.53958229e-02,  1.33667300e-02,  9.19539109e-03,  7.34772580e-03,\n",
      "        6.31759362e-03,  5.55514032e-03,  3.63873155e-03,  3.31364735e-03,\n",
      "        2.80785863e-03,  2.38528359e-03,  1.96939497e-03,  1.55410578e-03,\n",
      "        1.27081363e-03,  1.20365678e-03,  1.12558645e-03,  9.03600885e-04,\n",
      "        7.43847049e-04,  5.86451904e-04,  5.40403766e-04,  4.70580067e-04,\n",
      "        3.65073996e-04,  3.10893898e-04,  2.65847018e-04,  2.26307195e-04,\n",
      "        1.77127178e-04,  1.65280799e-04,  1.47318424e-04,  1.23416685e-04,\n",
      "        1.13765163e-04,  8.77210332e-05,  8.61536973e-05,  6.96113202e-05,\n",
      "        5.31555052e-05,  4.14763090e-05,  3.57187819e-05,  2.61641289e-05,\n",
      "       -2.34737490e-05, -1.74950837e-05,  1.77700149e-05,  1.66443588e-05,\n",
      "        1.24556072e-05, -1.08134254e-05, -1.00874995e-05,  9.59156569e-06,\n",
      "       -7.47630111e-06, -7.20541948e-06,  7.69894177e-06,  7.38607332e-06,\n",
      "        6.78584138e-06,  4.78296079e-06, -4.58015393e-06, -4.38360576e-06,\n",
      "        4.29557031e-06, -3.61023876e-06,  3.59030150e-06, -2.75850357e-06,\n",
      "        2.83037707e-06,  2.38397934e-06, -2.18947866e-06, -1.71467047e-06,\n",
      "       -1.48395532e-06, -1.36958943e-06,  1.57225418e-06,  1.54489760e-06,\n",
      "        1.31928130e-06,  1.25090162e-06, -1.13144279e-06,  9.25865436e-07,\n",
      "       -8.32006776e-07, -7.23969606e-07, -6.84376801e-07,  8.04730348e-07,\n",
      "        7.80028984e-07,  5.97501014e-07, -4.99543660e-07, -3.98238910e-07,\n",
      "        4.06975744e-07, -3.03150898e-07,  3.32317882e-07,  3.00688356e-07,\n",
      "        2.85534497e-07, -2.40681970e-07, -1.79973298e-07, -1.59726952e-07,\n",
      "        2.04245239e-07,  1.78512764e-07,  1.44897683e-07,  1.12271103e-07,\n",
      "       -9.99547751e-08,  9.04940407e-08, -7.85842431e-08, -7.13244859e-08,\n",
      "       -5.88525424e-08,  5.56949260e-08,  5.28957536e-08, -4.07080485e-08,\n",
      "        3.82121392e-08, -2.84391035e-08,  2.34751685e-08, -2.36047999e-08,\n",
      "       -1.88669311e-08,  1.41371101e-08, -8.29280022e-09,  7.51891793e-09,\n",
      "        3.91095734e-09,  6.37575504e-09, -2.36839159e-10, -7.26454452e-10],\n",
      "      dtype=float32), array([[-0.06749892, -0.0783753 ,  0.18851772, ..., -0.00022426,\n",
      "        -0.00163849,  0.00056639],\n",
      "       [-0.06810309, -0.05270956,  0.09782025, ...,  0.0089229 ,\n",
      "        -0.00377408,  0.00222675],\n",
      "       [-0.00166315,  0.0074023 ,  0.00294393, ...,  0.21643753,\n",
      "        -0.01896596, -0.05764886],\n",
      "       ...,\n",
      "       [ 0.01423412, -0.01843336,  0.04294676, ..., -0.06374554,\n",
      "         0.02521543,  0.04915059],\n",
      "       [-0.17173623,  0.03446579,  0.01625721, ..., -0.00041319,\n",
      "        -0.00201663, -0.00110658],\n",
      "       [-0.03740995, -0.03574769, -0.00669024, ...,  0.03933457,\n",
      "        -0.00815918,  0.05642341]], dtype=float32))\n",
      "(array([ 8.35575500e+02,  2.46934280e-01,  1.08553760e-01,  1.02506816e-01,\n",
      "        2.69849561e-02,  2.12060381e-02,  1.04628084e-02,  6.34620618e-03,\n",
      "        2.43769772e-03,  2.07812944e-03,  1.53778389e-03,  9.62057500e-04,\n",
      "        6.19641389e-04,  4.16514900e-04,  3.91364301e-04,  2.70346121e-04,\n",
      "        2.21669397e-04,  1.37200826e-04,  1.26998100e-04,  9.65028739e-05,\n",
      "        8.35749161e-05,  5.79105508e-05,  4.60573137e-05, -2.85115329e-05,\n",
      "        3.59289297e-05,  3.14851386e-05, -2.20222046e-05,  2.63006441e-05,\n",
      "        2.41883408e-05, -1.77630573e-05,  2.04766457e-05,  1.97192039e-05,\n",
      "       -1.35875625e-05,  1.72844557e-05,  1.57575996e-05,  1.42252256e-05,\n",
      "       -1.19229435e-05, -1.00839561e-05,  1.20058921e-05,  1.11653935e-05,\n",
      "       -8.50709148e-06,  9.93386402e-06,  8.94983441e-06, -6.37293579e-06,\n",
      "        7.79492348e-06,  6.82327527e-06, -5.47011996e-06,  6.29419037e-06,\n",
      "        5.43967917e-06,  5.11877624e-06,  4.80484368e-06, -3.79997914e-06,\n",
      "       -3.49010361e-06, -3.22678352e-06,  4.07144034e-06,  3.51696190e-06,\n",
      "        3.01021737e-06, -2.93918765e-06, -2.29165357e-06,  2.45462070e-06,\n",
      "        2.36542473e-06, -2.02849742e-06,  2.27780561e-06, -1.80808308e-06,\n",
      "        1.96399378e-06, -1.41774308e-06, -1.11060069e-06,  1.65013716e-06,\n",
      "        1.55133887e-06,  1.29210991e-06,  1.26813472e-06,  1.21556991e-06,\n",
      "       -8.98895280e-07, -7.39899406e-07,  8.48545142e-07,  7.88260877e-07,\n",
      "       -6.06863409e-07,  6.22551056e-07, -5.02943919e-07,  5.99170221e-07,\n",
      "       -3.80549551e-07, -2.85550612e-07,  5.17772321e-07,  4.87080740e-07,\n",
      "        4.24493919e-07,  3.83208800e-07,  3.52603649e-07,  2.74646737e-07,\n",
      "       -2.27670000e-07, -1.63774899e-07,  2.31801636e-07,  2.26533928e-07,\n",
      "        1.83499651e-07,  1.75806846e-07, -1.33739590e-07, -1.21303799e-07,\n",
      "       -1.05784608e-07,  1.46415388e-07,  1.21759825e-07, -6.58072707e-08,\n",
      "        9.86636053e-08,  8.36294802e-08,  6.19060216e-08, -4.42542216e-08,\n",
      "        4.39966179e-08,  4.05085920e-08, -2.10541113e-08,  2.91567535e-08,\n",
      "       -1.80337896e-08,  1.94549354e-08,  1.84842399e-08, -9.84751125e-09,\n",
      "        1.27479414e-08,  9.91791449e-09, -5.33806466e-09, -3.15207194e-09,\n",
      "        3.67434061e-09,  1.65675407e-09,  1.00958586e-09,  6.06198824e-09],\n",
      "      dtype=float32), array([[-0.07615237,  0.24504142,  0.14661077, ...,  0.00120687,\n",
      "        -0.00256726,  0.0052653 ],\n",
      "       [-0.06957335,  0.19104284, -0.18027882, ..., -0.00336031,\n",
      "        -0.0110944 , -0.00385071],\n",
      "       [-0.00237038,  0.00652053,  0.00970997, ..., -0.09679617,\n",
      "        -0.24479498, -0.02450674],\n",
      "       ...,\n",
      "       [ 0.01507639, -0.06523169, -0.00451777, ...,  0.0084967 ,\n",
      "        -0.01935389,  0.01525404],\n",
      "       [-0.1714599 ,  0.02270363, -0.03494202, ..., -0.00307752,\n",
      "         0.02155076, -0.00990602],\n",
      "       [-0.03896171,  0.01588016,  0.0367691 , ...,  0.02010519,\n",
      "        -0.01066295,  0.01464309]], dtype=float32))\n",
      "(array([ 8.35676331e+02,  3.37108135e+00,  3.86886358e-01,  1.67527333e-01,\n",
      "        1.19002685e-01,  4.34775390e-02,  3.46338935e-02,  2.32088231e-02,\n",
      "        1.87631156e-02,  9.39277187e-03,  8.63215514e-03,  5.14143799e-03,\n",
      "        3.39503004e-03,  2.90505169e-03,  2.43041851e-03,  1.77661236e-03,\n",
      "        1.59927853e-03,  1.25712343e-03,  1.13945326e-03,  1.09485548e-03,\n",
      "        7.16922339e-04,  6.03922061e-04,  5.42229274e-04,  4.10562992e-04,\n",
      "        3.70974885e-04,  3.09851544e-04,  2.55417719e-04,  2.39177549e-04,\n",
      "        2.12125160e-04,  1.69994804e-04,  1.19930490e-04,  1.15982941e-04,\n",
      "        1.00534555e-04,  8.51281220e-05,  6.01940446e-05,  4.94511987e-05,\n",
      "        4.30646651e-05,  3.69689515e-05,  3.42317471e-05,  3.21248444e-05,\n",
      "        2.73264013e-05, -2.29685538e-05, -1.64419362e-05,  2.36729993e-05,\n",
      "        2.08170004e-05,  1.92623665e-05,  1.80079624e-05, -1.26807290e-05,\n",
      "        1.47305836e-05,  1.44867945e-05, -1.09106204e-05,  1.23019063e-05,\n",
      "        1.11938634e-05,  9.68487984e-06, -7.27644783e-06, -6.92549202e-06,\n",
      "        7.67586153e-06,  7.44536646e-06,  6.32457022e-06,  5.57241947e-06,\n",
      "       -4.82902215e-06, -4.50125026e-06,  5.08104404e-06,  4.08343249e-06,\n",
      "       -4.05426772e-06, -3.03170577e-06,  3.47754099e-06, -2.23443294e-06,\n",
      "        2.96533585e-06,  2.66214738e-06,  2.21765117e-06,  2.06293294e-06,\n",
      "       -1.66283394e-06,  1.75640321e-06, -1.48141771e-06, -1.35321045e-06,\n",
      "        1.25675479e-06,  1.05700053e-06,  9.49214950e-07,  8.65727770e-07,\n",
      "       -8.73809370e-07, -7.54637313e-07,  7.38998210e-07,  6.26583414e-07,\n",
      "       -6.23581570e-07, -6.04677496e-07,  5.19018556e-07, -4.51224423e-07,\n",
      "        4.83647682e-07, -4.16745934e-07, -3.75693901e-07,  2.75987929e-07,\n",
      "        2.96238937e-07, -2.45955448e-07, -2.21025587e-07,  1.77804708e-07,\n",
      "        1.53838343e-07, -1.51308072e-07, -1.13482962e-07,  9.58779580e-08,\n",
      "        8.92046614e-08, -7.60672023e-08, -6.61635724e-08,  7.81903182e-08,\n",
      "        6.22307752e-08, -5.75216248e-08,  3.55862610e-08,  2.97044984e-08,\n",
      "       -3.67399124e-08, -2.10992415e-08,  1.51439945e-08,  1.25018715e-08,\n",
      "       -1.73542034e-08,  8.10877676e-09, -3.43671674e-10, -3.11342330e-09,\n",
      "       -5.02940001e-09, -9.02846242e-09, -1.35979183e-08,  5.12355580e-09],\n",
      "      dtype=float32), array([[ 0.06591929, -0.31719947, -0.12585646, ...,  0.00034025,\n",
      "        -0.0009588 ,  0.01906846],\n",
      "       [ 0.07074602, -0.09255695,  0.02685961, ...,  0.00041686,\n",
      "         0.05192444,  0.02338151],\n",
      "       [ 0.00259105, -0.0027587 , -0.0058951 , ..., -0.11678661,\n",
      "         0.06457212, -0.09446137],\n",
      "       ...,\n",
      "       [-0.01751689, -0.00324917, -0.07688955, ..., -0.12130733,\n",
      "         0.01846479,  0.05016407],\n",
      "       [ 0.17127798,  0.04123983, -0.1911942 , ..., -0.00254557,\n",
      "        -0.01355429, -0.00867549],\n",
      "       [ 0.03790271, -0.03804626, -0.03647675, ...,  0.03562308,\n",
      "        -0.00955748, -0.04185503]], dtype=float32))\n",
      "(array([ 8.46787048e+02,  2.74748945e+00,  3.37069839e-01,  1.27724096e-01,\n",
      "        5.97378500e-02,  3.50966081e-02,  2.96646655e-02,  1.25319427e-02,\n",
      "        8.43919441e-03,  5.87128801e-03,  5.01807407e-03,  2.34746700e-03,\n",
      "        2.00861669e-03,  1.77856744e-03,  1.34731096e-03,  1.05098472e-03,\n",
      "        9.24694061e-04,  7.58515205e-04,  5.18880726e-04,  5.00602124e-04,\n",
      "        4.37307084e-04,  3.83234874e-04,  3.18110368e-04,  2.50677025e-04,\n",
      "        1.92071326e-04,  1.47266081e-04,  1.34825896e-04,  1.08402732e-04,\n",
      "        9.20220555e-05,  7.12249966e-05,  6.99122829e-05,  5.97407525e-05,\n",
      "        4.88928526e-05,  4.63716751e-05,  3.71480892e-05,  3.04739606e-05,\n",
      "        2.79095784e-05,  2.45738611e-05, -1.92579864e-05,  2.21053670e-05,\n",
      "        2.00999020e-05, -1.73674562e-05,  1.72726959e-05, -1.54663048e-05,\n",
      "       -1.47613173e-05,  1.64599896e-05,  1.53570672e-05, -1.06362313e-05,\n",
      "       -8.16796182e-06,  1.39922695e-05,  1.28888341e-05,  1.23589880e-05,\n",
      "        1.16328129e-05,  9.04028184e-06,  8.62576690e-06,  7.48731372e-06,\n",
      "        6.22557036e-06,  5.42490170e-06, -5.40397059e-06, -5.06625747e-06,\n",
      "       -4.54269320e-06, -3.96777205e-06,  4.51864344e-06,  4.38323241e-06,\n",
      "       -3.19131368e-06,  3.81890777e-06,  3.47111745e-06, -2.53850226e-06,\n",
      "        2.72627017e-06,  2.63483275e-06,  2.52602786e-06, -1.97385202e-06,\n",
      "        2.13062503e-06,  1.89162222e-06, -1.70994213e-06,  1.53639019e-06,\n",
      "        1.22101551e-06, -1.17659579e-06, -1.07079848e-06, -8.90247918e-07,\n",
      "        9.17037937e-07,  7.82941925e-07, -6.53841710e-07,  6.32610465e-07,\n",
      "       -5.73055956e-07, -5.14526789e-07,  5.03177716e-07, -4.10886514e-07,\n",
      "        4.48605419e-07,  3.78155505e-07,  3.02001979e-07, -3.27479285e-07,\n",
      "       -2.90578896e-07,  2.69858987e-07, -2.14854509e-07,  2.31937491e-07,\n",
      "        1.88252415e-07, -1.52907987e-07, -1.01427382e-07, -9.00318682e-08,\n",
      "        1.40374809e-07,  1.31206420e-07,  1.03910075e-07,  7.82281617e-08,\n",
      "       -7.07068963e-08, -4.62937386e-08, -3.29441399e-08,  3.47052129e-08,\n",
      "       -2.35277930e-08,  2.67795084e-08, -1.72073253e-08, -1.14856302e-08,\n",
      "        1.77341448e-08,  1.57139635e-08, -7.48382956e-09,  1.15795915e-08,\n",
      "       -1.59961711e-09, -5.38794634e-11,  6.36928421e-09,  4.19471968e-09],\n",
      "      dtype=float32), array([[ 6.55743703e-02, -2.83290237e-01, -1.60882413e-01, ...,\n",
      "         1.50634171e-02,  1.05338302e-02,  5.16461348e-03],\n",
      "       [ 6.87950775e-02, -1.16690159e-01,  1.65546745e-01, ...,\n",
      "        -1.89749654e-02, -6.13427022e-03,  1.44000016e-02],\n",
      "       [ 2.84360186e-03, -1.28027987e-05, -1.43169435e-02, ...,\n",
      "         1.39475256e-01, -1.73102304e-01, -1.69059038e-01],\n",
      "       ...,\n",
      "       [-1.41369607e-02, -3.12567048e-04, -6.35174066e-02, ...,\n",
      "        -2.17830273e-03, -3.32878605e-02, -4.50204648e-02],\n",
      "       [ 1.73338354e-01,  2.55775917e-02, -7.82155842e-02, ...,\n",
      "        -3.36304214e-03, -1.85536104e-03, -2.43881973e-03],\n",
      "       [ 3.73815782e-02, -5.13417013e-02, -6.73208311e-02, ...,\n",
      "        -8.99344566e-04, -4.47415300e-02,  3.72865051e-02]], dtype=float32))\n",
      "(array([ 7.4116180e+02,  1.7041757e+00,  7.2129154e-01,  4.4661152e-01,\n",
      "        1.4405291e-01,  4.6551652e-02,  3.6536556e-02,  2.8779333e-02,\n",
      "        2.0609081e-02,  1.4391105e-02,  9.7383736e-03,  7.2227633e-03,\n",
      "        5.8546243e-03,  5.4844231e-03,  4.0347516e-03,  3.3351949e-03,\n",
      "        1.9511470e-03,  1.7563915e-03,  1.4112057e-03,  1.0768548e-03,\n",
      "        9.8165614e-04,  8.7139185e-04,  6.4294739e-04,  6.2557735e-04,\n",
      "        4.2460774e-04,  4.1791031e-04,  3.1407690e-04,  2.1761344e-04,\n",
      "        2.0246502e-04,  1.9850385e-04,  1.5037513e-04,  1.3900164e-04,\n",
      "        1.2432298e-04,  1.1386278e-04,  7.2518706e-05,  6.7964618e-05,\n",
      "        5.6820518e-05,  4.5287030e-05,  4.4238459e-05,  3.3203505e-05,\n",
      "        2.7909133e-05,  2.4744506e-05, -1.7854252e-05,  2.0436128e-05,\n",
      "       -1.6341281e-05,  1.7386928e-05, -1.1492136e-05,  1.5761683e-05,\n",
      "        1.4344766e-05,  1.3517911e-05,  1.2125623e-05, -9.8946502e-06,\n",
      "        9.2102919e-06, -7.4682498e-06,  8.0836380e-06, -6.0223492e-06,\n",
      "        6.2555805e-06,  6.0353564e-06, -4.3449977e-06,  5.0359249e-06,\n",
      "        4.9578871e-06,  4.0378814e-06,  3.6239537e-06,  3.0405647e-06,\n",
      "       -3.6750498e-06, -3.3908427e-06, -2.7719916e-06, -2.5866609e-06,\n",
      "        2.2976606e-06, -1.8552348e-06,  2.0204998e-06,  1.6551455e-06,\n",
      "       -1.5778509e-06, -1.2063610e-06,  1.3950360e-06,  1.1805635e-06,\n",
      "        9.5514531e-07, -1.0518695e-06, -8.7881273e-07, -7.5322077e-07,\n",
      "        7.7262416e-07,  6.7754684e-07,  6.3966581e-07, -5.5760904e-07,\n",
      "       -5.2622181e-07,  4.6594130e-07,  3.9543906e-07,  3.6155191e-07,\n",
      "       -3.5707075e-07, -3.1180818e-07,  2.8565844e-07, -2.4786951e-07,\n",
      "        2.5025935e-07, -1.7356416e-07,  1.9211467e-07,  1.8438141e-07,\n",
      "        1.3177244e-07, -1.2736552e-07, -1.1423668e-07, -9.4681191e-08,\n",
      "        8.8205027e-08, -7.0744811e-08, -6.2614681e-08,  7.3175720e-08,\n",
      "        6.2250990e-08,  4.5307189e-08, -4.3657664e-08, -3.4530739e-08,\n",
      "       -2.7365065e-08,  3.1339901e-08,  2.7203408e-08,  1.9193012e-08,\n",
      "        1.5910468e-08, -1.1498230e-08, -8.6647756e-09,  5.3519313e-09,\n",
      "       -4.5485931e-09,  2.3373903e-09, -2.7969718e-10, -1.9013708e-09],\n",
      "      dtype=float32), array([[ 0.06655571,  0.3224579 ,  0.07481462, ..., -0.01003114,\n",
      "         0.01697809,  0.00727596],\n",
      "       [ 0.06130688,  0.09111962, -0.178276  , ...,  0.00298904,\n",
      "         0.00870994, -0.01525856],\n",
      "       [ 0.00298703,  0.0099407 ,  0.02552121, ...,  0.0517478 ,\n",
      "        -0.10084978, -0.18489373],\n",
      "       ...,\n",
      "       [-0.01409584,  0.0035513 , -0.00524872, ..., -0.02149344,\n",
      "         0.01212044, -0.02959243],\n",
      "       [ 0.16781357, -0.08121066, -0.11041435, ...,  0.01040692,\n",
      "        -0.01008857,  0.00499158],\n",
      "       [ 0.03674401,  0.06082848,  0.01978048, ..., -0.0157133 ,\n",
      "        -0.00072579, -0.00521662]], dtype=float32))\n",
      "(array([ 6.69845642e+02,  1.10563445e+00,  4.97267932e-01,  4.13423449e-01,\n",
      "        8.95848423e-02,  6.15418851e-02,  4.97384295e-02,  2.74567455e-02,\n",
      "        1.79579258e-02,  1.61692183e-02,  7.19050877e-03,  6.62636105e-03,\n",
      "        3.98417423e-03,  3.07933730e-03,  2.67301197e-03,  2.33715237e-03,\n",
      "        1.72825472e-03,  1.60727662e-03,  1.37767254e-03,  1.10569398e-03,\n",
      "        8.94529512e-04,  8.19951878e-04,  6.31512841e-04,  5.31325059e-04,\n",
      "        4.69074497e-04,  3.93364608e-04,  3.29772040e-04,  3.01119580e-04,\n",
      "        2.22259478e-04,  1.69892941e-04,  1.46302773e-04,  1.17492818e-04,\n",
      "        1.10939385e-04,  1.07762979e-04,  7.66762896e-05,  7.73448701e-05,\n",
      "        5.67171155e-05,  3.68891779e-05,  3.56286291e-05,  3.21835214e-05,\n",
      "        2.90725329e-05,  2.47525986e-05,  2.27733581e-05,  1.93113792e-05,\n",
      "       -1.39164549e-05,  1.60949803e-05,  1.51365348e-05, -1.00975576e-05,\n",
      "        1.22288502e-05, -9.28466670e-06, -8.42518239e-06,  9.83320479e-06,\n",
      "        9.15231249e-06, -6.51809887e-06, -5.82531220e-06,  7.54734447e-06,\n",
      "        7.00427154e-06,  6.41821589e-06,  5.84418376e-06,  5.16473983e-06,\n",
      "        4.57117176e-06, -3.69135614e-06, -3.80116330e-06, -3.00680426e-06,\n",
      "        3.18442972e-06,  3.48564822e-06, -2.47624166e-06,  2.81758889e-06,\n",
      "       -2.12391865e-06, -1.85693057e-06,  1.90521303e-06, -1.48186064e-06,\n",
      "       -1.37259212e-06,  1.55073690e-06,  1.41137866e-06,  1.17048796e-06,\n",
      "       -9.68202357e-07,  8.81231074e-07, -7.77236323e-07,  7.94127800e-07,\n",
      "       -6.50745449e-07, -5.97092651e-07,  6.66378469e-07, -4.54405466e-07,\n",
      "        5.60700585e-07,  5.09110919e-07,  4.55648433e-07, -3.71619336e-07,\n",
      "       -3.31094498e-07,  2.93260229e-07, -2.70991734e-07,  2.27660763e-07,\n",
      "        1.89590139e-07, -2.43301884e-07, -2.10176594e-07, -1.64456182e-07,\n",
      "        1.47783581e-07,  1.26366913e-07, -1.09896853e-07,  1.08638545e-07,\n",
      "       -7.73376954e-08,  8.29770244e-08, -6.29362873e-08,  7.56730927e-08,\n",
      "        5.67785747e-08,  6.69930103e-08, -4.49468942e-08,  3.30827206e-08,\n",
      "       -2.84892572e-08, -2.16993268e-08,  2.02615436e-08, -1.17591901e-08,\n",
      "       -7.20384641e-09, -4.10595113e-09,  1.08965015e-08, -1.64784886e-09,\n",
      "        7.75938869e-09,  6.30629504e-09,  3.09532022e-09,  3.67988195e-09],\n",
      "      dtype=float32), array([[-0.06874732,  0.05276751, -0.13611425, ...,  0.00188099,\n",
      "        -0.00868347, -0.02784275],\n",
      "       [-0.05772318,  0.142545  ,  0.11673437, ..., -0.0036879 ,\n",
      "         0.03434851, -0.02814227],\n",
      "       [-0.00287155, -0.0141053 , -0.01880963, ..., -0.02318418,\n",
      "         0.22036073,  0.25766474],\n",
      "       ...,\n",
      "       [ 0.01289454, -0.04442226, -0.0067639 , ..., -0.11548976,\n",
      "        -0.09999961,  0.06860061],\n",
      "       [-0.16478136,  0.05537052, -0.17506854, ..., -0.0023961 ,\n",
      "         0.00101555,  0.01246612],\n",
      "       [-0.03479612, -0.00282826, -0.08650453, ..., -0.0019563 ,\n",
      "         0.05006618,  0.06698306]], dtype=float32))\n",
      "(array([ 5.24047852e+02,  7.23647892e-01,  5.10526240e-01,  1.65781498e-01,\n",
      "        5.44561148e-02,  4.52455170e-02,  3.55866589e-02,  2.89167576e-02,\n",
      "        1.38801252e-02,  9.75107960e-03,  6.07384183e-03,  4.88895224e-03,\n",
      "        3.01248766e-03,  2.20258557e-03,  1.87147048e-03,  1.39795593e-03,\n",
      "        1.34626671e-03,  8.71515775e-04,  7.72348489e-04,  5.09716629e-04,\n",
      "        4.51880682e-04,  3.84293497e-04,  3.07473267e-04,  2.89961929e-04,\n",
      "        2.65113602e-04,  2.35299594e-04,  1.70536397e-04,  1.49516316e-04,\n",
      "        1.08605127e-04,  1.01893856e-04,  8.89633084e-05,  6.52822491e-05,\n",
      "        4.62077951e-05,  4.46054801e-05,  4.09947461e-05,  3.61661550e-05,\n",
      "        3.22432425e-05,  2.78241332e-05,  1.74286961e-05,  1.58368475e-05,\n",
      "       -1.17227200e-05,  1.37596899e-05,  1.17900663e-05, -7.89399201e-06,\n",
      "        1.11646868e-05,  9.30241276e-06,  8.19780144e-06,  7.30165402e-06,\n",
      "       -6.00843669e-06, -4.53117445e-06,  6.59715670e-06,  6.13472957e-06,\n",
      "        5.70047132e-06,  4.72317743e-06,  4.31931676e-06, -3.29403338e-06,\n",
      "        3.41178202e-06, -2.78985112e-06, -2.42342230e-06, -2.14646684e-06,\n",
      "        2.77440449e-06,  2.58224895e-06,  2.30566820e-06,  2.06641971e-06,\n",
      "       -1.82239569e-06, -1.65191295e-06,  1.84367821e-06,  1.68211659e-06,\n",
      "        1.39389977e-06,  1.25241570e-06, -1.37982408e-06, -1.19288188e-06,\n",
      "       -1.03423099e-06,  9.21466437e-07,  7.85188774e-07, -6.91963692e-07,\n",
      "       -6.08831442e-07,  7.05042055e-07,  6.24617996e-07,  5.78368542e-07,\n",
      "       -4.60102029e-07,  5.01813020e-07,  4.72196376e-07, -3.89164313e-07,\n",
      "       -3.62205498e-07,  3.87345722e-07,  3.06287632e-07,  2.33349809e-07,\n",
      "       -3.05173245e-07, -2.29855630e-07, -2.00635881e-07, -1.92941627e-07,\n",
      "        1.77088154e-07, -1.51254198e-07, -1.30800728e-07,  1.38138944e-07,\n",
      "        1.28361449e-07,  9.53262926e-08, -1.13037245e-07, -9.02397090e-08,\n",
      "        8.73953496e-08,  8.11524146e-08, -5.60893412e-08, -4.15840944e-08,\n",
      "        4.50282158e-08,  3.80229217e-08, -3.24497869e-08, -2.46433594e-08,\n",
      "       -2.10510844e-08,  2.19582361e-08,  2.01496064e-08,  1.50256394e-08,\n",
      "       -1.34724978e-08, -1.24552741e-08, -5.66088199e-09, -2.45348386e-09,\n",
      "        3.68876840e-09,  1.22135446e-09,  8.33377634e-09,  1.09052882e-08],\n",
      "      dtype=float32), array([[-5.68240285e-02,  1.85256571e-01,  6.35777786e-02, ...,\n",
      "        -1.87325070e-03, -2.81419605e-02,  8.20883270e-03],\n",
      "       [-4.97185886e-02,  2.32265163e-02, -1.99096769e-01, ...,\n",
      "         4.05636951e-02, -4.15692991e-03,  1.05034010e-02],\n",
      "       [-2.01566028e-03,  1.50976460e-02,  5.85288648e-03, ...,\n",
      "         7.68110007e-02, -3.06585804e-02, -2.45217998e-02],\n",
      "       ...,\n",
      "       [ 8.37377552e-03, -1.68073544e-04,  2.89676171e-02, ...,\n",
      "        -1.04054160e-01,  4.05166559e-02,  7.78826512e-03],\n",
      "       [-1.56135708e-01, -2.17489064e-01,  1.09330304e-01, ...,\n",
      "        -4.05950844e-03,  8.28934310e-04, -1.95552665e-03],\n",
      "       [-2.94121951e-02,  3.03076836e-03,  1.74612328e-02, ...,\n",
      "        -8.83051381e-02, -1.74278338e-02,  3.29351649e-02]], dtype=float32))\n",
      "(array([ 4.63600769e+02,  7.04207242e-01,  3.62808973e-01,  1.14322767e-01,\n",
      "        6.48487210e-02,  5.15410490e-02,  3.14607807e-02,  2.60371696e-02,\n",
      "        1.64698251e-02,  7.19681382e-03,  6.17597532e-03,  3.66355013e-03,\n",
      "        2.94496352e-03,  2.23831157e-03,  1.97925465e-03,  1.63675530e-03,\n",
      "        1.21078501e-03,  8.49535514e-04,  7.11476139e-04,  6.13541109e-04,\n",
      "        5.46032912e-04,  4.01934347e-04,  3.45835258e-04,  2.43863702e-04,\n",
      "        2.16893459e-04,  1.75311550e-04,  1.44618127e-04,  1.12730617e-04,\n",
      "        8.74001707e-05,  8.06718745e-05,  7.26939616e-05,  5.67735988e-05,\n",
      "        5.16951477e-05,  4.27114501e-05,  3.36012490e-05,  3.21156476e-05,\n",
      "        2.69089633e-05,  2.34401978e-05, -1.23370446e-05,  1.68540646e-05,\n",
      "        1.61969238e-05,  1.43738325e-05,  1.20698205e-05, -8.51232107e-06,\n",
      "       -7.05228103e-06,  8.63381501e-06,  7.95421329e-06,  7.30258944e-06,\n",
      "       -4.97245628e-06,  6.39321661e-06,  5.82545908e-06, -4.13544194e-06,\n",
      "        5.01480736e-06,  4.59308558e-06,  3.88734588e-06, -3.49691072e-06,\n",
      "       -2.88626575e-06,  3.01722412e-06,  2.73591627e-06, -2.14756983e-06,\n",
      "        2.10919598e-06,  2.52116297e-06,  1.93199412e-06, -1.48875733e-06,\n",
      "        1.47892274e-06,  1.35676771e-06, -1.14137765e-06, -9.30351007e-07,\n",
      "       -8.56800000e-07,  1.08069241e-06,  1.09640746e-06,  9.06976481e-07,\n",
      "       -6.97419694e-07,  7.51270989e-07,  7.13043221e-07, -6.10773498e-07,\n",
      "        6.17364435e-07,  5.40588474e-07,  4.88983574e-07, -4.24799168e-07,\n",
      "       -4.10859769e-07,  4.08832022e-07,  3.47758487e-07, -3.42542705e-07,\n",
      "        3.00112333e-07, -2.90349675e-07,  2.20566463e-07, -2.30985904e-07,\n",
      "       -2.24037151e-07,  1.85262351e-07, -1.66329372e-07,  1.39563042e-07,\n",
      "       -1.34721219e-07,  1.17317605e-07,  1.07038161e-07, -1.09981237e-07,\n",
      "        9.34337905e-08, -9.66598890e-08, -9.38655518e-08,  7.95932920e-08,\n",
      "        6.08064212e-08, -8.43956300e-08, -5.87954467e-08, -5.46156862e-08,\n",
      "        5.28261417e-08,  4.06019574e-08, -3.47273286e-08,  3.15261417e-08,\n",
      "       -2.77344299e-08,  2.08781561e-08,  2.00056469e-08,  1.29341107e-08,\n",
      "       -1.59720379e-08,  1.72848391e-09, -1.55844526e-09, -1.06012266e-08,\n",
      "       -8.22316348e-09, -5.50180479e-09,  5.30584998e-09,  7.26027727e-09],\n",
      "      dtype=float32), array([[-0.05370013,  0.11927529,  0.09617958, ...,  0.01798584,\n",
      "        -0.00310857,  0.03737685],\n",
      "       [-0.04836836, -0.19802086,  0.03484767, ..., -0.00269383,\n",
      "        -0.00794215, -0.01138174],\n",
      "       [-0.00176875, -0.00173084,  0.02117104, ...,  0.1461284 ,\n",
      "        -0.34226513,  0.04263593],\n",
      "       ...,\n",
      "       [ 0.00608899,  0.05552896, -0.05432529, ..., -0.00651735,\n",
      "        -0.16451113,  0.09778352],\n",
      "       [-0.15056907,  0.13736439, -0.24842305, ...,  0.02500489,\n",
      "         0.00289763, -0.01568714],\n",
      "       [-0.02755734,  0.04672833,  0.02930036, ..., -0.05814525,\n",
      "         0.11398808,  0.05398485]], dtype=float32))\n",
      "(array([ 4.97655762e+02,  7.69798636e-01,  5.11099875e-01,  1.71169192e-01,\n",
      "        5.41957170e-02,  4.15901244e-02,  3.89241092e-02,  2.58634891e-02,\n",
      "        1.93992704e-02,  6.17176481e-03,  4.07384057e-03,  3.70295811e-03,\n",
      "        2.75956187e-03,  2.03982065e-03,  1.52074639e-03,  1.27730332e-03,\n",
      "        1.09758670e-03,  1.01361820e-03,  6.95751631e-04,  6.10733405e-04,\n",
      "        5.43947157e-04,  3.26232053e-04,  3.12470074e-04,  2.90181255e-04,\n",
      "        2.14339132e-04,  1.94887951e-04,  1.71655702e-04,  1.47221523e-04,\n",
      "        1.18048600e-04,  9.44073545e-05,  8.25232200e-05,  6.60355581e-05,\n",
      "        5.95691781e-05,  5.40516448e-05,  4.18379022e-05,  3.66687673e-05,\n",
      "        3.23105123e-05,  2.98202503e-05,  2.26244283e-05,  1.94923941e-05,\n",
      "        1.64611483e-05, -1.18372591e-05, -1.00886155e-05,  1.34617658e-05,\n",
      "        1.15683497e-05,  1.06022544e-05,  1.00795678e-05,  8.86560974e-06,\n",
      "       -5.70480415e-06,  7.17965304e-06,  6.32787533e-06,  5.86328360e-06,\n",
      "       -4.46444710e-06,  4.99584985e-06,  4.42861028e-06,  3.75180571e-06,\n",
      "        3.49133984e-06, -3.81859127e-06, -3.39982034e-06, -2.91938090e-06,\n",
      "        2.75635830e-06,  2.37220047e-06, -2.31466015e-06, -2.02641513e-06,\n",
      "        2.04834691e-06, -1.84519456e-06, -1.32507512e-06,  1.66276902e-06,\n",
      "        1.43259297e-06, -1.16805768e-06,  1.22248809e-06,  1.10981387e-06,\n",
      "       -9.31774025e-07,  1.05406332e-06,  8.35727064e-07, -6.89743047e-07,\n",
      "        6.84139650e-07,  6.51183370e-07, -5.57678675e-07,  6.05867058e-07,\n",
      "       -5.14814019e-07, -4.52657957e-07, -3.69377773e-07,  4.87287082e-07,\n",
      "        4.20803332e-07,  3.78375432e-07,  2.80259684e-07, -2.81433358e-07,\n",
      "       -2.77196705e-07,  2.26533302e-07,  1.95956261e-07, -1.98933662e-07,\n",
      "       -1.83962257e-07,  1.70711942e-07, -1.67376029e-07, -1.53881984e-07,\n",
      "       -1.13605921e-07,  1.28757463e-07,  1.06283196e-07, -7.14667294e-08,\n",
      "        8.25127628e-08,  7.47358655e-08, -4.99526429e-08,  5.78242911e-08,\n",
      "        4.88306036e-08, -3.98340561e-08,  4.16601083e-08,  2.87661592e-08,\n",
      "       -2.81176860e-08, -2.52528221e-08, -1.63403744e-08,  2.22225136e-08,\n",
      "        1.93356247e-08,  1.21030084e-08, -9.32668787e-09, -4.84930895e-09,\n",
      "       -4.15196633e-09, -7.18695714e-10,  4.97865527e-09,  2.07150586e-09],\n",
      "      dtype=float32), array([[-0.06089295,  0.01462428, -0.05068727, ...,  0.01705451,\n",
      "        -0.01258415,  0.02516127],\n",
      "       [-0.0494236 ,  0.18053521,  0.09446006, ...,  0.02535834,\n",
      "         0.05124629, -0.02838825],\n",
      "       [-0.00227886,  0.00545574, -0.0213052 , ..., -0.12533149,\n",
      "         0.09176829,  0.11316189],\n",
      "       ...,\n",
      "       [ 0.00543785, -0.03361176, -0.00747617, ..., -0.10060192,\n",
      "         0.04952371,  0.09853359],\n",
      "       [-0.15236233, -0.24951267,  0.11972345, ..., -0.00387607,\n",
      "         0.00898753, -0.0006688 ],\n",
      "       [-0.02950836, -0.02230306, -0.01186235, ...,  0.05391036,\n",
      "         0.05510172,  0.00866727]], dtype=float32))\n",
      "(array([ 3.9948203e+02,  1.5424167e+00,  7.8976375e-01,  2.5016299e-01,\n",
      "        9.4019875e-02,  8.6345665e-02,  3.9579242e-02,  3.3216320e-02,\n",
      "        2.3584297e-02,  1.4211299e-02,  1.0787049e-02,  5.4198639e-03,\n",
      "        4.1967318e-03,  3.2903904e-03,  2.5004286e-03,  2.1926335e-03,\n",
      "        1.7698220e-03,  1.5882660e-03,  1.3432435e-03,  1.0159418e-03,\n",
      "        8.5317210e-04,  5.4919539e-04,  5.0737080e-04,  4.3268054e-04,\n",
      "        3.6397684e-04,  3.2564969e-04,  2.8739349e-04,  1.8931898e-04,\n",
      "        1.6455929e-04,  1.5803150e-04,  1.2789290e-04,  1.0271166e-04,\n",
      "        9.2339949e-05,  7.8645062e-05,  6.4068648e-05,  5.4645632e-05,\n",
      "        5.0309027e-05,  4.2457119e-05,  3.3906170e-05,  2.8403947e-05,\n",
      "        2.6902275e-05,  2.2596138e-05,  1.8580520e-05, -1.0510484e-05,\n",
      "        1.2984028e-05,  1.1991374e-05, -8.2745501e-06,  9.3022618e-06,\n",
      "        8.2056204e-06, -6.7061546e-06,  7.3701767e-06,  5.7730767e-06,\n",
      "        4.8739757e-06,  4.3819787e-06,  3.7330187e-06, -3.1829281e-06,\n",
      "       -3.1473307e-06,  2.8739785e-06,  2.5148959e-06, -2.3070822e-06,\n",
      "       -2.1159271e-06, -1.7299384e-06,  1.9804697e-06,  1.8650729e-06,\n",
      "       -1.2979683e-06,  1.4300289e-06,  1.3729378e-06, -9.9643808e-07,\n",
      "        1.1029467e-06,  1.0361749e-06, -8.9936026e-07,  8.3265650e-07,\n",
      "       -6.9635780e-07,  5.9388742e-07,  5.3116423e-07, -6.2681755e-07,\n",
      "       -5.2472518e-07, -4.5950370e-07,  4.4390896e-07,  3.9400302e-07,\n",
      "       -3.8662867e-07, -3.6753551e-07,  3.5024115e-07, -3.0513948e-07,\n",
      "        2.8716985e-07,  2.6181371e-07, -2.7055637e-07, -2.2156813e-07,\n",
      "       -1.9048512e-07, -1.5204188e-07,  2.1305630e-07,  1.8756938e-07,\n",
      "        1.7910428e-07, -1.2721928e-07,  1.5492627e-07,  1.2807430e-07,\n",
      "        1.1927055e-07, -8.4979114e-08, -9.5707371e-08,  8.6039428e-08,\n",
      "       -7.0542562e-08,  6.5349610e-08,  5.5074644e-08, -4.7603510e-08,\n",
      "        4.1726356e-08, -3.2677114e-08, -3.7215671e-08,  3.0160034e-08,\n",
      "       -2.4528720e-08,  2.8766015e-08, -1.9701686e-08,  1.9742519e-08,\n",
      "        1.4170153e-08,  7.2516650e-09,  5.3223888e-09,  2.5040832e-09,\n",
      "       -9.4741015e-10, -7.7067845e-09, -6.8731008e-09, -3.8436005e-09],\n",
      "      dtype=float32), array([[ 5.37855625e-02,  3.50755937e-02,  1.79920509e-01, ...,\n",
      "         5.66855632e-03, -2.67800465e-02,  4.09624539e-03],\n",
      "       [ 4.48199138e-02,  1.33894488e-01, -1.56334206e-01, ...,\n",
      "         2.35326309e-02, -2.91046370e-02, -1.67417421e-03],\n",
      "       [ 1.43892423e-03,  8.96881986e-03,  1.23185534e-02, ...,\n",
      "        -7.41045401e-02,  8.46552327e-02,  6.70488402e-02],\n",
      "       ...,\n",
      "       [ 1.18886375e-04,  2.19403114e-03,  7.56589919e-02, ...,\n",
      "        -5.65642724e-03,  1.12408720e-01,  4.56887595e-02],\n",
      "       [ 1.44307986e-01, -2.55634725e-01, -1.88484788e-02, ...,\n",
      "        -2.25044489e-02,  1.06387958e-02,  9.84934159e-03],\n",
      "       [ 2.51380578e-02, -1.75707620e-02,  2.85039879e-02, ...,\n",
      "        -4.14371714e-02,  8.46218392e-02,  4.17432515e-03]], dtype=float32))\n",
      "(array([ 3.02503479e+02,  1.57194734e+00,  7.08539248e-01,  2.32141629e-01,\n",
      "        1.57003254e-01,  1.05187565e-01,  3.29689682e-02,  3.07503622e-02,\n",
      "        2.30448004e-02,  1.49554871e-02,  1.11689437e-02,  6.95296470e-03,\n",
      "        4.83418163e-03,  3.22521385e-03,  2.67060311e-03,  2.08684965e-03,\n",
      "        1.50259642e-03,  1.15661847e-03,  1.00984995e-03,  8.87820031e-04,\n",
      "        6.33737014e-04,  5.76242455e-04,  4.38293559e-04,  3.20000516e-04,\n",
      "        2.29872108e-04,  1.87271464e-04,  1.52069450e-04,  1.29940658e-04,\n",
      "        1.13987357e-04,  9.44608837e-05,  6.83021863e-05,  5.99551531e-05,\n",
      "        5.05062599e-05,  4.45482256e-05,  4.00916360e-05,  3.85454186e-05,\n",
      "        2.84492635e-05,  2.52515620e-05,  2.11110346e-05,  1.76916947e-05,\n",
      "        1.15914872e-05, -6.92512276e-06,  9.31924569e-06,  8.99431416e-06,\n",
      "        7.70165025e-06, -5.25411133e-06,  6.52488961e-06,  5.89398269e-06,\n",
      "        4.96239318e-06,  4.73614637e-06, -3.33313778e-06, -2.74480362e-06,\n",
      "        3.78674213e-06,  3.47218656e-06,  2.70710257e-06,  2.58286695e-06,\n",
      "       -2.25641315e-06,  2.31694344e-06, -1.75755724e-06,  1.87368289e-06,\n",
      "        1.59174954e-06,  1.45319279e-06, -1.35928292e-06, -1.25457382e-06,\n",
      "       -9.64015726e-07,  1.10554970e-06,  1.05848892e-06, -8.24249184e-07,\n",
      "        8.51456321e-07, -7.43048531e-07,  7.95032008e-07,  7.49527203e-07,\n",
      "       -6.27660199e-07,  6.10027939e-07,  5.64916832e-07, -5.30597390e-07,\n",
      "       -4.78039624e-07,  3.84896225e-07,  3.36625050e-07, -3.76722596e-07,\n",
      "       -3.49021235e-07,  3.11509524e-07,  2.71162463e-07,  2.60603713e-07,\n",
      "       -2.10284824e-07,  2.22596654e-07,  1.91048258e-07, -1.89390462e-07,\n",
      "       -1.51303439e-07, -1.37337622e-07,  1.65346975e-07,  1.34803585e-07,\n",
      "        1.03410201e-07,  8.99685020e-08, -9.83977841e-08, -8.63046239e-08,\n",
      "       -8.82154296e-08,  7.11124599e-08, -7.19530320e-08,  5.98569159e-08,\n",
      "       -4.77104152e-08,  4.44858976e-08,  4.14554435e-08, -3.79563261e-08,\n",
      "        3.24723075e-08, -3.10735864e-08,  2.09437214e-08,  1.29908182e-08,\n",
      "        1.02630633e-08,  3.29649263e-09,  7.23927540e-09, -2.16684128e-08,\n",
      "       -2.25465939e-08,  4.20860946e-09, -2.15844942e-09, -1.13571830e-09,\n",
      "       -3.98599109e-09, -6.73152956e-09, -1.30154492e-08, -8.95071839e-09],\n",
      "      dtype=float32), array([[ 0.05474608,  0.05447533,  0.04588949, ...,  0.02765434,\n",
      "        -0.02874003, -0.00072729],\n",
      "       [ 0.04468558,  0.08660882, -0.16570711, ..., -0.03135146,\n",
      "        -0.02924875,  0.04064083],\n",
      "       [ 0.00113811,  0.03193993,  0.00857915, ..., -0.16563034,\n",
      "         0.13851054, -0.15009725],\n",
      "       ...,\n",
      "       [ 0.00326597, -0.0050341 ,  0.0176751 , ..., -0.07943357,\n",
      "         0.15171984,  0.00675134],\n",
      "       [ 0.13056526, -0.2234425 ,  0.11479203, ..., -0.0133629 ,\n",
      "         0.00473137, -0.0049153 ],\n",
      "       [ 0.02091851, -0.01097292,  0.01495911, ..., -0.00995977,\n",
      "         0.0674775 ,  0.11541393]], dtype=float32))\n",
      "(array([ 2.89610535e+02,  4.87215787e-01,  2.46146232e-01,  9.22002941e-02,\n",
      "        3.56865823e-02,  3.08806188e-02,  2.51736306e-02,  1.29256118e-02,\n",
      "        6.30148640e-03,  5.05758729e-03,  2.65798811e-03,  1.98837370e-03,\n",
      "        1.74190255e-03,  1.06096279e-03,  7.87663041e-04,  6.03899243e-04,\n",
      "        5.77900326e-04,  4.35590773e-04,  3.25249304e-04,  2.54858838e-04,\n",
      "        2.23568059e-04,  1.96279638e-04,  1.43813377e-04,  1.23280857e-04,\n",
      "        1.10808607e-04,  9.39312886e-05,  6.54822288e-05,  6.19037892e-05,\n",
      "        5.12354236e-05,  4.80606068e-05,  4.24459213e-05,  3.32100462e-05,\n",
      "        2.50327303e-05,  2.34804302e-05,  1.90906139e-05,  1.78047176e-05,\n",
      "        1.62751530e-05,  1.38520090e-05,  1.15998801e-05,  1.09297962e-05,\n",
      "        9.77982018e-06, -6.90213210e-06,  8.59498505e-06, -6.05263540e-06,\n",
      "        7.22992581e-06,  6.53544203e-06, -4.37458311e-06,  5.19976675e-06,\n",
      "        4.58930117e-06, -3.64505331e-06,  3.17422928e-06,  3.07911023e-06,\n",
      "       -2.59572244e-06, -2.28583531e-06,  2.48796437e-06,  2.45665296e-06,\n",
      "        2.26527209e-06,  1.99870124e-06, -1.40192776e-06, -1.23543271e-06,\n",
      "        1.57829072e-06,  1.42206216e-06,  1.23788129e-06,  9.89225896e-07,\n",
      "       -9.81939365e-07, -9.16169938e-07,  8.67638278e-07, -7.20699461e-07,\n",
      "       -5.84200109e-07,  7.10026427e-07,  6.55203110e-07,  5.04292814e-07,\n",
      "       -4.35606836e-07, -4.13230737e-07,  4.56478347e-07,  4.13135240e-07,\n",
      "        3.29719768e-07, -3.14321966e-07, -2.93723218e-07, -2.64024663e-07,\n",
      "        3.19964528e-07, -2.11530562e-07, -1.90109105e-07,  2.79249832e-07,\n",
      "        2.56483759e-07,  2.31510299e-07,  2.10869999e-07,  1.77615405e-07,\n",
      "        1.71427558e-07, -1.38962150e-07, -1.24183529e-07, -1.09060394e-07,\n",
      "       -8.89398351e-08,  1.23337728e-07,  1.12411364e-07,  1.05437351e-07,\n",
      "        9.02160053e-08, -6.50256951e-08, -5.57206441e-08, -4.73710280e-08,\n",
      "        6.44791456e-08,  5.61091476e-08,  4.77377071e-08,  4.63626719e-08,\n",
      "        3.18153575e-08, -3.76740132e-08, -3.25123146e-08, -2.72830221e-08,\n",
      "       -1.88672509e-08,  1.77127646e-08,  1.60683697e-08,  1.30219542e-08,\n",
      "        1.09406590e-08, -1.35211558e-08, -9.49405710e-09,  2.61703259e-09,\n",
      "       -1.07520459e-09, -2.55275157e-09, -3.96339139e-09, -4.08410195e-09],\n",
      "      dtype=float32), array([[-0.05110036,  0.07004762,  0.14149223, ..., -0.014011  ,\n",
      "         0.01160168,  0.00487878],\n",
      "       [-0.03983327,  0.06357953, -0.14356326, ..., -0.04410164,\n",
      "        -0.04657472, -0.03332586],\n",
      "       [ 0.00094711,  0.03966786,  0.03025188, ..., -0.3485521 ,\n",
      "        -0.11762714,  0.06371421],\n",
      "       ...,\n",
      "       [-0.00714623, -0.00292736,  0.03914446, ..., -0.06369815,\n",
      "        -0.00349285, -0.02512877],\n",
      "       [-0.12880206, -0.21852238,  0.07971324, ..., -0.01113868,\n",
      "         0.00947792, -0.00489771],\n",
      "       [-0.01790655,  0.00725767,  0.06490868, ..., -0.0372568 ,\n",
      "         0.02930829,  0.07596903]], dtype=float32))\n",
      "(array([ 2.96461090e+02,  1.70984256e+00,  5.47531009e-01,  2.70890415e-01,\n",
      "        2.36732766e-01,  1.21142223e-01,  7.06497878e-02,  6.05915040e-02,\n",
      "        4.18564230e-02,  2.58085784e-02,  1.72802191e-02,  8.29927623e-03,\n",
      "        6.59647258e-03,  4.14714823e-03,  3.53242666e-03,  3.09602614e-03,\n",
      "        2.64456798e-03,  2.39312486e-03,  1.82645151e-03,  1.40047388e-03,\n",
      "        1.21641473e-03,  1.14639662e-03,  8.56358092e-04,  7.99185887e-04,\n",
      "        7.12105189e-04,  4.62183758e-04,  4.50266438e-04,  3.53310839e-04,\n",
      "        3.33683041e-04,  3.18606151e-04,  2.41718473e-04,  2.25631156e-04,\n",
      "        1.95058645e-04,  1.65715741e-04,  1.61880307e-04,  1.23340869e-04,\n",
      "        1.18245356e-04,  9.07428475e-05,  8.20957575e-05,  7.27067090e-05,\n",
      "        6.70810186e-05,  6.33041564e-05,  5.17250737e-05,  4.50905973e-05,\n",
      "        3.63600848e-05,  3.34350370e-05,  2.20499624e-05,  1.83194170e-05,\n",
      "        1.21055609e-05,  9.41120834e-06,  8.23993651e-06, -5.92891138e-06,\n",
      "        4.80929202e-06, -3.80277993e-06,  3.47260561e-06, -3.26511099e-06,\n",
      "        2.96127564e-06, -2.89942977e-06,  2.31829313e-06, -2.09220980e-06,\n",
      "       -1.72703812e-06,  1.77352797e-06, -1.43561442e-06,  1.43900661e-06,\n",
      "        1.26014231e-06, -1.14456577e-06,  9.10945346e-07, -8.14750763e-07,\n",
      "        6.96991378e-07,  6.54974372e-07, -6.86694136e-07, -6.10088932e-07,\n",
      "       -5.45550733e-07,  4.49228367e-07,  4.18897287e-07, -4.54335606e-07,\n",
      "       -4.13570461e-07, -3.80816061e-07, -3.38322451e-07,  3.41316280e-07,\n",
      "        3.18831439e-07,  3.06464301e-07, -2.90289790e-07,  2.47040958e-07,\n",
      "        1.97349578e-07,  1.75199986e-07,  1.63542069e-07, -2.09333805e-07,\n",
      "       -2.20243166e-07, -1.78837624e-07, -1.52343659e-07,  1.42230192e-07,\n",
      "        1.25986489e-07, -1.09674041e-07,  9.82347999e-08, -9.50113872e-08,\n",
      "        9.39594713e-08, -8.07827618e-08,  6.84244910e-08, -6.28166319e-08,\n",
      "       -4.84624181e-08, -4.66879477e-08, -3.52311531e-08,  4.59777567e-08,\n",
      "        4.03885920e-08,  3.35336345e-08,  2.76372116e-08, -2.90366948e-08,\n",
      "       -2.23710153e-08,  1.51890429e-08, -4.21828600e-10,  7.55226814e-09,\n",
      "        5.24929389e-09,  2.13715889e-08,  1.89509564e-08,  1.30510247e-09,\n",
      "       -4.93301178e-09, -1.33402187e-08, -9.15002030e-09, -1.23524861e-08],\n",
      "      dtype=float32), array([[ 5.66880852e-02, -2.20002085e-02, -1.53458253e-01, ...,\n",
      "         2.61829868e-02,  1.05694607e-02, -1.64595069e-04],\n",
      "       [ 5.03398329e-02, -7.78932944e-02,  1.50916532e-01, ...,\n",
      "         4.07341719e-02, -2.14892253e-02,  7.53682703e-02],\n",
      "       [ 1.72667857e-03, -2.39363480e-02, -3.54618132e-02, ...,\n",
      "         2.83561684e-02, -9.04472768e-02, -9.44575574e-03],\n",
      "       ...,\n",
      "       [-2.47687945e-04,  6.31342530e-02, -5.18053174e-02, ...,\n",
      "        -7.66744390e-02,  5.10445461e-02,  2.69790851e-02],\n",
      "       [ 1.33294731e-01,  1.86271414e-01, -1.04652867e-01, ...,\n",
      "         1.68797513e-03, -1.24391625e-02, -1.08456509e-02],\n",
      "       [ 2.42364630e-02,  2.04842445e-02, -5.00496887e-02, ...,\n",
      "         6.98712990e-02, -9.45203064e-04, -8.97861458e-03]], dtype=float32))\n",
      "(array([ 4.66579285e+02,  2.24602795e+00,  7.71089911e-01,  4.30882096e-01,\n",
      "        3.09155852e-01,  2.40090281e-01,  5.39516695e-02,  4.56148870e-02,\n",
      "        4.50491607e-02,  3.20146717e-02,  1.46660730e-02,  1.23853898e-02,\n",
      "        9.24256910e-03,  5.99499978e-03,  5.31745143e-03,  3.76681797e-03,\n",
      "        2.91854190e-03,  2.85454141e-03,  2.25062924e-03,  1.89271406e-03,\n",
      "        1.73515093e-03,  1.51869853e-03,  1.17026037e-03,  9.78716183e-04,\n",
      "        8.54149868e-04,  7.22912897e-04,  5.94994519e-04,  5.00559981e-04,\n",
      "        4.19155142e-04,  4.02704551e-04,  3.47987487e-04,  2.77079060e-04,\n",
      "        2.56662403e-04,  2.25265263e-04,  1.84817982e-04,  1.61748496e-04,\n",
      "        1.35226815e-04,  1.09025037e-04,  9.83893842e-05,  8.53545571e-05,\n",
      "        8.09057019e-05,  6.06236499e-05,  5.37431006e-05,  3.86409411e-05,\n",
      "        3.23148670e-05,  3.06115689e-05,  2.41854195e-05,  2.05175820e-05,\n",
      "        1.74857742e-05, -1.34667325e-05,  1.41474356e-05,  1.11772715e-05,\n",
      "       -8.47671981e-06,  7.41512167e-06, -5.32570357e-06,  5.96396103e-06,\n",
      "       -4.24076097e-06,  4.57513534e-06,  4.10368102e-06, -3.39351459e-06,\n",
      "       -2.79772598e-06, -2.69560405e-06,  2.66911093e-06,  2.70136525e-06,\n",
      "       -2.15849605e-06, -1.81541986e-06,  1.85007036e-06,  1.63315451e-06,\n",
      "       -1.57489762e-06, -1.37989548e-06,  1.23445773e-06, -1.19143522e-06,\n",
      "       -1.07862763e-06, -7.95229539e-07,  1.12543512e-06,  1.01891305e-06,\n",
      "        9.09142670e-07,  7.51087953e-07,  6.80123662e-07, -6.57498333e-07,\n",
      "        5.87802162e-07,  5.47902232e-07, -5.53089649e-07, -4.54348537e-07,\n",
      "       -4.11019954e-07, -3.66244933e-07,  4.17455823e-07,  3.89934570e-07,\n",
      "        3.03338339e-07, -2.26024170e-07, -2.03633675e-07,  2.00603012e-07,\n",
      "        1.88187684e-07, -1.62010480e-07, -1.15993913e-07,  1.23251795e-07,\n",
      "       -9.78558887e-08,  1.02860994e-07,  9.19583840e-08, -8.71926602e-08,\n",
      "        6.77157530e-08,  5.81829624e-08, -7.37716022e-08, -6.32048298e-08,\n",
      "       -5.05562454e-08,  4.49542625e-08, -3.83428933e-08,  2.49841037e-08,\n",
      "       -2.45193803e-08,  2.05216271e-08,  1.46925032e-08, -1.90523952e-08,\n",
      "        6.97553038e-09,  5.16009102e-09,  2.86023605e-09, -1.84884597e-09,\n",
      "       -5.79538462e-09, -4.66471395e-09, -1.00118029e-08, -1.47267132e-08],\n",
      "      dtype=float32), array([[ 0.04985457,  0.10949871,  0.1325635 , ..., -0.0147405 ,\n",
      "         0.00336353, -0.06322075],\n",
      "       [ 0.04829263, -0.02985699, -0.23409116, ...,  0.01827766,\n",
      "        -0.08083517, -0.05052272],\n",
      "       [-0.00047339, -0.02574963,  0.02591723, ..., -0.13400659,\n",
      "         0.16786285, -0.07098834],\n",
      "       ...,\n",
      "       [ 0.00525297,  0.10077497,  0.08700976, ..., -0.02008883,\n",
      "         0.02143516,  0.08111592],\n",
      "       [ 0.16541676, -0.04495068,  0.02255187, ..., -0.00695763,\n",
      "         0.0097587 ,  0.00790924],\n",
      "       [ 0.03563365, -0.05722151,  0.09271466, ..., -0.09872376,\n",
      "         0.09817866,  0.09474698]], dtype=float32))\n",
      "(array([ 3.96041443e+02,  4.73015022e+00,  1.01991296e+00,  2.81250417e-01,\n",
      "        9.01609957e-02,  8.32777619e-02,  5.20640649e-02,  2.51155421e-02,\n",
      "        1.33255823e-02,  1.15965726e-02,  1.01553593e-02,  7.98880961e-03,\n",
      "        5.65872621e-03,  5.55499690e-03,  4.07125754e-03,  3.53877083e-03,\n",
      "        2.31573195e-03,  2.24395259e-03,  1.24872080e-03,  1.15469331e-03,\n",
      "        9.24064545e-04,  8.89128947e-04,  6.86575891e-04,  6.63155981e-04,\n",
      "        4.78053320e-04,  4.11869027e-04,  3.72285751e-04,  3.13226483e-04,\n",
      "        2.50545330e-04,  1.95523215e-04,  1.89139930e-04,  1.47609971e-04,\n",
      "        1.39910713e-04,  9.99731637e-05,  9.09953960e-05,  7.81681301e-05,\n",
      "        7.41415934e-05,  4.90199600e-05,  3.82163489e-05,  3.40695042e-05,\n",
      "        2.90084481e-05,  2.46186610e-05,  2.19855665e-05,  1.77685615e-05,\n",
      "        1.44132855e-05,  1.27367503e-05, -8.26494943e-06,  1.12812149e-05,\n",
      "        1.02390568e-05, -6.26929204e-06,  6.83131520e-06,  6.73464046e-06,\n",
      "        5.71681403e-06, -4.84911880e-06,  4.78612174e-06, -3.49333709e-06,\n",
      "        4.19663183e-06,  3.63165077e-06, -2.92542404e-06,  2.89392301e-06,\n",
      "        2.43517843e-06, -2.18707623e-06, -2.11234328e-06,  1.96827432e-06,\n",
      "        1.86477791e-06, -1.74251932e-06, -1.56044689e-06,  1.42353758e-06,\n",
      "       -1.28940110e-06, -1.26520706e-06,  1.24574103e-06,  1.10810970e-06,\n",
      "        9.97535949e-07, -8.47200397e-07, -7.65758671e-07,  7.13780196e-07,\n",
      "        6.92078174e-07, -6.46519140e-07, -5.59703494e-07, -4.43073333e-07,\n",
      "        5.87650618e-07,  5.33101002e-07,  5.07044945e-07,  3.74867454e-07,\n",
      "       -4.73525233e-07, -3.97691650e-07, -3.90662734e-07, -2.89605850e-07,\n",
      "        2.71384039e-07, -2.18775000e-07,  2.24119077e-07,  2.11412498e-07,\n",
      "        1.78422411e-07, -1.60968312e-07, -1.64985053e-07,  1.36985520e-07,\n",
      "        1.32524448e-07, -1.27293717e-07, -1.11908818e-07, -9.09553393e-08,\n",
      "        1.05732795e-07,  9.80849393e-08,  8.08509810e-08, -7.02345062e-08,\n",
      "       -5.45975176e-08, -3.72769762e-08,  6.41959872e-08,  4.60843772e-08,\n",
      "        3.82420744e-08,  1.83232292e-08,  2.92152116e-08,  2.73118825e-08,\n",
      "        6.04401107e-09,  1.95701699e-09, -6.96508673e-09, -4.09138723e-09,\n",
      "       -1.57570526e-08, -2.35033148e-08, -2.41716815e-08, -1.95127328e-08],\n",
      "      dtype=float32), array([[-0.04556126,  0.08187875,  0.05737524, ...,  0.07958104,\n",
      "        -0.00498839, -0.01808437],\n",
      "       [-0.05235595, -0.00942731, -0.1816683 , ..., -0.05778818,\n",
      "         0.03911891,  0.07818392],\n",
      "       [-0.00489386, -0.04146745,  0.06185971, ..., -0.11296801,\n",
      "         0.11152773, -0.13467292],\n",
      "       ...,\n",
      "       [ 0.01513727,  0.10722722,  0.02918788, ..., -0.08698881,\n",
      "         0.02475761,  0.04153365],\n",
      "       [-0.17581561, -0.00404708,  0.11234486, ...,  0.02059327,\n",
      "         0.0011272 , -0.02027774],\n",
      "       [-0.0471023 , -0.06946813,  0.03887208, ..., -0.05245594,\n",
      "         0.05643548, -0.05763399]], dtype=float32))\n",
      "(array([ 3.68072235e+02,  2.35155082e+00,  8.69866192e-01,  2.31437922e-01,\n",
      "        1.19072542e-01,  6.78325519e-02,  4.23935987e-02,  3.16367038e-02,\n",
      "        2.41245553e-02,  1.38399918e-02,  1.18323490e-02,  1.01711517e-02,\n",
      "        6.19033724e-03,  5.03285881e-03,  3.78611428e-03,  3.57155479e-03,\n",
      "        2.36830278e-03,  2.13216548e-03,  1.56995072e-03,  1.26166979e-03,\n",
      "        1.19367521e-03,  6.03622990e-04,  5.51102799e-04,  4.81412280e-04,\n",
      "        4.05100494e-04,  3.75725271e-04,  3.01284861e-04,  2.13651845e-04,\n",
      "        1.84456556e-04,  1.64140511e-04,  1.37538169e-04,  1.25299353e-04,\n",
      "        1.03679209e-04,  8.77208222e-05,  8.72322926e-05,  6.58353456e-05,\n",
      "        5.33882267e-05,  5.12521801e-05,  4.76114838e-05,  4.21211589e-05,\n",
      "        3.44221771e-05,  2.86413233e-05,  2.35725256e-05,  2.09037753e-05,\n",
      "        1.88158956e-05,  1.35220052e-05,  1.18563221e-05,  8.76534159e-06,\n",
      "        7.46820433e-06, -6.62049024e-06,  6.33934042e-06, -5.80247251e-06,\n",
      "       -4.94740016e-06,  4.37326889e-06, -4.16210651e-06,  3.87283808e-06,\n",
      "        2.80869699e-06,  2.46175568e-06, -2.85185865e-06, -2.77456138e-06,\n",
      "       -2.31227182e-06, -1.95597249e-06,  2.05078845e-06,  1.86308910e-06,\n",
      "        1.52931068e-06,  1.39586325e-06,  1.27504620e-06, -1.31351374e-06,\n",
      "        1.08294580e-06, -1.05455683e-06, -1.00218836e-06,  9.53966946e-07,\n",
      "       -8.21656897e-07,  8.26551741e-07, -6.76187540e-07,  7.42819225e-07,\n",
      "        6.86953967e-07, -5.83131282e-07,  6.00084434e-07,  5.76891807e-07,\n",
      "        5.02280045e-07, -5.20392121e-07, -4.84563145e-07, -4.11791547e-07,\n",
      "       -4.09128091e-07,  4.36188941e-07, -3.05191179e-07,  3.32892199e-07,\n",
      "        2.99849859e-07,  2.28147329e-07, -2.22965809e-07, -2.02596965e-07,\n",
      "        1.84651114e-07, -1.80992103e-07, -1.51765846e-07, -1.32923276e-07,\n",
      "        1.65282103e-07,  1.53939183e-07,  1.28906009e-07, -1.00613263e-07,\n",
      "        8.55067483e-08, -7.27694385e-08, -4.32789662e-08,  6.94598796e-08,\n",
      "        6.46472955e-08,  5.59031434e-08,  5.01809048e-08, -3.77253748e-08,\n",
      "        3.24161959e-08,  2.80289871e-08,  1.19367645e-08, -2.71427876e-08,\n",
      "       -2.44752503e-08, -1.67616285e-08, -1.29647812e-08, -1.08064286e-08,\n",
      "       -7.59732632e-09,  5.33759126e-09, -1.62366132e-09,  1.94781702e-09],\n",
      "      dtype=float32), array([[ 0.04247301, -0.16132183,  0.02488888, ...,  0.05209557,\n",
      "        -0.0268712 ,  0.02237922],\n",
      "       [ 0.05253769, -0.01251895, -0.19274107, ...,  0.01318747,\n",
      "         0.02906475, -0.03072365],\n",
      "       [ 0.00491222,  0.01094454,  0.04972496, ..., -0.19427736,\n",
      "        -0.19386473, -0.16660875],\n",
      "       ...,\n",
      "       [-0.01500991, -0.03224163,  0.03605549, ...,  0.10770769,\n",
      "        -0.01243167, -0.07473898],\n",
      "       [ 0.1692101 , -0.04128425,  0.10258716, ..., -0.01192878,\n",
      "         0.00281   , -0.00390011],\n",
      "       [ 0.0450042 ,  0.03714788,  0.04497937, ...,  0.125103  ,\n",
      "         0.04049546, -0.02195583]], dtype=float32))\n",
      "(array([ 3.91330322e+02,  2.15956259e+00,  1.08144367e+00,  6.35391951e-01,\n",
      "        1.95150539e-01,  8.56583193e-02,  3.88107970e-02,  3.24372724e-02,\n",
      "        2.52338611e-02,  1.92598589e-02,  1.57575253e-02,  1.27811152e-02,\n",
      "        9.77865141e-03,  5.71746659e-03,  4.80824756e-03,  4.10563918e-03,\n",
      "        3.72975622e-03,  3.01280874e-03,  1.97923137e-03,  1.66130753e-03,\n",
      "        1.12643733e-03,  1.10337918e-03,  9.35599150e-04,  7.71799707e-04,\n",
      "        6.12427248e-04,  4.97358385e-04,  4.36896720e-04,  4.09643922e-04,\n",
      "        3.24395834e-04,  2.92433106e-04,  2.69679032e-04,  2.24611882e-04,\n",
      "        1.92406675e-04,  1.90541992e-04,  1.26064755e-04,  1.17970303e-04,\n",
      "        9.31328759e-05,  7.58159076e-05,  6.88471773e-05,  6.39062855e-05,\n",
      "        4.85647652e-05,  4.68652979e-05,  3.71016395e-05,  3.18985549e-05,\n",
      "        2.63992624e-05,  2.40354057e-05,  1.80630050e-05,  1.24338594e-05,\n",
      "       -1.05749095e-05,  8.92190747e-06, -7.31555974e-06,  7.57583211e-06,\n",
      "       -6.19755929e-06,  6.23000687e-06,  5.75772538e-06, -5.24842926e-06,\n",
      "        3.85454859e-06,  3.54857320e-06, -3.09488473e-06,  2.80802237e-06,\n",
      "        2.42166334e-06, -2.40943450e-06, -2.19297999e-06, -1.84599025e-06,\n",
      "        1.83725058e-06,  1.58943419e-06, -1.49218386e-06, -1.16666774e-06,\n",
      "        1.23290658e-06,  1.13279771e-06,  9.83886252e-07, -9.68952122e-07,\n",
      "       -8.59187821e-07, -7.99496092e-07,  8.03520379e-07,  7.83955727e-07,\n",
      "       -7.77132641e-07, -6.65340622e-07,  6.26042208e-07,  5.65985374e-07,\n",
      "       -5.25993187e-07, -5.03663500e-07,  4.44379822e-07, -3.58907783e-07,\n",
      "        3.59814891e-07,  3.40789370e-07,  3.28267674e-07,  2.93818772e-07,\n",
      "        2.30453452e-07,  2.01375656e-07, -2.52245627e-07, -2.15580343e-07,\n",
      "       -2.26381488e-07,  1.79919539e-07, -1.78528694e-07, -1.70562188e-07,\n",
      "       -1.45807817e-07,  1.40113499e-07, -1.08373598e-07,  1.03370198e-07,\n",
      "        7.54203882e-08, -9.06108681e-08, -7.68019888e-08,  6.29273771e-08,\n",
      "       -5.38439409e-08,  4.88906267e-08, -4.72422741e-08,  4.09605789e-08,\n",
      "        3.55718122e-08, -3.10426316e-08, -2.42946712e-08,  2.43311344e-08,\n",
      "       -1.93446166e-08, -1.36263187e-08, -6.24171426e-09, -4.06095629e-10,\n",
      "       -3.98007807e-11,  1.05213367e-08,  4.28506874e-09,  7.56773844e-09],\n",
      "      dtype=float32), array([[ 0.04407584, -0.08479355, -0.07933262, ..., -0.01219764,\n",
      "        -0.01623284,  0.03203833],\n",
      "       [ 0.05054398,  0.06838576,  0.16242936, ...,  0.03359299,\n",
      "        -0.00144376, -0.05003037],\n",
      "       [ 0.00237868,  0.05140711, -0.07432893, ..., -0.12364833,\n",
      "        -0.04098436, -0.28259414],\n",
      "       ...,\n",
      "       [-0.00935498, -0.15642823,  0.05675624, ...,  0.05713939,\n",
      "         0.05745491, -0.01336461],\n",
      "       [ 0.16848707,  0.01391317, -0.16472803, ...,  0.00497742,\n",
      "         0.00997484, -0.00301842],\n",
      "       [ 0.04260967,  0.0858821 , -0.09783319, ...,  0.02129023,\n",
      "         0.02044441,  0.0345872 ]], dtype=float32))\n",
      "(array([ 5.3850195e+02,  3.9057310e+00,  7.6201606e-01,  6.6078633e-01,\n",
      "        2.0335212e-01,  9.0798229e-02,  5.5926166e-02,  2.7780600e-02,\n",
      "        2.4412777e-02,  1.9531846e-02,  1.4284522e-02,  9.9007394e-03,\n",
      "        5.7729231e-03,  5.3175036e-03,  3.5140209e-03,  3.1210338e-03,\n",
      "        2.7634972e-03,  2.2726124e-03,  1.8336432e-03,  1.3365092e-03,\n",
      "        1.2227407e-03,  1.0729863e-03,  7.6289760e-04,  7.4482383e-04,\n",
      "        6.2327989e-04,  5.2972737e-04,  4.4714133e-04,  3.7617492e-04,\n",
      "        3.5053433e-04,  2.8201178e-04,  2.2089784e-04,  1.8791162e-04,\n",
      "        1.5368000e-04,  1.2926516e-04,  1.2006933e-04,  1.1019220e-04,\n",
      "        9.5240641e-05,  8.2076353e-05,  7.4893876e-05,  6.3534135e-05,\n",
      "        5.1927080e-05,  4.8504644e-05,  4.0931354e-05,  2.9420022e-05,\n",
      "        2.7339100e-05,  2.1787535e-05,  1.7759761e-05,  1.3061599e-05,\n",
      "       -1.1021059e-05,  1.1606736e-05, -9.3788385e-06,  9.7631982e-06,\n",
      "       -7.7942732e-06,  8.0569471e-06,  7.0140927e-06, -6.1520291e-06,\n",
      "       -5.4415104e-06,  5.1133029e-06, -4.2279335e-06,  4.2390552e-06,\n",
      "       -3.5264568e-06,  3.6580914e-06,  3.1818727e-06, -2.5457546e-06,\n",
      "       -2.1305548e-06,  2.2865572e-06, -1.8973195e-06,  1.7826080e-06,\n",
      "        1.6940035e-06,  1.5953129e-06, -1.3975206e-06, -1.2309526e-06,\n",
      "        1.2845596e-06,  1.1652899e-06, -1.0895025e-06,  1.0038830e-06,\n",
      "        8.3977676e-07, -8.8298651e-07, -9.8320186e-07, -7.7721779e-07,\n",
      "       -6.4666170e-07, -5.4834265e-07,  6.0664297e-07, -4.7371969e-07,\n",
      "        5.3529499e-07, -3.6843286e-07,  4.6712086e-07,  3.9710181e-07,\n",
      "       -3.3866343e-07,  3.3845876e-07,  3.1901095e-07, -2.3713744e-07,\n",
      "        2.2669336e-07, -1.9099510e-07, -1.7390420e-07, -1.2922794e-07,\n",
      "        1.8682606e-07,  1.7657787e-07,  1.3801598e-07, -9.0152660e-08,\n",
      "       -7.8099013e-08,  8.4610470e-08,  7.7447098e-08, -5.8989738e-08,\n",
      "        5.8927412e-08, -4.3245169e-08,  4.0806100e-08,  3.8645435e-08,\n",
      "       -2.6639620e-08, -2.3076078e-08, -1.7012287e-08,  2.4562635e-08,\n",
      "       -8.3353786e-09, -6.8946320e-09,  2.6930136e-10,  2.4478319e-09,\n",
      "        3.6713601e-09,  7.4345881e-09,  1.4412643e-08,  1.2853976e-08],\n",
      "      dtype=float32), array([[ 0.05603755, -0.12098552, -0.09393641, ...,  0.01205926,\n",
      "         0.04056821, -0.0154939 ],\n",
      "       [ 0.05345488, -0.0179524 , -0.14909624, ...,  0.00575068,\n",
      "        -0.03662731,  0.03933652],\n",
      "       [ 0.00153021,  0.02835597, -0.00427837, ..., -0.04032589,\n",
      "        -0.3099824 ,  0.0173387 ],\n",
      "       ...,\n",
      "       [-0.01149773, -0.07815593,  0.13773435, ..., -0.00158956,\n",
      "         0.00110409,  0.07339137],\n",
      "       [ 0.17278774, -0.00587954, -0.02787496, ...,  0.00367523,\n",
      "         0.00783713, -0.00639957],\n",
      "       [ 0.04068872,  0.05954237, -0.04100659, ..., -0.02393636,\n",
      "         0.01058321, -0.035684  ]], dtype=float32))\n",
      "(array([ 3.8674988e+02,  2.1234479e+00,  2.9170272e-01,  1.6205865e-01,\n",
      "        5.2234571e-02,  4.6489403e-02,  2.2751424e-02,  1.5493892e-02,\n",
      "        1.2022286e-02,  8.5453019e-03,  4.9884245e-03,  3.8895258e-03,\n",
      "        3.1443848e-03,  2.4985229e-03,  1.8358619e-03,  1.2067838e-03,\n",
      "        9.9764706e-04,  9.0124510e-04,  7.1299274e-04,  5.9268496e-04,\n",
      "        4.9781305e-04,  4.3169333e-04,  3.3963606e-04,  2.5498509e-04,\n",
      "        2.0759301e-04,  1.4740402e-04,  1.1369476e-04,  1.1091579e-04,\n",
      "        9.2815710e-05,  7.3455951e-05,  6.2729741e-05,  6.4419597e-05,\n",
      "        5.1912179e-05,  4.1668340e-05,  3.5349032e-05,  3.0307590e-05,\n",
      "        2.3857579e-05,  2.3105131e-05,  2.0894639e-05,  1.5156034e-05,\n",
      "        1.2642027e-05, -9.0622434e-06,  1.0380832e-05,  9.4639345e-06,\n",
      "       -5.6333984e-06,  8.4205822e-06,  7.1753248e-06,  6.5321719e-06,\n",
      "        6.3015978e-06, -4.9102464e-06, -3.7836428e-06,  4.7519861e-06,\n",
      "        4.1093581e-06,  3.7862569e-06, -3.1143109e-06, -2.8013426e-06,\n",
      "        3.3546235e-06,  3.2452674e-06, -2.3215816e-06,  2.3423358e-06,\n",
      "        2.2647794e-06, -1.9920662e-06, -1.8173679e-06,  1.7842308e-06,\n",
      "       -1.6645217e-06,  1.5277537e-06,  1.2851301e-06,  1.2607246e-06,\n",
      "       -1.2131608e-06, -1.1365223e-06, -1.0415287e-06,  1.1037828e-06,\n",
      "       -8.5193784e-07,  9.3937371e-07,  9.1039482e-07,  7.4863243e-07,\n",
      "        6.9231720e-07, -6.8571973e-07, -6.4168279e-07,  4.3273246e-07,\n",
      "        5.2058232e-07,  5.1436928e-07, -5.1812265e-07, -4.2205207e-07,\n",
      "       -4.4966060e-07,  4.0046203e-07,  3.6493958e-07, -3.5192670e-07,\n",
      "       -3.0035716e-07, -2.4491891e-07,  2.6770155e-07,  2.4471495e-07,\n",
      "        2.1140778e-07, -1.7555114e-07,  1.6003399e-07, -1.2676522e-07,\n",
      "        1.2941629e-07, -1.1297568e-07,  1.0568056e-07,  1.0102934e-07,\n",
      "       -8.7212008e-08,  8.2139309e-08,  5.9928915e-08, -7.0276450e-08,\n",
      "       -6.1675095e-08,  4.7195400e-08, -4.2708020e-08,  3.1047701e-08,\n",
      "        2.8003685e-08, -2.2160062e-08, -1.8874250e-08, -1.5880310e-08,\n",
      "        1.5431619e-08, -1.1297064e-08, -4.2552331e-09,  7.3928934e-09,\n",
      "        4.2606585e-09,  1.8914459e-09,  1.3656459e-09,  8.1234042e-10],\n",
      "      dtype=float32), array([[ 0.04261157, -0.05855164, -0.00453892, ...,  0.02046702,\n",
      "         0.01223632,  0.02071505],\n",
      "       [ 0.04984773,  0.01860731,  0.14496464, ..., -0.0059858 ,\n",
      "        -0.02032495,  0.00130408],\n",
      "       [ 0.00370872,  0.03776641, -0.05935475, ...,  0.01846637,\n",
      "        -0.07733984, -0.31868052],\n",
      "       ...,\n",
      "       [-0.01376155, -0.08615979,  0.03227714, ..., -0.01772746,\n",
      "        -0.0249418 , -0.07007439],\n",
      "       [ 0.16730905, -0.03049435, -0.11062884, ..., -0.0082548 ,\n",
      "         0.01086186,  0.00419954],\n",
      "       [ 0.04534011,  0.05810234, -0.03260612, ..., -0.02259717,\n",
      "         0.06582025,  0.04218513]], dtype=float32))\n",
      "(array([ 4.36925293e+02,  2.07838869e+00,  9.01559591e-01,  3.99689406e-01,\n",
      "        3.58276993e-01,  7.23824650e-02,  5.33077568e-02,  4.68250699e-02,\n",
      "        2.89521795e-02,  1.19070243e-02,  8.63548927e-03,  7.49001186e-03,\n",
      "        4.17451421e-03,  3.93188512e-03,  3.52346152e-03,  3.43402196e-03,\n",
      "        2.08948320e-03,  1.73580309e-03,  1.51594542e-03,  1.13661762e-03,\n",
      "        7.77716108e-04,  7.30430591e-04,  6.62383682e-04,  4.85118333e-04,\n",
      "        4.14289301e-04,  3.69545043e-04,  2.83382076e-04,  2.68608244e-04,\n",
      "        2.31395563e-04,  2.04442957e-04,  1.62265831e-04,  1.33226786e-04,\n",
      "        1.28801883e-04,  1.15319453e-04,  8.37031112e-05,  6.87845022e-05,\n",
      "        6.40562794e-05,  5.53503742e-05,  3.74535448e-05,  2.68645344e-05,\n",
      "        2.02838291e-05,  1.79357339e-05, -1.30405706e-05,  1.37781090e-05,\n",
      "        1.04574910e-05, -8.49482149e-06,  8.37565858e-06,  7.29319527e-06,\n",
      "       -6.34154549e-06, -5.75209970e-06,  5.74855221e-06, -4.34262847e-06,\n",
      "        5.21765105e-06, -3.07971004e-06,  4.59266312e-06,  4.44665329e-06,\n",
      "        3.62281321e-06,  3.15107150e-06, -2.73318574e-06, -2.38942403e-06,\n",
      "        2.73872365e-06,  2.45979663e-06,  2.03012996e-06, -1.84182670e-06,\n",
      "        1.74817285e-06, -1.61661580e-06, -1.42580814e-06,  1.59471028e-06,\n",
      "        1.44092871e-06,  1.27186229e-06, -1.13537033e-06,  1.03865068e-06,\n",
      "       -9.59429940e-07, -7.93392758e-07,  7.43912210e-07, -6.67193945e-07,\n",
      "       -6.35249933e-07, -5.52890299e-07,  6.36864456e-07,  6.10184259e-07,\n",
      "        5.61804825e-07, -4.48918286e-07,  4.67493493e-07,  3.96199994e-07,\n",
      "        3.70582455e-07, -3.23542480e-07, -2.77419645e-07, -2.61632152e-07,\n",
      "       -2.42037686e-07,  2.82020551e-07,  2.65413860e-07,  2.24479948e-07,\n",
      "       -2.01218768e-07,  1.74214591e-07, -1.73200235e-07, -1.58429202e-07,\n",
      "       -9.53878896e-08,  1.23096882e-07,  1.18045094e-07,  1.07093257e-07,\n",
      "       -7.48782440e-08, -7.72699309e-08,  7.09245853e-08,  8.08566369e-08,\n",
      "       -4.35962697e-08,  4.74234909e-08,  4.34164136e-08, -2.91288345e-08,\n",
      "        2.89038162e-08, -1.78322210e-08,  1.63093805e-08, -1.20663595e-08,\n",
      "       -8.81870488e-09,  1.30812596e-08, -6.27545749e-09,  7.77873055e-09,\n",
      "       -2.30530839e-09, -8.12584611e-10,  5.30205346e-09,  3.55262908e-09],\n",
      "      dtype=float32), array([[ 0.05002401,  0.07042099,  0.02130023, ...,  0.01977931,\n",
      "         0.00931037,  0.00707236],\n",
      "       [ 0.0496688 , -0.0077291 ,  0.04135205, ...,  0.00293867,\n",
      "         0.04452207, -0.00936487],\n",
      "       [ 0.00029288,  0.02506628, -0.08985304, ...,  0.16870996,\n",
      "         0.22983013,  0.12611473],\n",
      "       ...,\n",
      "       [-0.00640448, -0.08019336,  0.28390452, ..., -0.02158815,\n",
      "         0.06108288,  0.01652588],\n",
      "       [ 0.16575262,  0.12647319,  0.00180402, ...,  0.00853842,\n",
      "         0.0031642 ,  0.01008182],\n",
      "       [ 0.0416395 ,  0.04711644, -0.12785554, ..., -0.03248392,\n",
      "        -0.03462278, -0.02284444]], dtype=float32))\n",
      "(array([ 4.5314758e+02,  1.1730124e+00,  6.6578430e-01,  4.3800020e-01,\n",
      "        1.1922795e-01,  4.8263941e-02,  3.1827070e-02,  2.1276550e-02,\n",
      "        1.1062040e-02,  7.8957872e-03,  6.0017304e-03,  4.6460731e-03,\n",
      "        3.0682336e-03,  2.1939927e-03,  1.8879350e-03,  1.6338506e-03,\n",
      "        1.3056996e-03,  1.0093941e-03,  7.6606421e-04,  6.1810046e-04,\n",
      "        3.3721304e-04,  2.7262516e-04,  2.4248453e-04,  2.1171839e-04,\n",
      "        1.4143594e-04,  1.3257535e-04,  1.2320158e-04,  9.2212977e-05,\n",
      "        9.1491049e-05,  7.5139746e-05,  5.4242912e-05,  5.0473620e-05,\n",
      "        3.8784285e-05,  3.5098503e-05,  2.7317979e-05, -1.6803195e-05,\n",
      "        2.1483198e-05,  1.7778511e-05,  1.4771626e-05,  1.3906204e-05,\n",
      "        1.3246549e-05, -9.6067824e-06,  1.1740380e-05,  1.0236815e-05,\n",
      "        9.3302569e-06, -7.4840368e-06,  8.3843061e-06,  6.9578514e-06,\n",
      "        6.7368537e-06, -4.8293041e-06,  5.5933128e-06,  4.3787695e-06,\n",
      "       -4.1938574e-06, -3.6888798e-06, -3.4467278e-06, -2.7655390e-06,\n",
      "        4.0241744e-06,  3.6359509e-06,  3.3673446e-06,  2.9350899e-06,\n",
      "        2.5655593e-06, -2.0880877e-06,  2.1345047e-06,  2.0319483e-06,\n",
      "        1.9475704e-06,  1.5496182e-06, -1.3866594e-06, -1.3112829e-06,\n",
      "       -1.1597286e-06, -9.7059785e-07, -8.0739051e-07,  1.3653939e-06,\n",
      "        9.1213718e-07,  1.1717599e-06,  1.1133608e-06,  7.9507686e-07,\n",
      "       -6.2635667e-07,  6.8267309e-07, -5.5724422e-07,  5.7765192e-07,\n",
      "        5.2965754e-07, -4.7191227e-07, -3.8738276e-07,  4.3015362e-07,\n",
      "        3.6540897e-07,  3.0965313e-07,  2.4461073e-07, -2.8901661e-07,\n",
      "       -2.5602887e-07, -2.3134879e-07,  2.0982090e-07,  1.9230440e-07,\n",
      "       -1.6742509e-07, -1.2796652e-07,  1.3345527e-07,  1.2129114e-07,\n",
      "       -1.0613871e-07,  9.7867805e-08, -9.7443845e-08, -8.4555126e-08,\n",
      "       -7.1299795e-08,  7.8539763e-08,  7.2793341e-08, -5.4825566e-08,\n",
      "        6.5607068e-08, -3.9196390e-08,  4.6833165e-08,  3.7600682e-08,\n",
      "       -2.7881692e-08,  2.7947992e-08,  2.3343881e-08,  1.6364957e-08,\n",
      "       -1.3074770e-08, -1.6802355e-08,  6.3525651e-09,  4.2244488e-09,\n",
      "        3.1293276e-10, -1.7669344e-09, -6.1989076e-09, -5.4419576e-09],\n",
      "      dtype=float32), array([[ 0.04865886,  0.1298462 ,  0.01149019, ...,  0.00674746,\n",
      "         0.00692757,  0.04366245],\n",
      "       [ 0.04341657,  0.02175175, -0.16709168, ..., -0.02572085,\n",
      "         0.03446842,  0.0250784 ],\n",
      "       [-0.00493732,  0.01593194,  0.06772614, ...,  0.03224365,\n",
      "        -0.03221443,  0.03511155],\n",
      "       ...,\n",
      "       [ 0.01229157, -0.04467994, -0.12925538, ...,  0.0205621 ,\n",
      "        -0.04334354, -0.01355842],\n",
      "       [ 0.16343127,  0.13328151,  0.12306242, ...,  0.01091278,\n",
      "         0.01107098, -0.01127524],\n",
      "       [ 0.03139821,  0.11256376,  0.09580161, ...,  0.03157379,\n",
      "        -0.03152666, -0.03139798]], dtype=float32))\n",
      "(array([ 4.16877533e+02,  7.17520356e-01,  8.72323886e-02,  5.16806021e-02,\n",
      "        3.94917130e-02,  1.50445150e-02,  7.20287953e-03,  4.17632889e-03,\n",
      "        3.90433474e-03,  2.27888371e-03,  2.09404924e-03,  1.33153540e-03,\n",
      "        9.37127857e-04,  8.54518381e-04,  6.02680899e-04,  4.31988796e-04,\n",
      "        3.57655925e-04,  3.05242400e-04,  2.74853868e-04,  2.26096367e-04,\n",
      "        2.02158830e-04,  1.56409253e-04,  1.06379448e-04,  9.61786645e-05,\n",
      "        8.24118833e-05,  6.33102609e-05,  4.85159690e-05,  3.60731683e-05,\n",
      "        3.04319165e-05,  2.89504733e-05,  2.21853170e-05,  1.96862693e-05,\n",
      "       -1.08485392e-05,  1.75906116e-05,  1.56973310e-05,  1.49100169e-05,\n",
      "        1.31340767e-05,  1.25315428e-05,  1.20246204e-05, -8.78711671e-06,\n",
      "       -7.16729073e-06,  9.15564306e-06,  8.10689471e-06,  7.88916623e-06,\n",
      "        7.06748733e-06,  6.64780873e-06,  6.10392908e-06, -4.09260929e-06,\n",
      "        4.96628036e-06,  4.30052796e-06,  3.92876609e-06, -3.02529611e-06,\n",
      "       -2.53377971e-06,  3.68186079e-06,  2.96401549e-06,  2.85605324e-06,\n",
      "       -2.26860266e-06,  2.57965894e-06,  2.13492149e-06, -1.79744166e-06,\n",
      "        1.85838360e-06,  1.69405348e-06, -1.30291210e-06,  1.42377769e-06,\n",
      "        1.28953820e-06, -1.10401584e-06, -9.57693601e-07,  1.20059235e-06,\n",
      "        1.04905132e-06,  9.13375629e-07, -8.14658961e-07, -7.29487681e-07,\n",
      "        7.48381865e-07, -6.26090127e-07,  7.07127924e-07, -4.75727745e-07,\n",
      "        5.68616599e-07,  5.32777904e-07,  4.92816525e-07,  4.59697048e-07,\n",
      "       -3.87448864e-07, -3.39200312e-07, -3.15418447e-07,  3.81984421e-07,\n",
      "        3.16760122e-07,  2.61302347e-07, -2.41260921e-07, -2.11065213e-07,\n",
      "        2.02857734e-07,  1.83178798e-07,  1.46548459e-07, -1.42466746e-07,\n",
      "       -1.30929237e-07, -1.13826587e-07, -1.04793870e-07,  1.10254675e-07,\n",
      "        1.02444872e-07,  8.50688409e-08, -7.82670782e-08, -7.48013775e-08,\n",
      "       -5.34005125e-08,  6.12809856e-08,  4.98731865e-08, -3.98087217e-08,\n",
      "       -3.26892646e-08, -3.16554143e-08,  4.28927045e-08,  3.59966918e-08,\n",
      "        3.25628520e-08, -2.10941913e-08,  2.36390623e-08, -1.71847994e-08,\n",
      "        1.82755375e-08, -1.22760193e-08, -4.51003412e-09, -3.78620779e-09,\n",
      "        1.34243434e-08,  1.19729071e-09,  6.44543929e-09,  7.40701234e-09],\n",
      "      dtype=float32), array([[-0.04605385, -0.03902759,  0.17190151, ...,  0.00563697,\n",
      "         0.02046002, -0.00168686],\n",
      "       [-0.04051381,  0.19151622,  0.02414405, ...,  0.00073778,\n",
      "         0.01854792, -0.05397068],\n",
      "       [ 0.00759321, -0.04183041,  0.04412234, ...,  0.00436351,\n",
      "        -0.09096237,  0.07192161],\n",
      "       ...,\n",
      "       [-0.01724157,  0.03568317, -0.14522871, ..., -0.09877817,\n",
      "        -0.04003448,  0.06273928],\n",
      "       [-0.15706648, -0.11579581,  0.11890517, ...,  0.00315649,\n",
      "        -0.00355262, -0.02191029],\n",
      "       [-0.02638281, -0.07876899,  0.07737032, ...,  0.02819193,\n",
      "         0.03213339, -0.01387285]], dtype=float32))\n",
      "(array([ 4.63641602e+02,  1.16428649e+00,  9.85038877e-01,  5.45660973e-01,\n",
      "        1.85947776e-01,  1.13495573e-01,  8.14621896e-02,  5.72489165e-02,\n",
      "        4.40321304e-02,  2.56455746e-02,  2.14201994e-02,  1.33217517e-02,\n",
      "        9.68219712e-03,  8.58738367e-03,  5.26441867e-03,  3.10871960e-03,\n",
      "        2.98334891e-03,  2.49266718e-03,  2.20824243e-03,  1.92563725e-03,\n",
      "        1.59740483e-03,  1.38686958e-03,  1.12252403e-03,  7.56406225e-04,\n",
      "        7.36387796e-04,  5.31097292e-04,  4.98062407e-04,  4.18209092e-04,\n",
      "        3.20285209e-04,  2.61211389e-04,  2.24004718e-04,  2.00463313e-04,\n",
      "        1.61433723e-04,  1.33370777e-04,  1.20621458e-04,  1.17495001e-04,\n",
      "        1.06670122e-04,  8.89720468e-05,  7.12375768e-05,  6.70771915e-05,\n",
      "        5.30907164e-05,  4.42652527e-05,  3.73186122e-05,  3.05357353e-05,\n",
      "        2.92046279e-05,  2.51199472e-05,  2.09822101e-05,  1.83852408e-05,\n",
      "       -1.18256157e-05,  1.15865396e-05,  9.42228144e-06, -7.19071295e-06,\n",
      "        7.92732953e-06,  7.05535558e-06, -5.76888533e-06,  5.33160664e-06,\n",
      "       -4.19512617e-06,  4.59326702e-06,  4.01673060e-06, -3.22192022e-06,\n",
      "        3.19878473e-06, -2.65856602e-06, -2.33845662e-06,  2.16394506e-06,\n",
      "        1.97478039e-06, -2.00939394e-06, -1.84386204e-06,  1.66910911e-06,\n",
      "        1.44574699e-06, -1.18162359e-06,  1.09260134e-06, -1.05956292e-06,\n",
      "        9.61989485e-07,  9.44585508e-07, -9.24026324e-07, -8.58880696e-07,\n",
      "       -6.74107810e-07, -7.60105763e-07,  7.15453837e-07,  7.43439500e-07,\n",
      "        6.26565225e-07,  4.33677116e-07, -4.29802583e-07, -3.92427921e-07,\n",
      "       -3.47021427e-07, -3.08250179e-07,  3.40008654e-07,  3.35027266e-07,\n",
      "        2.81836776e-07,  2.27286947e-07, -2.28499516e-07, -1.96508211e-07,\n",
      "       -1.70136175e-07,  1.99684109e-07, -1.26087073e-07,  1.40667865e-07,\n",
      "        1.21991661e-07, -9.80288632e-08, -9.04388529e-08,  1.01918090e-07,\n",
      "        8.48111696e-08, -8.00815627e-08, -5.89383689e-08, -5.41201786e-08,\n",
      "        4.81877009e-08,  4.54451410e-08, -3.43339224e-08,  2.99829139e-08,\n",
      "       -2.65104365e-08, -2.04758006e-08,  2.35061819e-08,  1.88145659e-08,\n",
      "       -1.38049865e-08,  1.28239988e-08, -5.88018612e-09, -1.92799909e-09,\n",
      "        7.18168325e-09,  6.09065687e-09,  2.16368834e-09,  2.60162625e-09],\n",
      "      dtype=float32), array([[-0.06291065, -0.01090103, -0.04797371, ...,  0.01479739,\n",
      "         0.01726823,  0.01583912],\n",
      "       [-0.05020133,  0.0033116 , -0.2328439 , ...,  0.01570542,\n",
      "        -0.00310071, -0.02151956],\n",
      "       [ 0.00371769,  0.04257056,  0.00290163, ...,  0.08257992,\n",
      "        -0.18331988,  0.00719215],\n",
      "       ...,\n",
      "       [-0.00481001, -0.09943451,  0.03375191, ...,  0.00470044,\n",
      "        -0.00069302,  0.11274339],\n",
      "       [-0.16048902,  0.10386374,  0.10375758, ..., -0.00765737,\n",
      "        -0.01220081,  0.01193302],\n",
      "       [-0.03272786,  0.02467781,  0.05039249, ...,  0.00044575,\n",
      "         0.06200655,  0.07854006]], dtype=float32))\n",
      "(array([ 3.31943634e+02,  9.65518892e-01,  7.31197655e-01,  2.91127682e-01,\n",
      "        1.21591419e-01,  7.41229430e-02,  3.82773541e-02,  1.88505333e-02,\n",
      "        1.43702077e-02,  7.75750587e-03,  6.94159232e-03,  4.78815194e-03,\n",
      "        3.90062202e-03,  3.26711917e-03,  2.74361763e-03,  1.94914546e-03,\n",
      "        1.54992356e-03,  1.23620941e-03,  1.12049037e-03,  1.03442324e-03,\n",
      "        7.89106358e-04,  6.29563117e-04,  5.08680125e-04,  3.42145708e-04,\n",
      "        2.91940058e-04,  2.53631559e-04,  2.12913452e-04,  1.98930924e-04,\n",
      "        1.57586430e-04,  1.11306705e-04,  1.01778067e-04,  9.10667004e-05,\n",
      "        7.38914532e-05,  6.45830078e-05,  5.72772369e-05,  4.93045954e-05,\n",
      "        4.04072598e-05,  3.83768856e-05,  3.16004953e-05,  2.48749748e-05,\n",
      "        2.26074189e-05,  1.70632520e-05, -1.12996231e-05,  1.57225368e-05,\n",
      "        1.32634123e-05,  1.28397514e-05,  9.37812092e-06,  9.52928531e-06,\n",
      "        8.49878234e-06, -6.65799325e-06, -6.48659488e-06,  5.71527562e-06,\n",
      "       -3.82778535e-06,  4.64489995e-06, -3.24183929e-06,  4.05605033e-06,\n",
      "        3.60440458e-06,  2.76479454e-06, -1.87976536e-06, -1.81252369e-06,\n",
      "        2.19185131e-06,  1.86002046e-06, -1.47617300e-06,  1.55368616e-06,\n",
      "       -1.14603438e-06,  1.33707442e-06,  1.22303243e-06, -9.94285415e-07,\n",
      "        9.64132596e-07,  7.96187862e-07,  6.80935500e-07, -7.70164206e-07,\n",
      "       -7.25352095e-07, -6.46244814e-07,  5.98808128e-07,  5.77894014e-07,\n",
      "       -4.92597678e-07, -4.11918876e-07, -3.67605224e-07,  4.30826020e-07,\n",
      "        3.67785873e-07,  3.81987377e-07, -3.19568869e-07,  2.84284653e-07,\n",
      "       -2.67114416e-07, -2.51066808e-07,  2.31898412e-07, -2.08870574e-07,\n",
      "        1.76107406e-07, -1.61490163e-07,  1.58729492e-07, -1.34610971e-07,\n",
      "       -1.13876517e-07,  1.37441290e-07,  1.30994550e-07,  1.21510112e-07,\n",
      "       -1.05058319e-07, -7.83336063e-08,  9.29946466e-08,  8.50312034e-08,\n",
      "       -6.60654607e-08, -5.88585252e-08,  5.68808680e-08,  5.90130576e-08,\n",
      "        4.63728931e-08, -3.62195358e-08,  3.31839800e-08,  2.98715861e-08,\n",
      "       -3.06540286e-08,  1.79006481e-08, -2.57652335e-08, -1.56311390e-08,\n",
      "       -2.09442650e-08,  1.01173763e-08,  6.61775035e-09,  2.96034774e-09,\n",
      "        5.77012327e-10, -3.34200578e-09, -8.27277979e-09, -6.91541358e-09],\n",
      "      dtype=float32), array([[ 0.05980908,  0.06371091, -0.21110444, ...,  0.02076712,\n",
      "        -0.02038313, -0.00373806],\n",
      "       [ 0.04482988, -0.20028521, -0.00183274, ...,  0.0469584 ,\n",
      "         0.02261388, -0.0415892 ],\n",
      "       [-0.01227523,  0.03832838,  0.09715584, ...,  0.02810675,\n",
      "         0.05337435, -0.09939045],\n",
      "       ...,\n",
      "       [ 0.02508609, -0.07149848, -0.16975394, ..., -0.09491485,\n",
      "        -0.05699851, -0.04149815],\n",
      "       [ 0.1474589 ,  0.10259903,  0.00832191, ..., -0.03721004,\n",
      "        -0.01470665, -0.00305794],\n",
      "       [ 0.02563297,  0.08720343,  0.0427653 , ...,  0.05109921,\n",
      "         0.03616666,  0.0227469 ]], dtype=float32))\n",
      "(array([ 2.98897247e+02,  1.24040437e+00,  8.16516161e-01,  3.86217058e-01,\n",
      "        6.07725643e-02,  5.16475327e-02,  3.19678299e-02,  2.79186200e-02,\n",
      "        1.36827352e-02,  9.00637172e-03,  6.17595064e-03,  4.88248933e-03,\n",
      "        3.99221433e-03,  2.64799478e-03,  2.36085989e-03,  2.16949894e-03,\n",
      "        1.47959997e-03,  1.33116625e-03,  9.85592022e-04,  6.06689195e-04,\n",
      "        4.26165905e-04,  3.65107378e-04,  3.37004225e-04,  2.28161691e-04,\n",
      "        1.95298402e-04,  1.48595806e-04,  1.15306313e-04,  1.03081467e-04,\n",
      "        8.69271316e-05,  8.03034636e-05,  6.77647113e-05,  5.23283306e-05,\n",
      "        4.40533986e-05,  3.87073160e-05,  3.55972697e-05,  2.94823240e-05,\n",
      "        2.12467403e-05,  1.82714011e-05,  1.57118011e-05,  1.36866956e-05,\n",
      "        1.26100358e-05, -7.62690252e-06,  9.94738912e-06,  8.71938937e-06,\n",
      "        8.28502471e-06, -5.65299206e-06, -4.57478654e-06,  6.38949723e-06,\n",
      "        5.64816219e-06,  5.40799283e-06,  4.53401708e-06,  4.04228604e-06,\n",
      "       -3.21862922e-06, -2.60516708e-06,  2.76321589e-06, -2.32955858e-06,\n",
      "        2.69008706e-06, -1.53074109e-06,  2.19619074e-06,  1.96796123e-06,\n",
      "        1.73291323e-06, -1.32379728e-06, -1.20978098e-06,  1.30726380e-06,\n",
      "        1.20527977e-06, -8.06547575e-07,  9.18271837e-07, -6.89343267e-07,\n",
      "        8.38218000e-07,  7.08140306e-07, -6.10515656e-07, -5.46466708e-07,\n",
      "        5.90117907e-07,  5.34213598e-07,  5.13987288e-07, -4.47008119e-07,\n",
      "        4.42529767e-07,  3.87360018e-07, -3.64864036e-07, -3.49226923e-07,\n",
      "        3.08686595e-07,  3.45000700e-07, -3.80742790e-07, -3.00071633e-07,\n",
      "       -2.84376142e-07,  2.58026063e-07,  2.45052604e-07,  2.27791801e-07,\n",
      "       -1.48010542e-07, -1.32173085e-07,  1.76167049e-07,  1.35582155e-07,\n",
      "        1.06208702e-07,  8.64829133e-08, -1.05542718e-07, -8.44237178e-08,\n",
      "       -7.15861788e-08, -6.50678444e-08,  6.57080506e-08,  6.15042381e-08,\n",
      "       -5.60932492e-08,  4.50858799e-08, -4.84824412e-08, -3.80496239e-08,\n",
      "        2.90880315e-08,  2.78549059e-08, -2.50598422e-08, -3.01224823e-08,\n",
      "       -2.95071523e-08,  2.38392648e-08, -1.59597473e-08,  1.73495458e-08,\n",
      "       -9.57650315e-09, -7.73762387e-09,  1.34953799e-08,  6.52963950e-09,\n",
      "       -3.70453401e-09,  7.37126360e-10, -1.03413411e-09,  1.06456275e-08],\n",
      "      dtype=float32), array([[ 0.05609724, -0.00126885, -0.04824822, ..., -0.02785182,\n",
      "        -0.022149  ,  0.002611  ],\n",
      "       [ 0.04479493,  0.05735676,  0.202241  , ...,  0.02468133,\n",
      "         0.06808284, -0.01698042],\n",
      "       [-0.01225303,  0.06709105, -0.03624924, ...,  0.00404631,\n",
      "        -0.06848901, -0.02253233],\n",
      "       ...,\n",
      "       [ 0.02448172, -0.1771274 ,  0.06499125, ...,  0.01273412,\n",
      "        -0.05698935, -0.00221254],\n",
      "       [ 0.14210118, -0.20166978, -0.12641515, ..., -0.01910238,\n",
      "         0.0113726 ,  0.00646665],\n",
      "       [ 0.02616301,  0.01921429, -0.07702734, ...,  0.00918493,\n",
      "        -0.10049058,  0.01654111]], dtype=float32))\n",
      "(array([ 2.73282928e+02,  1.34328330e+00,  7.33682096e-01,  3.99888098e-01,\n",
      "        6.83892444e-02,  4.56380472e-02,  2.33433358e-02,  1.74169801e-02,\n",
      "        1.54740484e-02,  9.72445682e-03,  7.24874018e-03,  7.04438984e-03,\n",
      "        3.79584963e-03,  3.09203099e-03,  2.25001900e-03,  1.46541651e-03,\n",
      "        1.23638345e-03,  9.42759216e-04,  7.53534609e-04,  5.97062230e-04,\n",
      "        4.79447335e-04,  4.45005746e-04,  3.89770401e-04,  3.56950448e-04,\n",
      "        2.64609698e-04,  1.90029954e-04,  1.64746554e-04,  1.15927876e-04,\n",
      "        1.12427675e-04,  9.64489591e-05,  8.95746998e-05,  7.07577710e-05,\n",
      "        6.69850706e-05,  6.15810350e-05,  4.43278841e-05,  3.90225759e-05,\n",
      "        3.08691597e-05,  2.81098437e-05,  2.39121855e-05,  2.15866494e-05,\n",
      "        1.77625425e-05,  1.42593935e-05,  1.24450762e-05, -6.49047433e-06,\n",
      "        8.57316354e-06,  8.22118818e-06,  7.27263705e-06, -5.08853191e-06,\n",
      "        6.19520779e-06,  5.33622961e-06, -3.97255053e-06,  4.36451546e-06,\n",
      "       -3.06293441e-06, -2.74398917e-06,  3.24261009e-06,  2.72270768e-06,\n",
      "        2.35185098e-06,  2.25493773e-06, -2.04646358e-06,  1.77871038e-06,\n",
      "        1.65483016e-06, -1.57108457e-06, -1.39964902e-06,  1.44674539e-06,\n",
      "        1.17211300e-06, -8.49686444e-07,  9.04680803e-07, -7.60126568e-07,\n",
      "       -7.46286673e-07,  8.09349785e-07,  6.91752859e-07, -5.60538467e-07,\n",
      "        5.94882465e-07,  5.56761506e-07, -5.04321690e-07, -4.06269237e-07,\n",
      "        4.64524277e-07,  3.89531863e-07,  3.29063909e-07, -3.14323785e-07,\n",
      "       -2.98369628e-07,  2.63031694e-07, -2.38847747e-07,  2.42994389e-07,\n",
      "        1.98800620e-07, -2.06303184e-07, -2.05159068e-07,  1.59147888e-07,\n",
      "       -1.63525229e-07, -1.40607483e-07,  1.29985040e-07,  1.19377830e-07,\n",
      "       -1.09484326e-07, -9.98242200e-08,  9.48867438e-08,  7.92626054e-08,\n",
      "        7.44024220e-08, -8.24253235e-08, -7.14699979e-08,  5.08496214e-08,\n",
      "        4.97659407e-08, -4.79176485e-08, -4.49300899e-08,  3.71673963e-08,\n",
      "        2.63705573e-08, -3.55634384e-08, -2.61367195e-08, -2.46029561e-08,\n",
      "        2.31917809e-08,  1.80660074e-08,  1.41651642e-08, -1.35490863e-08,\n",
      "       -1.18620402e-08, -1.05298819e-08, -5.93158100e-09,  8.40667358e-09,\n",
      "       -2.28203900e-09,  6.65880329e-09,  3.39270967e-09,  2.73644507e-09],\n",
      "      dtype=float32), array([[ 0.05450194,  0.04548566,  0.1654705 , ..., -0.00796713,\n",
      "        -0.01728331,  0.00881452],\n",
      "       [ 0.04232505,  0.14483725, -0.13023987, ..., -0.00855499,\n",
      "        -0.0492465 ,  0.02603298],\n",
      "       [-0.01763419, -0.11174963, -0.11003297, ..., -0.00971036,\n",
      "        -0.09899409,  0.06162523],\n",
      "       ...,\n",
      "       [ 0.03258052,  0.19603567,  0.18809663, ..., -0.00974523,\n",
      "        -0.09489631, -0.01170525],\n",
      "       [ 0.13811214, -0.06979466,  0.17992504, ..., -0.0071334 ,\n",
      "        -0.0256105 , -0.02482504],\n",
      "       [ 0.0212668 , -0.10232782, -0.00574963, ...,  0.0266403 ,\n",
      "         0.01663024,  0.0172605 ]], dtype=float32))\n",
      "(array([ 2.8162241e+02,  8.9360410e-01,  4.9282783e-01,  2.4699529e-01,\n",
      "        9.5942490e-02,  5.3419981e-02,  3.9719053e-02,  3.2769352e-02,\n",
      "        2.0057138e-02,  1.2679044e-02,  6.8645249e-03,  5.4553333e-03,\n",
      "        3.9977320e-03,  3.1934192e-03,  2.5812811e-03,  2.2085854e-03,\n",
      "        1.9377220e-03,  1.0723361e-03,  8.1151229e-04,  7.3592621e-04,\n",
      "        5.6670298e-04,  4.1863578e-04,  3.6029553e-04,  2.7037179e-04,\n",
      "        2.4350952e-04,  2.0958310e-04,  1.6996710e-04,  1.5218300e-04,\n",
      "        1.3497948e-04,  1.0017898e-04,  9.8539203e-05,  8.4782158e-05,\n",
      "        6.5274326e-05,  5.4145596e-05,  4.2735788e-05,  3.7266913e-05,\n",
      "        3.3261778e-05,  2.9965007e-05,  2.6886528e-05,  2.2441543e-05,\n",
      "        1.9823101e-05,  1.8146622e-05,  1.3310366e-05,  1.2215038e-05,\n",
      "        1.0536721e-05, -8.0256195e-06,  8.2825982e-06,  5.9964686e-06,\n",
      "       -4.7112080e-06, -3.2807638e-06,  4.9253417e-06,  4.0038858e-06,\n",
      "        4.2664228e-06,  3.6040597e-06, -2.3290302e-06,  2.8941340e-06,\n",
      "        2.4733711e-06,  2.0628547e-06, -2.0662133e-06, -1.8632187e-06,\n",
      "        1.5757308e-06, -1.3011221e-06, -1.2171557e-06,  1.2002810e-06,\n",
      "       -9.4038580e-07,  1.0835897e-06,  9.7460418e-07, -7.8728362e-07,\n",
      "        7.6957650e-07,  6.3115209e-07,  5.5451659e-07, -6.5212691e-07,\n",
      "       -5.7321307e-07, -4.7833834e-07,  4.4904556e-07, -3.4377933e-07,\n",
      "        4.0919480e-07,  3.5374458e-07, -3.1896280e-07, -2.5185733e-07,\n",
      "        2.8085969e-07,  2.5028015e-07,  2.2642266e-07, -2.2064260e-07,\n",
      "        2.0847445e-07, -1.8328822e-07, -1.6928539e-07, -1.5015104e-07,\n",
      "        1.8996820e-07,  1.6903627e-07,  1.4473302e-07, -1.3186069e-07,\n",
      "       -1.1789047e-07, -1.1182634e-07,  9.2227680e-08, -8.2495319e-08,\n",
      "        7.5093844e-08, -7.3632329e-08,  6.2835120e-08,  5.3152139e-08,\n",
      "       -4.3895717e-08, -4.2762196e-08, -3.4335223e-08, -2.8674076e-08,\n",
      "        3.2477576e-08,  3.0755267e-08,  2.5415629e-08, -2.0232690e-08,\n",
      "       -1.7174303e-08, -1.3451301e-08,  2.0988104e-08, -7.3800051e-09,\n",
      "       -3.2643617e-09, -1.3411160e-09,  7.9058349e-10,  3.1296596e-09,\n",
      "        1.6346794e-08,  1.4908856e-08,  8.4107850e-09,  1.1567197e-08],\n",
      "      dtype=float32), array([[ 0.05163831, -0.04490155, -0.13659754, ..., -0.0591934 ,\n",
      "        -0.04838301, -0.03710407],\n",
      "       [ 0.04011686,  0.19211847,  0.02267239, ..., -0.04215426,\n",
      "         0.0278833 ,  0.08631215],\n",
      "       [-0.0172616 , -0.03099565,  0.09762649, ...,  0.14041297,\n",
      "         0.03577388, -0.11676958],\n",
      "       ...,\n",
      "       [ 0.03592087,  0.05482185, -0.22942103, ...,  0.03466687,\n",
      "         0.06709657, -0.03650627],\n",
      "       [ 0.13950413, -0.13023616, -0.14797746, ...,  0.00172398,\n",
      "        -0.00124144,  0.01039649],\n",
      "       [ 0.01957534, -0.0864851 ,  0.02938601, ...,  0.02402305,\n",
      "        -0.00525339,  0.01389005]], dtype=float32))\n",
      "(array([ 2.9666260e+02,  7.3506427e-01,  3.4075361e-01,  1.2845479e-01,\n",
      "        4.1646138e-02,  2.3266573e-02,  1.6603617e-02,  7.6709879e-03,\n",
      "        7.2703748e-03,  4.1689430e-03,  3.1205192e-03,  2.1457386e-03,\n",
      "        1.7436214e-03,  1.4464585e-03,  1.1936204e-03,  6.3603168e-04,\n",
      "        4.6222063e-04,  3.7280124e-04,  2.4216836e-04,  2.5394576e-04,\n",
      "        1.3515553e-04,  1.0750896e-04,  8.7486434e-05,  7.3687414e-05,\n",
      "        6.0689370e-05,  5.5111668e-05,  5.1333889e-05,  4.8607493e-05,\n",
      "        2.8376844e-05,  2.3269247e-05,  1.8296238e-05,  1.5086397e-05,\n",
      "        1.4050082e-05,  1.1852695e-05, -8.5073943e-06,  9.6844478e-06,\n",
      "        8.2535944e-06,  7.2812340e-06,  6.0680759e-06, -5.3997987e-06,\n",
      "        5.4115790e-06, -3.8173434e-06,  4.4888870e-06,  4.1790390e-06,\n",
      "       -3.0711360e-06,  3.4067600e-06,  3.2139576e-06, -2.1756798e-06,\n",
      "        2.9595492e-06,  2.7313197e-06,  2.3846562e-06, -1.8037500e-06,\n",
      "       -1.5830698e-06,  1.9945169e-06,  1.8866062e-06,  1.6243672e-06,\n",
      "        1.3987333e-06, -1.2511287e-06, -1.1358461e-06,  1.2259712e-06,\n",
      "       -9.0102662e-07,  1.0689665e-06,  9.9195188e-07, -8.5035958e-07,\n",
      "        8.6499188e-07, -7.1540518e-07,  7.9740454e-07, -5.7566211e-07,\n",
      "       -5.2538377e-07,  7.1992417e-07,  6.8572484e-07,  5.4241536e-07,\n",
      "        5.0892794e-07, -4.6165334e-07, -3.8867162e-07,  3.9043124e-07,\n",
      "       -2.6683750e-07,  3.1352315e-07,  2.9435765e-07, -2.4301835e-07,\n",
      "       -2.1810729e-07,  2.6068716e-07,  2.3855631e-07,  2.2549729e-07,\n",
      "       -1.7703893e-07,  1.9293702e-07,  1.6912126e-07, -1.5413740e-07,\n",
      "        1.5996311e-07, -1.3429165e-07, -1.1894369e-07, -1.0323052e-07,\n",
      "        1.4597349e-07,  1.0164267e-07,  1.1285158e-07, -7.8871089e-08,\n",
      "        8.0765894e-08, -6.5902562e-08,  7.0210959e-08,  5.8386689e-08,\n",
      "        5.6025229e-08, -5.0844456e-08, -4.5103945e-08,  4.4281045e-08,\n",
      "        3.5709412e-08, -2.8943996e-08, -3.0232485e-08,  2.3332429e-08,\n",
      "       -2.2523205e-08, -1.8805627e-08, -1.0550749e-08,  5.5288747e-09,\n",
      "        8.6954571e-10, -2.6920739e-09, -4.3664370e-09,  3.1988545e-08,\n",
      "        3.1130686e-08,  2.0874845e-08,  1.2167139e-08, -6.6389216e-10],\n",
      "      dtype=float32), array([[-0.05591906,  0.01038969,  0.02505673, ..., -0.00343953,\n",
      "         0.0071131 ,  0.00309853],\n",
      "       [-0.04150517,  0.1941395 , -0.00942651, ...,  0.06897301,\n",
      "        -0.03300242, -0.04823934],\n",
      "       [ 0.02201458, -0.05422912, -0.07644635, ...,  0.04696742,\n",
      "         0.02795638,  0.01197822],\n",
      "       ...,\n",
      "       [-0.04688087,  0.08577508,  0.20405637, ..., -0.01482194,\n",
      "         0.0131785 , -0.0109912 ],\n",
      "       [-0.14422911, -0.10777389,  0.10098809, ...,  0.00504368,\n",
      "        -0.02647069,  0.01398137],\n",
      "       [-0.018824  , -0.10151101,  0.00858564, ...,  0.033262  ,\n",
      "         0.00126989,  0.0498734 ]], dtype=float32))\n",
      "(array([ 2.70370728e+02,  9.93275642e-01,  2.94943452e-01,  1.38846561e-01,\n",
      "        5.54340519e-02,  4.12612036e-02,  1.30107151e-02,  9.75633506e-03,\n",
      "        8.00412614e-03,  7.55871413e-03,  3.48648755e-03,  2.19965051e-03,\n",
      "        1.88581983e-03,  1.51797803e-03,  1.17737090e-03,  1.00461626e-03,\n",
      "        9.20220104e-04,  5.35223924e-04,  4.16239229e-04,  3.38725164e-04,\n",
      "        2.48683617e-04,  1.82956763e-04,  1.71671520e-04,  1.38627205e-04,\n",
      "        1.19586388e-04,  9.94633447e-05,  8.78039136e-05,  7.68488171e-05,\n",
      "        5.64327820e-05,  4.91744577e-05,  4.76201785e-05,  3.25051005e-05,\n",
      "        3.07225309e-05,  2.31596296e-05,  2.25306121e-05,  1.41103328e-05,\n",
      "        1.26897312e-05,  1.01246624e-05, -7.12965948e-06, -6.64895106e-06,\n",
      "        8.45386421e-06,  7.50695972e-06,  7.00121109e-06,  5.55536917e-06,\n",
      "        4.97024485e-06, -3.96271116e-06,  3.88537819e-06,  3.42751559e-06,\n",
      "        2.45367119e-06,  2.31352078e-06, -2.40145187e-06, -2.20269476e-06,\n",
      "       -1.99345914e-06, -1.79697179e-06,  1.98230373e-06,  1.82255667e-06,\n",
      "        1.55523878e-06,  1.41192811e-06,  1.35216510e-06, -1.17812726e-06,\n",
      "       -1.12163320e-06,  1.18503181e-06,  1.08632196e-06, -9.14936720e-07,\n",
      "        9.43416751e-07,  8.82802908e-07, -7.26572296e-07,  6.84587519e-07,\n",
      "        6.26976373e-07, -5.66984568e-07, -4.81726659e-07, -5.16933085e-07,\n",
      "        5.08609901e-07,  4.38171554e-07,  3.81984620e-07, -3.22960744e-07,\n",
      "        2.76840325e-07,  2.60223572e-07,  2.33430683e-07, -2.93746211e-07,\n",
      "       -2.63919333e-07, -2.54847151e-07, -2.07619848e-07,  2.02575663e-07,\n",
      "       -1.64808327e-07,  1.69769351e-07,  1.57740772e-07, -1.28886228e-07,\n",
      "       -1.11910410e-07,  1.29275250e-07,  1.20469934e-07,  1.06715369e-07,\n",
      "       -1.02357447e-07,  8.86908538e-08, -8.68409344e-08, -7.54379315e-08,\n",
      "       -6.67138167e-08, -5.96460907e-08,  8.22361343e-08,  7.77519205e-08,\n",
      "        6.51891909e-08, -4.60309799e-08,  4.71863935e-08,  4.07909262e-08,\n",
      "       -3.13512203e-08, -2.32445281e-08, -2.05118589e-08,  2.84593842e-08,\n",
      "       -1.54707607e-08,  2.40373410e-08,  2.04359782e-08,  1.74161219e-08,\n",
      "       -1.28341338e-08, -4.78165330e-09, -1.86126259e-09,  1.54997981e-09,\n",
      "        1.26006565e-08,  1.00669446e-08,  5.61030511e-09,  6.03947248e-09],\n",
      "      dtype=float32), array([[ 0.04563996, -0.06046851,  0.09847891, ..., -0.04134329,\n",
      "        -0.05210843,  0.00442368],\n",
      "       [ 0.03693012,  0.18394423, -0.06693632, ...,  0.06538884,\n",
      "        -0.02067213,  0.05301142],\n",
      "       [-0.01643709, -0.04352667, -0.1279426 , ...,  0.0991742 ,\n",
      "        -0.09545147, -0.00339616],\n",
      "       ...,\n",
      "       [ 0.03551469,  0.07847884,  0.2520502 , ..., -0.05057915,\n",
      "         0.00127883,  0.00163974],\n",
      "       [ 0.13618334, -0.13219461,  0.15897337, ...,  0.01320543,\n",
      "         0.00488526,  0.00362833],\n",
      "       [ 0.01757207, -0.08160112, -0.06625963, ..., -0.26874006,\n",
      "        -0.01188559, -0.00306915]], dtype=float32))\n",
      "(array([ 2.73325287e+02,  8.57253611e-01,  7.08010793e-01,  2.40340993e-01,\n",
      "        5.94222397e-02,  4.67281453e-02,  2.58342214e-02,  1.76246725e-02,\n",
      "        1.28612742e-02,  7.83639401e-03,  6.16464205e-03,  3.75580112e-03,\n",
      "        2.85071274e-03,  2.42456421e-03,  1.78213534e-03,  1.26364431e-03,\n",
      "        1.01844908e-03,  7.79178750e-04,  6.50972244e-04,  5.52528596e-04,\n",
      "        4.85696772e-04,  3.83363076e-04,  3.01147084e-04,  2.52142549e-04,\n",
      "        2.20450980e-04,  1.71655964e-04,  1.31173234e-04,  1.00395431e-04,\n",
      "        8.92189710e-05,  8.05331365e-05,  5.85381749e-05,  5.32699560e-05,\n",
      "        3.93726878e-05,  3.43498796e-05,  3.10649484e-05,  2.74790691e-05,\n",
      "        2.09068730e-05,  1.80958668e-05,  1.51793474e-05,  1.06472207e-05,\n",
      "       -8.52318681e-06,  9.26962821e-06,  8.16270676e-06,  7.03711567e-06,\n",
      "        6.54473297e-06,  6.27154532e-06,  5.43689612e-06, -4.54604151e-06,\n",
      "        4.19258322e-06, -3.57518229e-06,  3.50047208e-06, -2.48910783e-06,\n",
      "       -2.25908184e-06,  2.72250168e-06,  2.43980094e-06,  2.13821204e-06,\n",
      "       -1.83100087e-06,  1.94383620e-06, -1.52621226e-06,  1.62084393e-06,\n",
      "        1.36859626e-06, -1.11769646e-06,  1.17809873e-06,  1.00536226e-06,\n",
      "       -8.55205030e-07,  8.91238017e-07, -7.16019315e-07, -6.08420123e-07,\n",
      "        6.75741035e-07, -5.18657828e-07,  6.07636480e-07,  5.99343878e-07,\n",
      "       -4.54246134e-07, -3.94223520e-07, -3.52654098e-07,  5.02760201e-07,\n",
      "        4.19309856e-07,  3.88715279e-07,  3.99765241e-07, -3.24404425e-07,\n",
      "        3.13592409e-07,  2.92763787e-07, -2.51832120e-07,  2.07393200e-07,\n",
      "        2.27531316e-07, -1.97349408e-07, -2.10906663e-07, -1.64477939e-07,\n",
      "       -1.53865955e-07, -1.40419516e-07,  1.34666010e-07,  1.38357677e-07,\n",
      "        1.07359746e-07, -1.00702621e-07, -8.99176555e-08, -8.09543508e-08,\n",
      "       -6.54269812e-08,  8.99615600e-08,  7.96530486e-08,  6.47871019e-08,\n",
      "       -5.14756842e-08,  5.84071351e-08,  5.14939558e-08,  4.33161738e-08,\n",
      "       -3.16289110e-08, -2.79372454e-08, -1.41892640e-08, -2.20869065e-08,\n",
      "       -2.14369198e-08,  3.19713962e-08,  2.86158919e-08, -3.86246102e-09,\n",
      "       -2.59135646e-09,  2.11243396e-08,  2.17804508e-09,  3.65332387e-09,\n",
      "        7.17628801e-09,  1.14281642e-08,  1.64439165e-08,  1.67050214e-08],\n",
      "      dtype=float32), array([[ 0.04961165,  0.04366384,  0.04649614, ..., -0.00271104,\n",
      "         0.02948989,  0.00844323],\n",
      "       [ 0.03986432, -0.18724357,  0.04702373, ...,  0.06728858,\n",
      "        -0.05167998, -0.09304861],\n",
      "       [-0.02139982,  0.01483797, -0.09364674, ..., -0.05149557,\n",
      "         0.05699701, -0.0312253 ],\n",
      "       ...,\n",
      "       [ 0.04261708,  0.01680085,  0.22521262, ..., -0.03674575,\n",
      "        -0.10385427, -0.01636966],\n",
      "       [ 0.13902771,  0.16078112,  0.07857876, ...,  0.02290906,\n",
      "        -0.00886065,  0.00648756],\n",
      "       [ 0.01711054,  0.08549275, -0.05063595, ..., -0.0497392 ,\n",
      "         0.12520559,  0.11949814]], dtype=float32))\n",
      "(array([ 2.50380615e+02,  1.30070353e+00,  8.65207136e-01,  2.72441775e-01,\n",
      "        6.85756654e-02,  6.14704117e-02,  3.10987663e-02,  1.69201363e-02,\n",
      "        1.28708892e-02,  9.21049342e-03,  9.00552608e-03,  3.82866315e-03,\n",
      "        2.67782877e-03,  2.06450396e-03,  1.90350588e-03,  1.48698804e-03,\n",
      "        1.09807926e-03,  1.08145038e-03,  7.99020345e-04,  5.59693959e-04,\n",
      "        4.94478387e-04,  4.04789636e-04,  2.83050525e-04,  2.53544073e-04,\n",
      "        2.21858194e-04,  1.82453616e-04,  1.44810154e-04,  1.28648171e-04,\n",
      "        1.11862028e-04,  8.63117384e-05,  6.91818568e-05,  6.06840913e-05,\n",
      "        5.15263309e-05,  4.35141665e-05,  3.30499497e-05,  2.63418115e-05,\n",
      "        2.39096989e-05,  1.56827518e-05,  1.32913910e-05,  1.31604229e-05,\n",
      "        1.15725643e-05,  7.92098945e-06,  7.00126293e-06, -5.66242170e-06,\n",
      "        6.26776637e-06, -5.08212270e-06,  5.04858326e-06,  4.45273827e-06,\n",
      "       -4.00874342e-06,  3.82093185e-06,  3.22393862e-06, -2.21725486e-06,\n",
      "        2.57501415e-06,  2.30822911e-06, -1.92520770e-06, -1.68693930e-06,\n",
      "        1.79081349e-06,  1.58438422e-06,  1.34345180e-06,  1.25401004e-06,\n",
      "       -1.15058981e-06,  1.13073099e-06, -7.91790626e-07,  1.01466946e-06,\n",
      "        8.95889286e-07,  6.95475023e-07,  6.43730289e-07, -6.45692182e-07,\n",
      "       -5.71677788e-07, -4.98402869e-07,  4.79795460e-07,  4.51599988e-07,\n",
      "       -4.17891641e-07, -3.73742523e-07,  3.66423052e-07, -3.35053187e-07,\n",
      "        3.13678214e-07,  2.92080585e-07, -3.03204246e-07, -2.83953312e-07,\n",
      "        2.27158836e-07,  2.05239147e-07, -2.09581614e-07, -1.93953326e-07,\n",
      "       -1.74016122e-07,  1.63054040e-07,  1.53997306e-07, -1.41517916e-07,\n",
      "        1.38293885e-07, -1.10580352e-07, -1.07165143e-07,  1.25314855e-07,\n",
      "        1.22213265e-07, -8.50061284e-08,  1.00976735e-07,  8.46421884e-08,\n",
      "        7.68268933e-08,  6.95848854e-08,  6.23267056e-08, -6.43964313e-08,\n",
      "        4.77698521e-08, -5.58746542e-08,  3.87434866e-08,  2.62270063e-08,\n",
      "       -4.20473043e-08, -3.54864333e-08, -3.25869287e-08,  1.91766141e-08,\n",
      "       -2.16411085e-08,  1.45867762e-08,  1.18246781e-08,  8.92654217e-09,\n",
      "       -1.93099510e-08, -1.74372889e-08,  6.26780405e-09, -1.26263959e-08,\n",
      "        1.91428451e-09, -7.97319633e-09, -2.19185914e-09, -3.22146443e-09],\n",
      "      dtype=float32), array([[ 4.9368978e-02,  2.0289587e-02,  8.8742033e-02, ...,\n",
      "        -7.3500414e-05,  3.2028060e-02, -4.6356488e-02],\n",
      "       [ 3.9085273e-02, -1.8995200e-01, -3.9062057e-02, ...,\n",
      "         6.3428290e-02,  5.2752368e-02, -2.2114666e-02],\n",
      "       [-2.1040292e-02,  2.2207718e-02,  1.6098959e-02, ...,\n",
      "         7.9209551e-02, -8.9806654e-02, -7.6954648e-02],\n",
      "       ...,\n",
      "       [ 3.8478360e-02,  2.7425406e-03, -1.3467431e-01, ...,\n",
      "         2.5827298e-03,  2.0038344e-02,  4.9953414e-03],\n",
      "       [ 1.3481526e-01,  1.7633741e-01, -6.5226443e-02, ...,\n",
      "         6.5666591e-03, -1.0846050e-02,  3.5663281e-02],\n",
      "       [ 1.5853129e-02,  7.1261071e-02,  5.9031125e-02, ...,\n",
      "         1.3221900e-01,  5.0856818e-02,  9.9379189e-02]], dtype=float32))\n",
      "(array([ 2.85540924e+02,  9.83160555e-01,  7.93669522e-01,  3.21518153e-01,\n",
      "        7.49710426e-02,  4.80272882e-02,  3.38532440e-02,  2.64224559e-02,\n",
      "        2.01693755e-02,  1.11618796e-02,  6.46621268e-03,  6.00342778e-03,\n",
      "        3.87544744e-03,  2.66825012e-03,  2.40852660e-03,  1.86075468e-03,\n",
      "        1.73146650e-03,  1.08680816e-03,  9.39140620e-04,  7.48073624e-04,\n",
      "        6.38823432e-04,  5.76937513e-04,  4.84542368e-04,  3.56868230e-04,\n",
      "        2.58973043e-04,  2.45172501e-04,  2.12918632e-04,  1.73238295e-04,\n",
      "        1.50344640e-04,  1.33635462e-04,  1.29743465e-04,  1.02263817e-04,\n",
      "        8.23868395e-05,  7.34051064e-05,  5.32174708e-05,  4.35944894e-05,\n",
      "        3.69570880e-05,  3.47027162e-05,  2.64289283e-05,  2.39448473e-05,\n",
      "        2.23875159e-05,  1.91366216e-05,  1.42735489e-05,  1.18749158e-05,\n",
      "       -9.12393443e-06,  1.03899565e-05,  7.44645604e-06, -5.07036611e-06,\n",
      "        6.18887952e-06,  5.25097585e-06, -3.62642595e-06, -3.17622334e-06,\n",
      "        4.09124368e-06,  3.48297704e-06,  3.17065565e-06,  2.95460268e-06,\n",
      "       -2.28123827e-06, -1.78817288e-06,  1.88264551e-06,  1.62028539e-06,\n",
      "       -1.43864679e-06,  1.42292060e-06,  1.30502383e-06, -1.08959728e-06,\n",
      "       -9.72183216e-07, -8.61666422e-07,  9.63900106e-07,  9.01931514e-07,\n",
      "       -7.54630094e-07, -6.85463135e-07,  7.92205526e-07,  6.85744908e-07,\n",
      "       -5.56972054e-07,  5.74235514e-07,  5.11036603e-07,  4.55519711e-07,\n",
      "       -4.46853079e-07, -4.09474012e-07,  3.42685610e-07, -3.19983940e-07,\n",
      "        2.92068648e-07, -3.01615728e-07, -2.68431393e-07,  2.54767258e-07,\n",
      "        2.32033244e-07, -1.73858922e-07,  1.74512934e-07, -1.52916371e-07,\n",
      "        1.56228197e-07,  1.44807700e-07, -1.22633494e-07,  1.33720505e-07,\n",
      "       -1.04738028e-07,  1.13875167e-07,  9.88419444e-08, -8.82070665e-08,\n",
      "       -7.62910943e-08, -6.46088978e-08, -5.55475630e-08, -4.43338806e-08,\n",
      "       -3.38413706e-08,  5.27271844e-08,  5.16034717e-08,  4.35955236e-08,\n",
      "        3.10448236e-08,  3.83997758e-08, -2.85584161e-08, -2.39263720e-08,\n",
      "        2.78495325e-08, -1.81633713e-08, -2.13390301e-08,  2.44701788e-08,\n",
      "       -6.54416832e-09, -5.40894618e-09, -2.19315441e-10, -1.95831884e-09,\n",
      "        7.08816428e-09,  9.30626154e-09,  1.38402152e-08,  1.61573297e-08],\n",
      "      dtype=float32), array([[ 0.05173667,  0.12368914,  0.00364875, ...,  0.00962572,\n",
      "        -0.00022408,  0.00023177],\n",
      "       [ 0.04338387, -0.14098877,  0.1296733 , ...,  0.07911778,\n",
      "         0.0365105 ,  0.09798843],\n",
      "       [-0.01773362, -0.06030321, -0.10538279, ...,  0.0902397 ,\n",
      "        -0.10476748,  0.00851293],\n",
      "       ...,\n",
      "       [ 0.03452051,  0.1630513 ,  0.2065199 , ...,  0.072809  ,\n",
      "        -0.01011472, -0.10339206],\n",
      "       [ 0.14055705,  0.1885161 , -0.02702562, ..., -0.02341088,\n",
      "         0.00183702,  0.00607541],\n",
      "       [ 0.01952425,  0.02437928, -0.08247776, ...,  0.10890739,\n",
      "         0.14010598, -0.07048668]], dtype=float32))\n",
      "(array([ 3.04827209e+02,  8.19278538e-01,  5.83039761e-01,  1.47525787e-01,\n",
      "        7.66912326e-02,  3.97813395e-02,  3.43890637e-02,  2.19197515e-02,\n",
      "        1.54683311e-02,  6.63508428e-03,  4.93931258e-03,  3.28220753e-03,\n",
      "        2.46769469e-03,  1.79579260e-03,  1.69362326e-03,  1.08979340e-03,\n",
      "        1.02462072e-03,  8.36645835e-04,  5.89707517e-04,  4.72777523e-04,\n",
      "        3.57938465e-04,  2.75207363e-04,  2.41894537e-04,  1.68515806e-04,\n",
      "        1.46544262e-04,  1.37743889e-04,  1.05522187e-04,  9.77981326e-05,\n",
      "        7.82772258e-05,  6.95365597e-05,  4.60604024e-05,  4.07859152e-05,\n",
      "        3.12379780e-05,  2.65618546e-05,  2.31380745e-05,  1.99037186e-05,\n",
      "        1.88566555e-05,  1.36920426e-05, -8.17641012e-06,  1.12803000e-05,\n",
      "        9.69474695e-06,  9.53674135e-06,  7.52913093e-06, -6.19821503e-06,\n",
      "        6.08548817e-06,  5.71773535e-06, -4.19812113e-06,  4.58756813e-06,\n",
      "       -3.42535168e-06,  3.65980600e-06, -2.71157296e-06,  3.21583798e-06,\n",
      "        3.09426810e-06, -2.05357492e-06,  2.41838893e-06,  2.03866625e-06,\n",
      "        1.92956372e-06, -1.51343556e-06,  1.52438179e-06,  1.34025447e-06,\n",
      "       -1.29000773e-06, -1.13730323e-06,  1.16535796e-06, -9.38386336e-07,\n",
      "       -8.81237838e-07,  1.02881177e-06,  1.00454440e-06,  9.03335319e-07,\n",
      "       -5.97758117e-07, -5.81056327e-07,  7.48374134e-07,  6.65237337e-07,\n",
      "        6.40821384e-07,  5.24791460e-07, -4.58373307e-07,  4.64482667e-07,\n",
      "       -4.36336052e-07,  4.24410416e-07, -3.05118647e-07, -2.86025312e-07,\n",
      "        3.56068085e-07,  3.20372209e-07,  3.04864585e-07, -2.28178379e-07,\n",
      "       -1.98150587e-07,  2.13775692e-07,  2.00612121e-07, -1.60272961e-07,\n",
      "       -1.45546295e-07, -1.12212646e-07, -1.09973676e-07, -8.14817867e-08,\n",
      "        1.26203815e-07,  1.19119022e-07,  1.11363754e-07,  9.48234486e-08,\n",
      "        1.03547443e-07,  7.21044131e-08, -6.15185414e-08, -5.34739684e-08,\n",
      "       -4.66679637e-08,  4.95463794e-08,  6.23425152e-08,  5.79098263e-08,\n",
      "       -4.12354062e-08, -3.40926469e-08,  4.09873913e-08,  3.46354554e-08,\n",
      "        2.51639989e-08, -2.37504860e-08, -2.09828599e-08,  1.61617297e-08,\n",
      "        1.41620893e-08, -1.47323691e-08,  7.46500139e-10, -2.23921215e-09,\n",
      "       -6.87777257e-09, -1.24544899e-08,  8.76383854e-09,  1.01802984e-08],\n",
      "      dtype=float32), array([[-0.05234073, -0.0211603 , -0.04981893, ...,  0.00333188,\n",
      "        -0.02216246,  0.00187587],\n",
      "       [-0.04189296, -0.08738088,  0.19173855, ..., -0.0958628 ,\n",
      "        -0.04828449, -0.08022387],\n",
      "       [ 0.01698919,  0.07978628,  0.01210449, ..., -0.05480827,\n",
      "        -0.06538845, -0.17999353],\n",
      "       ...,\n",
      "       [-0.0350966 , -0.21670228, -0.11734229, ..., -0.15355077,\n",
      "         0.01932471,  0.02789675],\n",
      "       [-0.14451157, -0.03009727, -0.15617968, ...,  0.0012529 ,\n",
      "        -0.02266702,  0.00702433],\n",
      "       [-0.02062274,  0.06356509, -0.05671544, ..., -0.14947997,\n",
      "        -0.00128147, -0.01562647]], dtype=float32))\n",
      "(array([ 2.66560516e+02,  1.01860690e+00,  6.27977550e-01,  4.83003438e-01,\n",
      "        8.23840946e-02,  6.05263896e-02,  3.98147143e-02,  3.04560550e-02,\n",
      "        2.25061048e-02,  1.82140842e-02,  8.72830302e-03,  5.81781007e-03,\n",
      "        4.13725898e-03,  3.25752096e-03,  2.49565160e-03,  2.24685809e-03,\n",
      "        1.78082229e-03,  1.30979763e-03,  1.00541080e-03,  8.61277280e-04,\n",
      "        7.50487321e-04,  6.15933444e-04,  5.08345140e-04,  4.32675646e-04,\n",
      "        3.95387120e-04,  3.13579192e-04,  2.59925117e-04,  2.34396197e-04,\n",
      "        2.00123395e-04,  1.59486328e-04,  1.51004439e-04,  1.06228850e-04,\n",
      "        8.62077723e-05,  8.28174743e-05,  7.48683160e-05,  6.36061013e-05,\n",
      "        4.97356377e-05,  4.37225171e-05,  3.27747657e-05,  3.10019495e-05,\n",
      "        2.36369870e-05,  2.25455369e-05,  1.87002679e-05,  1.48142026e-05,\n",
      "        1.41116807e-05,  9.57719840e-06,  8.44323586e-06, -5.93281175e-06,\n",
      "       -5.17802300e-06,  6.60998739e-06,  6.33083482e-06,  4.69223232e-06,\n",
      "        4.12848158e-06, -3.45623425e-06, -2.35112316e-06,  2.77877643e-06,\n",
      "        2.44309444e-06,  2.19963090e-06,  2.00626937e-06, -1.76188144e-06,\n",
      "       -1.40331292e-06, -1.14206466e-06, -1.02214892e-06,  1.26043551e-06,\n",
      "        1.11399322e-06,  1.10697908e-06,  9.35205094e-07, -8.75044748e-07,\n",
      "        7.21529659e-07, -7.41542976e-07, -6.11895814e-07,  5.45362468e-07,\n",
      "        5.24767756e-07, -5.04730906e-07, -4.32807013e-07,  4.57076368e-07,\n",
      "       -3.54145840e-07, -2.80578035e-07, -2.92528597e-07,  3.58946409e-07,\n",
      "        3.42700702e-07,  2.94183678e-07,  2.63705715e-07, -2.32862405e-07,\n",
      "        2.08260929e-07,  1.78332527e-07, -1.75358167e-07,  1.62044870e-07,\n",
      "       -1.58681843e-07, -1.34818436e-07,  9.59039497e-08,  1.20087293e-07,\n",
      "        1.14270193e-07, -9.11765454e-08, -1.07088425e-07,  7.39397450e-08,\n",
      "       -7.61677441e-08, -7.28831608e-08,  6.12895903e-08, -6.14575555e-08,\n",
      "       -5.24079695e-08,  4.79591513e-08,  3.94414101e-08,  3.02690637e-08,\n",
      "        2.50977283e-08, -3.42414666e-08, -3.19809139e-08, -2.68260294e-08,\n",
      "        1.63603939e-08, -2.03969943e-08,  1.24882105e-08,  9.74754855e-09,\n",
      "        4.93542895e-09, -1.59517786e-08, -2.29634245e-09, -7.21985449e-09,\n",
      "       -1.12876997e-08, -9.48430046e-09,  2.53174681e-09,  1.70833592e-09],\n",
      "      dtype=float32), array([[ 0.05121614,  0.01727546,  0.10542579, ..., -0.01834629,\n",
      "        -0.02083399, -0.00112781],\n",
      "       [ 0.04251034, -0.16502547,  0.03418848, ...,  0.07174747,\n",
      "        -0.05258817,  0.03543507],\n",
      "       [-0.01394085,  0.01421471, -0.10895828, ..., -0.07389029,\n",
      "         0.03173645, -0.0430295 ],\n",
      "       ...,\n",
      "       [ 0.02695226,  0.00805613,  0.2405363 , ..., -0.06582289,\n",
      "        -0.04030585,  0.02013198],\n",
      "       [ 0.136631  ,  0.23223048,  0.08412232, ...,  0.01766251,\n",
      "         0.00109038, -0.02165175],\n",
      "       [ 0.02099864,  0.05159405, -0.05560469, ..., -0.17429483,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.01194282, -0.06955633]], dtype=float32))\n",
      "(array([ 2.77633240e+02,  1.53030872e+00,  6.57243490e-01,  4.99216110e-01,\n",
      "        7.30897039e-02,  5.00877313e-02,  3.37895378e-02,  2.81453263e-02,\n",
      "        2.16183346e-02,  1.50324106e-02,  7.32716359e-03,  6.49176119e-03,\n",
      "        4.57994826e-03,  3.70392925e-03,  3.20172659e-03,  2.04352522e-03,\n",
      "        1.58522837e-03,  1.27478305e-03,  1.10204122e-03,  1.02993276e-03,\n",
      "        6.23086700e-04,  4.86456527e-04,  4.36202303e-04,  4.16917843e-04,\n",
      "        3.29551141e-04,  2.71025317e-04,  2.35459927e-04,  1.83925382e-04,\n",
      "        1.40941396e-04,  1.26086685e-04,  1.18228061e-04,  9.36632568e-05,\n",
      "        6.73490140e-05,  6.02975779e-05,  4.40451622e-05,  3.92101247e-05,\n",
      "        3.18350467e-05,  2.70194632e-05,  2.30692185e-05,  1.35575565e-05,\n",
      "        1.13016322e-05,  9.58733563e-06,  7.99877307e-06, -6.41794531e-06,\n",
      "        5.65465780e-06, -4.77433241e-06, -4.21422783e-06,  4.44445959e-06,\n",
      "        4.14642318e-06,  3.88080616e-06, -3.22596725e-06, -2.67347605e-06,\n",
      "        2.98272471e-06,  2.31156355e-06, -2.05351398e-06, -1.77276172e-06,\n",
      "        2.12887289e-06,  1.98319344e-06,  1.88091587e-06, -1.41173507e-06,\n",
      "       -1.08063955e-06,  1.23457687e-06,  1.15625357e-06, -9.25751237e-07,\n",
      "        9.66260131e-07,  9.20572461e-07,  7.90998968e-07, -7.33354284e-07,\n",
      "       -6.37255823e-07,  6.44448448e-07,  5.92074969e-07, -5.01340821e-07,\n",
      "        5.00199576e-07, -4.29804231e-07,  4.61235260e-07,  4.21666698e-07,\n",
      "        3.37910251e-07, -3.45038842e-07,  2.91804184e-07,  2.66659669e-07,\n",
      "       -2.70179470e-07, -2.56963489e-07, -2.32273734e-07, -2.03188719e-07,\n",
      "        2.04880280e-07,  1.73973248e-07, -1.71238440e-07, -1.33646552e-07,\n",
      "       -1.21980463e-07,  1.59049279e-07,  1.43263378e-07,  1.37154572e-07,\n",
      "       -1.07024626e-07,  1.02006624e-07, -8.51701714e-08, -7.79482505e-08,\n",
      "        8.03612323e-08,  7.33753538e-08,  7.50202886e-08, -6.02425203e-08,\n",
      "       -6.73502569e-08,  5.46645467e-08,  4.20378363e-08, -3.59944821e-08,\n",
      "       -4.40064447e-08,  2.74058269e-08, -2.52274504e-08,  2.22629488e-08,\n",
      "       -2.02239185e-08, -1.79051032e-08, -1.54490802e-08, -1.17438272e-08,\n",
      "       -7.57610774e-09,  1.86722353e-08,  1.64509508e-08,  1.31056970e-08,\n",
      "        4.16339008e-09, -5.23738297e-09, -4.34590475e-10,  6.78070178e-09],\n",
      "      dtype=float32), array([[ 0.05376844, -0.02706272, -0.05623275, ..., -0.01935381,\n",
      "        -0.00766569, -0.01291181],\n",
      "       [ 0.04484137, -0.07276757,  0.17898788, ...,  0.02634167,\n",
      "        -0.06542141, -0.06691498],\n",
      "       [-0.01796442, -0.04129794, -0.06436595, ..., -0.06282361,\n",
      "        -0.03686647, -0.0770511 ],\n",
      "       ...,\n",
      "       [ 0.03436567,  0.13606884,  0.11400176, ..., -0.00879646,\n",
      "         0.00019088, -0.01349524],\n",
      "       [ 0.14136346,  0.17265418, -0.0806262 , ...,  0.00552741,\n",
      "         0.00819188, -0.01413892],\n",
      "       [ 0.0190088 ,  0.01581765, -0.09051633, ...,  0.05249888,\n",
      "        -0.04382046, -0.04027627]], dtype=float32))\n",
      "(array([ 2.4235622e+02,  1.2982980e+00,  8.7197948e-01,  7.8037694e-02,\n",
      "        6.5044709e-02,  3.3705242e-02,  1.7311165e-02,  1.4335538e-02,\n",
      "        1.0510745e-02,  6.9413367e-03,  4.8667407e-03,  3.2056172e-03,\n",
      "        2.2129586e-03,  1.5148717e-03,  9.8952663e-04,  9.1397663e-04,\n",
      "        7.6216023e-04,  6.5604725e-04,  4.8237719e-04,  3.8304369e-04,\n",
      "        3.1989405e-04,  2.5428535e-04,  1.9697416e-04,  1.7217649e-04,\n",
      "        1.5194119e-04,  1.3077496e-04,  9.7548997e-05,  8.0191341e-05,\n",
      "        7.3015704e-05,  6.1302118e-05,  5.0995106e-05,  4.0859846e-05,\n",
      "        3.6373949e-05,  2.6190773e-05,  2.2038668e-05,  2.1809414e-05,\n",
      "        1.4349817e-05,  1.1625252e-05,  1.0344800e-05,  8.1024518e-06,\n",
      "        7.5421071e-06,  6.6749176e-06, -4.7285675e-06,  5.7695893e-06,\n",
      "       -4.0822970e-06,  4.5637084e-06,  3.8666280e-06, -2.7756973e-06,\n",
      "       -2.5641596e-06,  2.7547990e-06,  2.8304146e-06,  2.1631902e-06,\n",
      "        2.0122825e-06, -1.6619158e-06,  1.6151479e-06, -1.4216380e-06,\n",
      "       -1.2964584e-06, -1.2201369e-06,  1.3321867e-06,  1.4579375e-06,\n",
      "        1.1580918e-06,  1.0036706e-06, -8.2487833e-07,  8.5989069e-07,\n",
      "       -7.1599004e-07,  7.6596729e-07, -6.4582463e-07,  7.1994441e-07,\n",
      "        5.9792154e-07, -4.8191697e-07, -4.5167496e-07,  5.2211033e-07,\n",
      "        4.6029524e-07,  4.1225263e-07, -3.3394625e-07, -2.9661595e-07,\n",
      "        3.1601238e-07,  2.8510416e-07,  2.4920618e-07, -2.5129637e-07,\n",
      "       -2.3188346e-07, -1.9484951e-07, -1.5984926e-07,  2.2324723e-07,\n",
      "        1.9423726e-07,  1.7583943e-07,  1.6930025e-07,  1.4568604e-07,\n",
      "       -1.2413575e-07, -9.9682147e-08,  1.1035298e-07,  1.0417261e-07,\n",
      "       -8.1194273e-08, -6.9324450e-08, -7.5352389e-08,  6.9042670e-08,\n",
      "        7.3715611e-08, -4.8685028e-08,  5.3614329e-08,  5.0204957e-08,\n",
      "        4.3246185e-08, -4.4037641e-08, -3.8056864e-08, -3.1712883e-08,\n",
      "        3.1349835e-08,  2.9134650e-08,  2.1380494e-08, -2.5065031e-08,\n",
      "       -2.1573094e-08, -1.3752556e-08,  1.7662884e-08, -1.0849046e-08,\n",
      "        1.1259834e-08,  1.0290825e-08,  7.0641306e-09, -5.7566143e-09,\n",
      "       -3.9865116e-09,  3.7709826e-09, -2.1011366e-09,  2.7171465e-09],\n",
      "      dtype=float32), array([[ 0.03641365,  0.02455109, -0.15312226, ...,  0.10619257,\n",
      "         0.0158866 ,  0.0132169 ],\n",
      "       [ 0.041308  , -0.15342297,  0.12434906, ...,  0.00655853,\n",
      "         0.00308412, -0.01934605],\n",
      "       [-0.00979908, -0.03577315, -0.02398045, ...,  0.08946199,\n",
      "        -0.06102459, -0.05922518],\n",
      "       ...,\n",
      "       [ 0.01640555,  0.10855912,  0.07706884, ...,  0.09304347,\n",
      "         0.01121149,  0.14811699],\n",
      "       [ 0.13077275,  0.23117918, -0.04217113, ..., -0.02321878,\n",
      "         0.00673982,  0.03065714],\n",
      "       [ 0.02333783, -0.00507383, -0.08386721, ..., -0.07757381,\n",
      "        -0.00245638,  0.1622547 ]], dtype=float32))\n",
      "(array([ 2.5615503e+02,  1.0087864e+00,  7.7168965e-01,  6.2482506e-01,\n",
      "        1.2275387e-01,  6.9882393e-02,  3.6864325e-02,  3.4982588e-02,\n",
      "        2.1365322e-02,  1.0479945e-02,  8.7369848e-03,  7.3197973e-03,\n",
      "        4.4633094e-03,  3.2480056e-03,  2.7829774e-03,  2.2228376e-03,\n",
      "        1.6730389e-03,  1.4325582e-03,  1.2806433e-03,  1.0649019e-03,\n",
      "        6.7041017e-04,  6.3061411e-04,  5.2975549e-04,  3.7161785e-04,\n",
      "        3.1845758e-04,  2.3086579e-04,  1.8493374e-04,  1.6253938e-04,\n",
      "        1.4075749e-04,  1.2526728e-04,  1.1174938e-04,  1.0331405e-04,\n",
      "        8.3023893e-05,  7.0698559e-05,  6.1838356e-05,  5.0967748e-05,\n",
      "        3.8894217e-05,  2.7385368e-05,  2.5356767e-05,  2.2947959e-05,\n",
      "        1.8689476e-05,  1.4681775e-05,  1.2323475e-05,  1.0584955e-05,\n",
      "        8.9427413e-06, -5.8459909e-06,  6.2263521e-06,  5.9032568e-06,\n",
      "       -4.5270262e-06, -4.1255075e-06,  4.8368670e-06,  4.3321847e-06,\n",
      "        3.7764328e-06,  2.8819222e-06,  2.5696909e-06, -2.2542795e-06,\n",
      "        2.0250800e-06, -1.8106639e-06,  1.5931508e-06,  1.3759318e-06,\n",
      "       -1.4751164e-06, -1.3278868e-06,  1.1804048e-06,  1.0341639e-06,\n",
      "       -9.5885764e-07, -9.0705220e-07,  8.6270347e-07,  7.4675256e-07,\n",
      "        6.0210459e-07, -5.9070669e-07, -5.9266347e-07,  5.2009534e-07,\n",
      "        4.5870812e-07, -4.8862091e-07, -4.4118335e-07, -3.7316741e-07,\n",
      "       -3.3997287e-07, -3.4729806e-07,  3.9540637e-07,  3.4899057e-07,\n",
      "        3.3173731e-07,  2.5313639e-07,  2.4045420e-07, -2.6400068e-07,\n",
      "       -2.2592620e-07,  1.7708618e-07, -1.7917547e-07, -1.5190844e-07,\n",
      "       -1.2645678e-07,  1.4571890e-07,  1.3624940e-07,  1.2277644e-07,\n",
      "       -1.0135496e-07, -8.3334470e-08,  1.0160469e-07,  7.5558141e-08,\n",
      "        8.1394504e-08, -6.6767555e-08, -6.1973743e-08,  5.9246034e-08,\n",
      "        4.7219221e-08, -4.8962555e-08, -4.6150809e-08, -4.1020034e-08,\n",
      "       -3.0516262e-08,  3.7404490e-08,  3.4599719e-08,  2.7491966e-08,\n",
      "        1.9376257e-08, -2.3287200e-08,  1.6277824e-08, -1.8411471e-08,\n",
      "       -1.4624434e-08, -1.0917246e-08, -8.3572340e-09,  7.3789486e-09,\n",
      "        5.4039009e-09,  2.7940048e-09,  3.8814274e-10, -2.9067737e-09],\n",
      "      dtype=float32), array([[ 0.05598253,  0.03840584,  0.12988642, ...,  0.00670789,\n",
      "        -0.00493417,  0.00268833],\n",
      "       [ 0.0475049 ,  0.13909556,  0.07705351, ..., -0.00271569,\n",
      "         0.04232228,  0.06449746],\n",
      "       [-0.00904034, -0.00995194, -0.10718081, ...,  0.12184882,\n",
      "        -0.16847418, -0.00991101],\n",
      "       ...,\n",
      "       [ 0.01336926, -0.03814338,  0.1819383 , ..., -0.01628564,\n",
      "        -0.06017563,  0.02518188],\n",
      "       [ 0.13052876, -0.22133894,  0.09753262, ..., -0.00637709,\n",
      "         0.01588698, -0.01609088],\n",
      "       [ 0.02587558, -0.02504566, -0.09506325, ...,  0.07017321,\n",
      "         0.02205775, -0.00342004]], dtype=float32))\n",
      "(array([ 2.41137512e+02,  7.43958950e-01,  3.22083443e-01,  6.47936910e-02,\n",
      "        5.13830520e-02,  2.55315546e-02,  7.73946708e-03,  6.03716867e-03,\n",
      "        4.43735579e-03,  3.89647321e-03,  2.57411553e-03,  1.59190875e-03,\n",
      "        1.10677502e-03,  7.48192251e-04,  6.23215514e-04,  4.86526085e-04,\n",
      "        4.15381946e-04,  3.03868641e-04,  2.91425647e-04,  1.55296526e-04,\n",
      "        1.32858186e-04,  1.05649917e-04,  9.50770118e-05,  8.40985449e-05,\n",
      "        7.01744502e-05,  6.68913854e-05,  3.71214301e-05,  3.46169581e-05,\n",
      "        3.09244351e-05,  2.85991537e-05,  2.16591670e-05,  1.88741251e-05,\n",
      "        1.62007000e-05,  1.18053249e-05,  1.01800770e-05,  9.46630098e-06,\n",
      "       -7.48635603e-06,  7.87850422e-06, -5.19571586e-06,  5.57296471e-06,\n",
      "        5.50800769e-06,  4.89958484e-06, -3.48098229e-06,  4.32964816e-06,\n",
      "        3.72389309e-06,  3.09109237e-06,  2.81570601e-06,  2.48840252e-06,\n",
      "        2.09906375e-06, -1.95691291e-06,  1.89654770e-06, -1.61960145e-06,\n",
      "       -1.49833136e-06,  1.68534552e-06,  1.56660894e-06,  1.37858979e-06,\n",
      "        1.20893674e-06, -1.06823052e-06, -9.41151598e-07,  1.07987091e-06,\n",
      "        8.58024123e-07, -7.27316717e-07,  8.06455887e-07, -6.56776137e-07,\n",
      "        7.27020449e-07,  6.71616931e-07, -6.19237142e-07, -5.17434046e-07,\n",
      "       -4.59885428e-07, -3.59988775e-07,  5.60972467e-07,  5.51890707e-07,\n",
      "        4.14612629e-07,  4.45134390e-07,  3.55533132e-07, -2.80651903e-07,\n",
      "        3.04228394e-07,  2.89129986e-07, -2.43834137e-07,  2.37687132e-07,\n",
      "       -2.01649783e-07, -1.95383890e-07,  1.97090884e-07,  1.74543104e-07,\n",
      "        1.50745834e-07, -1.58764863e-07, -1.48898877e-07, -1.30205322e-07,\n",
      "        1.35565088e-07, -1.00136958e-07,  1.16753419e-07,  1.03777545e-07,\n",
      "        8.87568348e-08,  7.03664469e-08, -8.53103472e-08, -6.95513620e-08,\n",
      "       -6.28037000e-08,  5.69106398e-08, -4.29082512e-08,  4.56217428e-08,\n",
      "        4.26356657e-08, -4.02960687e-08, -3.44267654e-08,  3.90090911e-08,\n",
      "        3.31337695e-08,  2.38085196e-08, -2.93055269e-08, -2.03862758e-08,\n",
      "        1.98660555e-08, -2.12933635e-08,  2.05576054e-08,  1.32420617e-08,\n",
      "       -3.16704774e-09, -8.80640449e-09, -9.54978674e-09, -2.67769921e-11,\n",
      "        7.26980343e-09,  5.30019761e-09,  3.39754114e-09,  3.44332607e-09],\n",
      "      dtype=float32), array([[ 0.04020197, -0.10374138,  0.1551317 , ...,  0.02872491,\n",
      "        -0.01460672,  0.00637922],\n",
      "       [ 0.04712943,  0.19956522, -0.01516872, ..., -0.00045046,\n",
      "        -0.03237362,  0.02778971],\n",
      "       [-0.00389335,  0.01734045,  0.02663634, ..., -0.00926228,\n",
      "        -0.2149967 ,  0.2313511 ],\n",
      "       ...,\n",
      "       [ 0.00317902, -0.05523302, -0.0974246 , ...,  0.06683376,\n",
      "        -0.14774916,  0.04196359],\n",
      "       [ 0.12468433, -0.21489692, -0.06239625, ..., -0.01743655,\n",
      "         0.0143074 , -0.01618929],\n",
      "       [ 0.02864781, -0.0209012 ,  0.07627633, ..., -0.10353056,\n",
      "        -0.00714344, -0.02606205]], dtype=float32))\n",
      "(array([ 2.50029663e+02,  9.82900083e-01,  5.73241353e-01,  4.42224145e-01,\n",
      "        6.34369478e-02,  3.93062942e-02,  3.05187590e-02,  2.54319422e-02,\n",
      "        2.05939375e-02,  1.03747500e-02,  8.11923109e-03,  4.55410220e-03,\n",
      "        2.58671958e-03,  2.09651934e-03,  1.90725434e-03,  1.33081945e-03,\n",
      "        1.01158861e-03,  6.86597195e-04,  5.92280878e-04,  4.74506960e-04,\n",
      "        3.87156149e-04,  3.57950019e-04,  2.58055312e-04,  2.04450655e-04,\n",
      "        1.80837029e-04,  1.61335847e-04,  1.47166415e-04,  1.35198512e-04,\n",
      "        1.18005984e-04,  8.99454244e-05,  7.11661050e-05,  6.77833887e-05,\n",
      "        4.60131560e-05,  4.14183014e-05,  3.67245339e-05,  2.69999473e-05,\n",
      "        2.51674028e-05,  2.32529565e-05,  1.55419111e-05,  1.34135707e-05,\n",
      "        1.28260253e-05,  9.54721509e-06, -6.67282393e-06,  7.77874266e-06,\n",
      "        7.46076421e-06, -4.34569938e-06,  5.51341282e-06,  5.09052279e-06,\n",
      "        4.70770419e-06, -3.18043840e-06,  3.52837787e-06, -2.61255173e-06,\n",
      "        3.01627756e-06,  2.45014758e-06,  2.18318951e-06, -1.88985678e-06,\n",
      "       -1.75323635e-06,  1.83522468e-06, -1.35235803e-06,  1.53076644e-06,\n",
      "        1.31084471e-06, -1.04935600e-06,  1.06621042e-06, -8.79204890e-07,\n",
      "       -7.80087191e-07,  8.39962127e-07,  6.85206771e-07, -5.73173395e-07,\n",
      "        6.03131014e-07,  5.65322750e-07, -4.46160527e-07,  5.01633792e-07,\n",
      "        4.36947403e-07,  3.81130519e-07, -3.71884170e-07, -3.28777020e-07,\n",
      "       -2.84141095e-07, -2.46146470e-07, -2.51483954e-07,  3.07164498e-07,\n",
      "        2.91030972e-07,  2.34469212e-07,  2.11588969e-07, -1.77186209e-07,\n",
      "       -1.65358699e-07,  1.60683683e-07,  1.50329555e-07, -1.34624685e-07,\n",
      "       -1.38840491e-07,  1.21031988e-07, -1.07215278e-07,  1.10978505e-07,\n",
      "        8.71998864e-08, -8.08298566e-08, -7.27748102e-08, -6.46451852e-08,\n",
      "        9.17204943e-08,  6.32513490e-08, -5.40247846e-08,  5.82537112e-08,\n",
      "       -4.17938644e-08, -3.38233583e-08,  5.31973789e-08,  4.15490362e-08,\n",
      "        3.52580365e-08, -2.16968932e-08,  2.97315736e-08,  2.17695604e-08,\n",
      "        2.87362969e-08, -1.86200708e-08, -2.23947509e-08, -1.56756741e-08,\n",
      "       -1.17157750e-08,  1.10225908e-08,  7.09475856e-09,  6.58607746e-09,\n",
      "       -2.78735124e-09, -1.22836818e-09,  1.33305589e-09,  2.66721001e-09],\n",
      "      dtype=float32), array([[ 0.04287658, -0.05943115, -0.2607139 , ...,  0.06818773,\n",
      "        -0.07902664, -0.00074545],\n",
      "       [ 0.04501015, -0.10212349,  0.14855996, ...,  0.05570958,\n",
      "        -0.03279911, -0.00818792],\n",
      "       [-0.00825627, -0.00539935,  0.02639827, ..., -0.049562  ,\n",
      "         0.11886159, -0.17050974],\n",
      "       ...,\n",
      "       [ 0.01215655,  0.07271075, -0.04515212, ...,  0.09279485,\n",
      "        -0.11601478, -0.16734314],\n",
      "       [ 0.13066998,  0.18584436, -0.16007392, ..., -0.01259927,\n",
      "         0.02396107,  0.00669217],\n",
      "       [ 0.02246508, -0.0040807 , -0.0290563 , ...,  0.03897263,\n",
      "         0.09181681, -0.15238726]], dtype=float32))\n",
      "(array([ 2.43387436e+02,  9.30279255e-01,  5.79352856e-01,  3.83423209e-01,\n",
      "        1.17492244e-01,  8.67972225e-02,  5.16386554e-02,  4.01844978e-02,\n",
      "        1.51682254e-02,  1.18875252e-02,  8.56920145e-03,  6.50719460e-03,\n",
      "        4.86813346e-03,  3.79232992e-03,  3.43844900e-03,  1.97841343e-03,\n",
      "        1.71512854e-03,  1.41753943e-03,  1.12231844e-03,  9.16399062e-04,\n",
      "        7.93186540e-04,  4.78645234e-04,  4.42620774e-04,  3.72174458e-04,\n",
      "        2.93785211e-04,  2.57614185e-04,  2.24528485e-04,  2.17120236e-04,\n",
      "        1.91923973e-04,  1.29430875e-04,  9.84080034e-05,  1.01408485e-04,\n",
      "        7.51685875e-05,  7.32568078e-05,  6.90975794e-05,  4.92369400e-05,\n",
      "        3.47726127e-05,  3.05682042e-05,  2.29649941e-05,  1.89657148e-05,\n",
      "        1.57158665e-05,  1.30977051e-05,  1.12255248e-05,  1.03398970e-05,\n",
      "       -7.18690853e-06,  7.89608475e-06,  6.22579955e-06,  6.01991314e-06,\n",
      "       -4.41212660e-06, -3.66852737e-06,  4.68935377e-06,  3.65005894e-06,\n",
      "        3.54129520e-06,  3.17242507e-06, -2.11472593e-06,  2.43510112e-06,\n",
      "       -1.80934921e-06,  1.86490104e-06, -1.21660560e-06,  1.50349581e-06,\n",
      "        1.30998262e-06, -1.05955166e-06,  1.04163064e-06,  9.35942865e-07,\n",
      "       -9.07768879e-07, -8.13218833e-07,  7.97839107e-07,  6.55206861e-07,\n",
      "       -6.08898233e-07, -5.55658346e-07,  5.68211362e-07, -4.93622167e-07,\n",
      "        5.03303511e-07,  4.90977413e-07, -3.88276447e-07,  3.94693245e-07,\n",
      "        3.71808170e-07, -3.12331906e-07, -2.96461536e-07,  2.73427816e-07,\n",
      "       -2.53813653e-07, -2.18716721e-07, -1.86084705e-07,  2.39753035e-07,\n",
      "        2.43793579e-07,  1.85000459e-07,  1.68135145e-07, -1.63244678e-07,\n",
      "        1.35460311e-07, -1.16214594e-07,  1.21142435e-07, -9.96443177e-08,\n",
      "       -8.94563712e-08,  9.77883658e-08,  7.82703395e-08,  6.77469458e-08,\n",
      "       -7.24015550e-08,  5.97198309e-08, -5.69469059e-08,  5.36689448e-08,\n",
      "       -4.88059477e-08, -4.40683117e-08,  3.73924394e-08,  2.87085200e-08,\n",
      "        2.55049368e-08,  2.32585275e-08, -3.12461097e-08, -2.86697279e-08,\n",
      "       -2.18727632e-08,  1.64520308e-08, -1.63703735e-08,  1.16193384e-08,\n",
      "       -1.06385292e-08, -1.09967280e-08, -7.42157225e-09, -6.62735333e-09,\n",
      "        5.10688869e-09,  1.08753595e-09,  1.98260053e-09,  3.14327342e-09],\n",
      "      dtype=float32), array([[ 0.04565545, -0.20261493, -0.10981075, ...,  0.00610243,\n",
      "         0.03412304,  0.0013833 ],\n",
      "       [ 0.04669278,  0.15635397, -0.06835701, ..., -0.04992025,\n",
      "         0.07081767, -0.01932465],\n",
      "       [-0.0081176 ,  0.00709572,  0.07370227, ...,  0.12513815,\n",
      "        -0.01181274,  0.20281495],\n",
      "       ...,\n",
      "       [ 0.00938894, -0.05899219, -0.19922777, ..., -0.04040805,\n",
      "         0.07026987, -0.00982661],\n",
      "       [ 0.12923065, -0.2279536 ,  0.00932873, ..., -0.01598855,\n",
      "         0.02565246, -0.0084265 ],\n",
      "       [ 0.02567578, -0.02594475,  0.11694967, ...,  0.02481882,\n",
      "        -0.02368703,  0.00620754]], dtype=float32))\n",
      "(array([ 2.4196852e+02,  1.1545506e+00,  7.5145566e-01,  4.7616863e-01,\n",
      "        1.9668673e-01,  6.8592757e-02,  4.0766709e-02,  3.6692698e-02,\n",
      "        2.3337442e-02,  1.1909320e-02,  7.8539085e-03,  5.3357868e-03,\n",
      "        3.4639011e-03,  3.1644849e-03,  2.1490592e-03,  1.9179769e-03,\n",
      "        1.6632465e-03,  1.2497699e-03,  9.6754770e-04,  9.3204749e-04,\n",
      "        6.8894745e-04,  4.9946521e-04,  4.3870113e-04,  3.5128486e-04,\n",
      "        3.2054115e-04,  2.6391831e-04,  2.2835999e-04,  2.0096207e-04,\n",
      "        1.3745741e-04,  1.2919548e-04,  1.0502396e-04,  8.8971508e-05,\n",
      "        7.2372415e-05,  6.2585088e-05,  5.1398671e-05,  5.0896844e-05,\n",
      "        4.1193813e-05,  3.4954886e-05,  2.5836436e-05,  1.7093713e-05,\n",
      "        1.6993616e-05,  1.1317859e-05,  1.1131389e-05, -8.8379566e-06,\n",
      "        8.1584940e-06,  7.0483161e-06,  5.1567213e-06, -4.2194729e-06,\n",
      "        4.5089114e-06,  3.8004398e-06, -3.1199875e-06,  3.0115368e-06,\n",
      "       -2.4221820e-06, -2.0783821e-06,  2.5137890e-06,  2.4399812e-06,\n",
      "        2.0444531e-06, -1.2968452e-06,  1.4810558e-06,  1.3375414e-06,\n",
      "       -1.1387729e-06,  1.0740051e-06,  9.4109305e-07,  8.1087057e-07,\n",
      "       -8.1164467e-07, -7.4739756e-07,  6.8773147e-07,  5.9327652e-07,\n",
      "       -6.2836000e-07, -5.6635446e-07, -5.5795323e-07,  5.2741444e-07,\n",
      "        4.9981520e-07, -4.6052230e-07, -3.7278872e-07, -3.1548063e-07,\n",
      "       -3.3428876e-07,  4.0282305e-07,  3.6060925e-07,  3.0818072e-07,\n",
      "        3.2883148e-07,  2.7463216e-07, -2.4052912e-07, -2.2559138e-07,\n",
      "        1.9443135e-07, -1.9907596e-07,  1.7187723e-07,  1.4239878e-07,\n",
      "       -1.3083904e-07, -1.1935377e-07,  1.2703245e-07, -1.0773469e-07,\n",
      "       -9.3797958e-08,  1.0717854e-07,  9.8042086e-08,  8.4675655e-08,\n",
      "        7.4741585e-08, -6.1924105e-08,  6.6928166e-08, -5.8878136e-08,\n",
      "       -5.3194849e-08, -4.5299835e-08,  5.1898397e-08, -3.5289176e-08,\n",
      "        4.3379771e-08,  4.0449535e-08, -3.2684198e-08, -2.6049571e-08,\n",
      "        2.9669371e-08,  1.7212212e-08,  2.2306326e-08,  9.1351273e-09,\n",
      "        7.7322184e-09,  4.8545501e-09,  3.6133568e-10, -3.1239775e-09,\n",
      "       -6.0786483e-09, -9.0202290e-09, -1.1593422e-08, -1.0888861e-08],\n",
      "      dtype=float32), array([[ 0.04821978, -0.1292279 ,  0.18499011, ...,  0.01640152,\n",
      "        -0.04522666,  0.05845015],\n",
      "       [ 0.04679389, -0.12317991, -0.16280994, ...,  0.01864173,\n",
      "        -0.01190422, -0.0011443 ],\n",
      "       [-0.0140175 ,  0.10479351, -0.06490467, ...,  0.10101201,\n",
      "         0.05381019, -0.00814639],\n",
      "       ...,\n",
      "       [ 0.01668334, -0.19189829,  0.15296996, ...,  0.00988685,\n",
      "        -0.01489191,  0.1918141 ],\n",
      "       [ 0.13284482,  0.00785975,  0.19360888, ..., -0.02566534,\n",
      "        -0.02688142,  0.00040134],\n",
      "       [ 0.02299647,  0.09821381, -0.01812898, ..., -0.08185785,\n",
      "        -0.01365971,  0.03393219]], dtype=float32))\n",
      "(array([ 3.55033295e+02,  2.82344174e+00,  1.47323501e+00,  8.72434199e-01,\n",
      "        3.04978043e-01,  8.37742761e-02,  5.15125804e-02,  3.07287835e-02,\n",
      "        2.26258393e-02,  2.18127314e-02,  1.23305656e-02,  7.17945257e-03,\n",
      "        6.05169451e-03,  4.89794929e-03,  3.21121654e-03,  3.04494891e-03,\n",
      "        2.56077317e-03,  1.89178041e-03,  1.52288924e-03,  1.22095412e-03,\n",
      "        1.07136590e-03,  6.28389767e-04,  5.35360188e-04,  3.72003647e-04,\n",
      "        3.08566581e-04,  2.38813183e-04,  2.19809153e-04,  1.73774970e-04,\n",
      "        1.44495061e-04,  1.29379507e-04,  1.07791166e-04,  9.76419542e-05,\n",
      "        6.32034935e-05,  5.79212719e-05,  4.46765553e-05,  4.15835057e-05,\n",
      "        3.26630361e-05,  2.88792526e-05,  2.26491156e-05,  1.85803583e-05,\n",
      "        1.89075254e-05,  1.33521726e-05, -9.67210417e-06,  1.16364572e-05,\n",
      "        1.03244683e-05, -6.51645769e-06,  8.49587741e-06,  8.17625096e-06,\n",
      "       -5.15352576e-06,  6.38866868e-06,  5.86092074e-06,  5.26799568e-06,\n",
      "       -4.26481347e-06,  4.56963789e-06,  3.83995302e-06, -2.88010710e-06,\n",
      "        3.14714202e-06, -2.52811856e-06,  2.58946943e-06, -1.79013182e-06,\n",
      "        2.36836831e-06,  2.08370147e-06,  1.88735430e-06, -1.36408016e-06,\n",
      "       -1.12886619e-06,  1.49767459e-06,  1.37544998e-06,  1.40531972e-06,\n",
      "       -9.68262157e-07,  1.16743934e-06,  8.86781891e-07,  8.46211265e-07,\n",
      "        6.69642191e-07, -7.90049398e-07, -6.86341082e-07, -6.58897534e-07,\n",
      "       -5.77750541e-07, -5.25845962e-07, -4.36525454e-07,  4.70759034e-07,\n",
      "        4.18115690e-07,  3.70999970e-07, -3.26068232e-07, -2.67339715e-07,\n",
      "        3.08726953e-07,  2.79056337e-07,  2.34574784e-07, -1.97240325e-07,\n",
      "       -1.70168320e-07, -1.63098932e-07,  1.83825279e-07,  1.70193019e-07,\n",
      "       -1.21541248e-07, -1.08052106e-07, -9.15834590e-08,  1.18234013e-07,\n",
      "        1.12637302e-07, -7.41497601e-08,  8.76596360e-08,  8.99324917e-08,\n",
      "        7.38997485e-08, -5.35258664e-08,  5.71858401e-08, -4.44214159e-08,\n",
      "       -3.59592001e-08, -2.34542945e-08,  3.37612072e-08,  3.92543775e-08,\n",
      "        2.31267858e-08,  1.08183000e-08, -2.08432183e-09,  1.86479343e-09,\n",
      "        2.40865479e-08,  1.47659946e-08, -1.75629715e-08,  6.28780583e-09,\n",
      "       -6.59273391e-09, -1.14449321e-08, -1.47041570e-08, -1.87839722e-09],\n",
      "      dtype=float32), array([[ 0.0462441 ,  0.04442106,  0.05093244, ..., -0.04719158,\n",
      "        -0.03108672,  0.00569758],\n",
      "       [ 0.04019036, -0.03473561, -0.01279195, ..., -0.09515718,\n",
      "        -0.05002078,  0.05805174],\n",
      "       [-0.0074054 , -0.01996705,  0.07018451, ...,  0.07169779,\n",
      "        -0.19125107, -0.07838415],\n",
      "       ...,\n",
      "       [ 0.02128623,  0.0523742 , -0.1529518 , ...,  0.00189844,\n",
      "         0.03083902,  0.05401857],\n",
      "       [ 0.15600587,  0.0303839 ,  0.19501638, ...,  0.02276407,\n",
      "         0.01196253, -0.00697755],\n",
      "       [ 0.02732931, -0.05425598,  0.11515704, ..., -0.04661088,\n",
      "        -0.08480575,  0.08542071]], dtype=float32))\n",
      "(array([ 2.66816772e+02,  6.85398221e-01,  5.57639778e-01,  1.99051991e-01,\n",
      "        4.62770127e-02,  3.19880322e-02,  2.18908954e-02,  1.49273835e-02,\n",
      "        8.31976347e-03,  6.34988770e-03,  4.03804798e-03,  3.22854007e-03,\n",
      "        2.38237623e-03,  2.08831066e-03,  1.72918243e-03,  1.30755093e-03,\n",
      "        9.70444817e-04,  8.81054322e-04,  7.80619215e-04,  6.15399855e-04,\n",
      "        4.63305070e-04,  3.58786405e-04,  2.83254543e-04,  2.15334847e-04,\n",
      "        2.00432682e-04,  1.65894860e-04,  1.49113766e-04,  9.25143177e-05,\n",
      "        8.22287693e-05,  6.70220688e-05,  6.27983463e-05,  6.13017546e-05,\n",
      "        5.27495249e-05,  3.36660123e-05,  3.27300841e-05,  2.44531293e-05,\n",
      "        2.24905853e-05,  1.77898801e-05,  1.41404662e-05,  1.31062752e-05,\n",
      "        1.21881176e-05,  9.17790567e-06, -6.31893727e-06, -5.67211509e-06,\n",
      "        7.76592424e-06,  7.65802542e-06,  6.35561173e-06,  5.46155752e-06,\n",
      "        4.63703645e-06,  4.44651732e-06, -3.06814695e-06, -2.86954514e-06,\n",
      "        3.12198745e-06,  2.77206709e-06,  2.53232020e-06, -1.84215287e-06,\n",
      "        2.04713388e-06, -1.47064895e-06,  1.77051811e-06,  1.65657059e-06,\n",
      "       -1.30885701e-06,  1.43265459e-06,  1.22019594e-06,  1.10595681e-06,\n",
      "       -1.10531414e-06, -1.08065819e-06,  9.29623070e-07,  8.78146579e-07,\n",
      "       -9.18112562e-07, -8.01354986e-07,  7.76247418e-07, -6.49551396e-07,\n",
      "        7.43919372e-07, -5.94510595e-07,  6.31830574e-07, -5.19418393e-07,\n",
      "        5.43574799e-07,  4.98799864e-07,  4.63067835e-07, -4.19346634e-07,\n",
      "       -3.71387927e-07,  3.51557162e-07, -3.38406210e-07,  3.21757994e-07,\n",
      "       -2.95153399e-07,  2.85216402e-07, -2.48416569e-07, -2.29380191e-07,\n",
      "        2.58703693e-07,  2.41594336e-07,  1.79449501e-07,  1.70516600e-07,\n",
      "       -1.68084100e-07, -1.53179442e-07,  1.26340979e-07, -1.22344460e-07,\n",
      "        1.07152196e-07, -1.04772745e-07,  9.67825997e-08,  8.12682828e-08,\n",
      "        6.34285158e-08, -9.44071701e-08, -7.11649832e-08, -6.41207905e-08,\n",
      "       -4.75057220e-08,  3.92074178e-08, -3.23736202e-08,  3.62468455e-08,\n",
      "       -2.96722860e-08,  2.57228603e-08, -1.94722656e-08, -1.69089986e-08,\n",
      "        1.67159211e-08,  1.28152502e-08,  8.44647019e-09,  9.09910014e-09,\n",
      "       -6.39774500e-09, -1.83670457e-09,  1.90078087e-09, -5.04040587e-09],\n",
      "      dtype=float32), array([[ 0.03185204,  0.10190837, -0.20121728, ...,  0.02664203,\n",
      "         0.02275746,  0.05692277],\n",
      "       [ 0.05063961, -0.17832147,  0.01597105, ...,  0.01604174,\n",
      "         0.00920877, -0.00162109],\n",
      "       [ 0.00468612,  0.06596452,  0.02149265, ...,  0.18212727,\n",
      "        -0.16077721, -0.0176965 ],\n",
      "       ...,\n",
      "       [-0.00986828,  0.01199084, -0.07395665, ...,  0.13794647,\n",
      "        -0.08881889,  0.01404518],\n",
      "       [ 0.15528831,  0.1531753 ,  0.08958199, ..., -0.0004496 ,\n",
      "        -0.01824554,  0.00288414],\n",
      "       [ 0.0425647 ,  0.06548689,  0.07752607, ...,  0.04582503,\n",
      "        -0.0478033 ,  0.07853737]], dtype=float32))\n",
      "(array([ 2.76520081e+02,  1.59928143e+00,  1.16628242e+00,  5.56270957e-01,\n",
      "        1.98151141e-01,  8.18449855e-02,  5.15067689e-02,  3.21547538e-02,\n",
      "        2.07305308e-02,  1.58744920e-02,  1.33148562e-02,  1.05942888e-02,\n",
      "        8.42663925e-03,  4.97934502e-03,  4.63964231e-03,  4.17953450e-03,\n",
      "        3.51713621e-03,  2.68605864e-03,  2.22221250e-03,  1.73331460e-03,\n",
      "        1.32268597e-03,  1.17379660e-03,  9.28863126e-04,  8.05908174e-04,\n",
      "        6.50443253e-04,  6.30685361e-04,  5.36944310e-04,  4.44302510e-04,\n",
      "        3.96526768e-04,  2.95233680e-04,  2.08972022e-04,  1.84791614e-04,\n",
      "        1.64980942e-04,  1.47220970e-04,  1.08164335e-04,  8.99121442e-05,\n",
      "        7.71009436e-05,  5.63427093e-05,  4.02153528e-05,  3.51917188e-05,\n",
      "        3.44114014e-05,  2.64627761e-05,  2.25735967e-05,  1.97594818e-05,\n",
      "        1.35722985e-05,  1.07475371e-05,  9.88554893e-06, -6.62649563e-06,\n",
      "        7.39287134e-06,  5.67415555e-06,  5.35821891e-06, -3.58468969e-06,\n",
      "        3.74854699e-06,  3.37061647e-06, -2.94930032e-06,  2.93707126e-06,\n",
      "       -2.18977743e-06,  1.85821045e-06, -1.92952984e-06, -1.75057528e-06,\n",
      "       -1.46466311e-06,  1.68774909e-06,  1.49389507e-06,  1.17503441e-06,\n",
      "       -1.04905621e-06,  9.09786650e-07, -9.01169642e-07,  8.10343749e-07,\n",
      "        7.77573973e-07,  7.51512232e-07, -7.65654136e-07, -7.16881686e-07,\n",
      "       -6.69613144e-07, -5.35720687e-07, -4.56598173e-07,  4.96233270e-07,\n",
      "        4.55739496e-07,  4.25888032e-07, -3.67503134e-07, -3.40428926e-07,\n",
      "       -3.09421551e-07,  3.54853853e-07,  3.38344762e-07,  3.04025178e-07,\n",
      "        2.47213393e-07, -2.10378374e-07, -2.13629320e-07,  2.01034752e-07,\n",
      "       -1.83688471e-07, -1.63449997e-07,  1.68672827e-07,  1.54683562e-07,\n",
      "       -1.25390969e-07, -1.09560297e-07,  1.24947746e-07,  1.19456473e-07,\n",
      "        9.21126428e-08, -8.04127538e-08,  7.55167662e-08, -6.41218776e-08,\n",
      "        5.99360490e-08, -5.10297404e-08,  4.87173324e-08, -4.72520618e-08,\n",
      "       -2.96346041e-08, -3.45882967e-08, -1.71582339e-08,  3.42522277e-08,\n",
      "        2.73587020e-08,  2.01670503e-08,  1.63262719e-08, -1.19785319e-08,\n",
      "       -1.09806839e-08, -8.74577799e-10,  1.03654108e-09,  7.38326911e-09,\n",
      "        1.75723862e-08, -3.47654083e-09,  5.49765833e-09,  3.77951359e-09],\n",
      "      dtype=float32), array([[ 0.04103005, -0.18915229,  0.03088916, ..., -0.0023357 ,\n",
      "         0.05919633,  0.0444496 ],\n",
      "       [ 0.04957902,  0.00970494,  0.10010874, ..., -0.03330082,\n",
      "         0.08431076, -0.01311834],\n",
      "       [ 0.00192981,  0.06877276, -0.04947921, ...,  0.18759419,\n",
      "         0.22516668, -0.08784586],\n",
      "       ...,\n",
      "       [-0.00676766, -0.13373765,  0.04442344, ...,  0.13613531,\n",
      "        -0.0875388 ,  0.09037486],\n",
      "       [ 0.1560169 ,  0.00689545, -0.20045795, ...,  0.00907294,\n",
      "         0.00474544, -0.03592072],\n",
      "       [ 0.04018508,  0.07927916, -0.09542886, ...,  0.0137181 ,\n",
      "        -0.03538504,  0.13359594]], dtype=float32))\n",
      "(array([ 4.15712524e+02,  2.09952545e+00,  6.14025235e-01,  7.40849003e-02,\n",
      "        6.46259636e-02,  5.23818135e-02,  2.79797092e-02,  2.30749417e-02,\n",
      "        1.41553106e-02,  9.32626426e-03,  6.76333532e-03,  5.09729842e-03,\n",
      "        3.75738856e-03,  2.71365675e-03,  2.28473986e-03,  1.82328210e-03,\n",
      "        1.56478863e-03,  1.29882933e-03,  1.05535134e-03,  7.39072508e-04,\n",
      "        5.32836246e-04,  4.81713621e-04,  4.39941272e-04,  3.44030588e-04,\n",
      "        3.13778670e-04,  2.29256111e-04,  2.02307827e-04,  1.80632414e-04,\n",
      "        1.48798630e-04,  1.05374915e-04,  9.15245109e-05,  6.92475514e-05,\n",
      "        6.34539465e-05,  5.61018023e-05,  5.23192030e-05,  3.92296388e-05,\n",
      "        3.52644638e-05,  2.99702679e-05,  2.29772268e-05,  2.32985512e-05,\n",
      "        2.15500895e-05,  1.68766419e-05,  1.24357894e-05,  1.03081766e-05,\n",
      "       -6.91868445e-06, -5.53405289e-06,  8.82566019e-06,  7.83279029e-06,\n",
      "        7.95591313e-06,  6.85857640e-06,  5.32950571e-06,  5.25460200e-06,\n",
      "       -4.12103782e-06, -3.99052442e-06,  4.67432073e-06,  3.61312868e-06,\n",
      "       -3.09138545e-06, -2.77234085e-06,  3.33244270e-06,  2.66690222e-06,\n",
      "        2.31630952e-06,  2.00593854e-06,  1.82348185e-06, -1.97857230e-06,\n",
      "       -1.74950458e-06, -1.62936703e-06,  1.46456216e-06, -1.42327735e-06,\n",
      "       -1.16474075e-06, -1.03694470e-06,  1.08062704e-06,  1.00662544e-06,\n",
      "       -8.81677124e-07,  9.54044026e-07,  9.13059523e-07,  6.90110426e-07,\n",
      "       -7.38576830e-07, -6.51332130e-07,  5.75253637e-07, -5.59364480e-07,\n",
      "       -4.68712955e-07, -3.75578253e-07, -3.48138002e-07,  4.58000727e-07,\n",
      "        4.42273347e-07,  3.97335270e-07,  3.51401638e-07, -2.97142947e-07,\n",
      "        2.90237608e-07, -2.59112568e-07, -2.38823645e-07, -1.76150976e-07,\n",
      "        2.32341677e-07,  2.17048893e-07,  1.79667282e-07,  1.77495949e-07,\n",
      "       -1.59571627e-07,  1.26248807e-07, -1.15572206e-07, -1.07514666e-07,\n",
      "       -8.25497253e-08,  1.00093324e-07,  9.18480296e-08,  7.44495168e-08,\n",
      "       -5.96415504e-08,  5.35481597e-08,  3.87221490e-08, -3.61645860e-08,\n",
      "       -3.45453905e-08,  2.69131757e-08, -2.09871622e-08, -1.88439238e-08,\n",
      "        1.36039953e-08, -1.34159093e-08, -1.17065788e-08, -1.74400494e-09,\n",
      "       -5.98266603e-10,  3.73579523e-09,  6.16906304e-09,  9.15130460e-09],\n",
      "      dtype=float32), array([[ 4.5906436e-02,  1.7254268e-01, -1.0162015e-01, ...,\n",
      "         6.1545763e-03,  1.7561646e-02,  1.9704002e-04],\n",
      "       [ 5.2166816e-02,  2.1379185e-03,  2.0270035e-01, ...,\n",
      "         2.9692981e-02,  5.0073180e-02, -5.5228543e-02],\n",
      "       [ 4.5135585e-03, -9.9144075e-03, -5.4933958e-02, ...,\n",
      "         2.2689307e-01,  2.9951170e-02,  9.1676414e-02],\n",
      "       ...,\n",
      "       [-1.8480403e-02,  8.1714420e-03, -3.1289749e-02, ...,\n",
      "        -1.4149154e-02,  2.3274573e-03, -1.3435967e-01],\n",
      "       [ 1.6801229e-01,  2.5150426e-02, -9.9227980e-02, ...,\n",
      "         3.4463108e-02,  2.5958328e-02, -2.3157172e-02],\n",
      "       [ 4.5612868e-02, -1.5781945e-02, -4.7035605e-02, ...,\n",
      "        -2.5231967e-02, -2.4609582e-02, -1.3292080e-02]], dtype=float32))\n",
      "(array([ 4.34671295e+02,  3.40234089e+00,  5.45567036e-01,  3.50248069e-01,\n",
      "        1.29003212e-01,  1.08091496e-01,  7.73943886e-02,  5.43379635e-02,\n",
      "        3.83078679e-02,  1.27152838e-02,  1.12635810e-02,  9.23904032e-03,\n",
      "        6.85299095e-03,  6.30478235e-03,  4.58755996e-03,  3.46214511e-03,\n",
      "        2.69576232e-03,  2.41495669e-03,  1.71700283e-03,  1.41546084e-03,\n",
      "        1.08345889e-03,  9.66810097e-04,  7.67344784e-04,  7.03593949e-04,\n",
      "        5.04287018e-04,  3.84605431e-04,  3.33448465e-04,  2.63427239e-04,\n",
      "        2.25874071e-04,  1.92807755e-04,  1.81974116e-04,  1.53167697e-04,\n",
      "        1.21990299e-04,  1.00415651e-04,  8.78798091e-05,  6.60109727e-05,\n",
      "        6.00343701e-05,  5.80028282e-05,  4.92780237e-05,  4.49326653e-05,\n",
      "        3.24302782e-05,  2.82472247e-05,  2.26268094e-05,  1.80112056e-05,\n",
      "        1.72809359e-05,  1.52280818e-05,  1.07904525e-05, -9.19601007e-06,\n",
      "        9.93579033e-06,  8.11203245e-06, -6.52061044e-06,  6.31664989e-06,\n",
      "        5.81299446e-06, -4.54896417e-06,  5.15555303e-06,  4.21709728e-06,\n",
      "       -3.55739394e-06, -3.45983563e-06,  3.37762117e-06, -2.66746906e-06,\n",
      "        2.37952690e-06,  2.17013576e-06, -2.23895722e-06, -2.06015307e-06,\n",
      "       -1.90749256e-06,  1.72762429e-06,  1.40463806e-06, -1.30184424e-06,\n",
      "       -1.24387952e-06,  1.28649765e-06, -9.65436811e-07,  1.02577394e-06,\n",
      "       -9.45217039e-07, -8.73082172e-07,  9.11560619e-07,  8.13180236e-07,\n",
      "       -5.63713513e-07,  6.66910921e-07,  5.93039601e-07,  5.69325266e-07,\n",
      "        5.21926211e-07, -4.69498389e-07,  4.36486317e-07, -4.08212031e-07,\n",
      "       -3.54769014e-07, -3.00584475e-07,  3.42090317e-07,  3.07609071e-07,\n",
      "        2.94966156e-07,  2.36613715e-07, -2.46103099e-07, -2.37240954e-07,\n",
      "        1.97307415e-07, -2.17983157e-07,  1.38644069e-07, -1.66812583e-07,\n",
      "       -1.33938570e-07,  1.16811030e-07, -1.05910082e-07,  1.06793216e-07,\n",
      "       -8.60967972e-08,  8.91209595e-08,  8.06766707e-08, -6.52154881e-08,\n",
      "        4.68788528e-08,  3.86422734e-08, -4.76070525e-08, -4.56866154e-08,\n",
      "        2.96754425e-08, -3.09905452e-08, -2.63650382e-08,  1.67218701e-08,\n",
      "        1.47297845e-08, -1.68797083e-08, -8.13638312e-09, -5.53670354e-09,\n",
      "       -2.76576362e-09,  4.68840833e-09,  8.46456949e-09, -1.18453274e-08],\n",
      "      dtype=float32), array([[ 0.05145895,  0.1489775 , -0.0247008 , ...,  0.02106139,\n",
      "        -0.01909674,  0.07011954],\n",
      "       [ 0.05123008,  0.00354726,  0.22171246, ...,  0.00348488,\n",
      "        -0.02780571, -0.01341393],\n",
      "       [ 0.00243426, -0.02965586, -0.04279694, ...,  0.14905918,\n",
      "        -0.05791498, -0.2902024 ],\n",
      "       ...,\n",
      "       [-0.01308613,  0.08028199, -0.0498523 , ...,  0.058708  ,\n",
      "         0.02981947, -0.10871597],\n",
      "       [ 0.16891623,  0.01540408, -0.08032122, ...,  0.00483034,\n",
      "        -0.00258127,  0.02533678],\n",
      "       [ 0.04265061, -0.05377372, -0.0588911 , ..., -0.00444017,\n",
      "         0.00088317,  0.00243243]], dtype=float32))\n",
      "(array([ 3.66552948e+02,  2.92326951e+00,  6.88632488e-01,  1.56602189e-01,\n",
      "        7.13214353e-02,  5.00386506e-02,  3.55721638e-02,  2.79026646e-02,\n",
      "        2.31418256e-02,  1.36759970e-02,  1.10382969e-02,  6.35291263e-03,\n",
      "        5.98810147e-03,  4.33281669e-03,  3.29161086e-03,  2.56404211e-03,\n",
      "        1.62309513e-03,  1.45538175e-03,  1.21988636e-03,  1.24765863e-03,\n",
      "        8.84370646e-04,  6.81257690e-04,  5.17936831e-04,  4.21176432e-04,\n",
      "        4.02380421e-04,  3.38315702e-04,  2.63596681e-04,  2.41717615e-04,\n",
      "        1.83108001e-04,  1.59203861e-04,  1.25916005e-04,  1.14078008e-04,\n",
      "        9.34911732e-05,  7.48470120e-05,  6.01262509e-05,  5.17114568e-05,\n",
      "        3.99795063e-05,  3.47670539e-05,  2.94436832e-05,  2.62280682e-05,\n",
      "        2.28277240e-05,  1.95912180e-05,  1.62997294e-05,  1.21870789e-05,\n",
      "       -8.41298333e-06,  1.01424148e-05, -5.72240879e-06,  7.82042753e-06,\n",
      "        7.27590304e-06,  6.72968918e-06,  5.89374076e-06,  5.63808862e-06,\n",
      "       -4.84789689e-06,  3.96785072e-06, -3.55187876e-06, -3.30928970e-06,\n",
      "       -2.90935077e-06,  3.29007435e-06,  2.85016290e-06, -2.54036263e-06,\n",
      "       -2.18755758e-06,  2.74174931e-06,  2.50295057e-06,  1.93507663e-06,\n",
      "       -1.66830478e-06,  1.69485429e-06, -1.52346047e-06,  1.45215040e-06,\n",
      "        1.39894166e-06, -1.19153901e-06,  1.15289515e-06, -1.00733519e-06,\n",
      "       -8.24759468e-07,  9.01219096e-07,  8.43982605e-07, -6.69954602e-07,\n",
      "       -6.17743581e-07,  6.53811639e-07,  6.07766708e-07, -5.95460733e-07,\n",
      "        5.25067719e-07, -4.96204507e-07, -4.13806077e-07, -3.45668099e-07,\n",
      "        4.28533440e-07,  3.50372204e-07,  3.36455685e-07,  3.20844237e-07,\n",
      "       -2.87803061e-07, -2.38241796e-07, -1.94012429e-07,  2.51741227e-07,\n",
      "        2.32683860e-07,  1.79899786e-07, -1.55843850e-07,  1.60047691e-07,\n",
      "        1.43722744e-07, -1.31577337e-07, -1.08472065e-07, -8.54158202e-08,\n",
      "        9.75715366e-08,  9.29492145e-08, -6.88620005e-08,  6.02221775e-08,\n",
      "        5.33469837e-08, -4.33802327e-08, -3.39414044e-08,  3.33914052e-08,\n",
      "        2.74138756e-08, -2.40369218e-08,  1.99499723e-08,  1.72849006e-08,\n",
      "       -9.33308275e-09, -8.53816839e-09,  9.96034100e-09, -5.07749265e-09,\n",
      "       -3.55361807e-09,  5.27945598e-09,  1.11772158e-09,  1.83931659e-09],\n",
      "      dtype=float32), array([[ 0.04656745, -0.17614007,  0.0966274 , ...,  0.01512455,\n",
      "        -0.00911379, -0.01858606],\n",
      "       [ 0.05014366, -0.03548953, -0.18698831, ..., -0.04072881,\n",
      "        -0.04338993,  0.04141094],\n",
      "       [ 0.00567455,  0.0172919 ,  0.06441744, ...,  0.01733187,\n",
      "        -0.05567505, -0.3045129 ],\n",
      "       ...,\n",
      "       [-0.01842348, -0.00670848,  0.02341745, ...,  0.01305737,\n",
      "         0.05358892,  0.04568389],\n",
      "       [ 0.1676974 , -0.04644944,  0.12554426, ..., -0.01289767,\n",
      "         0.01994948, -0.01      ],\n",
      "       [ 0.04715688,  0.02335085,  0.05113067, ..., -0.01044891,\n",
      "        -0.04219874,  0.00692254]], dtype=float32))\n",
      "(array([ 3.4274362e+02,  1.6878322e+00,  8.4283650e-01,  3.7470400e-01,\n",
      "        1.9093168e-01,  6.9634452e-02,  5.5196185e-02,  3.9274219e-02,\n",
      "        1.9505026e-02,  1.2942590e-02,  1.2592756e-02,  8.4144091e-03,\n",
      "        7.3152035e-03,  4.3504527e-03,  3.4385123e-03,  2.9026978e-03,\n",
      "        2.3042250e-03,  1.8783811e-03,  1.7392345e-03,  1.3147343e-03,\n",
      "        9.4473147e-04,  8.5553894e-04,  5.8845530e-04,  5.4250762e-04,\n",
      "        4.4390111e-04,  3.8206764e-04,  3.0535541e-04,  2.4724856e-04,\n",
      "        2.1165075e-04,  1.9634090e-04,  1.7147629e-04,  1.3298071e-04,\n",
      "        1.1300887e-04,  1.0244517e-04,  7.7911354e-05,  7.2534705e-05,\n",
      "        4.7488902e-05,  4.3827367e-05,  3.9761104e-05,  3.3021170e-05,\n",
      "        2.8779714e-05,  2.0293232e-05,  1.8810326e-05,  1.3626016e-05,\n",
      "        1.3377372e-05, -1.0065045e-05,  1.0348735e-05,  9.6992799e-06,\n",
      "        7.9245174e-06,  7.1869681e-06, -5.5623054e-06,  5.7161797e-06,\n",
      "        4.6079990e-06,  3.8275743e-06, -3.8830426e-06, -3.6823312e-06,\n",
      "        2.9422540e-06,  2.4825990e-06, -2.7143103e-06, -2.3865912e-06,\n",
      "        2.1959156e-06,  1.9559118e-06, -1.9699214e-06, -1.8415371e-06,\n",
      "        1.4525167e-06, -1.3751223e-06,  1.3176874e-06,  8.9137319e-07,\n",
      "        1.0446133e-06,  1.0297376e-06, -1.1485794e-06, -1.0425338e-06,\n",
      "       -9.8227576e-07, -9.4759838e-07, -8.4201474e-07,  8.1201927e-07,\n",
      "       -7.0289167e-07,  6.6210418e-07,  6.3728601e-07, -5.0941867e-07,\n",
      "       -4.8432190e-07,  5.7336939e-07,  4.9872256e-07, -3.8732691e-07,\n",
      "        4.0281239e-07, -3.1335227e-07,  3.3314819e-07,  2.6951807e-07,\n",
      "        2.2946331e-07,  2.1056165e-07, -2.3636585e-07, -2.0625731e-07,\n",
      "       -2.1101053e-07, -1.6669054e-07, -1.3131135e-07,  1.5490080e-07,\n",
      "        1.3880643e-07,  1.2277796e-07, -1.0712051e-07,  9.6945520e-08,\n",
      "        1.3147438e-07,  6.6464082e-08, -7.7900822e-08, -6.8563764e-08,\n",
      "        4.4552376e-08, -4.8161990e-08, -4.3422833e-08,  3.3277008e-08,\n",
      "        2.4403224e-08,  2.9334519e-08,  1.3475784e-08, -3.1974988e-08,\n",
      "        3.7573753e-09,  1.7144003e-09, -1.2224507e-09, -3.2845309e-09,\n",
      "       -2.9243299e-08, -2.1574094e-08, -8.7676186e-09, -1.2605692e-08],\n",
      "      dtype=float32), array([[ 4.7366362e-02,  2.6325166e-01,  7.1995951e-02, ...,\n",
      "        -5.1443972e-02, -2.2354593e-04, -5.4086313e-02],\n",
      "       [ 5.1306359e-02,  4.1767016e-02, -1.7787497e-01, ...,\n",
      "         2.8953704e-03,  2.2133628e-02, -3.5588987e-02],\n",
      "       [ 5.1965849e-03, -1.8640110e-02,  4.9402554e-02, ...,\n",
      "        -1.0971999e-01, -2.4650943e-02, -1.3630962e-01],\n",
      "       ...,\n",
      "       [-1.8884541e-02,  4.4978492e-02,  4.4175047e-02, ...,\n",
      "         1.1423555e-01, -3.2190986e-02, -6.5775037e-02],\n",
      "       [ 1.6454464e-01, -6.8297625e-02,  1.4744218e-01, ...,\n",
      "        -1.4878881e-02,  1.9133553e-02,  1.9473504e-02],\n",
      "       [ 4.5101900e-02, -5.5792853e-02,  5.5421110e-02, ...,\n",
      "         1.0264752e-01, -7.7809915e-02, -9.3114555e-02]], dtype=float32))\n",
      "(array([ 3.83053955e+02,  3.11010051e+00,  7.18939126e-01,  1.75878540e-01,\n",
      "        1.01505101e-01,  8.18128958e-02,  5.49033061e-02,  4.36957777e-02,\n",
      "        2.89642494e-02,  1.59416646e-02,  1.09218052e-02,  9.86011047e-03,\n",
      "        8.41971114e-03,  5.33949630e-03,  4.93613072e-03,  3.40378820e-03,\n",
      "        2.15755333e-03,  1.91874290e-03,  1.53985515e-03,  1.47885224e-03,\n",
      "        1.29545934e-03,  1.09157758e-03,  8.82067368e-04,  6.98546355e-04,\n",
      "        5.82858513e-04,  4.45174985e-04,  3.70410067e-04,  3.53531213e-04,\n",
      "        2.98060797e-04,  2.29611382e-04,  1.90910258e-04,  1.71041698e-04,\n",
      "        1.44103717e-04,  1.08270506e-04,  8.19637426e-05,  7.34816422e-05,\n",
      "        6.76052005e-05,  4.99445305e-05,  4.33051355e-05,  3.60443701e-05,\n",
      "        2.59314165e-05,  2.17606939e-05,  2.10714097e-05,  1.80229636e-05,\n",
      "        1.49875959e-05,  1.35439996e-05, -1.04008968e-05,  1.17081481e-05,\n",
      "        9.45704869e-06, -5.80645838e-06,  6.03513035e-06,  4.98613917e-06,\n",
      "       -4.01039824e-06,  4.51205779e-06,  4.03780587e-06, -3.55660291e-06,\n",
      "       -3.29846603e-06,  3.35383447e-06,  3.00694182e-06, -2.50210678e-06,\n",
      "       -2.26566658e-06,  2.35401285e-06,  2.27404234e-06, -1.91574281e-06,\n",
      "        2.02159913e-06, -1.56241754e-06,  1.64513722e-06, -1.35853907e-06,\n",
      "        1.37744030e-06,  1.25571171e-06,  1.12982320e-06, -1.14521970e-06,\n",
      "       -1.07400604e-06, -8.89598482e-07,  9.12952771e-07,  8.57222972e-07,\n",
      "       -7.25708617e-07,  7.14549003e-07, -6.41649649e-07,  6.45728960e-07,\n",
      "       -5.46624790e-07,  5.46951924e-07, -4.67203478e-07,  4.51484084e-07,\n",
      "        4.00372954e-07, -4.06437493e-07, -2.96678877e-07,  3.08310035e-07,\n",
      "        2.87847172e-07,  2.67796395e-07,  2.57558554e-07, -2.15855337e-07,\n",
      "       -2.23801095e-07, -1.85930020e-07,  1.34727145e-07, -1.46232111e-07,\n",
      "       -1.54291698e-07, -1.18760923e-07,  1.06187130e-07,  1.03355028e-07,\n",
      "       -7.59973915e-08,  6.92651412e-08,  6.48376925e-08, -6.01559904e-08,\n",
      "        4.99926749e-08,  3.99401650e-08,  2.45202028e-08, -5.19751531e-08,\n",
      "       -4.93995636e-08,  1.75818826e-08, -3.17277831e-08, -2.95307014e-08,\n",
      "       -2.28672228e-08,  1.46170267e-08,  6.76288936e-09,  5.70154901e-09,\n",
      "        5.64494076e-11, -1.44094159e-09, -2.74746426e-09, -7.17438331e-09],\n",
      "      dtype=float32), array([[ 0.0475668 ,  0.16709036,  0.05927429, ...,  0.06746376,\n",
      "        -0.00061222,  0.03898127],\n",
      "       [ 0.05083117, -0.00646174, -0.21973315, ...,  0.04132343,\n",
      "         0.03727154,  0.006295  ],\n",
      "       [ 0.00399972, -0.01957075,  0.05462422, ..., -0.30607393,\n",
      "        -0.0322493 , -0.11408579],\n",
      "       ...,\n",
      "       [-0.01544501,  0.05806055,  0.01005113, ...,  0.02083888,\n",
      "        -0.1148743 ,  0.00123954],\n",
      "       [ 0.1668659 ,  0.01140072,  0.09143381, ..., -0.00708769,\n",
      "        -0.00520249,  0.02510915],\n",
      "       [ 0.04419214, -0.03595303,  0.08144981, ...,  0.03417832,\n",
      "        -0.03966157,  0.04321345]], dtype=float32))\n",
      "(array([ 4.31371979e+02,  4.88020515e+00,  7.55180061e-01,  3.79018128e-01,\n",
      "        1.37533292e-01,  7.67585784e-02,  5.90959303e-02,  3.69544290e-02,\n",
      "        3.15389298e-02,  1.61171909e-02,  1.45123834e-02,  8.80211312e-03,\n",
      "        6.18903106e-03,  4.67845099e-03,  3.99461808e-03,  3.80114233e-03,\n",
      "        3.01981461e-03,  1.99704547e-03,  1.54032826e-03,  1.31260732e-03,\n",
      "        1.04651786e-03,  1.02660002e-03,  9.30418435e-04,  7.84104341e-04,\n",
      "        7.00290373e-04,  5.68686461e-04,  4.67880280e-04,  4.55710746e-04,\n",
      "        4.03277372e-04,  3.06781032e-04,  2.55532097e-04,  2.30815975e-04,\n",
      "        2.03559597e-04,  1.81025534e-04,  1.52669556e-04,  1.26738392e-04,\n",
      "        1.00572419e-04,  9.66631778e-05,  7.86752571e-05,  6.32683441e-05,\n",
      "        5.67888928e-05,  5.12265578e-05,  4.74079025e-05,  3.86040774e-05,\n",
      "        3.09719435e-05,  2.28920017e-05,  2.22923936e-05,  1.79747403e-05,\n",
      "        1.24567450e-05, -1.05341232e-05, -7.96596942e-06,  7.89232308e-06,\n",
      "        6.44675038e-06, -5.37223877e-06, -5.17203944e-06,  5.04917125e-06,\n",
      "        4.26468705e-06, -3.63971230e-06, -2.91116476e-06,  3.36165999e-06,\n",
      "        2.98127679e-06, -2.49962955e-06,  2.63718925e-06,  2.31606191e-06,\n",
      "       -2.00187833e-06, -1.70730402e-06,  1.79223548e-06,  1.53207247e-06,\n",
      "        1.33777746e-06, -1.37320978e-06, -1.32759237e-06,  1.06484868e-06,\n",
      "       -9.68886638e-07,  8.26635301e-07,  7.09338792e-07, -9.00276575e-07,\n",
      "       -7.36969469e-07, -6.35468325e-07, -5.97135340e-07,  5.56556756e-07,\n",
      "        5.08006394e-07,  4.51291584e-07,  4.29274081e-07, -4.25574797e-07,\n",
      "       -3.83736449e-07, -3.56759131e-07,  3.31383916e-07,  2.66448922e-07,\n",
      "        2.23600665e-07, -2.81420000e-07, -2.64425807e-07, -2.08352716e-07,\n",
      "        2.09597658e-07,  1.63807471e-07, -1.67109008e-07, -1.21461483e-07,\n",
      "        1.08915515e-07, -9.80180417e-08,  8.65659402e-08,  7.79362423e-08,\n",
      "       -7.77596014e-08, -5.98976015e-08, -5.11633260e-08,  4.86280491e-08,\n",
      "        4.17377599e-08, -4.02235223e-08,  2.97329539e-08,  3.23662626e-08,\n",
      "        3.59225627e-09, -1.41707956e-09, -2.93223508e-08, -2.98882554e-08,\n",
      "        1.11347198e-08, -7.19493265e-09, -5.29626520e-09, -1.73888761e-08,\n",
      "       -1.50081103e-08,  2.06757491e-08,  1.71106098e-08,  1.50588839e-08],\n",
      "      dtype=float32), array([[-0.05019689,  0.10255909, -0.10966938, ..., -0.00248639,\n",
      "        -0.00779851,  0.04051054],\n",
      "       [-0.04983868, -0.00938331,  0.20691644, ..., -0.02460381,\n",
      "        -0.08245831,  0.03840832],\n",
      "       [-0.00214532, -0.02677529, -0.05410548, ...,  0.08023349,\n",
      "         0.1084771 ,  0.27747184],\n",
      "       ...,\n",
      "       [ 0.0113768 ,  0.07474199, -0.01986419, ...,  0.00606889,\n",
      "         0.09470733, -0.05949892],\n",
      "       [-0.16824311,  0.0168749 , -0.11428214, ..., -0.00139943,\n",
      "         0.0113663 ,  0.01508418],\n",
      "       [-0.04096432, -0.05127351, -0.05869544, ...,  0.01347381,\n",
      "         0.02483432,  0.03013718]], dtype=float32))\n",
      "(array([ 4.39046539e+02,  4.41757870e+00,  6.10058248e-01,  1.80608749e-01,\n",
      "        1.46616682e-01,  9.74736884e-02,  6.17093034e-02,  2.63522677e-02,\n",
      "        2.06267703e-02,  1.34717012e-02,  1.15526328e-02,  7.76360277e-03,\n",
      "        6.13467162e-03,  5.39072370e-03,  4.25890042e-03,  3.01525276e-03,\n",
      "        2.31683464e-03,  2.07034848e-03,  1.97856664e-03,  1.52278552e-03,\n",
      "        1.17836008e-03,  8.80774460e-04,  6.63093815e-04,  5.47091477e-04,\n",
      "        5.05637028e-04,  4.00933204e-04,  3.86239379e-04,  3.13485885e-04,\n",
      "        2.70968565e-04,  2.35275627e-04,  2.05035351e-04,  1.92062202e-04,\n",
      "        1.60240772e-04,  1.44672362e-04,  1.26267754e-04,  1.16917196e-04,\n",
      "        8.72629316e-05,  7.10794120e-05,  5.50119330e-05,  4.38464049e-05,\n",
      "        3.90540627e-05,  3.08899544e-05,  2.69171123e-05,  2.34643958e-05,\n",
      "        2.01107141e-05,  1.55481939e-05,  1.50999786e-05, -8.43130601e-06,\n",
      "        1.02490776e-05,  9.41653798e-06,  7.95854794e-06, -6.47888282e-06,\n",
      "        6.16957959e-06, -4.98401187e-06, -4.09380345e-06,  4.62919343e-06,\n",
      "       -3.45227068e-06,  3.89043453e-06,  3.40655629e-06, -2.54126644e-06,\n",
      "        2.63694255e-06,  1.92731659e-06, -1.88211675e-06, -1.68433519e-06,\n",
      "       -1.57031070e-06,  1.65304925e-06,  1.48741969e-06, -1.28461750e-06,\n",
      "       -1.12596456e-06,  1.27182977e-06,  1.15855062e-06, -1.01619776e-06,\n",
      "        1.03928789e-06, -9.03414843e-07,  7.69464521e-07, -7.15367946e-07,\n",
      "        6.87236025e-07, -6.24474922e-07, -5.53233463e-07,  5.83458302e-07,\n",
      "       -4.18135699e-07, -3.78085304e-07,  5.40017879e-07,  4.90987702e-07,\n",
      "        4.32616019e-07,  3.66328010e-07, -3.00963080e-07, -3.03020386e-07,\n",
      "        2.98011855e-07, -2.65103239e-07,  2.65149140e-07, -2.26665534e-07,\n",
      "       -1.96533591e-07,  2.00897759e-07,  1.57969581e-07,  1.46168034e-07,\n",
      "       -1.40237034e-07, -1.21303927e-07, -8.56430162e-08,  9.76125136e-08,\n",
      "        9.31113604e-08, -6.35167439e-08,  6.94304774e-08,  5.47175176e-08,\n",
      "       -4.21949586e-08, -3.84282401e-08, -3.00733234e-08, -2.41831923e-08,\n",
      "       -1.46077364e-08,  4.29086739e-08,  4.11079029e-08,  3.30812675e-08,\n",
      "       -7.18982385e-09,  2.27068178e-08,  1.87040339e-08,  2.98811753e-10,\n",
      "       -3.14632476e-09,  4.80031925e-09,  1.05474909e-08,  1.19194796e-08],\n",
      "      dtype=float32), array([[-0.05238359, -0.16227105, -0.12853713, ...,  0.0329396 ,\n",
      "        -0.06504825, -0.00122036],\n",
      "       [-0.05248301, -0.00824556,  0.19864415, ..., -0.02407423,\n",
      "        -0.04039093, -0.02219206],\n",
      "       [-0.0030497 ,  0.02480098, -0.07852883, ...,  0.13062727,\n",
      "         0.29050672, -0.12166332],\n",
      "       ...,\n",
      "       [ 0.01472586, -0.05919903,  0.02075516, ..., -0.01951216,\n",
      "        -0.0130859 ,  0.02710417],\n",
      "       [-0.16907653, -0.01242883, -0.08748402, ...,  0.01072618,\n",
      "         0.00136816, -0.00408117],\n",
      "       [-0.0428861 ,  0.04256381, -0.07757235, ..., -0.09489761,\n",
      "        -0.01521958, -0.05523117]], dtype=float32))\n",
      "(array([ 5.81672363e+02,  4.07223034e+00,  6.48053169e-01,  2.10668743e-01,\n",
      "        1.38650179e-01,  1.02864236e-01,  8.50929916e-02,  6.68669716e-02,\n",
      "        5.30839451e-02,  4.54369895e-02,  2.27184854e-02,  1.72751658e-02,\n",
      "        1.48754818e-02,  1.02341119e-02,  8.74724519e-03,  6.79905899e-03,\n",
      "        6.11552177e-03,  3.76576767e-03,  3.01388698e-03,  2.26831902e-03,\n",
      "        1.87811349e-03,  1.60486961e-03,  1.51318393e-03,  1.27887202e-03,\n",
      "        1.13111408e-03,  7.41553027e-04,  6.47317793e-04,  5.63066162e-04,\n",
      "        5.47450734e-04,  3.96037271e-04,  4.07338899e-04,  3.15530371e-04,\n",
      "        2.89615127e-04,  2.68235366e-04,  1.88117439e-04,  1.68053259e-04,\n",
      "        1.53906018e-04,  1.43287005e-04,  1.05366431e-04,  9.34077689e-05,\n",
      "        7.87222671e-05,  6.70598965e-05,  5.19153000e-05,  3.42909771e-05,\n",
      "        3.08722665e-05,  2.28476838e-05,  1.71682259e-05,  1.35245946e-05,\n",
      "       -1.18420503e-05,  1.15478597e-05,  9.13943495e-06, -7.88236775e-06,\n",
      "       -7.24526308e-06,  7.41875556e-06, -5.53292148e-06, -5.02233434e-06,\n",
      "        5.99467057e-06,  5.47969557e-06,  5.20692265e-06,  4.33922696e-06,\n",
      "       -3.99809232e-06, -3.71467627e-06,  3.57653698e-06,  3.43580473e-06,\n",
      "       -2.94876577e-06, -2.53995427e-06,  2.14148963e-06, -2.06458617e-06,\n",
      "       -1.73831211e-06,  1.66299628e-06, -1.53723022e-06,  1.53732412e-06,\n",
      "       -1.19042852e-06,  1.23264772e-06,  1.19220977e-06, -9.73514943e-07,\n",
      "        9.28379279e-07,  7.62914794e-07, -7.10186953e-07, -6.91733931e-07,\n",
      "        6.24182633e-07,  5.96448672e-07,  4.96945574e-07, -5.46208128e-07,\n",
      "       -4.41575679e-07, -4.12483303e-07, -3.63881810e-07,  3.52204296e-07,\n",
      "        3.19518421e-07, -2.70906611e-07,  2.54870145e-07,  2.38797611e-07,\n",
      "       -2.29716363e-07, -2.04486810e-07, -1.79412496e-07,  1.63567833e-07,\n",
      "       -1.18305081e-07,  1.33719112e-07,  1.15755782e-07,  9.98985428e-08,\n",
      "       -9.53692378e-08, -6.66763142e-08,  6.38898712e-08, -5.97802412e-08,\n",
      "       -4.87430327e-08,  5.16112557e-08,  4.38893331e-08, -3.20508242e-08,\n",
      "       -2.38651214e-08, -1.55977009e-08,  1.91870004e-08,  1.69963368e-08,\n",
      "        1.32820528e-08, -6.87316648e-09, -2.73527578e-09,  6.71168732e-10,\n",
      "       -7.68633379e-10,  3.64464059e-09,  8.26145019e-09,  6.94329838e-09],\n",
      "      dtype=float32), array([[ 0.05930689, -0.12071221, -0.00428733, ...,  0.01870297,\n",
      "         0.01681016, -0.00599977],\n",
      "       [ 0.05699505, -0.05631321, -0.22064678, ...,  0.02590528,\n",
      "         0.05568995, -0.0475243 ],\n",
      "       [ 0.00246869,  0.02042745,  0.045176  , ...,  0.08484706,\n",
      "        -0.01194426, -0.02118499],\n",
      "       ...,\n",
      "       [-0.01422168, -0.03842304,  0.03164766, ..., -0.15186335,\n",
      "        -0.11971856, -0.01722308],\n",
      "       [ 0.17295292, -0.00293613,  0.0947634 , ...,  0.00562985,\n",
      "        -0.00592418, -0.0098373 ],\n",
      "       [ 0.04370867,  0.04532543,  0.04412673, ...,  0.02915073,\n",
      "        -0.00923793,  0.06755046]], dtype=float32))\n",
      "(array([ 5.70913086e+02,  3.03020716e+00,  3.49536240e-01,  3.16840798e-01,\n",
      "        2.58068055e-01,  1.24370776e-01,  7.06970319e-02,  6.09153807e-02,\n",
      "        3.47305201e-02,  2.76521649e-02,  2.17858627e-02,  1.09733222e-02,\n",
      "        1.00464839e-02,  6.73483312e-03,  5.31659601e-03,  3.63367214e-03,\n",
      "        2.87675648e-03,  2.81473412e-03,  2.33134162e-03,  1.78486889e-03,\n",
      "        1.50482904e-03,  1.21936656e-03,  1.16469571e-03,  1.03336689e-03,\n",
      "        7.90267368e-04,  6.49755821e-04,  5.25738520e-04,  4.40308504e-04,\n",
      "        3.99827724e-04,  3.93073278e-04,  3.35885532e-04,  2.48171127e-04,\n",
      "        2.17299996e-04,  1.78548187e-04,  1.63107659e-04,  1.32280591e-04,\n",
      "        1.17554962e-04,  9.90407352e-05,  6.51041773e-05,  5.31635596e-05,\n",
      "        4.57428505e-05,  4.02007281e-05,  3.90994101e-05,  3.24165303e-05,\n",
      "        2.54588231e-05,  2.28672998e-05,  1.70293497e-05,  1.23568907e-05,\n",
      "       -1.00613006e-05, -8.66705795e-06,  1.06816242e-05, -7.51130437e-06,\n",
      "        9.71814006e-06,  8.31367743e-06, -5.62515743e-06,  7.11318626e-06,\n",
      "        6.37880066e-06, -5.20335607e-06,  4.24363134e-06,  3.70910379e-06,\n",
      "       -3.21485004e-06, -3.02897547e-06, -2.65627477e-06, -1.99793749e-06,\n",
      "        2.57409033e-06,  2.53288817e-06,  2.31429431e-06,  1.72570071e-06,\n",
      "       -1.65043150e-06, -1.48417166e-06,  1.55880230e-06,  1.31774698e-06,\n",
      "       -1.33516426e-06, -1.10176848e-06,  9.26115888e-07,  8.78179321e-07,\n",
      "        6.97252517e-07, -9.65055051e-07, -9.15002090e-07, -7.13515874e-07,\n",
      "       -6.27842894e-07, -5.65261985e-07,  5.60388003e-07,  5.04183618e-07,\n",
      "       -4.28577351e-07,  4.44285945e-07, -4.23054615e-07,  3.56762683e-07,\n",
      "       -3.11527771e-07, -2.72073123e-07,  3.44279499e-07,  2.89882905e-07,\n",
      "        2.44004440e-07, -2.31450258e-07,  1.89639366e-07, -1.76165187e-07,\n",
      "       -1.36134773e-07, -1.50024334e-07,  1.44701900e-07,  1.23558664e-07,\n",
      "       -6.87533728e-08,  9.71377361e-08,  8.91189202e-08,  6.81340850e-08,\n",
      "        6.41431370e-08, -5.52775106e-08,  4.79419562e-08,  3.83626357e-08,\n",
      "       -3.60077550e-08,  2.08189963e-08, -2.22615846e-08,  1.17865087e-08,\n",
      "        6.59678268e-09,  5.14129628e-09,  1.23955202e-09, -1.46046597e-08,\n",
      "       -3.64117159e-09, -5.81075810e-09, -1.14719398e-08, -8.53033377e-09],\n",
      "      dtype=float32), array([[ 0.0600339 , -0.1806051 ,  0.2011417 , ...,  0.02229093,\n",
      "         0.04340657,  0.02499939],\n",
      "       [ 0.05643777, -0.01997022, -0.03861601, ...,  0.00717957,\n",
      "         0.00499233,  0.00563383],\n",
      "       [ 0.00130322,  0.01586974,  0.08599765, ..., -0.3177612 ,\n",
      "        -0.03097458, -0.04381224],\n",
      "       ...,\n",
      "       [-0.0112983 , -0.03782262, -0.20627092, ..., -0.11555706,\n",
      "         0.00943486, -0.0479255 ],\n",
      "       [ 0.16832577, -0.01570417,  0.05531281, ...,  0.00106232,\n",
      "         0.01014693, -0.00041871],\n",
      "       [ 0.03932749,  0.04047553,  0.13247606, ...,  0.0351043 ,\n",
      "         0.02684781, -0.02241005]], dtype=float32))\n",
      "(array([ 4.65725525e+02,  2.28392053e+00,  7.22990274e-01,  4.33302313e-01,\n",
      "        1.40795469e-01,  1.09657362e-01,  6.85833842e-02,  4.05880623e-02,\n",
      "        3.47409174e-02,  1.56118870e-02,  1.51486099e-02,  1.34081589e-02,\n",
      "        7.56200543e-03,  4.99563059e-03,  4.17115819e-03,  3.50877643e-03,\n",
      "        2.86916574e-03,  2.18776707e-03,  1.75316224e-03,  1.43504958e-03,\n",
      "        1.44648284e-03,  1.14180602e-03,  7.49061932e-04,  6.72312046e-04,\n",
      "        5.27803728e-04,  4.38229123e-04,  4.04873223e-04,  3.09162628e-04,\n",
      "        2.79064348e-04,  2.39162240e-04,  2.06505778e-04,  1.98889393e-04,\n",
      "        1.36653660e-04,  1.26067069e-04,  1.09955647e-04,  9.41132021e-05,\n",
      "        8.62679080e-05,  6.99653901e-05,  6.76070631e-05,  5.84848895e-05,\n",
      "        4.13388116e-05,  3.51516319e-05,  3.17139966e-05,  2.22105336e-05,\n",
      "        2.07250869e-05,  1.31912911e-05,  1.10378005e-05, -8.44167698e-06,\n",
      "        9.69281245e-06, -7.47805598e-06,  8.11814516e-06, -5.95921256e-06,\n",
      "        6.30226077e-06,  5.69744998e-06, -4.14521401e-06,  4.69035194e-06,\n",
      "        3.79659900e-06, -3.31220417e-06,  3.31619003e-06,  2.98034342e-06,\n",
      "       -2.84031285e-06, -2.51769347e-06, -2.31958143e-06,  2.10453777e-06,\n",
      "        1.75181458e-06,  1.58002422e-06, -1.76214166e-06, -1.51176243e-06,\n",
      "       -1.30727017e-06,  1.32797641e-06, -1.14507873e-06,  1.06537675e-06,\n",
      "       -1.03037848e-06, -8.88704506e-07,  9.58811029e-07,  9.22466370e-07,\n",
      "       -6.59131558e-07, -5.77747869e-07, -4.78308493e-07,  6.67758570e-07,\n",
      "        6.25047619e-07,  5.63489436e-07,  5.04047591e-07,  4.59649101e-07,\n",
      "       -3.48300830e-07, -3.09616695e-07,  2.97270731e-07,  3.13110547e-07,\n",
      "        2.62821175e-07,  1.86721095e-07, -2.00841612e-07, -1.95027283e-07,\n",
      "       -1.81221026e-07, -1.54732064e-07,  1.33497920e-07, -1.37328811e-07,\n",
      "       -1.16300157e-07,  1.04629585e-07, -9.56614699e-08,  9.89543167e-08,\n",
      "        7.81053799e-08,  6.54797105e-08,  5.94375145e-08, -5.34457918e-08,\n",
      "       -4.81049192e-08,  4.14901073e-08,  3.45561837e-08,  3.03938208e-08,\n",
      "       -3.34680728e-08, -2.92949593e-08,  1.63224474e-08, -1.92257374e-08,\n",
      "        1.08751879e-08,  5.26808241e-09,  2.85303758e-09, -7.03724579e-11,\n",
      "       -1.12636123e-08, -7.96766386e-09, -6.27281160e-09, -3.33318217e-09],\n",
      "      dtype=float32), array([[ 0.04979324,  0.12646525, -0.09874756, ...,  0.02233314,\n",
      "         0.00149368, -0.00590232],\n",
      "       [ 0.05496298, -0.01752847,  0.20920226, ...,  0.01827905,\n",
      "         0.02388022,  0.0339369 ],\n",
      "       [ 0.00207647, -0.02275162, -0.04099246, ..., -0.07997285,\n",
      "         0.05603198, -0.00640604],\n",
      "       ...,\n",
      "       [-0.01321059,  0.06457579,  0.01120187, ..., -0.05720383,\n",
      "         0.05834522,  0.06308029],\n",
      "       [ 0.16424534,  0.04690346, -0.09939426, ..., -0.00311031,\n",
      "        -0.02361976,  0.01782148],\n",
      "       [ 0.04055833, -0.04803877, -0.05670839, ...,  0.00322698,\n",
      "         0.03192497, -0.01974542]], dtype=float32))\n",
      "(array([ 5.19220947e+02,  1.33440399e+00,  8.46775889e-01,  3.37725073e-01,\n",
      "        2.03675181e-01,  1.11622132e-01,  9.11719948e-02,  5.46869114e-02,\n",
      "        2.60045305e-02,  1.97709985e-02,  1.86637491e-02,  1.47631289e-02,\n",
      "        9.68994945e-03,  7.46594975e-03,  6.05539186e-03,  3.66619090e-03,\n",
      "        3.57069471e-03,  2.82282731e-03,  2.44166143e-03,  1.64521695e-03,\n",
      "        1.32769032e-03,  1.05802855e-03,  8.38347827e-04,  6.48381014e-04,\n",
      "        5.76959923e-04,  6.03052438e-04,  4.70475905e-04,  3.87907348e-04,\n",
      "        3.09886498e-04,  2.79115833e-04,  2.59383349e-04,  2.31608588e-04,\n",
      "        2.02085343e-04,  1.59566669e-04,  1.32595684e-04,  1.12755915e-04,\n",
      "        9.86588202e-05,  7.62781856e-05,  6.83148246e-05,  5.94165722e-05,\n",
      "        4.86525678e-05,  3.54345430e-05,  3.36861995e-05,  3.09634961e-05,\n",
      "        2.93923913e-05,  1.87553669e-05, -1.50950818e-05,  1.39674812e-05,\n",
      "        1.32963260e-05,  1.15892462e-05, -9.42971565e-06,  9.12691121e-06,\n",
      "       -7.25903465e-06, -6.90927300e-06,  7.00979353e-06, -4.36756090e-06,\n",
      "        5.41652253e-06,  4.90336288e-06,  4.08895266e-06,  3.91727417e-06,\n",
      "        2.98166538e-06, -2.76687297e-06, -2.44327634e-06, -2.26674842e-06,\n",
      "        2.29034140e-06,  2.11102588e-06, -1.83236966e-06,  1.87780142e-06,\n",
      "        1.69839575e-06, -1.56304566e-06,  1.33772869e-06, -1.41955434e-06,\n",
      "       -1.39725910e-06,  1.13192789e-06, -9.11913958e-07,  9.40659277e-07,\n",
      "        8.04743820e-07, -6.96322502e-07,  6.73541251e-07,  5.63562423e-07,\n",
      "        5.11037854e-07,  4.35088396e-07, -5.45036357e-07, -5.06341792e-07,\n",
      "       -4.98558506e-07, -4.13699439e-07,  3.84280582e-07,  2.86554297e-07,\n",
      "       -2.91655823e-07,  1.79102457e-07,  1.99242962e-07, -2.35464697e-07,\n",
      "       -2.19213248e-07, -1.63778537e-07, -1.87567963e-07, -1.38245468e-07,\n",
      "        1.29302705e-07,  1.17141724e-07, -1.25691116e-07, -7.48049089e-08,\n",
      "       -8.58848779e-08,  8.12421064e-08,  6.19822558e-08,  5.59040956e-08,\n",
      "       -4.06773921e-08,  4.27827764e-08, -3.38418644e-08, -2.29182469e-08,\n",
      "       -1.64512439e-08,  2.54739057e-08,  2.30324453e-08, -1.10759029e-08,\n",
      "        1.49501744e-08, -4.44427251e-09, -2.36298203e-09,  1.69958783e-10,\n",
      "        2.28391461e-09,  4.63273642e-09,  7.74955478e-09,  1.03627453e-08],\n",
      "      dtype=float32), array([[ 0.05894364,  0.18022795,  0.01180145, ...,  0.02858008,\n",
      "         0.03151442,  0.00356056],\n",
      "       [ 0.05100348,  0.03791045,  0.22633888, ...,  0.08917947,\n",
      "         0.0230058 , -0.06000831],\n",
      "       [ 0.00039624, -0.01365058, -0.01350807, ...,  0.0750497 ,\n",
      "         0.01476843,  0.0269649 ],\n",
      "       ...,\n",
      "       [-0.00707972,  0.03422507, -0.01943387, ..., -0.05325955,\n",
      "        -0.0703957 , -0.06168861],\n",
      "       [ 0.16379358, -0.0158098 , -0.10568626, ..., -0.01868224,\n",
      "         0.01321335,  0.00869133],\n",
      "       [ 0.03786243, -0.03855874, -0.06569975, ...,  0.02116288,\n",
      "         0.03952722,  0.087656  ]], dtype=float32))\n",
      "(array([ 4.09783325e+02,  1.28392375e+00,  8.97463262e-01,  1.23719715e-01,\n",
      "        8.60108286e-02,  3.84497792e-02,  2.44370103e-02,  1.99795961e-02,\n",
      "        1.28231281e-02,  6.46868534e-03,  5.44587197e-03,  3.33639537e-03,\n",
      "        1.80661830e-03,  1.27591705e-03,  1.16742204e-03,  7.38027389e-04,\n",
      "        6.41193590e-04,  6.04992092e-04,  3.67464643e-04,  2.81207875e-04,\n",
      "        2.66016199e-04,  2.08599507e-04,  1.87750265e-04,  1.62956800e-04,\n",
      "        1.16874609e-04,  9.85179504e-05,  8.82753375e-05,  7.42060147e-05,\n",
      "        6.49834619e-05,  5.65578084e-05,  3.52881652e-05,  2.58088730e-05,\n",
      "        2.26704324e-05,  2.12736850e-05,  1.67431481e-05,  1.49157577e-05,\n",
      "       -1.18590124e-05,  1.28807269e-05, -9.04794706e-06,  1.12428297e-05,\n",
      "       -7.96224413e-06,  9.53523431e-06,  9.32480907e-06,  8.13675888e-06,\n",
      "       -6.57123201e-06,  6.82706650e-06,  6.11824362e-06, -5.45046760e-06,\n",
      "       -4.10744906e-06,  4.70529812e-06,  4.46001968e-06,  3.89473917e-06,\n",
      "       -3.17252739e-06,  3.03141292e-06,  2.62420417e-06,  2.48858987e-06,\n",
      "       -1.99669807e-06, -1.68404654e-06,  2.04986145e-06,  1.85933743e-06,\n",
      "       -1.44640433e-06,  1.67641849e-06,  1.53767246e-06, -1.25792167e-06,\n",
      "       -9.50171284e-07, -9.21159085e-07, -7.52598396e-07,  1.32405626e-06,\n",
      "        1.26555108e-06,  1.09006760e-06,  9.85644874e-07,  8.59462148e-07,\n",
      "        8.42088923e-07, -6.22176174e-07,  7.04916260e-07,  6.37073640e-07,\n",
      "        5.93771347e-07, -5.34886055e-07, -4.57345465e-07,  5.02063358e-07,\n",
      "       -3.48782038e-07, -2.97484320e-07,  3.23846734e-07,  3.89126484e-07,\n",
      "        3.81131088e-07, -2.62967291e-07,  2.81050148e-07,  2.52099142e-07,\n",
      "       -1.99887992e-07, -1.73573795e-07,  2.02043125e-07,  2.06260410e-07,\n",
      "        1.54592030e-07, -1.24033321e-07, -1.11863159e-07,  1.33732939e-07,\n",
      "       -8.73830359e-08,  1.06614863e-07,  9.63231699e-08, -7.99269344e-08,\n",
      "        7.56485790e-08, -6.72105571e-08, -5.67464440e-08,  4.98953092e-08,\n",
      "        4.61191370e-08, -3.78735798e-08,  3.91298087e-08,  2.65690527e-08,\n",
      "       -3.42203776e-08, -2.94504812e-08, -1.70775571e-08, -1.38166536e-08,\n",
      "        1.61677818e-08, -5.47040457e-09,  7.57543805e-09,  6.72165701e-09,\n",
      "        3.69459219e-09,  1.31158681e-10, -8.40931325e-10, -1.58812308e-09],\n",
      "      dtype=float32), array([[ 6.2723443e-02,  1.6478406e-01,  1.1441371e-01, ...,\n",
      "        -1.5413370e-02,  4.9463022e-03, -1.4880374e-04],\n",
      "       [ 4.5328245e-02, -7.1281195e-02,  2.0545505e-01, ...,\n",
      "        -3.0229041e-02, -3.4628883e-02,  1.9036306e-02],\n",
      "       [ 2.8125640e-05,  6.2712207e-03, -1.8648926e-02, ...,\n",
      "        -1.6922309e-01, -3.5532996e-02, -9.0774763e-03],\n",
      "       ...,\n",
      "       [ 2.9298628e-03, -5.1906710e-03, -3.3030674e-02, ...,\n",
      "        -5.6836389e-02, -6.8835780e-02, -9.7272508e-02],\n",
      "       [ 1.4654157e-01,  2.2530618e-01, -2.5411136e-02, ...,\n",
      "        -2.3586424e-03,  6.1988532e-05, -5.0862092e-03],\n",
      "       [ 3.1274453e-02,  3.8920689e-02, -7.7984311e-02, ...,\n",
      "         6.9615985e-03, -1.6963823e-02, -3.4983911e-02]], dtype=float32))\n",
      "(array([ 3.5872879e+02,  3.9518708e-01,  9.0201013e-02,  8.1738405e-02,\n",
      "        4.2806562e-02,  2.5556827e-02,  6.2922598e-03,  4.2825798e-03,\n",
      "        2.7053601e-03,  2.3705801e-03,  1.6064654e-03,  8.8270550e-04,\n",
      "        5.9448584e-04,  5.5114663e-04,  3.5180885e-04,  2.6193558e-04,\n",
      "        2.0740158e-04,  2.0267509e-04,  1.4611523e-04,  1.1392583e-04,\n",
      "        9.7776996e-05,  7.6818098e-05,  5.4719290e-05,  5.0860101e-05,\n",
      "        4.3854081e-05,  3.5659075e-05,  2.2242029e-05,  1.8470733e-05,\n",
      "        1.4428605e-05, -9.9657655e-06,  1.2475995e-05,  1.0922435e-05,\n",
      "        9.9833023e-06,  9.5929117e-06,  8.8257539e-06, -7.8447229e-06,\n",
      "        7.8733638e-06, -5.5593669e-06,  5.3750969e-06,  4.7466606e-06,\n",
      "       -3.8201861e-06,  4.2870070e-06,  3.6762867e-06,  3.3214837e-06,\n",
      "       -2.9996247e-06, -2.8131251e-06, -2.2796235e-06,  2.9837854e-06,\n",
      "        2.8748348e-06,  2.5659369e-06, -2.1942478e-06,  2.1817193e-06,\n",
      "       -1.7500175e-06,  1.8161933e-06, -1.4726775e-06,  1.6266130e-06,\n",
      "        1.4981432e-06, -1.1313672e-06,  1.2222039e-06,  1.1328904e-06,\n",
      "        1.0587810e-06, -8.9110495e-07, -7.9171576e-07,  1.0088879e-06,\n",
      "        9.4095066e-07, -6.8300710e-07,  8.2587633e-07,  7.1006264e-07,\n",
      "       -5.7278197e-07,  6.7866239e-07, -4.9708245e-07,  5.7545816e-07,\n",
      "       -4.0107832e-07,  4.9545059e-07,  4.5486178e-07, -3.3740909e-07,\n",
      "       -2.9034473e-07,  4.3096452e-07,  3.5363240e-07,  3.1654511e-07,\n",
      "        3.0800604e-07,  2.2696773e-07, -2.1173170e-07, -1.9190509e-07,\n",
      "       -1.5303677e-07,  1.9285608e-07,  1.9914609e-07,  1.6859150e-07,\n",
      "       -1.3076998e-07, -9.6716917e-08,  1.4661583e-07,  1.2015921e-07,\n",
      "        1.0537626e-07,  9.1861295e-08, -7.1967818e-08,  8.1465302e-08,\n",
      "       -6.6125409e-08,  6.8649442e-08, -5.5426206e-08,  6.1573573e-08,\n",
      "        5.3748273e-08, -4.3984720e-08, -4.1036682e-08,  4.6410612e-08,\n",
      "       -3.0941866e-08,  3.5929965e-08, -2.1265803e-08,  2.6705088e-08,\n",
      "        2.3317657e-08,  2.1189898e-08,  1.5576797e-08,  1.3834863e-08,\n",
      "       -1.2439523e-08,  7.7989828e-09,  2.0639837e-09,  8.1326734e-10,\n",
      "       -9.4002739e-10, -7.5736448e-09, -6.5456378e-09, -4.1706882e-09],\n",
      "      dtype=float32), array([[-0.05073075,  0.10120039,  0.04156693, ..., -0.01062554,\n",
      "         0.00203097, -0.0449638 ],\n",
      "       [-0.03960264, -0.18798125,  0.05793209, ..., -0.04301826,\n",
      "        -0.03463723,  0.04681757],\n",
      "       [ 0.00171262,  0.01454259, -0.02937436, ...,  0.01071076,\n",
      "        -0.00446737, -0.03795293],\n",
      "       ...,\n",
      "       [-0.01006049,  0.02260209, -0.02110426, ..., -0.05049561,\n",
      "         0.01688398,  0.00791532],\n",
      "       [-0.13998269,  0.20561388,  0.16572137, ...,  0.00917292,\n",
      "        -0.00806457,  0.00210484],\n",
      "       [-0.02974989,  0.0549436 ,  0.00577005, ...,  0.00419849,\n",
      "        -0.00767051,  0.05999932]], dtype=float32))\n",
      "(array([ 3.20366089e+02,  2.74982393e-01,  1.41511470e-01,  2.07939334e-02,\n",
      "        1.29638799e-02,  8.19689594e-03,  2.87104677e-03,  1.78555842e-03,\n",
      "        1.28649117e-03,  5.64597431e-04,  2.73928861e-04,  2.44516123e-04,\n",
      "        1.89058526e-04,  1.51844346e-04,  1.40398537e-04,  1.08504464e-04,\n",
      "        8.83874382e-05,  6.01366155e-05,  4.36829105e-05,  3.71806818e-05,\n",
      "        2.91058313e-05,  2.14495467e-05,  1.61069438e-05,  1.35706432e-05,\n",
      "       -1.02175400e-05,  1.15921312e-05,  1.06489206e-05,  8.91245236e-06,\n",
      "       -6.50131460e-06,  7.46481419e-06,  7.07778690e-06,  6.08990740e-06,\n",
      "       -4.91855781e-06, -3.98628708e-06,  5.35693289e-06,  4.31577428e-06,\n",
      "        4.01377611e-06,  3.88301305e-06, -2.86615318e-06, -2.51405504e-06,\n",
      "       -2.23397842e-06,  3.01133286e-06,  2.59332865e-06,  2.55925465e-06,\n",
      "        2.37417589e-06, -1.69494740e-06,  2.03877426e-06,  1.74385343e-06,\n",
      "       -1.49872199e-06,  1.53626752e-06, -1.21303435e-06,  1.31254967e-06,\n",
      "        1.21843323e-06, -9.70465976e-07, -8.63426237e-07,  1.05254594e-06,\n",
      "        9.55130417e-07,  8.52185508e-07, -6.99309567e-07, -6.37675782e-07,\n",
      "       -5.16612261e-07,  7.85121131e-07,  7.73207489e-07,  6.03574961e-07,\n",
      "        6.98763756e-07,  6.70432314e-07, -4.64250178e-07, -4.03171896e-07,\n",
      "       -3.25177979e-07,  4.81262930e-07,  4.51482265e-07,  4.11733851e-07,\n",
      "        3.89632845e-07,  3.61863357e-07, -2.84543887e-07, -2.66378407e-07,\n",
      "        3.20113742e-07,  2.88358677e-07, -2.04881630e-07, -1.67388237e-07,\n",
      "       -1.44505933e-07,  2.29577552e-07,  1.72218321e-07,  1.98220818e-07,\n",
      "        1.94822903e-07,  1.40954924e-07,  1.32082064e-07, -1.03689217e-07,\n",
      "       -1.01446062e-07,  1.10842727e-07, -7.95387436e-08, -7.28247116e-08,\n",
      "       -4.98061823e-08,  9.15425602e-08,  8.50181650e-08,  7.19533588e-08,\n",
      "        6.54427197e-08, -4.53594922e-08,  5.34826796e-08, -3.21769456e-08,\n",
      "       -2.73166165e-08,  3.99559887e-08,  4.65427270e-08, -2.06529727e-08,\n",
      "       -1.40214009e-08, -1.58833942e-08,  3.02603631e-08,  2.77476992e-08,\n",
      "        2.62523443e-08,  2.09148627e-08, -4.97240782e-09, -3.00065639e-09,\n",
      "       -1.40831524e-09,  1.03307995e-09,  1.61659042e-08,  1.41761474e-08,\n",
      "        2.15847828e-09,  9.52035695e-09,  7.85717980e-09,  6.13860118e-09],\n",
      "      dtype=float32), array([[-0.04909906,  0.01510893, -0.0858603 , ...,  0.00282191,\n",
      "         0.0097904 ,  0.0417461 ],\n",
      "       [-0.03629968,  0.05067012,  0.16837959, ..., -0.05831645,\n",
      "         0.00405081,  0.05498445],\n",
      "       [ 0.00380232,  0.04601498, -0.0486285 , ...,  0.28468806,\n",
      "         0.08346292, -0.12876573],\n",
      "       ...,\n",
      "       [-0.01871744, -0.09066783,  0.02753892, ..., -0.01690292,\n",
      "        -0.00076014, -0.06247448],\n",
      "       [-0.13418011, -0.27049175, -0.09479924, ...,  0.00437885,\n",
      "        -0.00129409,  0.00596558],\n",
      "       [-0.02542857, -0.0272997 , -0.05755402, ..., -0.08544596,\n",
      "         0.01585505, -0.07312961]], dtype=float32))\n",
      "(array([ 2.68786804e+02,  4.87864822e-01,  1.68134883e-01,  9.57413539e-02,\n",
      "        4.16026860e-02,  2.38652565e-02,  1.24464901e-02,  7.67137250e-03,\n",
      "        3.47686326e-03,  2.13512522e-03,  1.83323468e-03,  1.40160078e-03,\n",
      "        6.94240327e-04,  5.91667369e-04,  4.17271745e-04,  3.15931422e-04,\n",
      "        2.08833982e-04,  1.82550211e-04,  1.43567493e-04,  1.15589741e-04,\n",
      "        1.07922868e-04,  7.01071185e-05,  6.80543453e-05,  4.59812763e-05,\n",
      "        3.42246603e-05,  2.42296828e-05,  2.27358196e-05,  1.71356205e-05,\n",
      "        1.41927658e-05,  1.19593105e-05, -7.07656091e-06,  9.13394433e-06,\n",
      "        8.36098479e-06,  7.54301118e-06, -5.65309074e-06, -4.45221031e-06,\n",
      "        5.53758673e-06,  4.56485668e-06,  4.39375117e-06,  4.08106325e-06,\n",
      "        3.72274894e-06, -2.76028481e-06,  3.29318209e-06,  2.92748655e-06,\n",
      "        2.87674038e-06, -2.34328650e-06, -2.02363640e-06,  2.23777715e-06,\n",
      "        2.13928888e-06, -1.59504862e-06,  1.76705112e-06,  1.54178747e-06,\n",
      "        1.42939382e-06,  1.27401586e-06, -1.18990988e-06, -9.94384550e-07,\n",
      "       -9.38323637e-07,  1.03821571e-06,  9.34955835e-07, -8.40391692e-07,\n",
      "        8.50458207e-07, -7.04118577e-07,  7.24111828e-07,  7.14312080e-07,\n",
      "       -5.37913195e-07,  5.71489977e-07, -5.19336709e-07, -4.17325253e-07,\n",
      "       -3.96797162e-07,  4.95386757e-07,  4.62219106e-07,  4.47972269e-07,\n",
      "        4.08457765e-07,  3.76148250e-07, -3.17459097e-07, -3.01412513e-07,\n",
      "        3.38466322e-07,  2.79374689e-07,  2.89116400e-07, -2.06346058e-07,\n",
      "       -1.93091836e-07, -1.67312379e-07,  2.31653729e-07,  2.22432334e-07,\n",
      "        1.85485419e-07,  1.67273129e-07, -1.24593882e-07, -1.11812255e-07,\n",
      "       -9.47173362e-08, -7.98593334e-08,  1.19436677e-07,  1.03311535e-07,\n",
      "        8.49139496e-08,  9.23995600e-08,  9.60107229e-08, -5.95288903e-08,\n",
      "        6.72269636e-08, -4.89445249e-08, -4.66338399e-08,  5.96559033e-08,\n",
      "       -2.99945171e-08,  4.25703242e-08, -2.61244342e-08,  5.12348386e-08,\n",
      "        3.44329010e-08,  3.24602674e-08, -1.82973920e-08,  2.49699106e-08,\n",
      "        2.28772663e-08, -1.38700189e-08, -1.06912204e-08,  1.65008949e-08,\n",
      "        1.27512028e-08, -7.38585593e-09, -5.43830270e-09, -2.05792672e-09,\n",
      "        8.82284190e-10,  2.09816897e-09,  4.61775018e-09,  8.39338288e-09],\n",
      "      dtype=float32), array([[-0.04774752,  0.06270639,  0.2043036 , ..., -0.0104628 ,\n",
      "        -0.02148567, -0.01769921],\n",
      "       [-0.03886224,  0.07327919, -0.12318499, ...,  0.00523392,\n",
      "        -0.02521945, -0.05944682],\n",
      "       [ 0.00194956,  0.02657814,  0.06728183, ..., -0.01913522,\n",
      "         0.08540689,  0.15774778],\n",
      "       ...,\n",
      "       [-0.01450215, -0.03885686, -0.06891264, ..., -0.05163118,\n",
      "        -0.06323358,  0.07998832],\n",
      "       [-0.12565993, -0.15527177,  0.11766195, ...,  0.00838934,\n",
      "         0.00217259,  0.00173   ],\n",
      "       [-0.02483498, -0.02983725,  0.0505096 , ...,  0.07276673,\n",
      "        -0.01791945,  0.03797273]], dtype=float32))\n",
      "(array([ 2.83688568e+02,  1.22740835e-01,  2.22460292e-02,  1.76719613e-02,\n",
      "        9.36060306e-03,  4.92572971e-03,  1.73130992e-03,  1.12393626e-03,\n",
      "        7.52655149e-04,  2.65604409e-04,  2.11948151e-04,  1.33524722e-04,\n",
      "        1.05038562e-04,  8.95929843e-05,  5.33147540e-05,  4.78674556e-05,\n",
      "        2.97015558e-05,  2.11973820e-05,  1.60807595e-05, -1.19996794e-05,\n",
      "        1.29388618e-05,  1.08308686e-05, -9.36615834e-06,  9.58016517e-06,\n",
      "       -6.08459186e-06,  7.43611417e-06,  6.77238222e-06,  6.28438147e-06,\n",
      "        5.40378005e-06,  5.28511191e-06,  4.20173455e-06, -3.26814938e-06,\n",
      "        3.70560861e-06,  3.54026974e-06, -2.85050669e-06,  2.96604821e-06,\n",
      "       -2.21004916e-06,  2.55367809e-06,  2.43875206e-06,  2.16859121e-06,\n",
      "       -1.79288952e-06,  2.06525488e-06, -1.77195102e-06, -1.37408244e-06,\n",
      "       -1.29816499e-06,  1.81978214e-06,  1.78413666e-06,  1.59067736e-06,\n",
      "        1.37253983e-06,  1.22871734e-06, -9.40732548e-07,  1.00654995e-06,\n",
      "       -7.90415640e-07,  8.74506156e-07, -7.28025839e-07, -6.61978333e-07,\n",
      "        7.47360730e-07,  6.72884596e-07,  6.25749749e-07, -4.99143880e-07,\n",
      "        5.75181105e-07,  5.40165502e-07, -4.30923592e-07, -4.01394914e-07,\n",
      "       -3.25455972e-07,  4.54828722e-07, -2.67664831e-07,  3.89267456e-07,\n",
      "        3.32022353e-07,  4.11242496e-07, -2.37695659e-07, -2.13367898e-07,\n",
      "        2.79164425e-07,  2.56406338e-07,  2.42607342e-07, -1.74903903e-07,\n",
      "        2.16083194e-07, -1.51445306e-07,  1.94517952e-07, -1.42607306e-07,\n",
      "        1.83089838e-07,  1.78596693e-07, -1.14271444e-07, -9.73358141e-08,\n",
      "        1.43681902e-07,  1.23678817e-07,  1.34889945e-07, -6.99553127e-08,\n",
      "       -5.47154961e-08, -4.50225031e-08,  9.57330357e-08,  8.66365539e-08,\n",
      "        7.49856142e-08,  7.26312805e-08,  6.50612506e-08,  5.84671156e-08,\n",
      "        5.04044273e-08,  4.27054019e-08, -3.20210916e-08, -2.95446796e-08,\n",
      "        3.56996637e-08, -2.49293013e-08, -2.28658390e-08,  2.57811834e-08,\n",
      "       -1.51160062e-08,  2.22321184e-08,  2.24017178e-08, -8.80233308e-09,\n",
      "       -6.17808471e-09,  1.68315690e-08, -5.16826537e-09, -2.68017519e-09,\n",
      "        5.33370859e-09,  2.75517564e-09,  1.24585542e-09,  1.62228353e-09,\n",
      "        1.09275859e-08,  1.43995029e-08,  1.30615039e-08,  9.67984981e-09],\n",
      "      dtype=float32), array([[-4.7028344e-02,  9.1457315e-02,  4.7073471e-03, ...,\n",
      "         2.8051900e-02, -2.4979092e-02, -4.7406643e-03],\n",
      "       [-3.4680124e-02, -1.6898015e-01, -3.7595466e-02, ...,\n",
      "         5.4448515e-02,  3.6840704e-03,  1.5108127e-02],\n",
      "       [ 4.4239773e-03,  2.5212534e-02,  5.1018864e-02, ...,\n",
      "        -1.4722231e-01,  7.3921718e-02, -3.7165184e-05],\n",
      "       ...,\n",
      "       [-2.0696372e-02,  8.3343564e-03, -6.7837715e-02, ...,\n",
      "        -2.6866686e-02,  1.0777807e-01, -1.9969145e-04],\n",
      "       [-1.2701319e-01,  1.6453128e-01, -8.1500404e-02, ...,\n",
      "         2.1762352e-02, -4.8048510e-03, -3.0763845e-03],\n",
      "       [-2.1501284e-02,  5.8757260e-02, -4.2387433e-02, ...,\n",
      "         5.4493812e-03, -9.5809631e-02,  6.8966955e-02]], dtype=float32))\n",
      "(array([ 2.47992554e+02,  2.00480199e+00,  5.82709312e-01,  3.98185641e-01,\n",
      "        4.73894887e-02,  2.70468406e-02,  2.55069565e-02,  1.55401276e-02,\n",
      "        1.06759723e-02,  4.75079985e-03,  2.58587883e-03,  2.47965194e-03,\n",
      "        2.02941103e-03,  1.47224939e-03,  1.13903417e-03,  8.17586493e-04,\n",
      "        7.24291371e-04,  4.95322980e-04,  4.18750307e-04,  3.95091192e-04,\n",
      "        2.44155730e-04,  1.53908157e-04,  1.35444978e-04,  1.13061695e-04,\n",
      "        8.88915747e-05,  7.34518107e-05,  6.11900614e-05,  4.73242835e-05,\n",
      "        3.57460776e-05,  3.33954413e-05,  2.72372581e-05,  2.08259462e-05,\n",
      "        1.61881762e-05,  1.35978762e-05,  1.16736246e-05, -8.34000548e-06,\n",
      "        9.93218418e-06,  9.50032336e-06,  6.46480930e-06,  6.34953631e-06,\n",
      "       -5.77990977e-06,  5.61847628e-06,  5.30709758e-06,  3.74641809e-06,\n",
      "       -3.84168015e-06, -3.40171778e-06, -3.29183104e-06,  3.12762904e-06,\n",
      "        2.60223055e-06, -1.96318001e-06,  2.37154700e-06,  2.02717024e-06,\n",
      "        1.55665896e-06,  1.40153963e-06, -1.20620803e-06,  1.16580009e-06,\n",
      "       -9.28670431e-07, -8.57931695e-07,  1.02637978e-06,  9.02778766e-07,\n",
      "        8.64117283e-07, -7.22803577e-07,  7.50462618e-07,  7.41255064e-07,\n",
      "       -5.89121214e-07, -5.14378030e-07, -5.06503056e-07,  5.62778268e-07,\n",
      "        5.22132154e-07,  4.90132891e-07, -4.51735502e-07,  4.10763903e-07,\n",
      "       -3.47881866e-07,  3.55436725e-07,  3.19809118e-07, -3.02390731e-07,\n",
      "        2.90088479e-07,  2.51915168e-07,  2.25048069e-07, -2.51292562e-07,\n",
      "       -2.16828283e-07, -1.97124606e-07, -1.83828234e-07,  1.92058522e-07,\n",
      "        1.68530349e-07, -1.49096536e-07,  1.51836602e-07,  1.30145537e-07,\n",
      "       -1.23281097e-07, -1.12531787e-07, -9.37270244e-08,  1.18329069e-07,\n",
      "        1.00917347e-07,  9.99485863e-08,  8.39119352e-08,  6.83902073e-08,\n",
      "       -5.22837880e-08, -4.60675516e-08,  5.47193046e-08,  4.89240257e-08,\n",
      "        4.45065460e-08,  4.20660982e-08, -4.14147081e-08, -3.23840439e-08,\n",
      "        2.50464662e-08, -2.54108894e-08,  3.44395623e-08, -1.21921779e-08,\n",
      "       -2.27490222e-08, -2.05734008e-08,  2.07409645e-08,  1.70981576e-08,\n",
      "        1.55997206e-08,  9.18420540e-09,  7.57662555e-09, -7.53110374e-09,\n",
      "       -3.68165631e-09,  4.20912583e-10, -1.97089189e-09, -1.01682629e-09],\n",
      "      dtype=float32), array([[ 0.04679224, -0.11524283, -0.04619753, ..., -0.00038961,\n",
      "        -0.00526672, -0.01905407],\n",
      "       [ 0.03902997,  0.07016815,  0.13626912, ...,  0.01180035,\n",
      "        -0.01047227,  0.01166629],\n",
      "       [-0.00419489,  0.06683616, -0.06942297, ...,  0.08675665,\n",
      "        -0.06521836,  0.1244212 ],\n",
      "       ...,\n",
      "       [ 0.02135871, -0.15287764,  0.07355387, ..., -0.04761383,\n",
      "        -0.00435358, -0.07832684],\n",
      "       [ 0.131444  , -0.01746624, -0.18920168, ...,  0.03834786,\n",
      "         0.00772545, -0.02122716],\n",
      "       [ 0.02467592,  0.09180339, -0.10881449, ..., -0.05770339,\n",
      "        -0.05056164, -0.03712778]], dtype=float32))\n",
      "(array([ 2.31510269e+02,  1.54278302e+00,  2.28791788e-01,  3.25909667e-02,\n",
      "        1.84900463e-02,  1.05472179e-02,  6.24547806e-03,  5.57560101e-03,\n",
      "        3.66355898e-03,  1.57805637e-03,  6.14905672e-04,  3.32908443e-04,\n",
      "        2.74749473e-04,  1.74253379e-04,  1.09629545e-04,  8.85068657e-05,\n",
      "        6.76043346e-05,  4.07398802e-05,  3.59495898e-05,  2.22086201e-05,\n",
      "        1.56078167e-05,  1.20156610e-05,  9.88279589e-06, -7.30916827e-06,\n",
      "        7.33994057e-06, -4.93864900e-06,  5.09451957e-06,  4.59556941e-06,\n",
      "        3.73664602e-06,  3.42848125e-06, -2.95282007e-06, -2.72966599e-06,\n",
      "        2.90004391e-06,  2.66802590e-06, -2.18581999e-06,  2.31347963e-06,\n",
      "        1.94336826e-06,  1.79838003e-06, -1.67619510e-06, -1.50814924e-06,\n",
      "       -1.23929965e-06,  1.50268227e-06,  1.42833824e-06, -1.09514815e-06,\n",
      "        1.22678750e-06,  1.14871511e-06,  1.06871198e-06, -8.27753581e-07,\n",
      "       -8.06245851e-07,  8.34612592e-07,  8.25500877e-07,  7.99132806e-07,\n",
      "       -7.05218213e-07,  6.36272262e-07,  6.90687102e-07, -5.41290490e-07,\n",
      "       -5.18160562e-07,  5.26821793e-07,  4.76374026e-07,  4.45100909e-07,\n",
      "        4.02683440e-07, -4.29793715e-07, -3.77660484e-07, -3.53685493e-07,\n",
      "        3.80226169e-07,  3.33874652e-07, -3.05680601e-07, -2.73983346e-07,\n",
      "       -2.50635765e-07,  2.86586584e-07,  2.73389134e-07, -2.10239335e-07,\n",
      "       -1.86863318e-07,  2.31929903e-07,  2.08460904e-07,  1.78358377e-07,\n",
      "        1.93929978e-07, -1.42556999e-07,  1.48608336e-07, -1.33509715e-07,\n",
      "        1.42328915e-07, -1.08642794e-07,  1.27357850e-07, -8.84011513e-08,\n",
      "       -8.25789996e-08,  1.11481611e-07,  9.64266960e-08,  8.54601794e-08,\n",
      "        8.60266027e-08, -7.13877881e-08, -5.88834830e-08,  6.45926193e-08,\n",
      "        5.35341442e-08,  4.93362720e-08, -4.57754048e-08, -3.88037513e-08,\n",
      "       -3.51697302e-08,  4.13992254e-08, -3.10659978e-08, -2.22164616e-08,\n",
      "       -1.88078726e-08, -1.25201201e-08,  3.33805623e-08,  2.74004073e-08,\n",
      "        2.58917474e-08,  2.24155379e-08, -8.28764879e-09,  1.77544273e-08,\n",
      "        1.83742230e-08,  1.54700235e-08, -7.43002859e-09, -5.55762414e-09,\n",
      "        1.27930493e-08,  8.18724555e-09,  6.66058941e-09, -2.28108021e-09,\n",
      "       -9.93214622e-10,  3.51639118e-09,  6.99467595e-10,  2.31218644e-09],\n",
      "      dtype=float32), array([[ 0.04106033,  0.16418162, -0.06105174, ...,  0.01839202,\n",
      "        -0.03404729, -0.01432813],\n",
      "       [ 0.0412778 , -0.09829725,  0.17790772, ..., -0.0007452 ,\n",
      "        -0.04381779,  0.0195426 ],\n",
      "       [ 0.00110723, -0.02902494, -0.04100071, ..., -0.07391219,\n",
      "        -0.02879762,  0.14490724],\n",
      "       ...,\n",
      "       [ 0.0115587 ,  0.17725311,  0.04734705, ..., -0.04590819,\n",
      "         0.02238559,  0.21791703],\n",
      "       [ 0.13074268,  0.00479857, -0.19058928, ..., -0.02495142,\n",
      "        -0.00371618,  0.02760712],\n",
      "       [ 0.03447428, -0.00494038, -0.03462589, ...,  0.03420688,\n",
      "         0.06659693,  0.096099  ]], dtype=float32))\n",
      "(array([ 2.59436127e+02,  2.54330349e+00,  9.05557752e-01,  3.35503310e-01,\n",
      "        2.16763109e-01,  1.01431705e-01,  5.45274690e-02,  3.41287553e-02,\n",
      "        1.87277794e-02,  1.38573106e-02,  1.21985888e-02,  7.75720784e-03,\n",
      "        5.59392059e-03,  4.68697492e-03,  2.84436299e-03,  2.39883806e-03,\n",
      "        1.71107287e-03,  1.57647848e-03,  1.45558978e-03,  9.20545252e-04,\n",
      "        7.88900070e-04,  7.44791352e-04,  5.74700127e-04,  4.39393480e-04,\n",
      "        4.20852622e-04,  3.27313173e-04,  2.72507401e-04,  1.94978958e-04,\n",
      "        1.78753195e-04,  1.53138943e-04,  1.15690942e-04,  1.03007820e-04,\n",
      "        8.60350920e-05,  7.74113360e-05,  7.06862338e-05,  5.14681633e-05,\n",
      "        4.93100779e-05,  3.74382253e-05,  3.19602113e-05,  2.28938989e-05,\n",
      "        1.74298566e-05,  1.50708493e-05, -1.03931179e-05,  1.03135098e-05,\n",
      "        9.05854540e-06, -5.61532761e-06,  7.50802928e-06,  6.94427126e-06,\n",
      "        6.24272707e-06, -4.09954464e-06,  4.58826071e-06,  3.85736212e-06,\n",
      "        3.05964659e-06,  2.89102036e-06,  2.29636930e-06, -2.15116279e-06,\n",
      "        1.71704778e-06, -1.76074514e-06, -1.59872229e-06, -1.24105736e-06,\n",
      "        1.42259273e-06, -1.01597709e-06,  1.14817874e-06,  1.03309583e-06,\n",
      "        8.22846800e-07, -6.86467899e-07, -6.24356119e-07,  6.79616392e-07,\n",
      "        6.56325653e-07,  5.91662342e-07, -5.38847303e-07, -4.52176266e-07,\n",
      "       -4.58269227e-07,  4.73082309e-07,  4.07131751e-07, -3.34478727e-07,\n",
      "       -3.04256503e-07, -2.65804118e-07, -2.39365363e-07,  2.88600091e-07,\n",
      "        2.36682283e-07,  2.29205597e-07,  2.05968078e-07,  1.73738016e-07,\n",
      "       -1.93223755e-07, -1.69487322e-07, -1.45416095e-07, -1.18570888e-07,\n",
      "        1.46649114e-07,  1.12376149e-07, -9.08057558e-08,  1.06223347e-07,\n",
      "        9.73655716e-08,  7.91364485e-08, -6.98295111e-08,  7.04021801e-08,\n",
      "       -6.43639808e-08, -6.06443962e-08,  5.78172710e-08, -4.69140176e-08,\n",
      "       -4.31500418e-08,  4.68372505e-08, -3.25988765e-08,  4.07092458e-08,\n",
      "        3.91385804e-08, -2.22523795e-08,  2.95451006e-08, -1.67188716e-08,\n",
      "       -1.31283846e-08,  2.06275654e-08,  1.90953866e-08, -8.86264306e-09,\n",
      "       -5.05642817e-09,  1.40778909e-08, -1.85003013e-09,  6.78492995e-09,\n",
      "        5.17362420e-09,  4.51469084e-10,  1.23495103e-09,  9.81613191e-09],\n",
      "      dtype=float32), array([[-0.03531531,  0.10363375,  0.12149537, ..., -0.01681326,\n",
      "         0.00582328, -0.00052058],\n",
      "       [-0.03693425, -0.09119152, -0.03326001, ...,  0.03166198,\n",
      "        -0.00939234, -0.01417919],\n",
      "       [ 0.01045001, -0.04489064,  0.06025137, ...,  0.05922743,\n",
      "         0.03444971,  0.05995101],\n",
      "       ...,\n",
      "       [-0.00192183,  0.14670354, -0.03212174, ...,  0.12771113,\n",
      "         0.0708896 , -0.01292294],\n",
      "       [-0.13991718, -0.00624597,  0.24312729, ...,  0.00140355,\n",
      "        -0.0011608 ,  0.02339635],\n",
      "       [-0.01849318, -0.07304336,  0.1385036 , ..., -0.0277645 ,\n",
      "         0.02932878,  0.09114196]], dtype=float32))\n",
      "(array([ 2.2540662e+02,  1.2223341e-01,  4.3989349e-02,  1.8060300e-02,\n",
      "        8.6556915e-03,  5.2349051e-03,  7.7384227e-04,  4.7702083e-04,\n",
      "        3.0580713e-04,  2.3096779e-04,  1.1151079e-04,  9.9952245e-05,\n",
      "        7.9108228e-05,  6.9095157e-05,  4.3084285e-05,  3.6810234e-05,\n",
      "        3.1401079e-05,  1.7421919e-05,  1.5827402e-05,  1.1014063e-05,\n",
      "       -8.5241363e-06,  9.0924777e-06,  8.4122448e-06, -6.4539427e-06,\n",
      "        6.8187710e-06,  5.4107927e-06, -4.6803216e-06,  4.6423556e-06,\n",
      "        3.8413468e-06,  3.0626245e-06, -2.7184401e-06,  2.6676632e-06,\n",
      "       -2.3455432e-06, -1.8346568e-06,  2.1509372e-06,  2.0069410e-06,\n",
      "        1.8423934e-06, -1.5184135e-06,  1.4961995e-06, -1.2032967e-06,\n",
      "       -9.0914989e-07,  1.1338293e-06,  1.0661089e-06,  1.0024075e-06,\n",
      "        9.3254977e-07,  8.6354117e-07, -7.5032460e-07, -6.8272965e-07,\n",
      "        8.3108955e-07,  7.7514926e-07, -5.9713744e-07,  6.8699728e-07,\n",
      "        6.7100962e-07, -5.0785530e-07, -4.6626721e-07,  5.4957115e-07,\n",
      "        4.9654051e-07,  4.8676009e-07, -3.9042672e-07,  3.8182719e-07,\n",
      "       -3.4119122e-07, -3.1216263e-07,  3.2820054e-07,  3.0534562e-07,\n",
      "       -2.2573366e-07,  2.7184311e-07,  2.5095986e-07, -2.0525079e-07,\n",
      "        2.1528245e-07, -1.7162719e-07,  1.8958390e-07,  1.7779580e-07,\n",
      "       -1.4696550e-07, -1.3097819e-07,  1.6376931e-07,  1.4606977e-07,\n",
      "        1.3697300e-07, -1.0373805e-07, -9.0040750e-08, -8.0714258e-08,\n",
      "       -6.7303880e-08,  1.1563032e-07,  1.0791935e-07,  9.1690239e-08,\n",
      "        8.2044615e-08,  7.5056889e-08, -5.0049092e-08,  6.3261560e-08,\n",
      "        6.1104593e-08, -4.5782720e-08,  5.7580820e-08, -3.7915065e-08,\n",
      "       -2.6288337e-08,  4.7922015e-08, -2.2253941e-08,  4.1284988e-08,\n",
      "        3.6569659e-08,  3.7331212e-08, -2.0619138e-08, -1.5103563e-08,\n",
      "        2.7966086e-08,  2.6157187e-08,  2.2758780e-08,  2.1774559e-08,\n",
      "       -9.2840589e-09, -8.5590548e-09,  2.0562336e-08,  1.4261044e-08,\n",
      "        1.3455347e-08, -3.5107444e-09, -4.6369686e-09,  9.4067243e-09,\n",
      "       -9.8124442e-10, -1.5480874e-10,  7.9629805e-09,  7.2857000e-09,\n",
      "        7.6506540e-10,  1.3781086e-09,  5.2817866e-09,  5.1570614e-09],\n",
      "      dtype=float32), array([[-0.04557989, -0.15297586,  0.20102398, ..., -0.0209485 ,\n",
      "         0.02168363, -0.02931345],\n",
      "       [-0.02995759,  0.16288298, -0.0221847 , ..., -0.05482582,\n",
      "         0.03744961, -0.02998511],\n",
      "       [ 0.0098289 , -0.03152175, -0.0023737 , ...,  0.09532602,\n",
      "         0.14476755, -0.02518279],\n",
      "       ...,\n",
      "       [-0.01042953, -0.01858867,  0.2491357 , ..., -0.06610185,\n",
      "         0.09761678, -0.08634097],\n",
      "       [-0.10751264, -0.1782773 , -0.12857538, ...,  0.00420752,\n",
      "         0.0194599 ,  0.01629409],\n",
      "       [-0.00998735, -0.07485658,  0.05606508, ...,  0.04977994,\n",
      "         0.07714319, -0.02530804]], dtype=float32))\n",
      "(array([ 2.31013885e+02,  1.06323637e-01,  7.98538234e-03,  4.08011954e-03,\n",
      "        8.50346871e-04,  5.12042898e-04,  2.05029704e-04,  8.28448392e-05,\n",
      "        6.11013020e-05,  5.44868490e-05,  4.00695972e-05,  2.96360668e-05,\n",
      "        1.72068249e-05,  1.20063132e-05, -9.67879623e-06,  8.84980091e-06,\n",
      "        7.77605874e-06, -6.53056031e-06,  6.27896998e-06,  5.26291842e-06,\n",
      "       -4.25089138e-06,  4.13868884e-06, -3.38214295e-06,  3.71570309e-06,\n",
      "       -2.79498681e-06,  3.14705812e-06,  2.69257544e-06,  2.48301058e-06,\n",
      "       -2.06229925e-06,  2.20103811e-06, -1.70661940e-06, -1.35080677e-06,\n",
      "        1.61226296e-06,  1.50233029e-06,  1.41835130e-06, -1.10490782e-06,\n",
      "       -9.36195875e-07,  1.17909474e-06,  1.09397104e-06,  1.03753280e-06,\n",
      "        8.90489730e-07,  8.23799780e-07,  7.14489829e-07, -7.94188395e-07,\n",
      "        6.07769948e-07, -7.30928491e-07, -5.63309641e-07, -5.84329086e-07,\n",
      "       -6.11194196e-07,  5.02259923e-07, -4.73451394e-07,  4.67840579e-07,\n",
      "        4.58595878e-07, -3.75918347e-07,  4.10878982e-07, -3.37687908e-07,\n",
      "        3.60029105e-07,  3.02123340e-07,  2.79011402e-07, -2.54352642e-07,\n",
      "       -2.45781905e-07,  2.33739698e-07, -1.94905269e-07,  2.01443527e-07,\n",
      "        1.89420859e-07, -1.63705465e-07,  1.74323560e-07, -1.48534809e-07,\n",
      "        1.61339031e-07,  1.54921281e-07, -1.24542964e-07, -1.13051826e-07,\n",
      "        1.24915601e-07,  1.06364674e-07, -9.21889409e-08,  9.48389172e-08,\n",
      "       -7.24803613e-08,  9.00345185e-08,  7.82110448e-08, -5.95205698e-08,\n",
      "        6.99244609e-08, -5.25872430e-08,  6.57106796e-08, -4.05823180e-08,\n",
      "       -3.50748337e-08,  5.51170700e-08,  4.90976504e-08,  4.63879921e-08,\n",
      "        4.27214211e-08, -3.11912700e-08, -2.73954779e-08,  3.75893485e-08,\n",
      "        3.57966989e-08, -1.91868015e-08, -1.61947913e-08,  2.80944690e-08,\n",
      "        2.61352167e-08,  2.73468626e-08,  2.23722889e-08, -1.12925731e-08,\n",
      "        1.95894110e-08, -9.23669496e-09,  1.52001949e-08,  1.40211416e-08,\n",
      "       -6.17080564e-09, -4.05537781e-09, -5.22404475e-09,  1.00619406e-08,\n",
      "        9.12168829e-09, -1.29077649e-09,  7.83595056e-09, -5.29853279e-11,\n",
      "       -3.90942029e-10,  1.66455949e-09,  9.59621937e-10,  6.87768020e-09,\n",
      "        5.95596683e-09,  4.50869742e-09,  3.78930398e-09,  2.18864860e-09],\n",
      "      dtype=float32), array([[-0.04709334, -0.13218424, -0.16626759, ..., -0.00406804,\n",
      "         0.00335003,  0.00061083],\n",
      "       [-0.02896206,  0.15939853,  0.09496877, ..., -0.01322062,\n",
      "        -0.00235926, -0.00635008],\n",
      "       [ 0.01026586, -0.03083868,  0.09052829, ...,  0.0173142 ,\n",
      "        -0.1288992 ,  0.09354907],\n",
      "       ...,\n",
      "       [-0.01404557, -0.00120251, -0.05371701, ...,  0.03531499,\n",
      "         0.02539061,  0.09071992],\n",
      "       [-0.10893772, -0.18404643, -0.00809508, ..., -0.0208484 ,\n",
      "         0.04059383,  0.00038917],\n",
      "       [-0.00995004, -0.07340627,  0.00230016, ...,  0.08745283,\n",
      "        -0.01698391, -0.08190698]], dtype=float32))\n",
      "(array([ 2.35063339e+02,  2.23949417e-01,  1.95577033e-02,  1.18567813e-02,\n",
      "        6.00359496e-03,  3.06031294e-03,  1.22017623e-03,  4.63629403e-04,\n",
      "        3.76556709e-04,  1.85841069e-04,  1.18184005e-04,  9.20411621e-05,\n",
      "        7.77452951e-05,  6.00083113e-05,  4.16114199e-05, -1.18225535e-05,\n",
      "        1.38684709e-05,  1.26809364e-05,  1.12216348e-05,  8.88085015e-06,\n",
      "        7.65292498e-06,  7.14066209e-06,  6.60772821e-06, -5.65773325e-06,\n",
      "       -4.58044724e-06, -3.93220034e-06,  4.44412353e-06,  3.94646759e-06,\n",
      "        3.41970463e-06,  2.88205501e-06, -2.46929221e-06,  2.31061267e-06,\n",
      "       -2.07809785e-06,  2.15491514e-06,  1.99546207e-06, -1.43130569e-06,\n",
      "        1.57707882e-06, -1.12587441e-06,  1.42937017e-06,  1.29539808e-06,\n",
      "       -9.78305025e-07, -8.77702860e-07,  1.09099483e-06,  1.00759598e-06,\n",
      "        9.51557354e-07,  9.11295615e-07, -6.99988050e-07, -6.14655505e-07,\n",
      "       -5.75535864e-07,  7.92157095e-07,  6.42419309e-07,  6.69244173e-07,\n",
      "       -5.17423530e-07,  5.34901972e-07, -4.57019723e-07,  4.53831518e-07,\n",
      "       -3.68221237e-07,  4.18392460e-07,  3.92743942e-07, -3.18327693e-07,\n",
      "        3.63662366e-07,  3.19983229e-07, -2.63854474e-07, -2.23320981e-07,\n",
      "       -2.05991597e-07,  2.70969281e-07,  2.66812634e-07,  2.20190742e-07,\n",
      "        1.99415851e-07,  1.86115571e-07, -1.58337443e-07,  1.48178671e-07,\n",
      "        1.46049473e-07, -1.24800138e-07,  1.25881627e-07, -1.04026888e-07,\n",
      "       -9.76559562e-08,  1.06196701e-07, -9.07011852e-08,  1.01153937e-07,\n",
      "        8.67013199e-08, -6.79838053e-08,  7.56757146e-08, -6.31100576e-08,\n",
      "        7.10739130e-08,  6.90775863e-08, -4.88447967e-08, -4.33193534e-08,\n",
      "        6.02845276e-08,  5.71580010e-08, -4.01679365e-08,  4.92614234e-08,\n",
      "       -3.07345971e-08, -2.47890828e-08,  4.10258139e-08,  3.69550435e-08,\n",
      "        3.42979547e-08,  2.69358473e-08, -1.83064373e-08,  2.08788880e-08,\n",
      "        1.98449488e-08, -1.31860700e-08, -1.17232579e-08, -1.07123430e-08,\n",
      "       -9.45869072e-09,  1.36390215e-08,  1.53046162e-08,  1.50239927e-08,\n",
      "       -7.87947041e-09, -3.78501852e-09,  1.01013518e-08, -2.04819695e-09,\n",
      "       -1.74853421e-09,  7.23438376e-09,  6.45682929e-09,  5.53410651e-09,\n",
      "        4.40760317e-09,  2.69586620e-09,  6.54409860e-10,  1.67639069e-09],\n",
      "      dtype=float32), array([[-0.04734345,  0.13546777, -0.10514892, ...,  0.00311067,\n",
      "        -0.01819593,  0.000267  ],\n",
      "       [-0.0291391 , -0.16175131, -0.02576475, ..., -0.04439306,\n",
      "         0.01094804, -0.03477162],\n",
      "       [ 0.01052634,  0.02478047, -0.00124173, ..., -0.11283641,\n",
      "         0.01902773, -0.09485369],\n",
      "       ...,\n",
      "       [-0.01663677, -0.00646251, -0.13603872, ..., -0.08134292,\n",
      "        -0.07069205,  0.01735508],\n",
      "       [-0.10980738,  0.1897172 , -0.06355712, ..., -0.00399431,\n",
      "        -0.00263025,  0.01324897],\n",
      "       [-0.01079813,  0.0814576 , -0.04317374, ..., -0.08452565,\n",
      "         0.07845687,  0.20754118]], dtype=float32))\n",
      "(array([ 2.37590164e+02,  1.12131812e-01,  8.13825056e-03,  3.57210473e-03,\n",
      "        5.17281704e-04,  1.58654773e-04,  1.35338851e-04,  6.74277399e-05,\n",
      "        5.28444070e-05,  3.15104953e-05,  2.26933353e-05,  1.48518166e-05,\n",
      "        1.23050868e-05, -8.63319292e-06,  8.92856133e-06,  8.14417763e-06,\n",
      "       -6.36117284e-06, -5.07640834e-06,  6.03273884e-06,  5.17433546e-06,\n",
      "        4.85705186e-06, -3.31446631e-06, -3.07633513e-06,  3.90420473e-06,\n",
      "        3.67941038e-06,  2.98070700e-06,  3.00801344e-06,  2.58647128e-06,\n",
      "       -1.93915912e-06, -1.64379799e-06,  1.93368760e-06, -1.38083089e-06,\n",
      "        1.63962716e-06,  1.58489979e-06,  1.35553694e-06,  1.22761332e-06,\n",
      "       -1.11983297e-06, -1.04331195e-06, -1.00866134e-06,  1.02220440e-06,\n",
      "       -8.30406805e-07,  9.65979552e-07,  8.65719187e-07,  7.53612596e-07,\n",
      "        6.90407433e-07, -6.22319646e-07, -5.78590061e-07,  5.75173431e-07,\n",
      "       -4.88532805e-07,  5.25255246e-07,  4.72133138e-07, -4.04764137e-07,\n",
      "        4.31629047e-07,  4.02686481e-07, -3.57189606e-07, -3.35611702e-07,\n",
      "       -2.75392864e-07, -2.42065028e-07,  3.82723044e-07,  3.17624767e-07,\n",
      "        3.44474472e-07,  2.75879330e-07,  2.37810312e-07, -1.84512132e-07,\n",
      "        2.10280831e-07, -1.72306500e-07,  1.86127124e-07, -1.48403117e-07,\n",
      "        1.81081361e-07,  1.62361673e-07, -1.22329183e-07, -1.13257158e-07,\n",
      "       -8.65657270e-08,  1.31257025e-07,  1.25371571e-07,  1.16660082e-07,\n",
      "        1.08194307e-07,  1.01504469e-07,  8.94516958e-08, -6.26195700e-08,\n",
      "        7.81889398e-08, -5.55160149e-08,  6.91234803e-08, -4.88191176e-08,\n",
      "        5.94502225e-08, -4.38494006e-08, -3.81499916e-08,  5.59225626e-08,\n",
      "        5.20697938e-08,  4.22422488e-08, -3.00280050e-08, -2.63577711e-08,\n",
      "        3.40199726e-08,  3.22519575e-08,  2.90452142e-08,  2.18512195e-08,\n",
      "        1.92750935e-08, -1.75328605e-08, -1.63897678e-08, -1.43392489e-08,\n",
      "       -1.17201182e-08,  1.68420939e-08,  1.40165293e-08, -7.22493887e-09,\n",
      "       -6.36329611e-09,  1.20377841e-08,  1.13197265e-08, -5.12906473e-09,\n",
      "       -3.77198095e-09, -1.99273931e-09, -1.68658154e-09,  9.58029123e-09,\n",
      "        1.14603294e-09, -6.42047041e-11,  8.17057089e-09,  6.53914523e-09,\n",
      "        5.84820503e-09,  3.16354765e-09,  3.99067357e-09,  4.13380041e-09],\n",
      "      dtype=float32), array([[-0.0481495 , -0.12925415,  0.16502374, ...,  0.06137944,\n",
      "         0.01472324,  0.00441242],\n",
      "       [-0.02839237,  0.16341083, -0.08950323, ...,  0.02485236,\n",
      "         0.00036615,  0.06641524],\n",
      "       [ 0.01060547, -0.03041126, -0.08585263, ..., -0.15974648,\n",
      "        -0.02984199, -0.06737924],\n",
      "       ...,\n",
      "       [-0.01835205,  0.00306368,  0.06381689, ..., -0.02024094,\n",
      "        -0.09056593, -0.00074332],\n",
      "       [-0.11021068, -0.17849062,  0.0038365 , ..., -0.00274501,\n",
      "        -0.00344735, -0.01673103],\n",
      "       [-0.01079837, -0.07216255,  0.01158647, ..., -0.00607427,\n",
      "         0.0672038 ,  0.1762129 ]], dtype=float32))\n",
      "(array([ 2.40091690e+02,  9.80173275e-02,  7.67376786e-03,  5.32697013e-04,\n",
      "        1.53393135e-04,  8.35513347e-05,  6.25971588e-05,  3.39494436e-05,\n",
      "        2.80620916e-05,  1.74372890e-05, -9.93860976e-06, -9.04323133e-06,\n",
      "        8.98931739e-06,  7.14540010e-06,  6.78209881e-06, -6.02519412e-06,\n",
      "        5.57381782e-06,  5.08750372e-06, -4.84194834e-06,  4.21128470e-06,\n",
      "       -3.63971571e-06,  3.13847318e-06,  2.76320043e-06,  2.43219370e-06,\n",
      "       -2.14269335e-06, -1.54174654e-06, -1.46274965e-06,  1.74405920e-06,\n",
      "        1.60013201e-06,  1.52469784e-06, -1.20246841e-06,  1.32914840e-06,\n",
      "        1.18179048e-06,  1.06430912e-06, -1.02791046e-06, -9.77345167e-07,\n",
      "       -9.05031982e-07,  9.11052211e-07,  7.41409224e-07, -7.09444294e-07,\n",
      "       -6.87316344e-07,  6.31324724e-07,  6.20580352e-07,  6.06366086e-07,\n",
      "       -4.49485015e-07,  5.40018050e-07,  5.09480856e-07,  4.90467642e-07,\n",
      "       -4.16241221e-07,  4.14904122e-07,  3.85821750e-07, -3.39345121e-07,\n",
      "       -2.91842809e-07, -2.76323760e-07, -2.23417402e-07, -2.32459598e-07,\n",
      "        3.24991703e-07,  2.96269945e-07,  2.80457613e-07,  2.39631390e-07,\n",
      "        2.56585963e-07,  1.87655218e-07,  1.78399461e-07, -1.62075636e-07,\n",
      "       -1.55582214e-07,  1.59532888e-07, -1.42910082e-07,  1.37732798e-07,\n",
      "        1.27486089e-07,  1.19241633e-07, -1.03539861e-07, -9.91648150e-08,\n",
      "       -9.28845623e-08,  1.01019836e-07,  8.96571635e-08, -7.13724759e-08,\n",
      "        8.14982144e-08,  7.26979934e-08, -5.89979123e-08,  6.70530511e-08,\n",
      "       -4.24937063e-08, -4.45377424e-08, -3.79420477e-08,  5.46208874e-08,\n",
      "        5.69255718e-08,  4.84947478e-08,  4.59461553e-08,  4.09470680e-08,\n",
      "        3.97399589e-08, -2.77522787e-08,  2.84845409e-08,  2.47402490e-08,\n",
      "       -2.47476049e-08, -2.21844587e-08, -1.92850358e-08, -1.60476414e-08,\n",
      "        2.15094200e-08, -1.39285810e-08,  1.99543724e-08,  1.76059700e-08,\n",
      "        1.33690623e-08,  1.28715314e-08, -7.14306703e-09, -6.31300301e-09,\n",
      "       -5.60223468e-09, -3.86485688e-09,  1.07712683e-08,  7.30769267e-09,\n",
      "        9.56001855e-09, -1.91335858e-09, -7.10262238e-10, -1.58737368e-09,\n",
      "        1.60866164e-11,  9.61729096e-09,  2.90748092e-09,  3.60406771e-09,\n",
      "        5.53042989e-09,  6.70765832e-10,  1.62781677e-09,  1.41906464e-09],\n",
      "      dtype=float32), array([[-0.0483786 ,  0.12305064, -0.17408618, ..., -0.00487395,\n",
      "        -0.0239808 ,  0.01543787],\n",
      "       [-0.02794132, -0.15852126,  0.0817474 , ..., -0.03779839,\n",
      "        -0.02400155,  0.03492964],\n",
      "       [ 0.01088862,  0.03064788,  0.08681439, ..., -0.10917849,\n",
      "         0.05438413, -0.09778643],\n",
      "       ...,\n",
      "       [-0.01889165,  0.00028336, -0.05278057, ..., -0.04875113,\n",
      "        -0.04211254,  0.01419179],\n",
      "       [-0.11054879,  0.17035519, -0.01625599, ...,  0.00761328,\n",
      "        -0.00212161,  0.00300415],\n",
      "       [-0.01019697,  0.07478201, -0.00769283, ...,  0.06238686,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.00378532,  0.07602531]], dtype=float32))\n",
      "(array([ 2.4366982e+02,  1.2596285e-01,  1.1675949e-02,  8.7011671e-03,\n",
      "        9.6589024e-04,  3.2933219e-04,  1.2492244e-04,  8.4999534e-05,\n",
      "        6.9356138e-05,  3.6826317e-05,  3.1844240e-05,  2.1182548e-05,\n",
      "        1.3411761e-05,  1.1233823e-05, -8.5842003e-06,  8.1389335e-06,\n",
      "       -6.5078102e-06,  6.8092299e-06,  5.7182019e-06,  5.4812713e-06,\n",
      "       -4.1850585e-06,  4.4490853e-06, -3.3143460e-06,  3.6809074e-06,\n",
      "        3.4053562e-06, -2.6582316e-06,  2.6219354e-06,  2.4230610e-06,\n",
      "       -1.8425151e-06, -1.7333334e-06,  2.1186299e-06,  1.7981534e-06,\n",
      "        1.6614183e-06, -1.3228590e-06,  1.3500633e-06,  1.2624365e-06,\n",
      "        1.2612194e-06, -1.0028402e-06, -9.5291239e-07,  1.1395603e-06,\n",
      "        1.0045744e-06, -7.5908014e-07,  8.4109416e-07,  7.6758511e-07,\n",
      "        7.2536733e-07, -5.7562085e-07, -5.5490523e-07,  6.3305350e-07,\n",
      "        5.8474745e-07, -5.2622943e-07, -4.8986630e-07, -4.6010356e-07,\n",
      "        4.8541551e-07,  4.4712456e-07,  3.8482077e-07, -3.4230140e-07,\n",
      "       -3.1547324e-07,  3.4345055e-07,  3.4675298e-07, -2.5076579e-07,\n",
      "        2.7104673e-07, -2.1729041e-07, -1.9323973e-07,  2.3160746e-07,\n",
      "        2.0922489e-07, -1.6080823e-07,  1.8236425e-07, -1.4914929e-07,\n",
      "        1.7225607e-07,  1.6544236e-07,  1.5365744e-07, -1.2492464e-07,\n",
      "       -1.0156839e-07,  1.2107601e-07,  1.1550991e-07,  1.0587254e-07,\n",
      "        9.9951933e-08, -8.8106752e-08,  8.9468941e-08, -7.5164301e-08,\n",
      "        7.3621862e-08,  6.7522038e-08, -6.4093108e-08, -5.5757443e-08,\n",
      "       -5.4270895e-08,  5.4774357e-08,  5.1147005e-08, -4.3131074e-08,\n",
      "        4.6319727e-08, -3.6605375e-08, -3.3040660e-08,  3.9192194e-08,\n",
      "        2.9616565e-08,  3.1461418e-08,  3.2077580e-08, -2.4793104e-08,\n",
      "       -2.3119744e-08,  2.6186727e-08,  2.3802780e-08, -1.5861291e-08,\n",
      "       -1.1749072e-08,  1.8849166e-08, -8.9439212e-09,  1.4333648e-08,\n",
      "        1.3822822e-08, -5.8249578e-09,  1.0581738e-08,  9.5888186e-09,\n",
      "        8.5910115e-09,  7.7794446e-09, -2.6822786e-09, -2.5209661e-09,\n",
      "        5.7120659e-09,  5.0151931e-09, -9.9429487e-10,  3.2816676e-09,\n",
      "        5.7061528e-10,  8.7404123e-10,  1.4689886e-09,  2.2221116e-09],\n",
      "      dtype=float32), array([[-0.05098291,  0.12237202, -0.14387026, ...,  0.00669563,\n",
      "         0.00307953,  0.00713072],\n",
      "       [-0.02753675, -0.16833039,  0.04194738, ..., -0.0282634 ,\n",
      "         0.05483424,  0.04381983],\n",
      "       [ 0.01041179,  0.03206711,  0.00902137, ..., -0.06887825,\n",
      "        -0.00348002,  0.05916335],\n",
      "       ...,\n",
      "       [-0.02168322, -0.00096801, -0.21696633, ...,  0.00942083,\n",
      "        -0.06701594,  0.0337291 ],\n",
      "       [-0.10977418,  0.17352048,  0.1201004 , ...,  0.00574439,\n",
      "        -0.00055142, -0.0073212 ],\n",
      "       [-0.01177819,  0.07587001, -0.05070373, ...,  0.08386429,\n",
      "         0.06719018,  0.01436712]], dtype=float32))\n",
      "(array([ 2.37448395e+02,  8.75513703e-02,  1.41218370e-02,  8.72578938e-03,\n",
      "        6.77812053e-03,  4.81267041e-03,  2.46794894e-04,  1.43063429e-04,\n",
      "        5.50395343e-05,  4.63812321e-05,  3.59949663e-05,  3.20280778e-05,\n",
      "        1.96648998e-05,  1.47806086e-05,  1.27469366e-05,  1.09308994e-05,\n",
      "        8.08866844e-06, -6.70996815e-06,  6.36255254e-06,  6.08570463e-06,\n",
      "       -5.05058733e-06,  5.13562145e-06, -4.22498078e-06,  4.36673236e-06,\n",
      "        3.71736974e-06,  3.86195734e-06, -2.77925596e-06,  2.83694044e-06,\n",
      "       -2.19080403e-06,  2.56413682e-06,  2.44365856e-06, -2.02381034e-06,\n",
      "        2.02026627e-06,  1.95091070e-06,  1.61282821e-06, -1.38409075e-06,\n",
      "        1.29918078e-06, -1.16616309e-06, -1.08325742e-06, -9.93753019e-07,\n",
      "        1.10154235e-06,  1.00641853e-06,  9.40319524e-07, -8.47294586e-07,\n",
      "        7.99186353e-07, -7.21886920e-07,  7.45056923e-07,  6.75220747e-07,\n",
      "       -5.99155669e-07,  5.70721738e-07, -4.64395725e-07,  4.85249871e-07,\n",
      "        3.93929525e-07,  3.70463908e-07, -3.80854715e-07, -3.59380437e-07,\n",
      "       -3.02206644e-07,  3.44828379e-07, -2.78916360e-07,  2.98970548e-07,\n",
      "        2.93926831e-07, -2.20260588e-07, -1.91735765e-07,  2.60513531e-07,\n",
      "        2.28342728e-07,  2.17015824e-07,  2.11098765e-07, -1.67103167e-07,\n",
      "       -1.49836566e-07, -1.35184109e-07, -1.32404679e-07, -1.13226875e-07,\n",
      "        1.57060015e-07,  1.47918797e-07,  1.29602199e-07,  1.17735304e-07,\n",
      "        1.06053520e-07,  8.95306798e-08,  8.47800266e-08, -8.00080002e-08,\n",
      "       -7.50181783e-08, -6.69887754e-08,  8.13943188e-08, -5.74611576e-08,\n",
      "       -5.16838838e-08,  6.54815153e-08,  6.28521235e-08,  5.68788359e-08,\n",
      "       -4.22799928e-08,  4.29055973e-08,  4.26334630e-08,  3.64154715e-08,\n",
      "        3.08752952e-08,  2.89133322e-08, -2.74648588e-08, -2.54387036e-08,\n",
      "       -2.18030838e-08, -1.86241849e-08,  2.27358541e-08,  1.84832629e-08,\n",
      "       -1.28619568e-08, -1.06742863e-08,  1.66595182e-08, -8.28509261e-09,\n",
      "        1.48461341e-08,  1.20077503e-08,  1.03919815e-08, -6.42403375e-09,\n",
      "       -5.08617504e-09,  7.84807774e-09,  7.04046554e-09, -2.31337505e-09,\n",
      "       -3.42107120e-09,  6.00996453e-09,  1.22832175e-10,  3.96319866e-10,\n",
      "        4.04197875e-09,  2.29648300e-09,  2.44731324e-09,  2.62261390e-09],\n",
      "      dtype=float32), array([[-4.80403081e-02,  1.23749807e-01,  1.71172947e-01, ...,\n",
      "        -1.63794272e-02, -2.51361425e-03,  3.79465669e-02],\n",
      "       [-2.89289486e-02, -1.60699368e-01, -3.57737467e-02, ...,\n",
      "         1.66995972e-02,  8.08480382e-02,  4.95359749e-02],\n",
      "       [ 9.89370141e-03,  3.53544690e-02,  2.98137814e-02, ...,\n",
      "         5.66203110e-02,  2.46134792e-02, -1.46204978e-01],\n",
      "       ...,\n",
      "       [-1.70398057e-02,  8.76035119e-05,  1.77331105e-01, ...,\n",
      "         4.20977585e-02,  8.86899605e-02, -5.19761294e-02],\n",
      "       [-1.10481665e-01,  1.77046627e-01, -6.03906140e-02, ...,\n",
      "         5.28539624e-03,  1.18561350e-02, -9.45148757e-04],\n",
      "       [-1.06777428e-02,  7.06108287e-02,  1.00775912e-01, ...,\n",
      "        -3.90461944e-02, -7.75866359e-02, -8.97852108e-02]], dtype=float32))\n",
      "(array([ 2.37744232e+02,  2.62697935e+00,  1.24696159e+00,  9.19130802e-01,\n",
      "        1.91812262e-01,  6.65344819e-02,  3.28350142e-02,  3.25368829e-02,\n",
      "        1.81614589e-02,  1.54669126e-02,  1.32869845e-02,  1.02592995e-02,\n",
      "        8.38744454e-03,  6.82345266e-03,  6.19887514e-03,  3.79597419e-03,\n",
      "        3.03551066e-03,  1.84349576e-03,  1.43341848e-03,  9.94004309e-04,\n",
      "        9.04773711e-04,  7.90028309e-04,  6.38356607e-04,  5.78566978e-04,\n",
      "        5.03868214e-04,  3.96082643e-04,  3.79779376e-04,  3.60442238e-04,\n",
      "        2.40379406e-04,  2.14855594e-04,  1.50987165e-04,  1.37099152e-04,\n",
      "        1.16974821e-04,  9.36966826e-05,  8.35078463e-05,  6.86930798e-05,\n",
      "        6.27009140e-05,  4.14889364e-05,  3.88674998e-05,  3.50285263e-05,\n",
      "        3.32545133e-05,  2.51741603e-05,  2.18080404e-05,  1.70839612e-05,\n",
      "        1.45909207e-05,  1.24180206e-05,  9.68412860e-06,  9.10229846e-06,\n",
      "        6.49879712e-06,  5.21653010e-06, -4.44972420e-06, -3.50886262e-06,\n",
      "        3.77752349e-06, -2.65693870e-06,  3.05926301e-06,  2.65303333e-06,\n",
      "        2.30027035e-06,  2.07873313e-06, -1.81505686e-06, -1.42507054e-06,\n",
      "        1.58700914e-06,  1.18326750e-06,  1.07840413e-06, -9.88926331e-07,\n",
      "       -8.52016171e-07,  8.74205284e-07,  6.23994481e-07,  6.60022238e-07,\n",
      "       -6.88003865e-07, -6.02618172e-07, -5.38157224e-07, -4.94625851e-07,\n",
      "        5.46369904e-07,  4.48821510e-07, -4.14782022e-07, -3.78810796e-07,\n",
      "        3.53927049e-07, -3.39674131e-07, -3.16103723e-07,  2.79681444e-07,\n",
      "        2.63782226e-07, -2.63016204e-07,  2.17072952e-07, -1.94957465e-07,\n",
      "       -1.92815733e-07,  1.80915265e-07, -1.63268723e-07,  1.46438595e-07,\n",
      "        1.26426286e-07,  1.09946704e-07, -1.11180697e-07, -1.03792644e-07,\n",
      "       -9.73646834e-08,  8.95988919e-08,  6.98489444e-08, -7.82086005e-08,\n",
      "       -6.63469351e-08, -6.21107148e-08,  6.40297202e-08,  6.04103363e-08,\n",
      "       -4.32887290e-08,  5.44387824e-08, -3.27739862e-08,  3.50846747e-08,\n",
      "       -2.69408833e-08, -2.26384174e-08,  2.98295895e-08,  2.85772455e-08,\n",
      "        2.19279279e-08,  1.90002378e-08, -6.63344490e-09,  1.62750950e-08,\n",
      "       -1.93501593e-09,  1.00163300e-08, -1.39081324e-08, -1.07186491e-08,\n",
      "       -3.68577124e-09,  2.43520226e-09,  7.11879800e-09,  6.17735019e-09],\n",
      "      dtype=float32), array([[-0.03354196,  0.10477547, -0.13784483, ..., -0.00997901,\n",
      "         0.0606455 , -0.02218588],\n",
      "       [-0.04256763, -0.09025995,  0.14006783, ...,  0.03907005,\n",
      "         0.06484081, -0.06271067],\n",
      "       [ 0.0049477 , -0.01968166, -0.0486127 , ..., -0.17654702,\n",
      "         0.06385805,  0.08984137],\n",
      "       ...,\n",
      "       [ 0.00314343,  0.10986755,  0.00287198, ...,  0.14006586,\n",
      "        -0.11577506,  0.13262767],\n",
      "       [-0.13760139, -0.08572324, -0.20902185, ...,  0.02326867,\n",
      "        -0.01033939,  0.01261588],\n",
      "       [-0.02352607, -0.06329082, -0.10914894, ..., -0.0094212 ,\n",
      "         0.01546733,  0.05545412]], dtype=float32))\n",
      "(array([ 2.69706329e+02,  4.88498300e-01,  3.06204259e-01,  3.06910723e-02,\n",
      "        2.32319981e-02,  1.41955642e-02,  1.17664859e-02,  8.31338391e-03,\n",
      "        5.33500221e-03,  3.31987208e-03,  2.58918270e-03,  1.75680371e-03,\n",
      "        1.67371659e-03,  1.22786383e-03,  7.08743872e-04,  5.41916699e-04,\n",
      "        3.61411745e-04,  2.26514676e-04,  2.16501416e-04,  1.96860012e-04,\n",
      "        1.29829437e-04,  1.12273439e-04,  9.43355335e-05,  8.53869569e-05,\n",
      "        6.52417948e-05,  4.61301497e-05,  4.39074101e-05,  3.99028613e-05,\n",
      "        2.66288116e-05,  2.54993647e-05,  2.06931836e-05,  1.93228916e-05,\n",
      "        1.47861110e-05,  1.41109358e-05,  1.18570297e-05,  9.20710590e-06,\n",
      "       -7.28456598e-06,  7.80550909e-06, -6.48300374e-06,  7.39476900e-06,\n",
      "        6.58760791e-06,  6.18527883e-06,  5.24957022e-06, -3.74774163e-06,\n",
      "        4.37912468e-06,  4.06962363e-06,  3.79473045e-06,  3.62099127e-06,\n",
      "       -3.04549212e-06, -2.74778677e-06,  2.62126696e-06, -2.04962271e-06,\n",
      "        1.93149185e-06, -1.86835553e-06, -1.58522982e-06, -1.32697062e-06,\n",
      "       -1.30303454e-06,  1.78037567e-06,  1.67599740e-06,  1.59694264e-06,\n",
      "        1.54453153e-06,  1.37268000e-06, -1.08021061e-06,  1.23348718e-06,\n",
      "       -9.41977873e-07,  1.13091221e-06, -7.47076626e-07,  1.06525727e-06,\n",
      "        9.51085042e-07,  7.68785242e-07,  6.81997960e-07, -5.50836546e-07,\n",
      "       -4.89597085e-07,  5.39986615e-07, -4.12491829e-07, -3.46801272e-07,\n",
      "       -3.34884078e-07,  4.82691235e-07,  4.05745396e-07,  3.48278178e-07,\n",
      "        3.25796464e-07,  3.14618234e-07, -2.56459032e-07,  2.61934929e-07,\n",
      "        2.34303911e-07, -2.12482263e-07, -1.93973491e-07, -1.65885666e-07,\n",
      "       -1.42531050e-07,  1.82783580e-07,  1.67877658e-07,  1.58065049e-07,\n",
      "       -1.15819134e-07, -1.10173900e-07,  1.20753811e-07,  1.12949920e-07,\n",
      "        1.06434570e-07, -7.62542598e-08, -5.98785945e-08,  6.51770549e-08,\n",
      "        5.66144536e-08,  5.06425586e-08,  4.63750283e-08, -5.19741974e-08,\n",
      "       -4.61182807e-08, -3.56881458e-08,  3.96144380e-08, -2.86201569e-08,\n",
      "       -1.97533154e-08, -1.27564173e-08, -8.45567616e-09, -9.58907087e-09,\n",
      "        2.26598864e-08,  2.00121555e-08,  1.32091182e-08,  1.20331238e-08,\n",
      "        4.28808405e-10,  2.35542719e-09,  6.87654556e-09,  4.94445684e-09],\n",
      "      dtype=float32), array([[-0.03066174,  0.10773805,  0.09095779, ..., -0.01601534,\n",
      "         0.02573909, -0.00572623],\n",
      "       [-0.04649996, -0.09075137, -0.14103843, ..., -0.01494073,\n",
      "         0.09453742, -0.00873219],\n",
      "       [ 0.00091697,  0.00673883,  0.07945505, ..., -0.18366897,\n",
      "        -0.16923632,  0.1639338 ],\n",
      "       ...,\n",
      "       [ 0.01198275,  0.07443038, -0.0160855 , ..., -0.14919867,\n",
      "         0.06986721, -0.05680879],\n",
      "       [-0.15452656,  0.07301205,  0.08410823, ..., -0.0066248 ,\n",
      "         0.02385109, -0.00187871],\n",
      "       [-0.03239396,  0.00963353,  0.07057352, ...,  0.01224557,\n",
      "         0.00763059, -0.03576651]], dtype=float32))\n",
      "(array([ 2.47705505e+02,  6.44778192e-01,  4.79978561e-01,  5.46693504e-02,\n",
      "        3.55807059e-02,  1.89052988e-02,  1.41776958e-02,  8.63402709e-03,\n",
      "        4.45083017e-03,  3.78180714e-03,  3.21485195e-03,  2.20917002e-03,\n",
      "        2.02381494e-03,  1.14861899e-03,  7.94354943e-04,  6.54102361e-04,\n",
      "        4.97219269e-04,  4.15956252e-04,  3.64833599e-04,  2.96946149e-04,\n",
      "        2.47290736e-04,  2.03006814e-04,  1.76813192e-04,  1.61258402e-04,\n",
      "        1.16122224e-04,  1.09327120e-04,  7.77341265e-05,  7.05910206e-05,\n",
      "        6.81876045e-05,  6.14244345e-05,  4.87131947e-05,  4.25872604e-05,\n",
      "        3.45161570e-05,  2.94289239e-05,  2.68345957e-05,  2.20969378e-05,\n",
      "        2.05863525e-05,  1.81857686e-05,  1.51975191e-05,  1.17814707e-05,\n",
      "        9.99382610e-06,  9.74758404e-06,  9.18919613e-06,  7.72565909e-06,\n",
      "        7.06982337e-06,  5.56485702e-06, -4.39048199e-06, -3.95081770e-06,\n",
      "        4.40073609e-06,  3.80219080e-06,  3.90380592e-06, -2.66769143e-06,\n",
      "        3.02135641e-06, -1.98309749e-06,  2.51676602e-06,  2.33825131e-06,\n",
      "       -1.59279762e-06,  1.71721729e-06,  1.52390021e-06,  1.39507006e-06,\n",
      "        1.22363940e-06,  1.08418249e-06, -1.11798693e-06, -1.00722525e-06,\n",
      "       -9.10121230e-07,  8.27462600e-07,  8.44655176e-07, -7.80175810e-07,\n",
      "       -7.71865473e-07, -6.18670413e-07, -5.39101336e-07, -5.12849965e-07,\n",
      "        6.49551964e-07,  6.18388583e-07,  5.76379364e-07,  5.53774612e-07,\n",
      "        4.77730339e-07, -4.20319623e-07,  3.84026862e-07,  3.61374958e-07,\n",
      "       -3.36183746e-07, -3.22141062e-07,  2.83141674e-07,  2.46716894e-07,\n",
      "       -2.82967051e-07, -2.59635101e-07, -2.37390992e-07, -2.04198855e-07,\n",
      "        1.91884496e-07, -1.70172925e-07, -1.64395715e-07,  1.48285039e-07,\n",
      "        1.36261207e-07,  1.14504964e-07, -1.28389360e-07,  9.50801606e-08,\n",
      "       -1.06950651e-07, -1.05415687e-07, -8.11269700e-08,  8.28298852e-08,\n",
      "        7.29620808e-08, -5.92410245e-08,  5.72957823e-08, -4.57580001e-08,\n",
      "       -4.07539744e-08,  4.38610570e-08,  3.65854369e-08,  3.20720552e-08,\n",
      "       -2.83885875e-08,  2.51835885e-08, -1.92389020e-08,  1.94316776e-08,\n",
      "       -1.14225545e-08, -1.05840883e-08,  1.14085790e-08,  1.11291296e-08,\n",
      "        7.34198791e-09, -4.94416152e-09,  1.55369362e-09, -9.91986604e-10],\n",
      "      dtype=float32), array([[ 0.02832599,  0.09623689,  0.10885105, ..., -0.01500468,\n",
      "        -0.03482511,  0.00142193],\n",
      "       [ 0.0488483 , -0.08870776, -0.15897892, ...,  0.01659226,\n",
      "         0.08316822,  0.0016854 ],\n",
      "       [ 0.00253295,  0.01575768,  0.07569076, ..., -0.07821728,\n",
      "        -0.11866456, -0.10849126],\n",
      "       ...,\n",
      "       [-0.01556836,  0.03812741,  0.02397428, ...,  0.21631537,\n",
      "        -0.15064926, -0.01486875],\n",
      "       [ 0.1549264 ,  0.07390216,  0.08678845, ..., -0.01590851,\n",
      "        -0.00250925,  0.01718457],\n",
      "       [ 0.03913562, -0.02642206,  0.11787369, ...,  0.04290646,\n",
      "         0.02204387, -0.00784832]], dtype=float32))\n",
      "(array([ 3.74643341e+02,  6.46476805e-01,  3.01884383e-01,  6.65582120e-02,\n",
      "        3.81123535e-02,  1.81397256e-02,  1.47797167e-02,  1.06828166e-02,\n",
      "        6.42734300e-03,  5.56218717e-03,  5.33059612e-03,  3.00025521e-03,\n",
      "        1.13800145e-03,  9.00403771e-04,  7.55718967e-04,  5.97151171e-04,\n",
      "        5.07457473e-04,  4.24278755e-04,  2.83277943e-04,  2.57807551e-04,\n",
      "        2.17200170e-04,  2.00867362e-04,  1.56394803e-04,  1.31677501e-04,\n",
      "        1.16271411e-04,  9.09489245e-05,  8.62690576e-05,  7.87120734e-05,\n",
      "        6.52366361e-05,  6.06198155e-05,  4.78135189e-05,  3.40616862e-05,\n",
      "        3.14403223e-05,  2.51247548e-05, -1.21107705e-05,  1.69165596e-05,\n",
      "        1.63648656e-05,  1.44335345e-05,  1.33933618e-05,  1.22658466e-05,\n",
      "        1.03807879e-05,  1.01013302e-05, -7.68241807e-06,  7.78049071e-06,\n",
      "        7.22281766e-06,  6.79815594e-06, -3.97140366e-06,  5.23807785e-06,\n",
      "        4.61204263e-06,  4.49447134e-06, -3.38745917e-06, -3.08044264e-06,\n",
      "        3.96591486e-06,  3.60941476e-06, -2.85362034e-06, -2.37229483e-06,\n",
      "        3.67990037e-06,  3.10400287e-06,  2.93001585e-06,  2.35950915e-06,\n",
      "       -1.81605867e-06,  1.96213114e-06,  1.70245107e-06, -1.46757554e-06,\n",
      "        1.53171800e-06, -1.21304004e-06,  1.40687314e-06, -1.02707372e-06,\n",
      "        1.25558233e-06,  1.03766797e-06, -9.00116618e-07,  9.70687665e-07,\n",
      "        9.09092137e-07, -7.25343511e-07, -6.92429467e-07, -5.59148020e-07,\n",
      "        6.81704478e-07,  6.46475144e-07,  6.04322111e-07, -5.09697031e-07,\n",
      "        5.28039948e-07,  5.00711963e-07, -4.20922987e-07, -4.00430054e-07,\n",
      "        3.45509960e-07,  3.22872665e-07, -3.01202789e-07, -2.87952588e-07,\n",
      "        3.01325713e-07, -2.39974383e-07,  2.57361478e-07,  2.33660174e-07,\n",
      "       -1.72975149e-07,  1.78804626e-07, -1.41802346e-07, -1.19202447e-07,\n",
      "       -1.14896736e-07,  1.26705700e-07,  1.19596621e-07, -7.39401216e-08,\n",
      "       -5.76888759e-08,  9.51374943e-08,  7.95917998e-08,  6.83650327e-08,\n",
      "        5.01636990e-08,  3.85618328e-08, -3.11015818e-08, -2.62102429e-08,\n",
      "       -2.02639505e-08,  2.45842529e-08,  2.66419509e-08, -1.87889331e-08,\n",
      "        1.99841619e-08,  1.24474004e-08,  8.93793306e-09,  4.22362811e-09,\n",
      "       -1.00423980e-08, -7.21780058e-09, -4.64626515e-09,  1.41537448e-09],\n",
      "      dtype=float32), array([[-0.04068007, -0.05945222,  0.08543333, ..., -0.00755811,\n",
      "        -0.00162639, -0.0251161 ],\n",
      "       [-0.05166046,  0.06130769, -0.16532026, ..., -0.00216746,\n",
      "        -0.00238878,  0.01958654],\n",
      "       [-0.00371108, -0.01004866,  0.0780982 , ..., -0.11152562,\n",
      "         0.00105466, -0.02466482],\n",
      "       ...,\n",
      "       [ 0.0205676 , -0.01637416,  0.03979358, ...,  0.0243598 ,\n",
      "         0.10148457, -0.00182201],\n",
      "       [-0.16602288, -0.06792671,  0.08136745, ..., -0.01473988,\n",
      "        -0.00403163, -0.00506036],\n",
      "       [-0.04213712,  0.02640886,  0.08151174, ..., -0.01394307,\n",
      "        -0.0102944 , -0.02758009]], dtype=float32))\n",
      "(array([ 4.30418365e+02,  3.23948562e-01,  1.91075832e-01,  8.69715810e-02,\n",
      "        4.54762578e-02,  3.69166695e-02,  2.78241970e-02,  1.20342793e-02,\n",
      "        9.40685160e-03,  5.34224370e-03,  3.10272002e-03,  2.60022935e-03,\n",
      "        1.88700971e-03,  1.35723350e-03,  9.61319311e-04,  7.43737444e-04,\n",
      "        6.45543449e-04,  5.15600143e-04,  4.28710686e-04,  3.64247913e-04,\n",
      "        2.71215627e-04,  2.27225843e-04,  1.84637436e-04,  1.76232163e-04,\n",
      "        1.41223194e-04,  1.26543033e-04,  1.20590907e-04,  9.54517745e-05,\n",
      "        8.02132563e-05,  6.06846006e-05,  5.45283328e-05,  5.26660660e-05,\n",
      "        4.22895500e-05,  3.44009022e-05,  3.07897426e-05,  2.84282214e-05,\n",
      "        2.39418350e-05,  1.96173260e-05,  1.60080781e-05, -1.01626711e-05,\n",
      "        1.35112741e-05,  1.19249644e-05,  1.05201616e-05,  9.75019248e-06,\n",
      "        9.89707951e-06,  8.32194019e-06,  7.77002788e-06, -6.91272908e-06,\n",
      "       -5.63851472e-06,  7.17972262e-06, -5.03208730e-06,  5.90471018e-06,\n",
      "        5.38940412e-06,  4.12141299e-06,  3.90800415e-06,  3.30156195e-06,\n",
      "       -3.19672904e-06, -2.95142604e-06, -2.40541704e-06,  3.18429238e-06,\n",
      "        2.78449443e-06,  2.42902593e-06, -1.81768758e-06,  2.08408323e-06,\n",
      "        1.87081378e-06,  1.59286355e-06, -1.41741896e-06, -1.25673841e-06,\n",
      "       -1.14576335e-06, -1.02508488e-06,  1.18897492e-06,  1.28427007e-06,\n",
      "       -8.47525826e-07,  1.03747880e-06,  9.24989251e-07,  8.19814034e-07,\n",
      "        7.43165458e-07, -6.69664757e-07, -5.96367784e-07,  6.12515919e-07,\n",
      "       -5.21767504e-07,  4.95456618e-07, -4.53549006e-07, -3.40437850e-07,\n",
      "       -3.01141682e-07,  4.02974621e-07,  3.75892085e-07,  3.55605266e-07,\n",
      "        2.81944295e-07, -2.27093167e-07, -2.08338022e-07,  1.85232821e-07,\n",
      "        1.73839922e-07, -1.64077420e-07, -1.53509816e-07,  1.32012175e-07,\n",
      "       -1.34546710e-07,  1.05407764e-07, -9.61559792e-08, -6.79655088e-08,\n",
      "        8.27445490e-08,  7.25621163e-08, -5.34859694e-08, -4.39807657e-08,\n",
      "        5.84477817e-08,  4.52577176e-08,  4.03883327e-08,  3.67443818e-08,\n",
      "       -3.12053032e-08, -2.70928293e-08,  1.93115461e-08,  1.68190386e-08,\n",
      "       -1.66145888e-08,  1.11112470e-08, -1.33245432e-08,  5.44638246e-09,\n",
      "        4.32118286e-10, -8.00781130e-09, -2.33739650e-09, -3.36221007e-09],\n",
      "      dtype=float32), array([[-0.04548644, -0.03094264,  0.10845549, ...,  0.00708004,\n",
      "         0.01864691,  0.03070481],\n",
      "       [-0.05213827, -0.05507714, -0.18826576, ..., -0.01612127,\n",
      "         0.05590259,  0.02063628],\n",
      "       [-0.00314266,  0.00498861,  0.05399498, ...,  0.0129869 ,\n",
      "        -0.15994582, -0.12064008],\n",
      "       ...,\n",
      "       [ 0.017551  ,  0.02008754,  0.06834209, ...,  0.0016672 ,\n",
      "        -0.00104989,  0.02840335],\n",
      "       [-0.16558999, -0.0331032 ,  0.09946474, ..., -0.02515539,\n",
      "         0.01216972,  0.00252697],\n",
      "       [-0.04276313,  0.01219683,  0.03645296, ..., -0.02592249,\n",
      "        -0.00660834,  0.04684382]], dtype=float32))\n",
      "(array([ 4.14308075e+02,  4.39077944e-01,  2.51161575e-01,  5.76427802e-02,\n",
      "        3.07407565e-02,  1.74376648e-02,  1.15611171e-02,  7.97608402e-03,\n",
      "        5.41308569e-03,  4.17748094e-03,  3.08257970e-03,  1.62719015e-03,\n",
      "        1.45654380e-03,  1.08126574e-03,  8.00747250e-04,  7.13783607e-04,\n",
      "        4.60429699e-04,  3.24086403e-04,  2.73631740e-04,  1.76771631e-04,\n",
      "        1.46730177e-04,  1.30021566e-04,  1.23993203e-04,  1.09646004e-04,\n",
      "        1.06824111e-04,  8.51972945e-05,  7.10684108e-05,  6.02830551e-05,\n",
      "        5.33157581e-05,  4.44938341e-05,  3.22720953e-05,  2.96902799e-05,\n",
      "        2.55023115e-05,  2.27469118e-05,  1.97173249e-05,  1.71671782e-05,\n",
      "       -1.08984632e-05,  1.55326197e-05,  1.20393443e-05,  1.15651237e-05,\n",
      "        1.07705036e-05,  9.77412310e-06, -7.64794004e-06, -6.28743874e-06,\n",
      "        8.26521500e-06,  7.79296897e-06,  6.19211278e-06, -4.85964529e-06,\n",
      "        5.82978964e-06,  4.80866038e-06,  4.55367899e-06,  4.28986732e-06,\n",
      "       -3.46321394e-06, -3.23312997e-06, -3.08513563e-06,  3.66303721e-06,\n",
      "        3.18821208e-06,  2.89896411e-06, -2.34273739e-06,  2.43955060e-06,\n",
      "        2.28793419e-06,  2.02880051e-06, -1.64179926e-06,  1.72855630e-06,\n",
      "       -1.39264330e-06,  1.56514557e-06,  1.32617572e-06, -1.19438664e-06,\n",
      "       -1.00113584e-06,  1.12667783e-06,  1.09308883e-06, -8.08476955e-07,\n",
      "        8.40386065e-07,  8.00675878e-07, -7.11132088e-07, -6.65539517e-07,\n",
      "        6.42799080e-07, -6.11133657e-07, -4.52039785e-07, -3.85694022e-07,\n",
      "        5.55317911e-07,  5.08086373e-07,  4.92524691e-07,  4.48926727e-07,\n",
      "        3.31727705e-07, -3.22577534e-07, -2.48736029e-07, -2.43304783e-07,\n",
      "       -1.92442926e-07,  2.93045588e-07,  2.46485570e-07,  2.31826590e-07,\n",
      "        2.09058925e-07, -1.48666231e-07,  1.41928766e-07, -1.14996048e-07,\n",
      "        1.14652160e-07,  1.03867933e-07,  8.24145800e-08, -8.79748114e-08,\n",
      "       -6.81999097e-08,  6.55434675e-08,  5.61040814e-08, -5.91388876e-08,\n",
      "       -4.58739997e-08,  4.51997444e-08, -3.65556510e-08,  3.36306272e-08,\n",
      "       -2.61458091e-08,  2.48766696e-08, -2.21336496e-08,  2.23989503e-08,\n",
      "       -1.30476216e-08,  1.71746084e-08, -8.37285974e-09, -2.30355379e-09,\n",
      "       -4.30367547e-10,  7.11787074e-09,  5.97851235e-09,  3.80643694e-09],\n",
      "      dtype=float32), array([[-4.1201416e-02, -9.4809497e-05, -1.5509695e-01, ...,\n",
      "         4.9073394e-02, -1.9113192e-02, -3.1183779e-04],\n",
      "       [-5.5569533e-02, -8.3681121e-03,  1.9210738e-01, ...,\n",
      "         1.2543951e-02, -7.5344900e-03,  4.2935116e-03],\n",
      "       [-3.7669388e-03,  9.3647428e-03, -5.7342395e-02, ...,\n",
      "        -1.1831476e-01,  5.3956462e-03,  1.0308481e-01],\n",
      "       ...,\n",
      "       [ 2.1560442e-02,  4.4699959e-03, -5.5145826e-02, ...,\n",
      "        -3.9381724e-02, -8.2706004e-02, -3.7805565e-02],\n",
      "       [-1.6392089e-01, -2.4056351e-02, -7.3192306e-02, ...,\n",
      "         6.1199558e-03, -2.2479789e-02,  1.0156803e-02],\n",
      "       [-4.2854127e-02,  6.8748616e-02, -1.0747688e-01, ...,\n",
      "         2.9729100e-02,  1.6586265e-02,  1.2565869e-02]], dtype=float32))\n",
      "(array([ 6.50489746e+02,  9.49263453e-01,  2.01989532e-01,  9.76267755e-02,\n",
      "        4.38212715e-02,  2.40114667e-02,  1.85519811e-02,  1.00279171e-02,\n",
      "        8.82171188e-03,  7.17765186e-03,  3.59535008e-03,  2.58793961e-03,\n",
      "        1.49282359e-03,  1.10860006e-03,  7.87225727e-04,  6.85959239e-04,\n",
      "        5.96714206e-04,  4.70228231e-04,  4.22850659e-04,  3.72492184e-04,\n",
      "        3.39995400e-04,  2.38495384e-04,  2.04093376e-04,  1.56852853e-04,\n",
      "        1.29387801e-04,  1.24465063e-04,  1.12366550e-04,  9.38224766e-05,\n",
      "        7.64379802e-05,  6.29380738e-05,  5.88115472e-05,  4.84883567e-05,\n",
      "        3.90371897e-05,  3.70767921e-05,  3.55349111e-05,  3.07394585e-05,\n",
      "        2.83360496e-05,  2.37716140e-05, -1.81783034e-05,  1.91177423e-05,\n",
      "       -1.33259346e-05, -1.14310069e-05,  1.56722581e-05,  1.43365660e-05,\n",
      "        1.12327052e-05,  1.07523783e-05, -8.73782574e-06,  9.39833080e-06,\n",
      "        8.42624559e-06,  8.06498156e-06, -5.50824552e-06,  7.53767199e-06,\n",
      "        6.51460687e-06,  5.85311591e-06, -4.57011492e-06,  4.88440583e-06,\n",
      "       -3.14423664e-06, -3.35621712e-06, -2.73253954e-06,  3.89906472e-06,\n",
      "        3.55868747e-06,  3.23078734e-06,  2.81853158e-06,  2.52760628e-06,\n",
      "       -2.15376076e-06, -1.62099332e-06,  1.86209149e-06,  1.78203027e-06,\n",
      "       -1.51132679e-06,  1.50851088e-06, -1.24237101e-06,  1.32429000e-06,\n",
      "        1.26379291e-06, -1.01415799e-06,  1.13248552e-06,  1.15243131e-06,\n",
      "       -9.14021427e-07,  9.41889425e-07,  7.49024423e-07, -7.72809130e-07,\n",
      "       -6.47352465e-07,  6.14623275e-07,  5.09477275e-07, -5.55605425e-07,\n",
      "       -4.49814962e-07, -3.36243943e-07,  4.20872738e-07,  3.63631841e-07,\n",
      "        2.67753506e-07, -2.65012204e-07, -2.55183267e-07,  2.23120281e-07,\n",
      "        2.12041854e-07, -1.71472522e-07,  1.71686509e-07, -1.61206827e-07,\n",
      "       -1.56093847e-07,  1.11865255e-07, -1.18394851e-07, -7.76068489e-08,\n",
      "        9.28609154e-08,  8.09296452e-08,  7.68764679e-08,  6.19870661e-08,\n",
      "       -6.26060768e-08, -4.43713120e-08,  3.96824760e-08, -3.63851385e-08,\n",
      "       -3.19304014e-08,  2.96872926e-08, -2.58098751e-08,  2.50976111e-08,\n",
      "       -1.45931800e-08, -1.28286421e-08,  1.29030546e-08,  9.37021127e-09,\n",
      "        6.97453784e-09,  2.01341988e-09, -2.59785549e-09, -1.89624250e-09],\n",
      "      dtype=float32), array([[-0.0546036 ,  0.14822322,  0.12384079, ..., -0.00198836,\n",
      "        -0.03209967,  0.0007635 ],\n",
      "       [-0.06539921,  0.04091558, -0.16735256, ..., -0.0048698 ,\n",
      "         0.01541593, -0.00659621],\n",
      "       [-0.00071804, -0.01200077,  0.04381016, ..., -0.07503915,\n",
      "         0.07421132,  0.1108518 ],\n",
      "       ...,\n",
      "       [ 0.0163664 ,  0.03245386,  0.08390673, ...,  0.00598243,\n",
      "         0.06834892,  0.07094342],\n",
      "       [-0.16270034,  0.05546769,  0.04550214, ..., -0.01348186,\n",
      "        -0.0088277 , -0.00773365],\n",
      "       [-0.03949794, -0.00056424,  0.07039268, ..., -0.01432071,\n",
      "        -0.0034064 ,  0.02506302]], dtype=float32))\n",
      "(array([ 7.84675293e+02,  1.69839883e+00,  1.97274923e-01,  1.69076458e-01,\n",
      "        9.24131200e-02,  3.22975852e-02,  3.02893165e-02,  1.87953897e-02,\n",
      "        1.01506896e-02,  9.23891459e-03,  5.95953502e-03,  4.88987193e-03,\n",
      "        3.65227205e-03,  2.90298020e-03,  2.23747897e-03,  1.90632604e-03,\n",
      "        1.33837119e-03,  1.07289257e-03,  8.37813946e-04,  6.33484044e-04,\n",
      "        5.82591514e-04,  4.83096781e-04,  3.57921788e-04,  2.87402887e-04,\n",
      "        2.73347337e-04,  2.25686992e-04,  1.78789880e-04,  1.66615369e-04,\n",
      "        1.43828700e-04,  1.28336120e-04,  1.05628387e-04,  9.67764863e-05,\n",
      "        1.02084952e-04,  6.53904281e-05,  5.60169501e-05,  4.88057085e-05,\n",
      "        4.62206372e-05,  3.96173236e-05,  3.38015707e-05,  2.97601509e-05,\n",
      "       -1.82491422e-05, -1.78284863e-05,  2.35246516e-05,  2.15428900e-05,\n",
      "        1.81446885e-05,  1.61419266e-05, -1.25411416e-05,  1.37169072e-05,\n",
      "       -1.10915944e-05,  1.21104604e-05, -9.27508245e-06,  1.14760869e-05,\n",
      "        1.03354760e-05, -8.78556602e-06,  9.37999721e-06,  7.54306529e-06,\n",
      "        7.08978951e-06,  6.70446479e-06, -5.60687886e-06, -4.85312785e-06,\n",
      "        5.69943450e-06, -3.68605788e-06,  4.29950751e-06,  4.12038389e-06,\n",
      "        3.59114483e-06,  2.79166079e-06, -2.77862182e-06, -2.71009390e-06,\n",
      "       -2.09419181e-06,  2.40248869e-06, -1.68311362e-06, -1.41907935e-06,\n",
      "        1.78083974e-06,  1.55212490e-06,  1.65152142e-06, -1.33255548e-06,\n",
      "        1.08596453e-06, -9.16656404e-07,  1.06375876e-06, -8.78835579e-07,\n",
      "       -6.67912275e-07,  8.76841796e-07,  7.57991870e-07,  6.58500994e-07,\n",
      "        5.49550464e-07, -5.08933852e-07,  3.69062889e-07, -3.68807292e-07,\n",
      "        3.04520938e-07, -3.32319757e-07, -2.58420499e-07,  2.21489842e-07,\n",
      "        1.95685800e-07,  1.79095906e-07, -2.09579198e-07, -1.82878509e-07,\n",
      "       -1.73619156e-07,  1.59806959e-07, -1.55949948e-07, -1.11701794e-07,\n",
      "        9.89230458e-08,  7.84446570e-08,  6.63683082e-08, -8.57474731e-08,\n",
      "       -6.89758082e-08, -5.24437915e-08,  4.01636910e-08, -2.98085858e-08,\n",
      "        3.10146149e-08, -1.78517663e-08,  2.21369980e-08,  1.99844266e-08,\n",
      "       -1.05596198e-08, -3.71087583e-09,  1.24495747e-08,  9.43202494e-09,\n",
      "       -2.59607308e-10,  1.74872028e-09,  3.99094402e-09,  6.03382455e-09],\n",
      "      dtype=float32), array([[ 6.01526909e-02, -2.00700298e-01, -1.60806239e-01, ...,\n",
      "         4.37535383e-02,  6.21677097e-03,  5.83140505e-03],\n",
      "       [ 7.46732801e-02, -8.83033779e-03, -2.06122950e-01, ...,\n",
      "        -2.64226589e-02,  1.23108542e-02, -5.79635194e-03],\n",
      "       [ 1.64167024e-04, -1.54131502e-02,  2.63568070e-02, ...,\n",
      "        -2.12554261e-01,  3.03529873e-02,  3.72603610e-02],\n",
      "       ...,\n",
      "       [-1.36519559e-02, -4.00685659e-03, -3.83676663e-02, ...,\n",
      "        -3.44293639e-02, -1.52156884e-02,  9.77266356e-02],\n",
      "       [ 1.66524678e-01, -1.00249033e-02, -1.49102313e-02, ...,\n",
      "        -5.67196286e-04,  1.45874021e-03,  1.09712582e-03],\n",
      "       [ 3.96245345e-02, -1.22191785e-02, -4.12913002e-02, ...,\n",
      "        -7.29737477e-03,  7.92429131e-03, -1.92844868e-02]], dtype=float32))\n",
      "(array([ 8.59251282e+02,  2.86937654e-01,  9.29481685e-02,  7.63715208e-02,\n",
      "        3.64828706e-02,  2.13919003e-02,  1.54459979e-02,  7.12007796e-03,\n",
      "        4.20215679e-03,  2.98225950e-03,  1.51567615e-03,  1.33586430e-03,\n",
      "        9.67071042e-04,  8.10218335e-04,  6.21810555e-04,  4.71816136e-04,\n",
      "        3.72883689e-04,  3.05262598e-04,  2.51137011e-04,  2.32207327e-04,\n",
      "        1.63286692e-04,  1.29589636e-04,  1.04386352e-04,  1.00965888e-04,\n",
      "        7.97262255e-05,  7.81951167e-05,  6.35670513e-05,  5.86809037e-05,\n",
      "        3.90111782e-05, -2.62421581e-05,  3.48823996e-05, -2.15570835e-05,\n",
      "        3.06926122e-05,  2.83162790e-05,  2.63045167e-05,  2.22547096e-05,\n",
      "        2.10269809e-05, -1.80417101e-05,  1.89245347e-05,  1.73263779e-05,\n",
      "       -1.28800184e-05,  1.59299543e-05,  1.21969633e-05,  1.20232216e-05,\n",
      "       -9.50223875e-06, -7.45382476e-06,  1.01100877e-05,  9.64823266e-06,\n",
      "        8.58131534e-06, -6.02746832e-06, -5.48634353e-06,  6.63671244e-06,\n",
      "        6.35834658e-06,  5.95225038e-06, -4.81402503e-06,  5.61201887e-06,\n",
      "        5.07655159e-06,  4.15958129e-06, -3.90148216e-06, -3.52542361e-06,\n",
      "       -3.27442763e-06, -2.51151414e-06,  3.86839383e-06,  3.33437924e-06,\n",
      "        2.99747239e-06,  2.64334153e-06,  2.46934906e-06, -1.81929181e-06,\n",
      "        2.02046408e-06,  1.94615677e-06, -1.56802457e-06,  1.71862109e-06,\n",
      "       -1.41118721e-06, -1.16017111e-06,  1.44411365e-06,  1.24982034e-06,\n",
      "        1.16298975e-06,  9.99804683e-07, -8.15891553e-07,  8.67188874e-07,\n",
      "        7.85015686e-07, -6.53622806e-07,  7.12219048e-07, -5.29983311e-07,\n",
      "       -4.05279422e-07,  5.19262755e-07,  5.24852510e-07, -3.42622400e-07,\n",
      "       -2.57260837e-07,  4.25668560e-07,  3.31401736e-07,  3.11923685e-07,\n",
      "        2.90238660e-07,  2.33760218e-07,  1.76054030e-07, -1.39125802e-07,\n",
      "        1.37732940e-07,  1.25668862e-07, -1.07989237e-07,  1.03377225e-07,\n",
      "       -8.59434479e-08,  6.53504131e-08,  5.96042753e-08, -6.89149502e-08,\n",
      "       -5.38599885e-08,  4.01257978e-08,  3.06616244e-08, -2.64004107e-08,\n",
      "        2.03116457e-08,  2.43657947e-08, -2.22987566e-08,  1.60666573e-08,\n",
      "       -2.01092458e-08,  8.01244138e-09, -1.18386057e-08, -1.07910809e-08,\n",
      "        2.92599633e-09,  1.00884967e-09, -4.08478718e-09, -2.76177881e-09],\n",
      "      dtype=float32), array([[-7.0429459e-02, -3.7360076e-02,  1.9485527e-01, ...,\n",
      "         1.3090302e-02,  2.4183666e-02,  1.4993259e-02],\n",
      "       [-7.9961069e-02, -1.0287257e-01, -8.5961744e-02, ...,\n",
      "        -2.0842209e-02, -2.4594564e-02,  1.4419381e-02],\n",
      "       [-5.3608068e-04,  3.0047147e-02, -5.0121150e-03, ...,\n",
      "         9.5952423e-03,  8.9522444e-02,  2.4088676e-01],\n",
      "       ...,\n",
      "       [ 1.2113136e-02,  4.8985608e-02,  7.0124410e-02, ...,\n",
      "         1.1113557e-02,  9.4750777e-02, -2.1018829e-02],\n",
      "       [-1.6834715e-01,  7.7072168e-03, -4.9836677e-02, ...,\n",
      "         3.7184579e-03, -8.8615583e-05,  2.5098721e-05],\n",
      "       [-4.0283136e-02,  2.7788065e-02,  4.8794795e-02, ...,\n",
      "        -4.6847366e-02,  6.4648301e-03,  2.2225924e-02]], dtype=float32))\n",
      "(array([ 8.60052673e+02,  3.13619375e-01,  1.72489598e-01,  1.23905942e-01,\n",
      "        6.96857125e-02,  1.75981130e-02,  1.38079589e-02,  1.11697996e-02,\n",
      "        8.66745599e-03,  6.25516940e-03,  3.94651480e-03,  2.24280590e-03,\n",
      "        1.61576271e-03,  1.22303690e-03,  9.49733832e-04,  8.75729718e-04,\n",
      "        6.35346514e-04,  4.19754680e-04,  3.75779200e-04,  2.66820221e-04,\n",
      "        1.58746829e-04,  1.34938397e-04,  1.22608995e-04,  1.16144525e-04,\n",
      "        7.41657059e-05,  6.45397085e-05,  5.29191675e-05,  3.74060801e-05,\n",
      "        3.17762642e-05, -2.62250105e-05,  2.91944052e-05, -2.01168841e-05,\n",
      "       -1.62438228e-05,  2.43148861e-05,  2.23396037e-05,  2.02754709e-05,\n",
      "        1.89443217e-05,  1.72265409e-05, -1.51533177e-05,  1.46525563e-05,\n",
      "       -1.22229058e-05, -1.02322811e-05,  1.26295763e-05,  1.18818207e-05,\n",
      "        1.09492230e-05, -8.26484575e-06, -5.73555917e-06,  8.60613818e-06,\n",
      "        8.53853817e-06,  8.27442636e-06,  8.05398122e-06,  6.47366778e-06,\n",
      "       -4.26602173e-06, -3.51787139e-06,  6.02206455e-06,  5.89531555e-06,\n",
      "        5.25912401e-06,  4.67526388e-06,  4.05430637e-06,  3.94772314e-06,\n",
      "       -2.75878210e-06,  2.96541452e-06, -2.51527149e-06,  2.43864042e-06,\n",
      "       -2.00193813e-06, -1.89762375e-06,  2.34324261e-06, -1.49042251e-06,\n",
      "        2.05746460e-06,  1.93115875e-06,  1.68665701e-06, -1.24252392e-06,\n",
      "        1.38846883e-06,  1.30206718e-06, -9.60947204e-07, -8.54884206e-07,\n",
      "        1.06916912e-06,  8.75339254e-07,  7.82119287e-07, -6.16404691e-07,\n",
      "        7.20545586e-07,  5.64965205e-07, -4.77910248e-07, -3.83748898e-07,\n",
      "       -3.06962335e-07,  4.81410552e-07,  4.30377384e-07,  3.80543071e-07,\n",
      "        3.90988106e-07,  2.85788474e-07, -1.99761573e-07,  2.11086217e-07,\n",
      "        1.66468141e-07, -1.51229656e-07,  1.50143805e-07, -1.27080881e-07,\n",
      "        1.17449815e-07, -1.03998261e-07, -7.93848116e-08,  8.15058883e-08,\n",
      "        7.42302646e-08,  6.22469400e-08, -6.54937082e-08, -5.39048770e-08,\n",
      "        5.21916590e-08, -4.00420888e-08,  4.16742338e-08, -3.13193773e-08,\n",
      "        3.45744731e-08,  2.59551243e-08, -1.89435827e-08,  1.25844233e-08,\n",
      "       -1.05525313e-08,  7.66663000e-09,  5.10225950e-09,  2.45077048e-09,\n",
      "        7.19432069e-10, -6.96568847e-09, -4.96607999e-09, -4.79031526e-09],\n",
      "      dtype=float32), array([[-6.59051239e-02, -1.71815053e-01, -3.29607278e-01, ...,\n",
      "         7.63705140e-03,  1.99877694e-02,  2.90006748e-03],\n",
      "       [-7.58237615e-02, -1.15741707e-01,  3.96933779e-02, ...,\n",
      "        -5.03786933e-03,  1.42009975e-02,  1.66569538e-02],\n",
      "       [-1.22922496e-03,  1.97369643e-02,  2.36279308e-03, ...,\n",
      "         6.86292872e-02,  1.90990433e-01,  1.59762278e-01],\n",
      "       ...,\n",
      "       [ 1.21506555e-02, -1.92028452e-02,  6.36574402e-02, ...,\n",
      "         5.27243614e-02,  1.06092557e-01, -8.18669870e-02],\n",
      "       [-1.70500323e-01, -4.98953322e-03, -2.09402220e-04, ...,\n",
      "         4.24340786e-03, -6.95614493e-04, -5.30535867e-03],\n",
      "       [-3.96777727e-02, -1.28532927e-02,  4.77239154e-02, ...,\n",
      "        -3.55963781e-02,  6.91515431e-02,  3.20179090e-02]], dtype=float32))\n",
      "(array([ 8.56865295e+02,  3.40410173e-01,  2.41326690e-01,  1.12282798e-01,\n",
      "        8.59907493e-02,  3.90833132e-02,  1.94727033e-02,  1.29041513e-02,\n",
      "        9.29854531e-03,  5.58736874e-03,  2.54437281e-03,  2.24019028e-03,\n",
      "        2.09040591e-03,  1.65662519e-03,  1.13652484e-03,  8.79601110e-04,\n",
      "        6.03594584e-04,  4.82741540e-04,  3.79770936e-04,  3.28713737e-04,\n",
      "        3.06779752e-04,  2.24931995e-04,  1.70010971e-04,  1.46309671e-04,\n",
      "        1.21001758e-04,  9.98277901e-05,  7.23129269e-05,  6.69851288e-05,\n",
      "        5.97054241e-05,  5.25378782e-05,  3.95654388e-05, -3.05126250e-05,\n",
      "        3.63920954e-05, -2.12141695e-05,  2.96773869e-05,  2.51235706e-05,\n",
      "        2.40132249e-05,  2.30722944e-05,  2.24089617e-05, -1.52289258e-05,\n",
      "       -1.43242605e-05,  1.97791651e-05,  1.85650370e-05,  1.39858748e-05,\n",
      "       -1.29208884e-05, -1.18785947e-05,  1.32584064e-05,  1.16510537e-05,\n",
      "       -9.15805504e-06,  9.74788873e-06,  9.28760164e-06, -7.27934639e-06,\n",
      "        8.01557053e-06,  6.87298780e-06, -5.72338968e-06, -4.86701629e-06,\n",
      "        5.73766056e-06,  5.60890385e-06,  4.77646518e-06,  4.31538365e-06,\n",
      "       -3.10497944e-06,  3.74804495e-06,  3.27976318e-06, -2.51493361e-06,\n",
      "       -1.90605431e-06,  2.78123548e-06,  2.61032415e-06,  2.52065661e-06,\n",
      "        2.33988089e-06, -1.79097856e-06,  2.16341414e-06,  1.99043529e-06,\n",
      "       -1.19523418e-06, -1.01927390e-06,  1.60471347e-06,  1.27021224e-06,\n",
      "        1.22170286e-06,  1.08056020e-06, -7.07376103e-07, -6.54156736e-07,\n",
      "        8.03169655e-07,  7.33044487e-07,  6.18973218e-07, -5.33114246e-07,\n",
      "        5.49133176e-07, -3.86448875e-07,  3.79879424e-07,  3.56506405e-07,\n",
      "       -2.92826769e-07,  3.05877222e-07,  2.78283125e-07, -2.47782253e-07,\n",
      "       -2.02937116e-07, -1.98131374e-07,  2.43286735e-07,  2.04534871e-07,\n",
      "        1.44408077e-07,  1.22730242e-07,  1.12081537e-07, -1.20022648e-07,\n",
      "       -1.01928059e-07, -7.88034882e-08,  7.31303089e-08, -6.24144008e-08,\n",
      "        5.76251082e-08,  4.95503336e-08, -4.41913102e-08,  3.83664371e-08,\n",
      "       -2.92428854e-08, -2.34971562e-08, -1.79589943e-08,  1.97548715e-08,\n",
      "        1.48246881e-08,  9.47382706e-09, -8.64124239e-09,  4.52977744e-09,\n",
      "        9.41319800e-10, -5.60692870e-09, -2.10205009e-09, -3.45080498e-09],\n",
      "      dtype=float32), array([[-0.0667867 ,  0.24392185, -0.27120343, ..., -0.00744103,\n",
      "         0.02189141, -0.00131743],\n",
      "       [-0.07649066,  0.09813862,  0.08632063, ..., -0.01269507,\n",
      "        -0.00930812, -0.00820038],\n",
      "       [-0.00117565, -0.01346279, -0.00777783, ...,  0.0390599 ,\n",
      "        -0.03240781, -0.184907  ],\n",
      "       ...,\n",
      "       [ 0.0118458 , -0.00486279,  0.09101326, ..., -0.07476139,\n",
      "         0.07848882,  0.05639008],\n",
      "       [-0.16999552,  0.00634674,  0.00404111, ...,  0.00966455,\n",
      "         0.00330272,  0.00983708],\n",
      "       [-0.03982769,  0.00202899,  0.08622089, ...,  0.02457478,\n",
      "         0.03511994,  0.00256775]], dtype=float32))\n",
      "(array([ 8.34970215e+02,  3.61985832e-01,  2.73207605e-01,  9.47952792e-02,\n",
      "        5.32540344e-02,  2.80242786e-02,  1.16572930e-02,  9.37903114e-03,\n",
      "        6.66278135e-03,  4.35830094e-03,  1.93114078e-03,  1.36413996e-03,\n",
      "        1.23932958e-03,  9.61122045e-04,  6.72306458e-04,  5.76972903e-04,\n",
      "        4.33119392e-04,  3.37205303e-04,  3.05465132e-04,  2.20555696e-04,\n",
      "        1.63953329e-04,  1.36028058e-04,  1.15785959e-04,  9.90266926e-05,\n",
      "        7.97910252e-05,  6.35590914e-05,  5.43943133e-05,  4.93142070e-05,\n",
      "        4.51165433e-05,  4.01464640e-05,  3.63743820e-05, -3.19851206e-05,\n",
      "       -2.74452632e-05, -1.93388059e-05,  2.51077527e-05,  2.37432450e-05,\n",
      "        2.22616472e-05,  2.00308205e-05, -1.38021196e-05,  1.80625466e-05,\n",
      "        1.72622385e-05,  1.45929134e-05, -1.20696131e-05,  1.27864996e-05,\n",
      "        1.30142580e-05, -9.50179310e-06,  1.05590398e-05,  1.04292249e-05,\n",
      "        9.69878329e-06,  8.27671101e-06,  7.07127901e-06, -6.55984604e-06,\n",
      "       -6.06472759e-06, -5.14329122e-06,  6.17495652e-06,  5.41865847e-06,\n",
      "        4.58406430e-06,  4.06257141e-06, -3.20693266e-06, -2.89585432e-06,\n",
      "        3.49446532e-06,  3.29134809e-06,  3.12693419e-06, -2.26817133e-06,\n",
      "        2.56469093e-06, -1.97707664e-06,  2.22399922e-06,  2.08930828e-06,\n",
      "       -1.56318220e-06,  1.67715632e-06,  1.32296691e-06, -1.32325829e-06,\n",
      "       -1.30181013e-06,  1.20150082e-06,  1.10468841e-06,  1.02137722e-06,\n",
      "       -8.57087116e-07,  9.29818100e-07, -7.45103307e-07,  7.21094807e-07,\n",
      "       -5.92476454e-07,  6.02686498e-07, -5.09695440e-07,  5.03379965e-07,\n",
      "       -4.32461121e-07, -4.14872119e-07,  4.40619118e-07,  3.76420758e-07,\n",
      "       -3.17739989e-07,  3.05075076e-07,  2.76111450e-07, -2.07979284e-07,\n",
      "       -1.76969394e-07,  2.13169898e-07,  2.02201520e-07,  1.69604675e-07,\n",
      "        1.35575760e-07, -1.06852056e-07,  1.04880279e-07, -7.97180917e-08,\n",
      "        8.21434156e-08, -6.94237485e-08, -4.92999241e-08, -4.11871781e-08,\n",
      "        6.09252808e-08,  5.16737693e-08,  4.44719106e-08, -2.91196578e-08,\n",
      "        2.90002191e-08, -2.28579875e-08, -1.75382180e-08,  1.86282723e-08,\n",
      "        1.56208824e-08,  1.20447572e-08, -4.91841812e-09, -3.74721854e-09,\n",
      "        5.35835154e-09,  3.92191479e-09,  9.33386146e-10,  1.88465576e-09],\n",
      "      dtype=float32), array([[-6.89148158e-02,  3.38744700e-01, -1.73092306e-01, ...,\n",
      "        -8.74404609e-03,  1.48582123e-02,  1.74842554e-03],\n",
      "       [-7.80219585e-02,  8.84738863e-02,  1.07045084e-01, ...,\n",
      "        -5.50035853e-03,  1.62440212e-03,  2.00014515e-03],\n",
      "       [-9.52805975e-04,  1.20104778e-04, -1.21992882e-02, ...,\n",
      "         1.47331789e-01,  1.09441496e-01, -1.83577403e-01],\n",
      "       ...,\n",
      "       [ 1.18162353e-02, -1.55354394e-02,  5.28934151e-02, ...,\n",
      "         2.74508987e-02,  3.44845541e-02, -6.43516630e-02],\n",
      "       [-1.68349966e-01,  5.07506356e-02, -3.68862972e-02, ...,\n",
      "         1.25322281e-03, -3.18886619e-03,  1.27136963e-03],\n",
      "       [-4.06219661e-02, -3.02147027e-02,  4.90502752e-02, ...,\n",
      "        -5.09421015e-03, -1.72868501e-02,  1.32394200e-02]], dtype=float32))\n",
      "(array([ 8.17881042e+02,  1.23497164e+00,  2.43842900e-01,  1.01615600e-01,\n",
      "        6.97487071e-02,  2.70926207e-02,  2.26593725e-02,  1.07441777e-02,\n",
      "        9.17315390e-03,  7.24090263e-03,  5.02633676e-03,  2.71133659e-03,\n",
      "        2.08225683e-03,  1.80503784e-03,  8.66405317e-04,  8.21199035e-04,\n",
      "        6.28997164e-04,  6.07404625e-04,  4.09630564e-04,  3.77385702e-04,\n",
      "        3.04051966e-04,  2.55560386e-04,  2.20246293e-04,  1.79099137e-04,\n",
      "        1.38414864e-04,  1.05690116e-04,  7.92979845e-05,  6.89277076e-05,\n",
      "        5.83337787e-05,  4.54173423e-05,  3.38803438e-05, -2.82408037e-05,\n",
      "        3.07419759e-05,  2.83061236e-05,  2.54262450e-05,  2.30613368e-05,\n",
      "       -1.93444102e-05,  2.06674376e-05, -1.57906561e-05, -1.31662664e-05,\n",
      "        1.65160855e-05,  1.40685670e-05,  1.36590534e-05,  1.33339281e-05,\n",
      "       -1.14518925e-05, -1.05424515e-05, -7.87658610e-06,  1.00349689e-05,\n",
      "        9.29472299e-06,  8.68775624e-06,  7.32013496e-06,  7.84545682e-06,\n",
      "       -5.83747396e-06,  6.59380112e-06, -4.70513714e-06, -4.30293994e-06,\n",
      "        4.67126529e-06,  4.28374278e-06, -3.23588097e-06,  3.59010073e-06,\n",
      "        3.34822153e-06,  3.05608114e-06,  2.76282890e-06, -2.50214885e-06,\n",
      "       -2.17613342e-06,  2.39416590e-06,  2.29858279e-06, -1.74760487e-06,\n",
      "        1.93989445e-06, -1.40214865e-06, -1.31863362e-06,  1.63137452e-06,\n",
      "        1.53292524e-06,  1.25371037e-06,  1.17208106e-06, -9.01235239e-07,\n",
      "        8.86837881e-07, -8.32358069e-07, -7.08574760e-07,  6.45717307e-07,\n",
      "        6.13064799e-07, -5.98788688e-07,  4.96970301e-07,  3.69764649e-07,\n",
      "       -4.87284012e-07, -3.77096654e-07, -4.11401686e-07,  3.27343997e-07,\n",
      "       -2.84304406e-07,  2.78176969e-07, -2.22299832e-07,  2.16809667e-07,\n",
      "        1.97859876e-07,  1.69028965e-07, -1.45943716e-07, -1.06535836e-07,\n",
      "        1.20506257e-07,  1.03504647e-07,  9.30239139e-08, -9.04219064e-08,\n",
      "       -7.68935919e-08, -5.44602834e-08,  7.88640406e-08,  7.27903569e-08,\n",
      "        5.55212551e-08, -4.08852401e-08,  4.63812455e-08,  3.55925316e-08,\n",
      "       -3.26307443e-08, -2.61762541e-08, -1.72263590e-08,  1.82258777e-08,\n",
      "       -1.09410170e-08, -4.97160046e-09, -4.44584547e-09,  1.33543256e-08,\n",
      "        8.97677399e-09,  7.68899255e-09,  9.66985714e-10,  3.68273101e-09],\n",
      "      dtype=float32), array([[-0.06656114,  0.14489022, -0.3307645 , ..., -0.01935774,\n",
      "        -0.0131006 , -0.00166795],\n",
      "       [-0.07493901,  0.08803041,  0.15538736, ..., -0.00755059,\n",
      "        -0.01001463, -0.01258731],\n",
      "       [-0.0009176 , -0.01673005, -0.00660886, ...,  0.13048886,\n",
      "        -0.10745882,  0.30914217],\n",
      "       ...,\n",
      "       [ 0.01226274,  0.03135186,  0.02127175, ...,  0.05140144,\n",
      "         0.02362499, -0.01726745],\n",
      "       [-0.16842993, -0.01140326, -0.04227241, ...,  0.00191482,\n",
      "         0.00729396, -0.00152543],\n",
      "       [-0.04109009,  0.04808621, -0.0273838 , ..., -0.00953494,\n",
      "         0.00067073, -0.01913694]], dtype=float32))\n",
      "(array([ 7.88249878e+02,  2.77881593e-01,  1.31327733e-01,  5.22322021e-02,\n",
      "        2.68551726e-02,  1.50361406e-02,  8.38836096e-03,  5.17655583e-03,\n",
      "        2.81058438e-03,  1.74606603e-03,  1.57417473e-03,  1.30153878e-03,\n",
      "        8.96674581e-04,  6.00998465e-04,  5.52747631e-04,  5.10627171e-04,\n",
      "        2.45628587e-04,  2.21187700e-04,  1.53500863e-04,  1.15539173e-04,\n",
      "        1.00679943e-04,  9.20180391e-05,  6.75280971e-05,  5.89846568e-05,\n",
      "        5.27107040e-05,  3.63567960e-05, -2.34423533e-05,  2.87499570e-05,\n",
      "       -1.89718012e-05,  2.45984102e-05, -1.71223946e-05,  2.07673675e-05,\n",
      "        1.95913963e-05,  1.82711046e-05,  1.65881629e-05, -1.27865378e-05,\n",
      "       -1.19653077e-05,  1.43075813e-05,  1.36109347e-05,  1.22879092e-05,\n",
      "        1.15806424e-05, -9.83735845e-06,  9.85992938e-06, -7.61749789e-06,\n",
      "        8.85391910e-06,  7.65683762e-06,  7.59030218e-06, -5.98177485e-06,\n",
      "        6.54763062e-06, -5.50842469e-06,  5.41839790e-06, -5.10356313e-06,\n",
      "       -3.83539145e-06, -3.24941288e-06,  5.11120834e-06,  4.88870728e-06,\n",
      "        4.81472034e-06,  4.28116164e-06,  4.09078302e-06,  3.10163887e-06,\n",
      "        2.83412169e-06, -2.21013102e-06,  2.32687535e-06, -2.17522779e-06,\n",
      "       -1.97244913e-06, -1.50205358e-06,  1.79901554e-06,  1.72862963e-06,\n",
      "        1.48979950e-06,  1.26586042e-06, -1.19193055e-06, -1.05752576e-06,\n",
      "        1.18748937e-06, -8.79837216e-07, -7.16216732e-07,  9.90124818e-07,\n",
      "        9.07319759e-07,  8.19727916e-07,  7.54423922e-07,  6.89429328e-07,\n",
      "        5.80292578e-07,  5.48955597e-07, -4.24329897e-07,  4.59159708e-07,\n",
      "       -3.78087378e-07,  3.76846714e-07, -3.03183469e-07, -2.17669225e-07,\n",
      "       -1.81043632e-07,  3.17180735e-07,  2.68277546e-07,  2.45200340e-07,\n",
      "        2.25370130e-07,  1.96486269e-07,  1.57856704e-07,  1.28843965e-07,\n",
      "        1.17653478e-07, -1.11772259e-07, -9.40042568e-08,  8.94913867e-08,\n",
      "        6.24009431e-08, -7.16164053e-08, -6.03153296e-08,  5.61859501e-08,\n",
      "       -3.73623621e-08, -3.07907655e-08,  3.79745551e-08,  2.97532488e-08,\n",
      "        2.50112855e-08, -1.93708676e-08, -1.85543367e-08, -1.30320235e-08,\n",
      "        1.69415273e-08,  1.56044013e-08,  1.15286749e-08,  1.10267200e-08,\n",
      "       -3.91206756e-09,  3.36551431e-09, -1.57066637e-09,  7.18984261e-10],\n",
      "      dtype=float32), array([[-0.0616202 ,  0.30794773,  0.05966241, ..., -0.01550531,\n",
      "        -0.00320024,  0.00873944],\n",
      "       [-0.07226399,  0.12824996, -0.08585618, ...,  0.00099298,\n",
      "         0.00610198,  0.00609951],\n",
      "       [-0.00059463,  0.00787576,  0.04166637, ..., -0.11139877,\n",
      "         0.17438969, -0.20722593],\n",
      "       ...,\n",
      "       [ 0.01323366,  0.03124415,  0.01329595, ..., -0.07251871,\n",
      "         0.01502661, -0.04974414],\n",
      "       [-0.16588256,  0.11470623,  0.05927346, ..., -0.00037789,\n",
      "         0.00596345, -0.01074423],\n",
      "       [-0.03914457, -0.00180933, -0.00633587, ...,  0.00088553,\n",
      "        -0.02779891,  0.01244319]], dtype=float32))\n",
      "(array([ 7.81775696e+02,  5.81000626e-01,  2.67739981e-01,  9.03749615e-02,\n",
      "        4.59795892e-02,  1.97664890e-02,  1.43078920e-02,  7.38651212e-03,\n",
      "        6.32714015e-03,  3.92035674e-03,  3.55864479e-03,  2.19066744e-03,\n",
      "        1.76800380e-03,  9.93975322e-04,  7.50601990e-04,  5.62353118e-04,\n",
      "        4.95967688e-04,  4.03339218e-04,  2.92584038e-04,  2.13763647e-04,\n",
      "        2.00790048e-04,  1.81575582e-04,  1.19973993e-04,  9.41471517e-05,\n",
      "        7.85458469e-05,  7.04093254e-05,  5.82926150e-05,  4.71652711e-05,\n",
      "        4.48190185e-05,  4.09480308e-05,  3.39732214e-05,  2.86993600e-05,\n",
      "        2.59886001e-05, -2.20315869e-05, -2.02675783e-05, -1.69430423e-05,\n",
      "        2.23089046e-05,  2.17444540e-05,  2.03160034e-05,  1.70661679e-05,\n",
      "       -1.28469701e-05,  1.41352002e-05,  1.35034788e-05,  1.26316827e-05,\n",
      "       -9.83076825e-06, -9.24335836e-06,  1.09184184e-05,  1.05400495e-05,\n",
      "        9.00729265e-06,  8.25735151e-06, -6.03290209e-06, -5.02319517e-06,\n",
      "        6.92283538e-06,  6.08317123e-06,  5.73917941e-06,  5.15399779e-06,\n",
      "        4.29591364e-06,  3.75532022e-06, -3.41732425e-06, -3.26590680e-06,\n",
      "        3.27226576e-06, -2.89042896e-06,  2.86101999e-06,  2.68059080e-06,\n",
      "        2.30750652e-06, -2.36306073e-06, -2.19653316e-06,  1.99328110e-06,\n",
      "       -1.42734780e-06,  1.83820362e-06,  1.64393771e-06, -1.23463565e-06,\n",
      "        1.37225072e-06,  1.25426675e-06,  1.19553499e-06, -8.86317537e-07,\n",
      "       -7.34700166e-07, -6.78117715e-07,  8.44205545e-07,  8.86149905e-07,\n",
      "        7.37836217e-07, -5.91639832e-07,  6.18136369e-07,  5.86167232e-07,\n",
      "       -4.42789457e-07, -4.22341685e-07,  4.91865933e-07,  4.13233181e-07,\n",
      "       -3.58024380e-07, -3.01358114e-07,  3.45911417e-07,  3.04850460e-07,\n",
      "        2.34273600e-07, -2.39239199e-07, -1.97179929e-07,  1.82615437e-07,\n",
      "        1.58249819e-07, -9.81043300e-08,  1.40321717e-07, -7.69267032e-08,\n",
      "       -6.83440007e-08,  1.13006202e-07,  9.97996352e-08,  6.79067966e-08,\n",
      "       -5.65602001e-08,  4.41979324e-08,  3.78446217e-08, -2.84255215e-08,\n",
      "       -3.06742720e-08,  2.34720119e-08, -1.25000108e-08, -1.02729345e-08,\n",
      "       -5.74127634e-09,  2.12039968e-08,  1.64521765e-08,  1.35790490e-08,\n",
      "       -1.63822556e-09,  6.40456133e-10,  2.56400901e-09,  8.89898910e-09],\n",
      "      dtype=float32), array([[-0.05727483,  0.24059787, -0.2689023 , ...,  0.0233345 ,\n",
      "        -0.03460931,  0.01130961],\n",
      "       [-0.06858606,  0.06768683, -0.06443653, ..., -0.01700267,\n",
      "        -0.02183029, -0.00891675],\n",
      "       [-0.00096556, -0.0170165 , -0.01802598, ...,  0.13017051,\n",
      "         0.02876867, -0.06193751],\n",
      "       ...,\n",
      "       [ 0.01340012,  0.00744997, -0.07526227, ..., -0.07273398,\n",
      "         0.07123276, -0.07713937],\n",
      "       [-0.16703755, -0.00946876, -0.13481519, ..., -0.00997815,\n",
      "        -0.0152628 ,  0.0202547 ],\n",
      "       [-0.03832245,  0.0055203 , -0.00189636, ...,  0.01147294,\n",
      "         0.02703279, -0.05451322]], dtype=float32))\n",
      "(array([ 7.14168396e+02,  1.32490531e-01,  8.71207491e-02,  5.40108420e-02,\n",
      "        2.99491491e-02,  2.00553164e-02,  8.25095922e-03,  7.32617499e-03,\n",
      "        5.25545469e-03,  3.41310888e-03,  2.16310727e-03,  1.84076035e-03,\n",
      "        1.17791444e-03,  7.78612157e-04,  7.37738679e-04,  5.86950860e-04,\n",
      "        4.22223296e-04,  3.64971173e-04,  2.85061658e-04,  2.40474183e-04,\n",
      "        2.12279090e-04,  1.50763022e-04,  1.38718489e-04,  9.91149645e-05,\n",
      "        8.97608552e-05,  5.84348854e-05,  5.16259715e-05,  4.92017098e-05,\n",
      "        4.37451854e-05,  4.04550447e-05,  3.25741130e-05,  2.69212469e-05,\n",
      "        2.25077692e-05, -1.80541701e-05,  1.89534803e-05,  1.83426109e-05,\n",
      "       -1.23932250e-05,  1.53047258e-05,  1.51019649e-05,  1.43643911e-05,\n",
      "       -1.17472546e-05,  1.26462892e-05,  1.24595708e-05, -9.82454094e-06,\n",
      "       -8.93424203e-06,  1.00010839e-05,  9.37164168e-06, -7.61924184e-06,\n",
      "        7.62034688e-06,  6.75910132e-06,  6.35247989e-06,  5.63601270e-06,\n",
      "       -4.72188958e-06,  5.29534736e-06,  4.92922891e-06, -3.91191907e-06,\n",
      "       -3.56361488e-06, -3.12155498e-06,  3.76207345e-06,  3.54727740e-06,\n",
      "        3.31695787e-06, -2.80014319e-06,  2.83086661e-06, -2.38423399e-06,\n",
      "       -1.80387326e-06, -1.52757400e-06,  2.44030184e-06,  2.19909248e-06,\n",
      "        2.05542392e-06,  1.74558704e-06,  1.49286802e-06, -1.22697725e-06,\n",
      "       -9.67416099e-07,  1.16883461e-06,  1.13705096e-06,  9.96299036e-07,\n",
      "        9.44825899e-07,  8.57860869e-07, -7.05083835e-07, -6.30116062e-07,\n",
      "        6.79458878e-07, -4.43540728e-07, -3.88432028e-07,  5.11106464e-07,\n",
      "        4.60543589e-07,  4.33037940e-07, -3.10105975e-07, -2.71670814e-07,\n",
      "        3.48400363e-07,  3.36130540e-07,  3.10435809e-07, -2.35021389e-07,\n",
      "       -2.21745097e-07,  2.38058504e-07,  1.93310754e-07, -1.52693715e-07,\n",
      "        1.63721751e-07,  1.36027467e-07, -1.07287121e-07,  1.20103877e-07,\n",
      "       -8.42106473e-08, -6.69315625e-08,  9.69365317e-08,  7.87895189e-08,\n",
      "       -5.07706872e-08,  5.95309686e-08,  5.39513891e-08,  4.78761315e-08,\n",
      "       -3.50942067e-08, -3.04795549e-08, -2.25049614e-08,  2.06613855e-08,\n",
      "        1.87259346e-08, -1.19007897e-08,  1.02489555e-08, -7.60007168e-09,\n",
      "       -2.56837773e-09, -1.94282701e-09,  4.58180693e-09,  3.51351304e-09],\n",
      "      dtype=float32), array([[-0.05588764,  0.22266212,  0.19221723, ..., -0.01947737,\n",
      "         0.00764646,  0.00292786],\n",
      "       [-0.06416048, -0.01859843, -0.01590756, ..., -0.02969033,\n",
      "         0.00651638,  0.01984654],\n",
      "       [-0.00044044,  0.01490032, -0.02000272, ...,  0.18459672,\n",
      "        -0.20204474, -0.06576114],\n",
      "       ...,\n",
      "       [ 0.01403384, -0.00164706,  0.1122273 , ...,  0.04303741,\n",
      "         0.05317767,  0.03192992],\n",
      "       [-0.16544762,  0.12754588, -0.06845657, ..., -0.0173941 ,\n",
      "         0.00373589,  0.00095436],\n",
      "       [-0.03925359,  0.05956907,  0.08191396, ..., -0.0283391 ,\n",
      "        -0.03482416, -0.02545464]], dtype=float32))\n",
      "(array([ 7.42781921e+02,  2.48766422e-01,  1.11667588e-01,  7.20197409e-02,\n",
      "        2.92643458e-02,  1.95485223e-02,  1.65776927e-02,  8.08809232e-03,\n",
      "        5.23437746e-03,  3.54877231e-03,  3.29834991e-03,  2.55304924e-03,\n",
      "        1.62230211e-03,  1.12777669e-03,  8.65079113e-04,  7.56008143e-04,\n",
      "        6.38924539e-04,  5.55147766e-04,  4.81914816e-04,  3.63451312e-04,\n",
      "        3.10038886e-04,  2.75431987e-04,  1.72105327e-04,  1.61278833e-04,\n",
      "        1.28101718e-04,  9.91180350e-05,  9.04321860e-05,  6.83206599e-05,\n",
      "        5.68586402e-05,  3.87450891e-05,  3.52235948e-05, -2.39572382e-05,\n",
      "        2.79240430e-05, -1.99517453e-05,  2.38756711e-05,  2.20482325e-05,\n",
      "        1.92653515e-05,  1.76859267e-05,  1.58765306e-05, -1.34127331e-05,\n",
      "       -1.17627587e-05,  1.40414868e-05,  1.20998757e-05,  1.10957508e-05,\n",
      "       -8.21821413e-06,  1.03510165e-05,  9.05119487e-06, -6.30467821e-06,\n",
      "        8.34795537e-06,  7.81798099e-06,  7.09868164e-06,  6.45433420e-06,\n",
      "        6.26482552e-06, -4.43337422e-06,  5.42709813e-06,  4.89943614e-06,\n",
      "       -3.80123333e-06,  4.17123374e-06, -3.04725131e-06,  3.33063940e-06,\n",
      "        3.28341957e-06, -2.72041461e-06,  2.75601496e-06, -2.26501220e-06,\n",
      "       -2.14350916e-06,  2.35515563e-06,  2.06689333e-06,  1.91899039e-06,\n",
      "       -1.45712715e-06,  1.65022436e-06,  1.49781056e-06, -1.29459431e-06,\n",
      "       -1.08422137e-06,  1.28929548e-06,  1.17472905e-06,  8.96097504e-07,\n",
      "        7.77050616e-07, -9.07353410e-07, -8.08748666e-07, -7.62945831e-07,\n",
      "        6.35343895e-07,  5.65283813e-07, -5.27661143e-07,  5.05708897e-07,\n",
      "       -4.38664017e-07,  4.30938371e-07, -3.94097754e-07,  4.22868510e-07,\n",
      "        3.10639081e-07,  2.96051354e-07, -2.93695706e-07,  2.13336449e-07,\n",
      "       -2.34496966e-07, -1.97687186e-07,  1.87395131e-07,  1.63020758e-07,\n",
      "       -1.40641660e-07, -1.35364303e-07,  1.25139152e-07,  1.09456337e-07,\n",
      "        8.65057856e-08, -6.40305160e-08, -5.78313113e-08, -4.72919517e-08,\n",
      "        6.41804832e-08,  5.61040565e-08,  5.90107945e-08, -4.28742837e-08,\n",
      "       -2.73563820e-08,  3.03188159e-08, -2.20776499e-08, -1.18758603e-08,\n",
      "        2.12835154e-08, -6.60406574e-09,  1.74250161e-08, -2.59865240e-09,\n",
      "        4.13003354e-10,  5.54405677e-09,  1.39732848e-08,  1.20101200e-08],\n",
      "      dtype=float32), array([[-0.05750705, -0.24900691, -0.13536184, ..., -0.00227148,\n",
      "        -0.01085489,  0.03711752],\n",
      "       [-0.06711495, -0.08169126,  0.16134536, ...,  0.04309389,\n",
      "         0.00574753,  0.01166754],\n",
      "       [-0.00039391, -0.01010385, -0.01725795, ...,  0.08093204,\n",
      "        -0.21773638, -0.34341833],\n",
      "       ...,\n",
      "       [ 0.01407865, -0.03773047, -0.03821818, ...,  0.01796995,\n",
      "        -0.01627827,  0.06339483],\n",
      "       [-0.16553278, -0.10086247, -0.03928788, ..., -0.00361632,\n",
      "         0.0258664 ,  0.00508206],\n",
      "       [-0.03850805,  0.01774816, -0.02334064, ..., -0.03179377,\n",
      "        -0.01827606, -0.00830825]], dtype=float32))\n",
      "(array([ 8.0349133e+02,  1.4082231e+01,  5.2837830e+00,  3.2199376e+00,\n",
      "        6.9620609e-01,  5.6406397e-01,  3.6295912e-01,  2.6312271e-01,\n",
      "        1.3748218e-01,  1.0313983e-01,  7.8624345e-02,  7.0943497e-02,\n",
      "        5.3019255e-02,  3.9623708e-02,  3.6118750e-02,  3.3323407e-02,\n",
      "        2.6991626e-02,  1.7339289e-02,  1.6214626e-02,  1.2167513e-02,\n",
      "        1.0749756e-02,  9.9295843e-03,  7.1809073e-03,  6.4576804e-03,\n",
      "        5.3640162e-03,  4.8702932e-03,  4.6856920e-03,  3.7379530e-03,\n",
      "        3.3191205e-03,  2.7359393e-03,  2.9705942e-03,  2.0729927e-03,\n",
      "        1.4606165e-03,  1.3654288e-03,  1.1573479e-03,  8.3721447e-04,\n",
      "        7.3276146e-04,  7.1669492e-04,  5.2514701e-04,  4.6598213e-04,\n",
      "        4.3004961e-04,  3.6099981e-04,  3.8463381e-04,  2.8847597e-04,\n",
      "        1.5470193e-04,  1.1622883e-04,  9.2001101e-05,  7.1196977e-05,\n",
      "        6.1037157e-05,  5.0424085e-05,  1.7188766e-05, -1.6525528e-05,\n",
      "       -1.5121733e-05, -1.2001527e-05,  1.1196921e-05,  1.0760375e-05,\n",
      "       -1.0592492e-05, -9.1541660e-06,  8.7141480e-06,  7.4918680e-06,\n",
      "       -7.4081504e-06, -5.7138609e-06, -5.0354265e-06,  5.5689279e-06,\n",
      "        5.6681520e-06, -3.2611390e-06,  3.6222209e-06,  3.2576761e-06,\n",
      "        2.6631033e-06,  2.2255913e-06,  2.0918237e-06,  1.8055728e-06,\n",
      "       -2.2807185e-06, -1.9987310e-06, -1.7419587e-06, -1.5433610e-06,\n",
      "       -1.2395791e-06,  1.4392984e-06,  1.2434166e-06, -1.1339948e-06,\n",
      "        9.8645125e-07, -8.2971985e-07,  7.9676170e-07, -6.4856488e-07,\n",
      "       -5.8952281e-07,  6.1464459e-07,  5.2841119e-07, -5.2237317e-07,\n",
      "        4.3641305e-07,  3.7017304e-07, -4.2947073e-07, -3.8255567e-07,\n",
      "        2.9857242e-07, -3.0414466e-07,  2.2104231e-07, -2.1773637e-07,\n",
      "       -2.0747557e-07,  1.7955982e-07,  1.4130634e-07, -1.3790086e-07,\n",
      "       -1.1979516e-07,  1.0706085e-07, -8.1711896e-08,  5.6695320e-08,\n",
      "       -4.9207717e-08,  4.1134182e-08,  3.3945582e-08,  3.1776782e-08,\n",
      "       -3.4868666e-08, -3.2473970e-08,  2.9379136e-08,  1.5155438e-08,\n",
      "        9.5925783e-09,  5.3074780e-09,  3.3789784e-09, -5.3018129e-10,\n",
      "       -2.3307392e-08, -1.6434738e-08, -1.8132383e-08, -9.9727577e-09],\n",
      "      dtype=float32), array([[-0.087295  ,  0.03316224,  0.14647546, ...,  0.03200541,\n",
      "         0.00319792,  0.00066266],\n",
      "       [-0.06686574,  0.15481858,  0.16115102, ..., -0.02474303,\n",
      "         0.00907038,  0.02852704],\n",
      "       [-0.0006851 ,  0.01216117, -0.03018497, ..., -0.14108145,\n",
      "         0.12287058, -0.21818517],\n",
      "       ...,\n",
      "       [ 0.01042134, -0.06476082, -0.050049  , ..., -0.05581893,\n",
      "         0.04045231,  0.00701337],\n",
      "       [-0.17604661, -0.04320864, -0.02775496, ...,  0.00615468,\n",
      "        -0.00467779,  0.01124942],\n",
      "       [-0.04142544, -0.03361633, -0.05532269, ...,  0.04735935,\n",
      "        -0.01227227, -0.02540649]], dtype=float32))\n",
      "(array([ 7.5133142e+02,  1.5439633e-01,  1.0741189e-01,  5.9676293e-02,\n",
      "        5.2007034e-02,  1.5707262e-02,  8.6736605e-03,  7.4336436e-03,\n",
      "        3.6336435e-03,  2.7631116e-03,  2.1486022e-03,  1.8056786e-03,\n",
      "        1.0720523e-03,  9.5756009e-04,  6.0186908e-04,  4.3362670e-04,\n",
      "        3.8887435e-04,  2.5242334e-04,  2.0600414e-04,  1.6847232e-04,\n",
      "        1.2386650e-04,  1.2189512e-04,  1.1079450e-04,  8.4172272e-05,\n",
      "        6.7957793e-05,  5.3828084e-05,  5.4955952e-05,  4.1933359e-05,\n",
      "        3.6996731e-05,  2.6316908e-05,  2.1816531e-05, -2.1359343e-05,\n",
      "       -1.9493436e-05, -1.4587441e-05,  2.1121274e-05,  1.9373996e-05,\n",
      "       -1.2988293e-05,  1.6796941e-05,  1.4861244e-05,  1.3025442e-05,\n",
      "       -9.5379319e-06,  1.1788940e-05,  1.0672493e-05,  1.0165116e-05,\n",
      "       -8.6837517e-06, -8.1822427e-06,  8.0560176e-06, -6.4962760e-06,\n",
      "        6.9240041e-06,  6.7216283e-06,  6.3789239e-06, -4.1866779e-06,\n",
      "        4.7157878e-06,  4.4048666e-06, -3.9501724e-06,  3.7685957e-06,\n",
      "        3.4479776e-06, -2.8618758e-06, -2.6609564e-06,  3.3476467e-06,\n",
      "        2.9743728e-06,  2.5696902e-06, -2.1270400e-06, -2.0500534e-06,\n",
      "        2.1349749e-06,  1.7304141e-06, -1.6346083e-06, -1.2184971e-06,\n",
      "       -1.0713635e-06,  1.5544290e-06,  1.4586913e-06,  1.2351505e-06,\n",
      "        1.0709542e-06,  1.0218569e-06, -7.2652665e-07,  7.8740845e-07,\n",
      "        6.5492372e-07, -4.8488721e-07, -4.4605198e-07,  5.6142829e-07,\n",
      "        4.9388643e-07,  5.1198685e-07,  4.2606842e-07, -3.4576340e-07,\n",
      "        3.7654007e-07,  3.4836160e-07,  2.9766511e-07, -2.7154513e-07,\n",
      "       -2.4849479e-07, -1.9031224e-07,  2.1446880e-07,  1.8245267e-07,\n",
      "       -1.3917192e-07, -1.2776280e-07,  1.5510388e-07,  1.4031291e-07,\n",
      "       -1.0721102e-07,  1.0691172e-07,  9.1548763e-08, -7.5062715e-08,\n",
      "       -6.3211587e-08, -4.6870547e-08, -3.6307323e-08,  6.6221574e-08,\n",
      "        6.4888468e-08,  4.7093891e-08, -1.7232802e-08, -2.0943746e-08,\n",
      "        4.1015923e-08,  3.1495553e-08,  2.6766042e-08, -4.4885491e-09,\n",
      "       -3.5235497e-09, -1.1789045e-10,  2.0715426e-08,  1.4739195e-08,\n",
      "        1.6323073e-08,  1.0243767e-08,  2.2209550e-09,  3.9126316e-09],\n",
      "      dtype=float32), array([[-0.05272843, -0.1501926 , -0.29529884, ..., -0.00258175,\n",
      "         0.00755022, -0.00588864],\n",
      "       [-0.06609575,  0.20327877, -0.0237696 , ...,  0.00971408,\n",
      "         0.00604323, -0.00159082],\n",
      "       [-0.00180137, -0.02834866,  0.00643239, ...,  0.23510765,\n",
      "         0.16788115, -0.03699616],\n",
      "       ...,\n",
      "       [ 0.01378587, -0.04763332,  0.02414878, ...,  0.10103312,\n",
      "        -0.08350448, -0.01516014],\n",
      "       [-0.16581894, -0.08585626, -0.12028389, ..., -0.00192186,\n",
      "         0.0011432 ,  0.00109138],\n",
      "       [-0.03811953, -0.04905054,  0.02137356, ...,  0.02517617,\n",
      "         0.01532733, -0.01308131]], dtype=float32))\n",
      "(array([ 5.02923553e+02,  4.69198895e+00,  8.84592235e-01,  4.27839965e-01,\n",
      "        8.60191807e-02,  4.52149138e-02,  2.67627146e-02,  1.72243081e-02,\n",
      "        1.18541690e-02,  8.22127517e-03,  5.36528463e-03,  3.82081908e-03,\n",
      "        3.41110444e-03,  2.53813853e-03,  1.77176110e-03,  1.18454231e-03,\n",
      "        1.03822851e-03,  9.21235827e-04,  8.22354923e-04,  6.38220576e-04,\n",
      "        5.81186847e-04,  3.90910427e-04,  3.26203852e-04,  2.70650693e-04,\n",
      "        2.08686848e-04,  1.73072782e-04,  1.43537312e-04,  1.18042117e-04,\n",
      "        1.06105843e-04,  8.59142310e-05,  7.57507296e-05,  7.20633034e-05,\n",
      "        5.80147025e-05,  5.23043636e-05,  4.19838070e-05,  3.22552842e-05,\n",
      "        3.06415277e-05,  2.44588646e-05,  2.06999684e-05,  1.97456902e-05,\n",
      "        1.90818628e-05,  1.52809480e-05,  1.48625586e-05,  1.31569686e-05,\n",
      "       -1.01578898e-05, -8.00227463e-06, -6.48948617e-06,  9.61330807e-06,\n",
      "        9.12291034e-06,  7.64358356e-06,  7.74966065e-06, -5.56759142e-06,\n",
      "        6.37208041e-06,  5.40935935e-06, -4.56440512e-06, -3.89112893e-06,\n",
      "        4.77298681e-06,  4.34470985e-06,  3.49581819e-06, -3.20692448e-06,\n",
      "       -3.05713957e-06, -2.16310718e-06,  2.77018330e-06,  2.43521617e-06,\n",
      "        2.33061382e-06,  2.24628843e-06, -1.89061484e-06,  1.79909580e-06,\n",
      "       -1.68220072e-06, -1.50847370e-06,  1.52556117e-06, -1.23893494e-06,\n",
      "        1.32562548e-06,  1.12312875e-06, -8.73504177e-07, -8.37819869e-07,\n",
      "        1.03109221e-06, -6.89744638e-07,  8.06542289e-07,  7.81014876e-07,\n",
      "        6.52304891e-07, -5.81497034e-07,  5.62042601e-07, -4.17107202e-07,\n",
      "        4.54770827e-07,  4.73150521e-07, -3.73208763e-07,  3.84891052e-07,\n",
      "        3.15440758e-07, -3.12225012e-07, -2.40355831e-07, -2.12343181e-07,\n",
      "        2.35109198e-07,  2.07955139e-07,  1.82740905e-07, -1.76222258e-07,\n",
      "       -1.65248494e-07,  1.58021223e-07,  1.40043710e-07,  9.88219853e-08,\n",
      "       -1.09184654e-07, -9.17477152e-08, -7.11909180e-08,  5.64453622e-08,\n",
      "       -4.76261910e-08,  4.12213339e-08,  3.90303754e-08,  3.50629854e-08,\n",
      "       -3.06483727e-08, -2.82876886e-08, -2.02402433e-08,  1.82530826e-08,\n",
      "       -1.66393370e-08, -6.82597223e-09, -3.80791665e-09, -2.26162156e-09,\n",
      "        4.53479393e-10,  1.18579049e-08,  7.57120322e-09,  8.85257734e-09],\n",
      "      dtype=float32), array([[ 0.06487754,  0.00664962, -0.1770792 , ..., -0.02816854,\n",
      "        -0.02256177, -0.00317012],\n",
      "       [ 0.05561936,  0.04202698,  0.10604167, ...,  0.05299688,\n",
      "         0.01987777, -0.00549711],\n",
      "       [ 0.00683895, -0.03274525, -0.03030269, ..., -0.29422608,\n",
      "         0.10139216, -0.16637297],\n",
      "       ...,\n",
      "       [-0.02488561,  0.05886593,  0.02147947, ..., -0.01673031,\n",
      "        -0.02393502,  0.05383671],\n",
      "       [ 0.16694754, -0.03543234, -0.1934893 , ...,  0.01560271,\n",
      "         0.00740292, -0.02302515],\n",
      "       [ 0.05526575, -0.05419394, -0.04276653, ..., -0.02741679,\n",
      "        -0.02527124,  0.03397005]], dtype=float32))\n",
      "(array([ 4.54698151e+02,  5.62153244e+00,  6.78925276e-01,  3.11902881e-01,\n",
      "        1.51378602e-01,  4.82102223e-02,  3.64184268e-02,  2.66104210e-02,\n",
      "        2.35527940e-02,  1.75668374e-02,  9.08848643e-03,  6.63829315e-03,\n",
      "        5.49116172e-03,  4.45178291e-03,  2.98446673e-03,  2.70200358e-03,\n",
      "        1.97429350e-03,  1.91409630e-03,  1.40557915e-03,  1.24556874e-03,\n",
      "        1.05323433e-03,  9.54568386e-04,  7.75664696e-04,  5.80522930e-04,\n",
      "        4.75450448e-04,  3.95549898e-04,  3.61442566e-04,  3.09737981e-04,\n",
      "        2.12720857e-04,  1.93721484e-04,  1.61630029e-04,  1.42688848e-04,\n",
      "        1.17912321e-04,  1.11644142e-04,  1.02255006e-04,  8.01196220e-05,\n",
      "        7.06284627e-05,  6.53257157e-05,  5.47278869e-05,  3.91906142e-05,\n",
      "        3.64298539e-05,  2.96753078e-05,  2.10796079e-05,  1.82350523e-05,\n",
      "        1.68801635e-05,  1.36479393e-05,  1.15735065e-05, -7.84746408e-06,\n",
      "        7.07653453e-06,  5.93034292e-06, -5.32188233e-06, -4.91505079e-06,\n",
      "        5.09083429e-06, -3.71532701e-06,  4.08866208e-06,  3.66098539e-06,\n",
      "       -2.81946882e-06,  3.00279089e-06,  2.79156166e-06, -2.43622480e-06,\n",
      "       -2.27170631e-06, -1.94703853e-06,  2.33068954e-06,  2.07071230e-06,\n",
      "        1.80089796e-06,  1.49548123e-06,  1.41758107e-06, -1.36715630e-06,\n",
      "       -1.27229964e-06, -1.17304194e-06, -1.06757363e-06,  1.27483997e-06,\n",
      "        1.17532397e-06,  9.74908517e-07,  9.00391569e-07, -8.73014358e-07,\n",
      "        6.47249351e-07, -6.69420558e-07, -6.86317264e-07,  5.98735369e-07,\n",
      "        5.70332702e-07, -5.33616003e-07, -4.98556346e-07, -4.22087595e-07,\n",
      "       -3.94688783e-07,  3.69046148e-07,  3.26894565e-07,  2.67051036e-07,\n",
      "       -3.16777857e-07, -2.89670112e-07, -2.53276625e-07, -2.08576267e-07,\n",
      "        2.38845615e-07,  2.14967230e-07, -1.56961050e-07,  1.59963662e-07,\n",
      "        1.44115845e-07, -1.22062971e-07,  1.06179947e-07,  8.75304451e-08,\n",
      "       -8.54659987e-08, -7.54183134e-08, -6.70750566e-08, -3.93165003e-08,\n",
      "       -3.38840849e-08, -2.13884412e-08,  6.85339643e-08,  6.58552892e-08,\n",
      "        3.62520893e-08,  5.38011449e-08,  5.00205779e-08, -1.75928623e-08,\n",
      "        1.90156815e-08,  1.44293804e-08, -1.32678668e-08, -7.68096875e-09,\n",
      "       -2.27683028e-09,  5.21880494e-09,  3.44951334e-09,  1.31492162e-09],\n",
      "      dtype=float32), array([[-0.07137837, -0.10271756,  0.09098659, ...,  0.00529273,\n",
      "         0.0245248 , -0.01064581],\n",
      "       [-0.05351751, -0.005336  , -0.1535961 , ...,  0.01200211,\n",
      "         0.00119288,  0.02958674],\n",
      "       [-0.00906769,  0.01979544,  0.02778407, ..., -0.16903143,\n",
      "         0.14956988,  0.06801906],\n",
      "       ...,\n",
      "       [ 0.02912673,  0.00122363,  0.06476571, ...,  0.01353871,\n",
      "         0.01168021,  0.04958531],\n",
      "       [-0.16859195, -0.09814594,  0.06230382, ...,  0.00747238,\n",
      "        -0.00207547, -0.00767809],\n",
      "       [-0.05851659,  0.00063719, -0.03279167, ...,  0.02744351,\n",
      "         0.00229375, -0.00875203]], dtype=float32))\n",
      "(array([ 4.31682617e+02,  2.32073069e+00,  4.70292151e-01,  8.50887522e-02,\n",
      "        5.91466390e-02,  3.82954851e-02,  3.07750013e-02,  1.77910998e-02,\n",
      "        1.41209345e-02,  1.02910921e-02,  5.55061316e-03,  4.05550329e-03,\n",
      "        3.48596531e-03,  2.88705784e-03,  2.05462589e-03,  1.52061356e-03,\n",
      "        1.40480860e-03,  1.24353985e-03,  1.01653207e-03,  9.46008833e-04,\n",
      "        7.34846049e-04,  5.89824514e-04,  4.17158444e-04,  3.50823044e-04,\n",
      "        2.71809957e-04,  2.59197433e-04,  2.12595027e-04,  1.74218891e-04,\n",
      "        1.58298761e-04,  1.29121428e-04,  1.02027363e-04,  8.83094399e-05,\n",
      "        8.64483445e-05,  7.36815928e-05,  6.17365440e-05,  4.24456885e-05,\n",
      "        3.75366508e-05,  2.93293160e-05,  2.51910351e-05,  2.25354088e-05,\n",
      "        1.70589246e-05,  1.58857238e-05,  1.37215393e-05,  1.12915250e-05,\n",
      "       -8.92638309e-06,  9.92010155e-06, -8.36159143e-06, -6.92737376e-06,\n",
      "        8.59445663e-06,  7.72831663e-06,  5.74547357e-06,  5.94563926e-06,\n",
      "       -4.44602392e-06,  5.02012517e-06, -3.43560191e-06, -3.13069131e-06,\n",
      "       -2.72761622e-06,  4.35278844e-06,  4.00940189e-06,  3.54103099e-06,\n",
      "        3.16109049e-06,  2.85538954e-06,  2.35527887e-06, -2.17310458e-06,\n",
      "       -2.11168481e-06,  1.97677946e-06,  1.80527968e-06, -1.55126884e-06,\n",
      "        1.56342207e-06, -1.37970676e-06, -1.33238325e-06,  1.26763325e-06,\n",
      "       -1.13502995e-06, -1.02701904e-06,  1.11278177e-06,  9.59450290e-07,\n",
      "       -8.22170648e-07, -7.86534088e-07,  8.21480000e-07,  7.83466817e-07,\n",
      "       -6.77654270e-07, -5.26053384e-07,  6.35080369e-07,  6.01591864e-07,\n",
      "       -4.43797120e-07,  4.66603609e-07,  4.13748239e-07, -3.65157376e-07,\n",
      "       -2.81071607e-07, -2.66387246e-07, -2.19068056e-07,  3.01884114e-07,\n",
      "        2.85891872e-07,  2.65720018e-07,  2.07325314e-07,  1.84762058e-07,\n",
      "       -1.62115242e-07,  1.55755529e-07, -1.42627769e-07,  9.92782319e-08,\n",
      "       -1.32209948e-07, -1.06244045e-07, -8.28246272e-08,  8.32107219e-08,\n",
      "        7.32746130e-08, -5.78324055e-08, -5.15983913e-08,  3.79515406e-08,\n",
      "        3.98168716e-08, -4.13034513e-08, -3.63958641e-08,  2.66367604e-08,\n",
      "        2.13112585e-08, -2.49518024e-08, -1.44014587e-08, -1.14529168e-08,\n",
      "       -4.78583440e-09, -2.56886734e-09,  8.52134363e-09,  5.96625638e-09],\n",
      "      dtype=float32), array([[ 0.06838026,  0.10049133, -0.08943857, ...,  0.00119549,\n",
      "        -0.07432628, -0.01210249],\n",
      "       [ 0.05229254,  0.00396954,  0.16409287, ...,  0.02431571,\n",
      "        -0.00989681,  0.00846497],\n",
      "       [ 0.0108605 , -0.02145617, -0.05061745, ..., -0.00859561,\n",
      "         0.04197723,  0.22251701],\n",
      "       ...,\n",
      "       [-0.03139959,  0.0182638 , -0.05259821, ..., -0.04735284,\n",
      "         0.02565561, -0.00973256],\n",
      "       [ 0.17205152,  0.08270362, -0.13192502, ..., -0.00172185,\n",
      "         0.00298582, -0.01125551],\n",
      "       [ 0.06081091, -0.0186038 , -0.02815951, ..., -0.00659443,\n",
      "         0.00474902, -0.00302174]], dtype=float32))\n",
      "(array([ 3.25405121e+02,  2.71706283e-01,  1.02193534e-01,  7.59438649e-02,\n",
      "        1.74791757e-02,  1.67649835e-02,  1.41681321e-02,  8.38341005e-03,\n",
      "        6.28564926e-03,  3.14006489e-03,  2.08953675e-03,  1.65189942e-03,\n",
      "        1.51179940e-03,  9.75354051e-04,  6.66673412e-04,  5.30121790e-04,\n",
      "        5.07880293e-04,  4.28475672e-04,  3.27373360e-04,  2.58481625e-04,\n",
      "        1.56908907e-04,  1.20379351e-04,  1.07922009e-04,  7.74336950e-05,\n",
      "        6.46872140e-05,  5.40356050e-05,  4.99730486e-05,  3.82987164e-05,\n",
      "        3.48838694e-05,  3.15293983e-05,  2.82717228e-05,  2.16287008e-05,\n",
      "        1.78123410e-05,  1.72441851e-05, -9.50104095e-06,  1.44746746e-05,\n",
      "        1.29960154e-05,  1.26359873e-05,  1.15219582e-05,  9.16711906e-06,\n",
      "       -5.56544637e-06,  8.21006688e-06,  7.77947025e-06,  6.63952960e-06,\n",
      "        5.94334870e-06,  4.91657056e-06, -3.71297756e-06,  4.31260924e-06,\n",
      "        4.18789887e-06, -3.13782516e-06,  3.49254515e-06, -2.64057599e-06,\n",
      "        3.30247735e-06,  2.56437647e-06,  2.46665195e-06, -2.01161834e-06,\n",
      "       -1.86336968e-06,  2.22337167e-06,  1.91457934e-06, -1.56201361e-06,\n",
      "        1.82836015e-06, -1.37703614e-06,  1.51916390e-06, -1.24632072e-06,\n",
      "        1.40054226e-06,  1.24641815e-06,  1.22639290e-06, -9.62013814e-07,\n",
      "        1.07808739e-06,  1.02546016e-06, -8.40687676e-07, -8.26508312e-07,\n",
      "        8.17877378e-07, -6.88360842e-07,  7.11478549e-07, -5.91517278e-07,\n",
      "       -4.82471762e-07,  6.56172460e-07,  6.30641296e-07,  5.73151851e-07,\n",
      "        5.44099237e-07, -4.24520550e-07, -3.90769230e-07, -3.36462449e-07,\n",
      "        3.43468997e-07,  3.54607607e-07, -2.47096807e-07,  3.11255462e-07,\n",
      "        2.81498899e-07, -2.12253127e-07, -1.96470111e-07, -1.75521677e-07,\n",
      "        2.04205989e-07,  1.97194240e-07,  1.64530022e-07,  1.50029535e-07,\n",
      "       -1.50282389e-07, -1.20125648e-07,  1.15314677e-07, -8.90511771e-08,\n",
      "        9.89474884e-08, -6.89380926e-08,  6.26283594e-08,  5.58442146e-08,\n",
      "        5.14728562e-08, -4.56448959e-08, -3.98674196e-08,  3.12615747e-08,\n",
      "       -3.01344372e-08,  2.73659744e-08, -3.54623886e-08,  1.91911482e-08,\n",
      "        1.43594789e-08, -1.29709212e-08, -1.06960441e-08,  9.58271951e-09,\n",
      "       -4.01422851e-09, -5.25308153e-09,  1.09614584e-09,  5.79678483e-09],\n",
      "      dtype=float32), array([[-0.05709172,  0.06189971,  0.08206177, ..., -0.01157176,\n",
      "         0.03100064, -0.00710423],\n",
      "       [-0.05397097,  0.02766854, -0.15777716, ...,  0.01781596,\n",
      "         0.03031125,  0.0103352 ],\n",
      "       [-0.01090598, -0.03769354,  0.04827693, ..., -0.05369577,\n",
      "        -0.00996786, -0.04450052],\n",
      "       ...,\n",
      "       [ 0.02657919,  0.03727379,  0.07481313, ...,  0.01872058,\n",
      "         0.06285064, -0.08565588],\n",
      "       [-0.15777221,  0.07048645,  0.11844271, ..., -0.01775283,\n",
      "        -0.0055353 , -0.00658059],\n",
      "       [-0.05872464, -0.03752138,  0.01376532, ...,  0.00959316,\n",
      "         0.00898476, -0.00729101]], dtype=float32))\n",
      "(array([ 8.22249207e+02,  2.33984017e+00,  1.48800477e-01,  1.24961697e-01,\n",
      "        8.41987953e-02,  6.58354834e-02,  2.38659140e-02,  2.23464165e-02,\n",
      "        1.13583766e-02,  6.86668511e-03,  5.49281854e-03,  4.16709902e-03,\n",
      "        3.11003579e-03,  2.10839557e-03,  1.92300847e-03,  1.80242863e-03,\n",
      "        1.09840615e-03,  9.45670821e-04,  7.21600372e-04,  5.50588709e-04,\n",
      "        4.98100009e-04,  4.78655857e-04,  3.34204349e-04,  2.83202739e-04,\n",
      "        2.23975032e-04,  1.84054792e-04,  1.39975455e-04,  1.09237277e-04,\n",
      "        9.90536646e-05,  8.20342029e-05,  7.99910413e-05,  7.12397523e-05,\n",
      "        6.03685221e-05,  5.19640271e-05,  4.73643631e-05,  4.39562209e-05,\n",
      "        3.99750606e-05,  3.00346564e-05,  2.62163703e-05,  2.35121679e-05,\n",
      "       -1.97998725e-05, -1.44967917e-05,  1.92966472e-05,  1.73733715e-05,\n",
      "        1.67343478e-05,  1.56018577e-05, -1.23974387e-05,  1.22014262e-05,\n",
      "       -9.76252795e-06, -9.44015210e-06,  1.08139748e-05,  9.87997646e-06,\n",
      "        8.82105360e-06, -6.45217779e-06,  7.33879642e-06,  6.78097422e-06,\n",
      "       -5.99553687e-06, -5.63092362e-06,  6.26527617e-06, -4.53136909e-06,\n",
      "       -4.34060894e-06,  5.51954417e-06,  4.82707173e-06,  4.65021958e-06,\n",
      "        4.13952785e-06,  3.70879411e-06, -2.74080935e-06,  3.11604322e-06,\n",
      "        2.57885267e-06, -2.45652268e-06, -2.23751044e-06,  2.35936636e-06,\n",
      "       -1.69834993e-06, -1.56624765e-06,  2.03039190e-06,  1.78143421e-06,\n",
      "       -1.14918532e-06,  1.65108133e-06,  1.45484171e-06,  1.14920169e-06,\n",
      "        8.79899915e-07, -9.10412155e-07, -8.66452353e-07,  7.56247289e-07,\n",
      "       -6.77940534e-07,  5.86282908e-07, -6.15598879e-07, -4.92401512e-07,\n",
      "       -4.21329560e-07,  4.94028654e-07,  4.51028143e-07,  3.90938055e-07,\n",
      "        2.97838909e-07,  2.78207352e-07, -2.61195652e-07, -2.41058842e-07,\n",
      "        2.38803125e-07, -2.15172037e-07,  1.75450865e-07, -1.59865621e-07,\n",
      "        1.37799645e-07, -1.18909561e-07, -1.07463620e-07,  1.13232026e-07,\n",
      "        7.79400011e-08, -7.46713127e-08,  6.26357064e-08, -5.68724019e-08,\n",
      "        4.41354580e-08,  3.25741105e-08, -3.54250389e-08, -3.20942171e-08,\n",
      "       -1.58843250e-08,  1.41741188e-08,  7.47801021e-09,  1.02153779e-08,\n",
      "       -8.36088798e-09, -5.39157252e-09, -2.67444122e-10, -2.12795692e-09],\n",
      "      dtype=float32), array([[ 0.09295396, -0.1434731 , -0.06806947, ..., -0.00457314,\n",
      "         0.01789916,  0.0126403 ],\n",
      "       [ 0.06282227, -0.11376134, -0.05127231, ..., -0.00651437,\n",
      "         0.02025771,  0.02660513],\n",
      "       [ 0.00674487,  0.02476353,  0.04795175, ...,  0.0934502 ,\n",
      "        -0.16484861, -0.21112773],\n",
      "       ...,\n",
      "       [-0.02652647,  0.03909104,  0.06128386, ..., -0.03870012,\n",
      "         0.03444511,  0.0485254 ],\n",
      "       [ 0.18123154,  0.04245907,  0.06394151, ..., -0.00416426,\n",
      "        -0.00629463,  0.00038254],\n",
      "       [ 0.06107702, -0.00802507,  0.04824351, ...,  0.0026564 ,\n",
      "        -0.01473244, -0.00321008]], dtype=float32))\n",
      "(array([ 8.29038330e+02,  1.71874416e+00,  6.08772635e-01,  5.12958169e-01,\n",
      "        1.42928571e-01,  7.12520033e-02,  5.35497926e-02,  4.68997881e-02,\n",
      "        2.48895958e-02,  1.51852928e-02,  1.23384129e-02,  7.09222443e-03,\n",
      "        5.74154546e-03,  4.19455720e-03,  3.03015020e-03,  2.56968918e-03,\n",
      "        2.26898165e-03,  1.95032556e-03,  1.50684069e-03,  1.05216238e-03,\n",
      "        8.45722854e-04,  6.23228610e-04,  5.43829578e-04,  4.33623121e-04,\n",
      "        3.75076983e-04,  3.58344230e-04,  3.07073962e-04,  2.19075941e-04,\n",
      "        2.03857388e-04,  1.93429791e-04,  1.63078003e-04,  1.41046345e-04,\n",
      "        1.09325585e-04,  9.28779482e-05,  7.97292814e-05,  7.51015177e-05,\n",
      "        5.61882807e-05,  4.92009021e-05,  3.70753114e-05,  3.30279763e-05,\n",
      "        3.08893141e-05,  2.82176607e-05,  2.36691649e-05, -1.93534979e-05,\n",
      "       -1.70933818e-05,  1.95578032e-05,  1.78275532e-05, -1.15701378e-05,\n",
      "        1.50363894e-05,  1.40646962e-05, -9.25850600e-06,  1.16885194e-05,\n",
      "        1.10294068e-05,  9.81395988e-06, -7.61060846e-06,  8.71360317e-06,\n",
      "       -6.71588487e-06, -6.31292869e-06,  8.00288853e-06,  7.82918323e-06,\n",
      "        7.09369306e-06, -5.19641844e-06,  5.57221119e-06,  4.48036917e-06,\n",
      "        4.34194635e-06, -3.73269268e-06, -3.53813039e-06,  3.56651299e-06,\n",
      "        3.20990443e-06, -2.68835674e-06,  2.87289367e-06, -2.30588921e-06,\n",
      "       -2.41056227e-06,  2.14668830e-06,  1.94694576e-06, -1.58571959e-06,\n",
      "       -1.28278964e-06,  1.58581156e-06, -1.09987616e-06,  1.48126912e-06,\n",
      "        1.27313524e-06,  1.09662028e-06, -9.85680344e-07, -9.25798986e-07,\n",
      "        9.72201747e-07,  8.08144875e-07, -6.57776468e-07,  6.72837302e-07,\n",
      "        6.06403773e-07,  4.51851264e-07, -4.65503007e-07, -4.31418897e-07,\n",
      "       -3.46821452e-07,  3.19954665e-07, -2.81992243e-07,  2.49610565e-07,\n",
      "        1.98702168e-07,  1.65778147e-07,  1.50544423e-07, -1.58820001e-07,\n",
      "       -1.33169607e-07,  9.96227243e-08,  1.02442840e-07, -8.78449740e-08,\n",
      "       -1.02379602e-07,  6.58307187e-08, -5.32933839e-08, -4.55412987e-08,\n",
      "       -3.20101208e-08, -3.83554486e-08,  3.98177100e-08,  2.60465729e-08,\n",
      "        2.25561898e-08, -1.11800631e-08,  6.70273081e-09,  5.49682433e-09,\n",
      "        3.83003496e-09,  2.34398700e-09, -8.69835370e-10, -3.04017811e-09],\n",
      "      dtype=float32), array([[-0.09382638, -0.13036367,  0.07175018, ...,  0.00747753,\n",
      "        -0.00787165,  0.00476011],\n",
      "       [-0.06431114, -0.11657961, -0.13922556, ...,  0.02761943,\n",
      "        -0.00788873,  0.02620776],\n",
      "       [-0.00647905,  0.02785778,  0.04152925, ..., -0.09290244,\n",
      "        -0.0024791 , -0.04385475],\n",
      "       ...,\n",
      "       [ 0.02421618,  0.013669  ,  0.05350961, ..., -0.01830114,\n",
      "         0.05791144, -0.01493733],\n",
      "       [-0.18166897,  0.04164577,  0.05554133, ...,  0.00342217,\n",
      "         0.00874609,  0.00046954],\n",
      "       [-0.05971557,  0.03718462,  0.00273957, ..., -0.01038187,\n",
      "         0.01118469, -0.01010913]], dtype=float32))\n",
      "(array([ 8.4187610e+02,  1.1459991e+00,  3.5866153e-01,  1.8196106e-01,\n",
      "        1.3290413e-01,  1.0473619e-01,  7.6578356e-02,  4.8375420e-02,\n",
      "        2.5490385e-02,  1.5887521e-02,  1.0760334e-02,  1.0013319e-02,\n",
      "        6.4172545e-03,  5.4078731e-03,  2.9754858e-03,  2.5310228e-03,\n",
      "        1.8582810e-03,  1.6241211e-03,  1.4049428e-03,  1.1067357e-03,\n",
      "        9.6410367e-04,  7.3850434e-04,  6.2954414e-04,  5.6039484e-04,\n",
      "        3.8309846e-04,  3.4712593e-04,  2.8374596e-04,  2.5430077e-04,\n",
      "        2.0266599e-04,  1.9001725e-04,  1.4200852e-04,  1.1844398e-04,\n",
      "        1.0191956e-04,  8.4971602e-05,  7.5255040e-05,  6.6931090e-05,\n",
      "        5.7586607e-05,  4.8920261e-05,  4.3245800e-05,  3.9904371e-05,\n",
      "        2.9920941e-05,  2.7278524e-05, -2.3382676e-05, -2.1491320e-05,\n",
      "        2.3329290e-05,  2.1910615e-05, -1.5595133e-05,  1.5664895e-05,\n",
      "        1.5146680e-05, -1.1626641e-05,  1.3590946e-05,  1.1771456e-05,\n",
      "        1.1477339e-05, -8.7018134e-06, -7.8983512e-06,  9.5343967e-06,\n",
      "        8.9279119e-06, -5.8808946e-06,  6.7961219e-06,  6.2943695e-06,\n",
      "        5.8453816e-06, -5.5056094e-06, -4.3608611e-06, -3.7326354e-06,\n",
      "       -3.2540634e-06,  3.6517995e-06,  3.5913597e-06,  2.7446013e-06,\n",
      "        3.0922506e-06,  3.1308114e-06,  2.3677362e-06, -1.9731845e-06,\n",
      "        1.9218387e-06, -1.7082471e-06,  1.6368606e-06, -1.4433416e-06,\n",
      "        1.3121352e-06, -1.1983694e-06, -1.1273692e-06,  1.1423602e-06,\n",
      "        1.0255017e-06, -7.4209277e-07,  8.9868257e-07,  7.5649729e-07,\n",
      "        6.1473310e-07,  5.1865379e-07, -6.4422238e-07, -5.5817799e-07,\n",
      "       -5.1755956e-07, -3.8369834e-07,  3.1866819e-07, -2.6864296e-07,\n",
      "        2.1883237e-07, -1.9878178e-07,  1.8451497e-07,  1.5905702e-07,\n",
      "       -1.8141968e-07, -1.5947140e-07, -1.0156475e-07,  1.2039105e-07,\n",
      "        1.1374391e-07, -7.7656189e-08,  7.5716287e-08,  6.1939090e-08,\n",
      "       -5.1975849e-08, -4.8455654e-08, -4.3807578e-08,  5.1466237e-08,\n",
      "        4.7518526e-08,  3.2217319e-08,  2.5842953e-08, -2.2664468e-08,\n",
      "       -1.7642062e-08, -7.8565732e-09,  1.4105358e-08,  9.5568300e-09,\n",
      "        5.7038472e-09, -3.2177676e-09, -1.0693977e-09,  4.1178165e-11],\n",
      "      dtype=float32), array([[-0.06880607, -0.25723562, -0.04489132, ..., -0.01656822,\n",
      "         0.00200092, -0.00052581],\n",
      "       [-0.06900158, -0.06639113, -0.10539598, ...,  0.00157251,\n",
      "         0.00825011,  0.00384014],\n",
      "       [-0.00141134, -0.00325651,  0.02229002, ...,  0.09961742,\n",
      "        -0.12980595,  0.03211645],\n",
      "       ...,\n",
      "       [ 0.01116076,  0.05752784,  0.05804814, ...,  0.19953382,\n",
      "         0.12407833,  0.0849629 ],\n",
      "       [-0.17077719, -0.01472917,  0.13038345, ...,  0.00089284,\n",
      "        -0.0067228 ,  0.00321892],\n",
      "       [-0.03906383, -0.03649753, -0.02480785, ...,  0.03919614,\n",
      "         0.01449881,  0.04033141]], dtype=float32))\n",
      "(array([ 9.26166565e+02,  6.04301393e-01,  1.13904804e-01,  6.46566004e-02,\n",
      "        2.77911928e-02,  1.76645499e-02,  1.04968287e-02,  7.36774923e-03,\n",
      "        4.01808601e-03,  3.51653388e-03,  1.63685472e-03,  1.40502595e-03,\n",
      "        9.87876439e-04,  7.58262991e-04,  7.26706407e-04,  5.53917896e-04,\n",
      "        3.56006756e-04,  2.98816274e-04,  2.19967260e-04,  1.76409594e-04,\n",
      "        1.61360455e-04,  1.29001288e-04,  8.75622500e-05,  7.64349243e-05,\n",
      "        7.11221292e-05,  5.86766873e-05,  4.93395346e-05,  4.32837187e-05,\n",
      "        3.81065765e-05,  3.22665001e-05,  3.01704495e-05,  2.75335624e-05,\n",
      "       -2.36329288e-05, -2.11379647e-05, -1.97188674e-05,  2.42690803e-05,\n",
      "        2.16111857e-05, -1.53258115e-05,  1.95891662e-05,  1.88441209e-05,\n",
      "        1.77591992e-05, -1.29403816e-05,  1.45655576e-05,  1.30545714e-05,\n",
      "        1.15947760e-05, -9.69493613e-06, -8.68336338e-06,  1.00734323e-05,\n",
      "        9.97273946e-06, -7.75488479e-06, -6.64885056e-06,  8.57699433e-06,\n",
      "        7.61622823e-06,  6.37861103e-06,  5.69806798e-06,  6.06472076e-06,\n",
      "       -4.43247245e-06,  4.92825666e-06, -4.02277055e-06, -3.83930637e-06,\n",
      "        4.51433743e-06, -2.59508670e-06,  3.50307391e-06,  3.66382073e-06,\n",
      "        3.17004628e-06,  2.77906179e-06,  2.35540961e-06, -2.09643395e-06,\n",
      "        2.09900008e-06, -1.68052429e-06,  1.89875902e-06,  1.36508504e-06,\n",
      "       -1.34452011e-06, -1.32221271e-06, -1.16239232e-06,  1.25279018e-06,\n",
      "        1.08729898e-06, -1.04090191e-06, -9.57817520e-07, -6.32344324e-07,\n",
      "        8.51910045e-07,  7.41186170e-07,  6.48249284e-07,  5.32243007e-07,\n",
      "       -4.45103751e-07, -4.15343635e-07,  4.38027200e-07, -3.06360477e-07,\n",
      "        3.58065023e-07,  3.10239642e-07,  2.89457375e-07,  2.43887769e-07,\n",
      "       -1.86079234e-07, -1.41387218e-07,  1.87598957e-07,  1.85815750e-07,\n",
      "        1.43027592e-07,  1.23025615e-07, -9.23455303e-08,  9.36113622e-08,\n",
      "       -7.55532952e-08, -6.75816239e-08, -5.55982957e-08,  8.43691836e-08,\n",
      "        7.91369175e-08,  6.14984614e-08, -3.20401767e-08,  3.33200632e-08,\n",
      "       -2.23586643e-08,  2.56537067e-08,  2.05580957e-08, -1.50029340e-08,\n",
      "        1.45194701e-08,  1.21534276e-08, -8.29661317e-09, -6.07036332e-09,\n",
      "        6.07187101e-09, -1.14027253e-10,  1.21599342e-09,  3.03871328e-09],\n",
      "      dtype=float32), array([[-0.0751517 , -0.09043774,  0.22233164, ...,  0.00607287,\n",
      "        -0.0074894 , -0.01804905],\n",
      "       [-0.07848247,  0.03300553,  0.16951756, ...,  0.01048978,\n",
      "         0.01641059, -0.00097293],\n",
      "       [-0.00159468, -0.02701114, -0.00913245, ..., -0.21120684,\n",
      "        -0.1887667 , -0.0965566 ],\n",
      "       ...,\n",
      "       [ 0.00979589, -0.01742374, -0.02602994, ...,  0.03208097,\n",
      "        -0.02401186, -0.013632  ],\n",
      "       [-0.17093994, -0.04587521,  0.01303908, ...,  0.00320854,\n",
      "         0.00864689, -0.00441492],\n",
      "       [-0.03924368,  0.07016016, -0.02852255, ...,  0.04987773,\n",
      "        -0.01469346,  0.03045647]], dtype=float32))\n",
      "(array([ 8.6181238e+02,  1.4814913e-01,  8.1005313e-02,  3.2493375e-02,\n",
      "        1.2719306e-02,  1.0294050e-02,  7.0219543e-03,  2.5984517e-03,\n",
      "        2.4595535e-03,  1.7577008e-03,  1.5446076e-03,  8.6584216e-04,\n",
      "        5.6259485e-04,  4.3562750e-04,  3.5798913e-04,  2.9285357e-04,\n",
      "        2.7453253e-04,  1.7230336e-04,  1.4222518e-04,  1.2821340e-04,\n",
      "        1.1127142e-04,  7.9181780e-05,  5.6528876e-05,  4.8958907e-05,\n",
      "        4.0862978e-05,  3.8304053e-05, -2.7036192e-05,  3.2731994e-05,\n",
      "        3.1124589e-05,  2.8953807e-05,  2.6829586e-05, -2.0554853e-05,\n",
      "        2.2104599e-05, -1.6163229e-05, -1.5217627e-05,  1.9934181e-05,\n",
      "        1.7957029e-05,  1.7343431e-05,  1.4666306e-05,  1.4115041e-05,\n",
      "       -1.1417348e-05,  1.1150948e-05, -9.0104922e-06, -8.6009177e-06,\n",
      "        1.0037453e-05,  8.8105971e-06,  7.9902020e-06,  7.4461473e-06,\n",
      "       -6.1594001e-06,  6.8488171e-06,  6.0626244e-06, -4.9283058e-06,\n",
      "       -4.6425466e-06,  5.2547821e-06,  4.9523242e-06,  4.7401427e-06,\n",
      "       -3.8208914e-06,  4.2373199e-06, -3.3498654e-06, -2.8730947e-06,\n",
      "       -2.2618137e-06,  3.6839583e-06,  3.5870341e-06,  3.1931418e-06,\n",
      "        2.9217249e-06, -1.8826875e-06,  2.0280424e-06,  1.9370611e-06,\n",
      "       -1.4190006e-06,  1.6911042e-06, -1.2901606e-06,  1.5922326e-06,\n",
      "        1.4130320e-06,  1.3551686e-06,  1.1214862e-06, -9.4078075e-07,\n",
      "        1.0464383e-06,  9.4664199e-07, -6.6704604e-07, -6.1798988e-07,\n",
      "        8.4401717e-07,  7.1683786e-07,  5.9283803e-07, -4.9470151e-07,\n",
      "        4.6457663e-07,  4.3528024e-07, -3.2353876e-07, -2.9031133e-07,\n",
      "        3.1546818e-07,  3.0238215e-07, -1.9972732e-07, -2.1676922e-07,\n",
      "        2.7150648e-07, -1.3934694e-07,  2.1358881e-07,  1.7891904e-07,\n",
      "        1.5405733e-07,  1.4413867e-07,  1.2973534e-07,  9.6888890e-08,\n",
      "        8.7478384e-08, -8.8041979e-08, -8.0193658e-08, -7.1534053e-08,\n",
      "        5.8498291e-08, -5.5467993e-08, -4.5546454e-08, -2.9975698e-08,\n",
      "        3.5749235e-08,  3.3645989e-08, -2.3069926e-08,  2.4226905e-08,\n",
      "        2.0038815e-08, -1.2373397e-08,  8.6205594e-09,  7.0799020e-09,\n",
      "       -3.5228176e-10, -2.2532518e-09, -8.4571337e-09, -6.7954491e-09],\n",
      "      dtype=float32), array([[-0.06869897, -0.10890159,  0.02566364, ...,  0.00026288,\n",
      "         0.00390869, -0.00793718],\n",
      "       [-0.07500865, -0.11963566,  0.17085779, ..., -0.01126465,\n",
      "        -0.02680827, -0.0197316 ],\n",
      "       [-0.00090036, -0.01415716, -0.01020933, ..., -0.07942697,\n",
      "        -0.06996764,  0.11786405],\n",
      "       ...,\n",
      "       [ 0.01100498,  0.01058372, -0.05245846, ..., -0.11577958,\n",
      "         0.07985304,  0.11662616],\n",
      "       [-0.16884734, -0.04032216, -0.00962212, ..., -0.00748706,\n",
      "        -0.0040493 , -0.0094748 ],\n",
      "       [-0.04033428, -0.00525577, -0.0184478 , ...,  0.00465917,\n",
      "         0.04787638,  0.01183193]], dtype=float32))\n",
      "(array([ 8.55739868e+02,  1.79155841e-01,  9.95507613e-02,  3.90557535e-02,\n",
      "        1.87713895e-02,  9.74786188e-03,  6.59022247e-03,  5.30669931e-03,\n",
      "        3.21220467e-03,  2.52236263e-03,  2.27098283e-03,  1.09575863e-03,\n",
      "        8.49149423e-04,  5.77604922e-04,  4.40211268e-04,  3.12276505e-04,\n",
      "        2.82644032e-04,  2.10069586e-04,  1.61737946e-04,  1.38066855e-04,\n",
      "        1.24388724e-04,  7.17648145e-05,  5.76187740e-05,  5.12948209e-05,\n",
      "        4.26806437e-05,  3.74969750e-05,  3.28038986e-05, -2.72192592e-05,\n",
      "       -2.49591776e-05,  2.93225221e-05,  2.57642841e-05,  2.26862812e-05,\n",
      "       -1.86089601e-05,  1.98326270e-05,  1.77264956e-05,  1.71728989e-05,\n",
      "       -1.31490460e-05,  1.51083068e-05, -1.08558761e-05, -1.03426291e-05,\n",
      "        1.22978472e-05,  1.16409819e-05,  1.05805957e-05,  9.78123990e-06,\n",
      "       -7.74978707e-06,  8.75866954e-06,  8.30543286e-06,  7.04094055e-06,\n",
      "       -5.78849540e-06, -5.05546586e-06,  6.78662991e-06, -4.43863792e-06,\n",
      "        6.13431530e-06,  5.38619406e-06,  5.63841513e-06,  4.77094591e-06,\n",
      "       -3.90458945e-06, -3.07787695e-06,  3.55739144e-06,  3.22222149e-06,\n",
      "        3.05591448e-06, -2.25182862e-06,  2.54027509e-06, -1.82948634e-06,\n",
      "        2.10548205e-06,  1.92004063e-06, -1.64974620e-06,  1.70783937e-06,\n",
      "        1.60598779e-06,  1.44482078e-06, -1.19993672e-06, -1.14045986e-06,\n",
      "        1.23242671e-06, -9.75922148e-07, -7.83661903e-07,  1.08110942e-06,\n",
      "        9.79936885e-07,  8.41494568e-07,  9.19111301e-07, -6.60027411e-07,\n",
      "        6.44268709e-07,  5.72625254e-07, -4.48500828e-07, -4.11722965e-07,\n",
      "        4.66071242e-07,  3.98504653e-07, -2.84195892e-07, -2.50334409e-07,\n",
      "        2.89374498e-07,  3.18227421e-07,  3.12001049e-07, -2.13280771e-07,\n",
      "        2.43096679e-07, -1.84538834e-07,  1.85344234e-07, -1.19272656e-07,\n",
      "       -1.10223183e-07,  1.49842492e-07,  1.38993428e-07, -7.72161357e-08,\n",
      "        1.17356159e-07,  1.00339378e-07,  7.47153095e-08,  5.80144111e-08,\n",
      "       -4.76284434e-08,  4.14174757e-08, -3.69368465e-08, -3.12557589e-08,\n",
      "        3.18322328e-08,  2.54717136e-08,  1.75851085e-08, -1.77245827e-08,\n",
      "       -1.65471015e-08, -1.03146673e-08,  1.10781455e-08, -6.44162812e-09,\n",
      "       -2.79335510e-09,  7.39413197e-09,  3.67863850e-09,  4.20794777e-09],\n",
      "      dtype=float32), array([[-6.73958808e-02, -2.51269907e-01, -2.62085861e-03, ...,\n",
      "         1.34127373e-02,  2.07591872e-03,  1.23295363e-03],\n",
      "       [-7.22250342e-02, -9.36983004e-02,  1.43038183e-01, ...,\n",
      "        -1.03542279e-03, -1.93682776e-04,  1.65298190e-02],\n",
      "       [-7.26897037e-04, -2.28880756e-02, -1.27797434e-02, ...,\n",
      "        -1.74935516e-02, -6.10774495e-02,  2.83090293e-01],\n",
      "       ...,\n",
      "       [ 1.08643444e-02, -3.51137929e-02, -3.93718705e-02, ...,\n",
      "         4.91126589e-02,  8.28139707e-02,  1.07521545e-02],\n",
      "       [-1.68934762e-01, -5.92498183e-02, -2.07647551e-02, ...,\n",
      "        -5.33057330e-03, -3.12552019e-03,  8.41514021e-03],\n",
      "       [-3.95549238e-02,  3.59995477e-02, -2.26379652e-02, ...,\n",
      "        -2.34632287e-02,  6.40761200e-03, -2.38587540e-02]], dtype=float32))\n",
      "(array([ 8.31395142e+02,  5.76809905e-02,  2.90168282e-02,  1.16738258e-02,\n",
      "        8.10294785e-03,  5.16306004e-03,  3.29963723e-03,  2.66406080e-03,\n",
      "        9.51135706e-04,  7.53457949e-04,  5.46837109e-04,  3.47848254e-04,\n",
      "        2.77476036e-04,  2.19645735e-04,  1.83418000e-04,  1.41178796e-04,\n",
      "        9.84785584e-05,  8.67035415e-05,  7.33903289e-05,  6.74679904e-05,\n",
      "        4.95844397e-05,  3.70612361e-05, -2.38171215e-05,  2.97898241e-05,\n",
      "        2.81176417e-05,  2.30264686e-05,  1.98027410e-05, -1.68922870e-05,\n",
      "        1.81379619e-05,  1.77204856e-05,  1.62542456e-05, -1.61125517e-05,\n",
      "       -1.39033200e-05, -1.26398563e-05, -1.14811101e-05,  1.31937641e-05,\n",
      "        1.24826829e-05,  1.13175875e-05, -9.29135058e-06,  1.04814735e-05,\n",
      "       -6.66633377e-06,  8.68061124e-06,  8.32367004e-06,  7.65143704e-06,\n",
      "       -6.07236643e-06,  7.13811278e-06, -5.37176220e-06,  6.19172260e-06,\n",
      "        5.47880836e-06,  5.50410959e-06, -4.53882922e-06,  4.96750226e-06,\n",
      "       -4.17934643e-06,  4.34724234e-06,  4.25769394e-06,  3.63331083e-06,\n",
      "        3.33934167e-06,  3.07949358e-06, -2.59743524e-06, -2.19530489e-06,\n",
      "        2.57206830e-06, -1.74879756e-06, -1.64564085e-06,  2.17028128e-06,\n",
      "        2.00632962e-06,  1.67653980e-06, -1.20889683e-06, -9.51712764e-07,\n",
      "       -8.37939638e-07,  1.48163178e-06,  1.32473554e-06,  1.24695680e-06,\n",
      "        1.12989233e-06,  9.55681458e-07,  8.30108831e-07, -5.98917097e-07,\n",
      "        7.40612506e-07, -4.99110911e-07,  5.92057916e-07,  5.67978248e-07,\n",
      "       -4.44229272e-07,  5.15696854e-07, -3.77480262e-07,  4.45152210e-07,\n",
      "        3.94707911e-07, -3.07219807e-07,  3.44919584e-07,  2.83934838e-07,\n",
      "       -2.56528153e-07, -2.26228480e-07, -2.12283481e-07,  2.36010294e-07,\n",
      "        1.97283384e-07, -1.50062931e-07,  1.82785513e-07, -1.13522240e-07,\n",
      "       -7.94207224e-08,  1.44935512e-07,  1.39780141e-07, -5.01916304e-08,\n",
      "        1.15291940e-07,  9.70406546e-08,  8.49522905e-08,  7.52030971e-08,\n",
      "       -2.34295783e-08,  5.76423780e-08,  4.56296654e-08, -1.68657355e-08,\n",
      "        3.66607296e-08, -9.90776083e-09,  3.27374892e-08, -7.21144344e-09,\n",
      "       -1.02021946e-09,  6.33930641e-09,  2.84685653e-09,  3.67482156e-09,\n",
      "        2.49603396e-08,  2.21139498e-08,  1.66506613e-08,  1.40236276e-08],\n",
      "      dtype=float32), array([[ 0.06429145,  0.0883623 ,  0.18407547, ...,  0.01685346,\n",
      "         0.02585758, -0.02561483],\n",
      "       [ 0.06934694, -0.14109434,  0.04167791, ...,  0.00127903,\n",
      "        -0.01398583,  0.00898557],\n",
      "       [ 0.00047509,  0.00923124, -0.04481094, ..., -0.3049022 ,\n",
      "         0.12366605, -0.19533989],\n",
      "       ...,\n",
      "       [-0.01098836,  0.05474927, -0.00948646, ..., -0.04971493,\n",
      "        -0.00529617, -0.02238714],\n",
      "       [ 0.16819571, -0.01856439, -0.13888657, ..., -0.00431788,\n",
      "        -0.00342905,  0.00783946],\n",
      "       [ 0.03940539,  0.03913119,  0.0247751 , ..., -0.00839437,\n",
      "         0.04674744,  0.01279541]], dtype=float32))\n",
      "(array([ 8.3214764e+02,  4.9626058e-01,  6.7821734e-02,  4.4410150e-02,\n",
      "        3.7072081e-02,  1.8563578e-02,  1.0256426e-02,  6.3317143e-03,\n",
      "        4.6401615e-03,  3.7122690e-03,  2.4680637e-03,  1.6607922e-03,\n",
      "        9.2329725e-04,  6.4375252e-04,  5.9230108e-04,  5.0901953e-04,\n",
      "        3.6128599e-04,  3.2093583e-04,  2.1046244e-04,  1.7712262e-04,\n",
      "        1.6650058e-04,  1.3446885e-04,  8.9997520e-05,  8.5801767e-05,\n",
      "        7.0382528e-05,  6.3343497e-05,  5.7503199e-05,  4.3932359e-05,\n",
      "        3.8655046e-05, -2.2684328e-05,  3.3103206e-05,  2.7922197e-05,\n",
      "        2.4107205e-05,  2.3600654e-05,  2.1389869e-05, -1.9500783e-05,\n",
      "       -1.7282358e-05,  2.0141410e-05,  1.7586010e-05,  1.5835161e-05,\n",
      "       -1.3282792e-05,  1.3907176e-05,  1.1331138e-05, -1.0124243e-05,\n",
      "       -9.6936437e-06,  9.8906739e-06, -7.1032227e-06,  8.9465775e-06,\n",
      "        8.0986838e-06,  7.4132527e-06, -5.2631563e-06,  6.5211602e-06,\n",
      "        5.7523953e-06,  5.6489339e-06, -5.1012548e-06, -4.3581990e-06,\n",
      "        4.7619756e-06, -3.5355490e-06,  4.0321879e-06,  3.5934486e-06,\n",
      "        3.1279631e-06, -2.9837497e-06, -2.7106632e-06,  2.8402067e-06,\n",
      "       -2.1780811e-06,  2.4439641e-06, -1.8819985e-06,  2.2455602e-06,\n",
      "        2.0313557e-06,  1.7538805e-06, -1.5016255e-06, -1.3498238e-06,\n",
      "        1.5301174e-06,  1.3423318e-06, -7.6751536e-07, -8.4353019e-07,\n",
      "       -8.8780229e-07,  1.1851204e-06,  1.1204701e-06,  9.2317180e-07,\n",
      "        8.5381953e-07,  7.1251588e-07, -5.8159344e-07,  5.8797019e-07,\n",
      "       -4.8919475e-07,  5.2766478e-07, -3.3488757e-07, -3.1429190e-07,\n",
      "        4.3419158e-07,  3.5853091e-07,  2.8958394e-07,  2.7062359e-07,\n",
      "        2.4045340e-07, -1.5016984e-07,  1.9099673e-07,  1.7847486e-07,\n",
      "        1.5076647e-07,  1.2654345e-07, -1.2858334e-07, -1.2028630e-07,\n",
      "       -9.0746546e-08,  9.2389350e-08, -6.1729075e-08, -5.7976795e-08,\n",
      "        6.6626598e-08,  5.5104753e-08,  3.6018289e-08,  3.4885286e-08,\n",
      "       -2.9369588e-08, -2.3513236e-08, -2.6848912e-08, -1.2187428e-08,\n",
      "        1.5903625e-08,  1.2174591e-08,  1.4153178e-08, -7.3790667e-09,\n",
      "       -6.2977836e-09,  5.9384644e-09, -6.4044225e-10,  1.2401341e-09],\n",
      "      dtype=float32), array([[-0.06535231, -0.18226211,  0.18163812, ..., -0.00290554,\n",
      "         0.01163399,  0.00630244],\n",
      "       [-0.06965841, -0.0364891 , -0.10001516, ..., -0.00868318,\n",
      "         0.0181511 ,  0.03572752],\n",
      "       [-0.00096748, -0.02169863, -0.00237586, ...,  0.01731637,\n",
      "         0.00799417,  0.02290845],\n",
      "       ...,\n",
      "       [ 0.01059246, -0.04256005,  0.04657308, ..., -0.06422851,\n",
      "        -0.07860976, -0.0166824 ],\n",
      "       [-0.16891943, -0.08336952, -0.04065034, ...,  0.00612   ,\n",
      "        -0.00094466, -0.00619868],\n",
      "       [-0.03872501,  0.05353172,  0.02286915, ..., -0.04143752,\n",
      "         0.00238611,  0.07313072]], dtype=float32))\n",
      "(array([ 8.9947839e+02,  2.9595792e-01,  2.4193192e-01,  6.7015916e-02,\n",
      "        2.2304764e-02,  1.9556386e-02,  1.1127138e-02,  7.0541031e-03,\n",
      "        3.8146672e-03,  2.8408999e-03,  1.6879668e-03,  1.0829079e-03,\n",
      "        8.6641609e-04,  6.6013989e-04,  5.2307651e-04,  2.1421982e-04,\n",
      "        1.8147765e-04,  1.3247502e-04,  9.1563030e-05,  7.6181983e-05,\n",
      "        5.7370762e-05,  5.2621570e-05, -3.1679094e-05,  3.4234727e-05,\n",
      "        3.0109084e-05,  2.7015221e-05, -2.2531976e-05, -1.9723315e-05,\n",
      "        2.3000066e-05,  2.1093172e-05, -1.7017232e-05,  1.9086661e-05,\n",
      "        1.7020257e-05,  1.6619506e-05,  1.5309070e-05, -1.3363413e-05,\n",
      "       -1.2456919e-05,  1.1817281e-05, -9.1832608e-06,  1.0475106e-05,\n",
      "        9.7585516e-06,  8.8575189e-06,  8.4144303e-06, -7.1380809e-06,\n",
      "       -6.7236297e-06,  7.4789077e-06, -5.5718178e-06,  5.9253143e-06,\n",
      "        5.1651064e-06,  4.7816025e-06, -4.0138202e-06, -4.2138718e-06,\n",
      "       -3.3295635e-06,  3.8376893e-06,  3.5950302e-06, -2.7326887e-06,\n",
      "        2.9604644e-06,  2.6947189e-06, -2.4318401e-06, -1.8462608e-06,\n",
      "       -1.5758324e-06,  2.3808029e-06,  2.4202279e-06,  2.0362265e-06,\n",
      "        1.5742983e-06,  1.4623871e-06,  1.3408592e-06,  1.2282607e-06,\n",
      "       -1.1769847e-06, -1.0244279e-06, -8.4142488e-07,  9.7255281e-07,\n",
      "        8.7633850e-07, -6.9931218e-07,  8.0383205e-07, -6.5011324e-07,\n",
      "        6.3407100e-07,  6.2044438e-07, -4.9052591e-07, -5.0883961e-07,\n",
      "        5.5566528e-07, -3.1493573e-07,  4.1103127e-07,  3.8190640e-07,\n",
      "        3.4578741e-07, -2.3557939e-07, -1.9094591e-07,  2.1270439e-07,\n",
      "        2.3320868e-07,  1.6678646e-07,  1.4901036e-07, -1.1712549e-07,\n",
      "       -1.0872636e-07,  1.2256228e-07,  1.1174130e-07,  9.8186739e-08,\n",
      "       -5.5135146e-08,  8.5378822e-08,  7.8792588e-08, -4.8026429e-08,\n",
      "       -4.8303907e-08, -2.9751284e-08,  6.0338678e-08, -3.5975958e-08,\n",
      "       -1.5310999e-08,  4.6633666e-08,  4.2604476e-08,  3.6529272e-08,\n",
      "       -9.7348600e-09,  3.1799342e-08,  3.0970529e-08, -6.8698047e-09,\n",
      "       -2.7956364e-09,  1.5649002e-08, -1.5163384e-10,  2.5632600e-09,\n",
      "        3.4907626e-09,  6.3352026e-09,  9.8466968e-09,  1.2626494e-08],\n",
      "      dtype=float32), array([[-0.07492246, -0.1126658 , -0.17145048, ..., -0.00135263,\n",
      "         0.015248  ,  0.00120327],\n",
      "       [-0.06629483,  0.16218348, -0.13370602, ...,  0.02751982,\n",
      "         0.02295959, -0.01122383],\n",
      "       [-0.00066428, -0.01825327,  0.00392908, ..., -0.0534425 ,\n",
      "        -0.05618571, -0.32365918],\n",
      "       ...,\n",
      "       [ 0.01038102, -0.02664441,  0.02887092, ...,  0.03532523,\n",
      "        -0.00570928,  0.0923754 ],\n",
      "       [-0.17325222, -0.01601694, -0.02457549, ..., -0.00680649,\n",
      "         0.00876069, -0.00589316],\n",
      "       [-0.04083727, -0.00311975,  0.04048812, ...,  0.00668677,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.01719631,  0.03218817]], dtype=float32))\n",
      "(array([ 9.4827966e+02,  2.9331839e+00,  5.3041172e-01,  1.8845040e-01,\n",
      "        8.8452570e-02,  5.8413986e-02,  4.5811482e-02,  2.9929837e-02,\n",
      "        1.8166710e-02,  1.2554898e-02,  7.3686894e-03,  5.7635349e-03,\n",
      "        3.5197549e-03,  2.7223655e-03,  2.2089547e-03,  1.7079253e-03,\n",
      "        1.3052227e-03,  9.0871775e-04,  7.7699812e-04,  6.6618290e-04,\n",
      "        6.1025884e-04,  5.7652663e-04,  4.0538551e-04,  3.5478061e-04,\n",
      "        2.7271186e-04,  1.8912132e-04,  1.5266279e-04,  1.0542522e-04,\n",
      "        9.4416893e-05,  8.1175924e-05,  5.9545830e-05,  3.7589733e-05,\n",
      "       -2.6665221e-05, -2.3430086e-05, -2.2379918e-05,  3.0228572e-05,\n",
      "        2.8855760e-05,  2.5663785e-05,  2.4613773e-05,  2.2574366e-05,\n",
      "        2.1159223e-05, -1.7898523e-05, -1.4748711e-05,  1.5652144e-05,\n",
      "        1.4589001e-05, -1.2851631e-05,  1.0467156e-05, -8.9345849e-06,\n",
      "       -8.5799984e-06,  8.5194142e-06, -7.4165841e-06,  7.7169343e-06,\n",
      "        7.3423366e-06, -5.8075707e-06,  6.1902638e-06,  5.5000992e-06,\n",
      "       -4.5105812e-06,  4.9557220e-06, -4.2327069e-06,  4.2747979e-06,\n",
      "       -3.4417430e-06, -2.7121098e-06,  3.9699225e-06,  3.5351700e-06,\n",
      "        2.9616288e-06,  2.5939448e-06,  2.3692664e-06,  2.1187000e-06,\n",
      "        1.8034200e-06, -1.6169130e-06, -1.3314663e-06,  1.4879930e-06,\n",
      "       -1.0574560e-06,  1.1573461e-06,  1.0662129e-06,  9.1079568e-07,\n",
      "        8.2679088e-07,  7.8352980e-07, -7.4131066e-07, -6.9104743e-07,\n",
      "        5.6384579e-07, -6.1165730e-07, -5.4003618e-07,  5.0354981e-07,\n",
      "       -4.4684262e-07, -3.8866813e-07,  3.1845056e-07, -2.8009592e-07,\n",
      "        2.9801953e-07,  2.7442027e-07, -2.2736096e-07, -1.9855369e-07,\n",
      "        2.3832833e-07,  2.0694496e-07, -1.5399785e-07,  1.6304521e-07,\n",
      "        1.7076330e-07, -1.1675753e-07,  1.3774147e-07,  1.0726381e-07,\n",
      "        7.9120227e-08, -7.8064524e-08, -6.5373051e-08, -4.4774939e-08,\n",
      "        5.1748135e-08,  4.2096364e-08, -2.9896423e-08,  3.2028652e-08,\n",
      "        2.7231501e-08, -1.1757581e-08,  2.1876952e-08,  1.5919632e-08,\n",
      "       -8.9519343e-09,  1.1228136e-08,  8.2495317e-09, -3.3003451e-09,\n",
      "       -1.7666731e-09,  9.3151553e-10,  2.7784786e-09,  4.8778301e-09],\n",
      "      dtype=float32), array([[ 0.08288712,  0.20988154,  0.01833126, ..., -0.00455295,\n",
      "        -0.01547497, -0.02368571],\n",
      "       [ 0.07291054,  0.12189554, -0.07750181, ...,  0.01108951,\n",
      "         0.0065369 , -0.01056014],\n",
      "       [ 0.00071954, -0.00276231,  0.01579899, ..., -0.05928773,\n",
      "        -0.06995697,  0.03345914],\n",
      "       ...,\n",
      "       [-0.00993848, -0.01337571,  0.09380359, ...,  0.00464938,\n",
      "         0.01102701, -0.0879611 ],\n",
      "       [ 0.17314325, -0.00502622, -0.00072297, ..., -0.00829187,\n",
      "         0.00062889, -0.00517528],\n",
      "       [ 0.04045741, -0.00709139,  0.05517583, ..., -0.015689  ,\n",
      "        -0.01095135, -0.01181267]], dtype=float32))\n",
      "(array([ 9.72044922e+02,  1.11009431e+00,  2.29393229e-01,  1.57581791e-01,\n",
      "        7.50624314e-02,  6.01590127e-02,  4.50345725e-02,  1.92634203e-02,\n",
      "        1.66726317e-02,  6.29415317e-03,  5.60574979e-03,  4.83755860e-03,\n",
      "        2.99911923e-03,  2.45045102e-03,  1.94227230e-03,  1.19579409e-03,\n",
      "        8.60467961e-04,  7.68010272e-04,  7.24664191e-04,  5.63918962e-04,\n",
      "        4.76197543e-04,  4.57202550e-04,  3.76657903e-04,  2.75205821e-04,\n",
      "        2.60230445e-04,  2.31181053e-04,  1.68046157e-04,  1.21857454e-04,\n",
      "        1.18435790e-04,  1.12156013e-04,  7.59851027e-05,  6.37778576e-05,\n",
      "        5.80383021e-05,  5.28018500e-05, -2.82242945e-05,  4.14914102e-05,\n",
      "        3.67806206e-05,  3.53464311e-05,  3.10343639e-05,  2.89869276e-05,\n",
      "       -2.48065426e-05, -1.80970073e-05,  2.64602604e-05,  2.43750765e-05,\n",
      "        2.29027610e-05,  2.03460477e-05,  1.90324663e-05, -1.53489855e-05,\n",
      "       -1.38219775e-05, -1.33571220e-05,  1.45569411e-05,  1.30023373e-05,\n",
      "        1.22541032e-05, -8.53401980e-06,  1.10799638e-05,  1.00501520e-05,\n",
      "       -7.57422822e-06,  8.82605582e-06, -6.86632256e-06, -4.55234658e-06,\n",
      "        7.39776533e-06,  7.06669744e-06,  6.64260688e-06,  6.13168322e-06,\n",
      "        4.95690665e-06,  4.74998751e-06, -3.80992901e-06,  3.79243716e-06,\n",
      "       -3.08836093e-06,  3.24935331e-06,  2.69190355e-06,  2.41704674e-06,\n",
      "       -2.11667884e-06, -1.81456437e-06,  2.05985589e-06,  1.94170025e-06,\n",
      "       -1.62913739e-06,  1.60419597e-06, -1.42078432e-06, -1.09641678e-06,\n",
      "       -8.84346036e-07,  1.20647883e-06,  1.02153786e-06,  1.06081495e-06,\n",
      "        7.93952950e-07, -6.64840343e-07,  6.17321746e-07, -5.60476110e-07,\n",
      "       -4.39255359e-07,  5.39117423e-07,  4.67984080e-07,  3.87042604e-07,\n",
      "        3.48404200e-07, -2.30956815e-07,  2.59928044e-07, -1.83345236e-07,\n",
      "        1.72627082e-07, -1.42695441e-07, -1.10974426e-07,  1.38166214e-07,\n",
      "        1.20953402e-07, -7.51059446e-08,  7.49254809e-08, -5.44256515e-08,\n",
      "        5.31745705e-08, -4.40689618e-08, -3.42682220e-08,  3.16007096e-08,\n",
      "       -2.20994707e-08,  2.27674679e-08,  1.98141059e-08, -1.79795645e-08,\n",
      "       -1.29075444e-08,  9.08587960e-09,  6.22386676e-09, -6.73694567e-09,\n",
      "        3.76364051e-09,  1.34389444e-09, -2.74438894e-09, -8.59116278e-10],\n",
      "      dtype=float32), array([[-0.08785661,  0.18602067,  0.09935936, ..., -0.00313225,\n",
      "        -0.0217671 ,  0.00520357],\n",
      "       [-0.07636406,  0.06687229, -0.1930712 , ..., -0.0017627 ,\n",
      "        -0.0137364 , -0.00705768],\n",
      "       [-0.00113657, -0.01689614, -0.00513444, ...,  0.04393209,\n",
      "        -0.18021858, -0.20670298],\n",
      "       ...,\n",
      "       [ 0.011318  ,  0.00452658,  0.00342381, ...,  0.11378036,\n",
      "        -0.10074758,  0.13192475],\n",
      "       [-0.17460358, -0.01456173, -0.01639386, ...,  0.00206552,\n",
      "        -0.00219398, -0.01147777],\n",
      "       [-0.04091601,  0.02086235, -0.00411921, ...,  0.01904376,\n",
      "        -0.03783349, -0.02547253]], dtype=float32))\n",
      "(array([ 9.73945068e+02,  3.43737423e-01,  1.91925123e-01,  1.13732204e-01,\n",
      "        6.19598441e-02,  3.51800285e-02,  2.48229429e-02,  1.47632612e-02,\n",
      "        9.03790817e-03,  3.96116497e-03,  3.40255885e-03,  1.40952109e-03,\n",
      "        1.06972537e-03,  7.37723894e-04,  6.06000132e-04,  5.53978316e-04,\n",
      "        3.20778519e-04,  2.75128346e-04,  2.50252662e-04,  2.10428494e-04,\n",
      "        1.66991507e-04,  1.60100710e-04,  1.39369222e-04,  9.13945332e-05,\n",
      "        7.41593976e-05,  6.93215188e-05,  5.47773561e-05,  4.71890817e-05,\n",
      "       -3.55160664e-05,  3.36444973e-05,  3.16696860e-05,  2.92211098e-05,\n",
      "       -2.60203960e-05, -2.21181981e-05, -1.79191466e-05, -1.67221897e-05,\n",
      "        2.67130617e-05,  2.45093433e-05,  2.36323194e-05,  1.88454542e-05,\n",
      "        2.14845222e-05,  2.23701336e-05,  1.45732174e-05, -1.28027250e-05,\n",
      "        1.36769531e-05,  1.32961013e-05, -1.03192324e-05,  1.13783999e-05,\n",
      "       -8.27001986e-06,  9.81451012e-06,  9.32005059e-06,  8.78385072e-06,\n",
      "        7.97018492e-06, -6.87176089e-06, -6.31771809e-06,  7.24535585e-06,\n",
      "        5.86037322e-06,  5.63880030e-06,  5.41378131e-06, -4.53711118e-06,\n",
      "        4.93176412e-06, -3.93978735e-06, -2.95122982e-06, -2.47011121e-06,\n",
      "        4.16502735e-06,  3.89972593e-06,  3.53499331e-06,  2.85345936e-06,\n",
      "        2.77592312e-06,  2.42315787e-06,  2.13257636e-06, -1.68386555e-06,\n",
      "        1.94749123e-06, -1.44182252e-06,  1.59092633e-06, -1.18589583e-06,\n",
      "        1.32193941e-06,  1.36738424e-06, -9.39065728e-07,  1.14325951e-06,\n",
      "        9.99383474e-07, -6.92380411e-07, -6.03656986e-07, -5.72499857e-07,\n",
      "        8.23681603e-07,  7.03498358e-07,  6.04646630e-07,  4.85731789e-07,\n",
      "        4.00279049e-07, -3.66316442e-07, -3.18102622e-07,  3.44064205e-07,\n",
      "       -2.15780659e-07,  2.53271764e-07,  1.74516074e-07, -1.64288338e-07,\n",
      "       -1.22309956e-07, -1.01695043e-07,  1.68682547e-07,  1.49223069e-07,\n",
      "        1.31401464e-07,  9.35327265e-08,  1.04139190e-07,  5.72195198e-08,\n",
      "       -5.54539703e-08, -4.65133603e-08,  4.13181986e-08, -3.92619803e-08,\n",
      "        3.65006194e-08,  2.63305964e-08,  1.83580120e-08, -1.54939119e-08,\n",
      "       -1.33168392e-08,  8.55114468e-09,  7.08520709e-09, -9.12543374e-09,\n",
      "       -5.57512791e-09, -1.92429650e-09,  1.39851897e-09,  2.72622813e-10],\n",
      "      dtype=float32), array([[-0.0869659 , -0.18057144,  0.02400042, ..., -0.00146641,\n",
      "        -0.01571656, -0.00242317],\n",
      "       [-0.07552411, -0.09896249, -0.1185003 , ...,  0.00662438,\n",
      "         0.00994865,  0.01217064],\n",
      "       [-0.0015912 ,  0.02231114,  0.00704039, ...,  0.24507137,\n",
      "        -0.00624062,  0.24678971],\n",
      "       ...,\n",
      "       [ 0.01121625,  0.01435892,  0.09375308, ..., -0.04806707,\n",
      "        -0.0851398 , -0.0094875 ],\n",
      "       [-0.17475016,  0.01862608, -0.01358028, ..., -0.00157439,\n",
      "         0.00479261,  0.00048961],\n",
      "       [-0.04020971, -0.01343305,  0.04385367, ...,  0.03096644,\n",
      "        -0.05650027, -0.01480967]], dtype=float32))\n",
      "(array([ 9.6059741e+02,  8.2426089e-01,  1.0134436e-01,  7.7069886e-02,\n",
      "        6.1025921e-02,  3.4213156e-02,  1.8640002e-02,  1.1875652e-02,\n",
      "        5.6641740e-03,  3.3344412e-03,  2.6472679e-03,  1.4050622e-03,\n",
      "        1.0885826e-03,  9.0130151e-04,  8.3024648e-04,  5.4858229e-04,\n",
      "        3.3255771e-04,  2.6611559e-04,  2.5769876e-04,  1.7995406e-04,\n",
      "        1.5933417e-04,  1.5713049e-04,  1.0521694e-04,  7.7858749e-05,\n",
      "        6.9438371e-05,  5.9616505e-05,  4.1478939e-05, -2.9098974e-05,\n",
      "        3.3003453e-05,  3.1243075e-05,  2.8195102e-05, -2.5659874e-05,\n",
      "       -2.3381268e-05, -1.8979297e-05, -1.7688786e-05,  2.0739284e-05,\n",
      "        1.9545238e-05,  1.7930754e-05,  1.7260842e-05, -1.4818494e-05,\n",
      "        1.5883850e-05,  1.5006268e-05,  1.3962934e-05,  1.3205537e-05,\n",
      "       -1.0189270e-05,  1.1327288e-05, -9.1202910e-06,  1.0055359e-05,\n",
      "        9.3755689e-06, -7.5658736e-06,  8.3827217e-06,  7.3982028e-06,\n",
      "       -5.7957263e-06, -5.6428003e-06,  6.1476144e-06, -5.1254897e-06,\n",
      "        5.6894901e-06,  5.1716779e-06, -4.3113741e-06, -3.6239528e-06,\n",
      "        4.4939329e-06, -2.7248097e-06,  3.8905719e-06,  3.2272671e-06,\n",
      "        3.0081246e-06, -2.6069870e-06,  2.5275194e-06,  2.1338840e-06,\n",
      "       -1.7849368e-06,  1.9840240e-06,  1.7671393e-06,  1.6521577e-06,\n",
      "       -1.1972909e-06, -1.0441249e-06, -8.8915590e-07,  1.3047990e-06,\n",
      "        1.0922060e-06,  1.0024539e-06,  8.2074047e-07,  7.7462255e-07,\n",
      "        7.1392230e-07, -4.0005725e-07,  5.3699978e-07,  4.5060710e-07,\n",
      "       -3.2790030e-07, -2.9901295e-07,  4.0154214e-07,  3.7934990e-07,\n",
      "        3.0276237e-07,  2.5671460e-07,  2.3495588e-07, -1.9242093e-07,\n",
      "        2.2345249e-07, -1.6755173e-07, -1.5463182e-07, -1.2169087e-07,\n",
      "        1.6167246e-07,  1.7516534e-07, -8.7937899e-08,  1.3068670e-07,\n",
      "       -7.5796166e-08,  8.6193744e-08,  6.5478581e-08, -4.5712568e-08,\n",
      "        5.8507982e-08,  4.2993811e-08, -3.1730163e-08, -2.5420508e-08,\n",
      "       -2.0875838e-08, -1.4866791e-08,  2.4400956e-08,  2.3913556e-08,\n",
      "        2.0335493e-08, -6.3714700e-09, -2.6156259e-09,  1.5577381e-08,\n",
      "        1.1388622e-08,  4.1349693e-10,  6.4078090e-09,  5.7174723e-09],\n",
      "      dtype=float32), array([[-0.08457854,  0.18445522,  0.00176449, ..., -0.00119051,\n",
      "        -0.00106795,  0.00169315],\n",
      "       [-0.07316078,  0.08438951,  0.12715447, ...,  0.00215375,\n",
      "         0.00808088,  0.00359928],\n",
      "       [-0.00164927, -0.01686249,  0.01021293, ..., -0.20289952,\n",
      "         0.14011608, -0.04990849],\n",
      "       ...,\n",
      "       [ 0.01118708, -0.02001769, -0.09749194, ..., -0.04102689,\n",
      "        -0.03021885,  0.05822289],\n",
      "       [-0.17456758, -0.02503902,  0.00392169, ...,  0.00553262,\n",
      "         0.00603426, -0.00277284],\n",
      "       [-0.0398661 ,  0.02551388, -0.00073783, ..., -0.01898885,\n",
      "         0.00767507,  0.0123214 ]], dtype=float32))\n",
      "(array([ 9.66210083e+02,  2.49795556e-01,  8.46833661e-02,  6.57788292e-02,\n",
      "        2.70943847e-02,  1.84954070e-02,  1.50180478e-02,  7.01508345e-03,\n",
      "        6.01686630e-03,  2.86657014e-03,  2.12754612e-03,  7.90399266e-04,\n",
      "        7.80187605e-04,  5.74375212e-04,  4.31408786e-04,  3.78372293e-04,\n",
      "        3.05664667e-04,  2.49235862e-04,  2.30026315e-04,  1.31541485e-04,\n",
      "        1.20091296e-04,  9.82738857e-05,  7.82975694e-05,  7.02242251e-05,\n",
      "        6.33433374e-05,  4.36340015e-05,  3.99220698e-05, -3.11010626e-05,\n",
      "       -2.78157531e-05,  3.61859675e-05,  3.58902143e-05, -2.22963117e-05,\n",
      "        2.97056613e-05,  2.72606376e-05,  2.41497728e-05, -1.70696749e-05,\n",
      "        2.07225366e-05,  1.90644350e-05, -1.29785121e-05,  1.74992347e-05,\n",
      "        1.78770624e-05,  1.58022212e-05, -1.12507132e-05,  1.39734511e-05,\n",
      "        1.29874561e-05,  1.19039287e-05,  1.00757898e-05, -8.54138216e-06,\n",
      "       -7.02531770e-06, -7.43801593e-06, -5.69821395e-06,  9.08017137e-06,\n",
      "        8.01595615e-06,  7.54270286e-06,  7.06201672e-06,  6.64872368e-06,\n",
      "        6.44902093e-06,  5.59670480e-06, -4.69900669e-06, -3.90999958e-06,\n",
      "        4.73031196e-06, -2.93353423e-06,  3.69007580e-06,  3.48005869e-06,\n",
      "        3.21636412e-06,  3.03927345e-06, -2.61563832e-06, -2.34082472e-06,\n",
      "        2.50512585e-06,  2.27336227e-06, -1.85043632e-06,  2.01603393e-06,\n",
      "       -1.17767343e-06,  1.53845144e-06,  1.39600752e-06,  1.23477446e-06,\n",
      "        1.07226504e-06,  9.31302282e-07, -8.76550985e-07, -7.37253515e-07,\n",
      "        7.07356890e-07, -6.29236183e-07,  6.44676447e-07,  6.20305457e-07,\n",
      "       -4.50064107e-07,  4.85243049e-07,  4.93951802e-07,  3.87951502e-07,\n",
      "        3.25495279e-07, -3.32695663e-07, -2.76403028e-07, -2.45919750e-07,\n",
      "        2.73981414e-07,  2.46537184e-07,  2.25768304e-07,  1.80701477e-07,\n",
      "       -1.45779836e-07, -1.36899374e-07, -1.07608173e-07, -8.01130255e-08,\n",
      "        1.39073805e-07,  1.14532220e-07,  1.12087378e-07,  8.48126476e-08,\n",
      "        7.94490305e-08, -3.81178609e-08,  5.35952616e-08,  3.73734466e-08,\n",
      "       -1.93343013e-08, -2.36085516e-08,  2.39821478e-08, -1.25905038e-08,\n",
      "        1.62964415e-08,  1.93131751e-08, -8.91742502e-09, -6.26554497e-09,\n",
      "       -7.13701154e-10,  1.27224609e-09,  5.34524736e-09,  8.30026892e-09],\n",
      "      dtype=float32), array([[-0.09008009, -0.12892431,  0.10612797, ..., -0.00409136,\n",
      "         0.01490178, -0.00719556],\n",
      "       [-0.07332255, -0.14986047, -0.0733904 , ..., -0.00062268,\n",
      "        -0.00242713,  0.00569515],\n",
      "       [-0.00108636,  0.01624953, -0.01481644, ..., -0.18828255,\n",
      "        -0.35523587,  0.30297476],\n",
      "       ...,\n",
      "       [ 0.01158585,  0.0911623 ,  0.03830312, ...,  0.11045548,\n",
      "         0.06503247, -0.03168428],\n",
      "       [-0.17448588,  0.02559988, -0.01419041, ..., -0.00707623,\n",
      "        -0.00626224, -0.0008394 ],\n",
      "       [-0.04055694,  0.02882929,  0.05217141, ..., -0.01659801,\n",
      "        -0.00274038,  0.00629503]], dtype=float32))\n",
      "(array([ 9.5998285e+02,  4.5662382e-01,  1.5316108e-01,  1.4669381e-01,\n",
      "        7.2141595e-02,  2.4741912e-02,  1.1614196e-02,  9.0700146e-03,\n",
      "        8.0748592e-03,  5.1615345e-03,  2.3844675e-03,  1.5876953e-03,\n",
      "        1.3397726e-03,  1.0011282e-03,  5.7037914e-04,  5.1828066e-04,\n",
      "        3.7906319e-04,  3.0054024e-04,  2.8849367e-04,  1.9635590e-04,\n",
      "        1.6591210e-04,  1.2578606e-04,  9.4532472e-05,  7.9444253e-05,\n",
      "        7.6185606e-05,  6.4257139e-05,  5.7588251e-05,  4.1270963e-05,\n",
      "       -2.9669556e-05,  3.5162026e-05,  3.4131870e-05,  3.1770167e-05,\n",
      "       -2.4349347e-05,  2.9061430e-05, -1.9728152e-05,  2.5283844e-05,\n",
      "       -1.7429940e-05,  2.1899263e-05,  2.1157968e-05,  2.0098492e-05,\n",
      "       -1.6196374e-05, -1.4603300e-05, -1.1297117e-05,  1.7017910e-05,\n",
      "        1.6127320e-05,  1.5415884e-05,  1.3548966e-05,  1.1979682e-05,\n",
      "        1.1451703e-05, -8.7698281e-06,  1.0278873e-05, -7.4796972e-06,\n",
      "        8.9278137e-06,  7.4333734e-06,  7.3282899e-06, -4.8935094e-06,\n",
      "        6.3034995e-06,  5.6327417e-06, -4.0078016e-06,  4.7386834e-06,\n",
      "       -3.7380591e-06,  4.2090619e-06,  3.7576608e-06,  3.5748467e-06,\n",
      "       -2.4802127e-06,  3.3259148e-06, -1.9846855e-06, -1.6367836e-06,\n",
      "        2.8060058e-06,  2.6592847e-06,  2.3001892e-06,  2.0422469e-06,\n",
      "        1.8723290e-06,  1.6382651e-06, -1.4011531e-06,  1.2724780e-06,\n",
      "       -1.0404464e-06, -9.0367860e-07,  1.0622114e-06,  9.0213973e-07,\n",
      "       -7.8016166e-07, -7.4249681e-07,  8.0449445e-07,  6.3224462e-07,\n",
      "        6.9745482e-07, -4.7600466e-07, -4.2982404e-07,  5.4277615e-07,\n",
      "        4.8628630e-07,  4.2235393e-07, -2.2677361e-07,  3.0291673e-07,\n",
      "        2.9603009e-07,  2.1218469e-07,  1.9300870e-07, -1.7368554e-07,\n",
      "       -1.3810295e-07, -1.2410227e-07,  1.5066178e-07,  1.1640314e-07,\n",
      "        1.0981802e-07, -8.9049742e-08,  9.2394437e-08, -6.1261368e-08,\n",
      "        5.6230107e-08, -4.3524537e-08,  4.5426123e-08, -2.5043351e-08,\n",
      "       -2.0295246e-08,  2.8443793e-08,  2.6686955e-08, -1.3664219e-08,\n",
      "        1.6261914e-08, -8.2158671e-09, -4.2248529e-09, -1.3131395e-09,\n",
      "        7.2789574e-09,  5.3074145e-09,  5.0577476e-09,  2.8718818e-09],\n",
      "      dtype=float32), array([[-8.79923105e-02, -5.65295182e-02, -8.86498690e-02, ...,\n",
      "         1.98831297e-02, -3.88643914e-03,  1.38449781e-02],\n",
      "       [-7.28388354e-02, -1.05040353e-02,  5.49934618e-02, ...,\n",
      "         1.52041195e-02,  1.16329547e-02, -3.26473312e-03],\n",
      "       [-1.22245960e-03,  2.29346137e-02, -1.99318468e-03, ...,\n",
      "        -1.04967192e-01, -2.83954859e-01, -1.22270845e-01],\n",
      "       ...,\n",
      "       [ 1.08645661e-02, -8.44467133e-02,  4.22412045e-02, ...,\n",
      "         6.55277967e-02, -7.62242870e-03,  5.50873205e-03],\n",
      "       [-1.74124435e-01,  3.41436602e-02, -5.65408543e-02, ...,\n",
      "        -5.22717508e-03,  4.11480991e-03,  2.82923080e-04],\n",
      "       [-4.00041528e-02, -1.09512592e-02, -8.36184993e-02, ...,\n",
      "        -3.19282128e-03,  1.50625512e-03, -3.09269167e-02]], dtype=float32))\n",
      "(array([ 9.51883118e+02,  1.61426231e-01,  9.15635526e-02,  4.72183824e-02,\n",
      "        1.58800744e-02,  1.02775460e-02,  7.02353753e-03,  6.63822098e-03,\n",
      "        3.85004142e-03,  1.65242888e-03,  1.17849885e-03,  7.48714607e-04,\n",
      "        4.82011063e-04,  3.44386179e-04,  2.74671649e-04,  2.57320498e-04,\n",
      "        1.67957405e-04,  1.12363872e-04,  1.00180361e-04,  7.83964279e-05,\n",
      "        6.16187317e-05,  5.74068545e-05,  4.03340891e-05, -3.03050929e-05,\n",
      "       -2.59513545e-05, -2.51128968e-05,  3.05164085e-05,  2.88591309e-05,\n",
      "        2.80255153e-05,  2.67422201e-05,  2.53268863e-05, -1.92571988e-05,\n",
      "        2.16262360e-05, -1.75541718e-05,  2.01162638e-05, -1.63856730e-05,\n",
      "        1.72204072e-05,  1.52502234e-05,  1.43776524e-05, -1.09300754e-05,\n",
      "       -9.64100946e-06,  1.27086869e-05,  1.10063029e-05,  1.05005247e-05,\n",
      "       -8.05101809e-06, -7.44485124e-06,  9.65558138e-06,  8.91578111e-06,\n",
      "        8.35709579e-06, -5.73853504e-06, -4.43954741e-06,  7.46413434e-06,\n",
      "        6.93344646e-06,  6.64464960e-06,  5.27182010e-06,  5.03063711e-06,\n",
      "        4.55769350e-06, -3.37201618e-06,  4.03588820e-06,  3.71947340e-06,\n",
      "        3.24001371e-06, -2.34063396e-06, -2.06845812e-06,  2.64759751e-06,\n",
      "        2.20784636e-06, -1.85462750e-06, -1.51848042e-06,  2.01223293e-06,\n",
      "        1.92884454e-06, -1.35284654e-06,  1.69850171e-06,  1.58807757e-06,\n",
      "        1.42985914e-06, -1.01763385e-06, -9.51451057e-07,  1.31319132e-06,\n",
      "       -7.72306350e-07,  9.78621642e-07,  7.99552367e-07,  7.29890985e-07,\n",
      "        6.03380670e-07,  5.40645374e-07, -3.94934659e-07, -3.54927494e-07,\n",
      "       -3.01956874e-07,  4.56272346e-07,  3.81583419e-07,  3.52635084e-07,\n",
      "        2.86415258e-07, -2.34521096e-07,  2.20908049e-07, -1.85174841e-07,\n",
      "       -1.68921829e-07,  1.83381033e-07,  1.71912333e-07, -1.38413853e-07,\n",
      "       -8.17543580e-08,  1.55548463e-07,  1.38846005e-07,  8.89388332e-08,\n",
      "        1.03325405e-07, -5.87311675e-08, -4.71242174e-08,  5.50275132e-08,\n",
      "        5.15579544e-08,  4.46719106e-08, -2.95094438e-08,  3.69554627e-08,\n",
      "        3.27086163e-08,  2.52699941e-08, -2.05283559e-08,  1.96960901e-08,\n",
      "       -1.66295315e-08,  8.73926087e-09,  5.65335245e-09, -7.77163667e-09,\n",
      "        1.80588822e-09, -4.85002571e-09, -3.05940029e-09, -1.18899612e-09],\n",
      "      dtype=float32), array([[-0.08649258, -0.06263668, -0.31275013, ..., -0.01525388,\n",
      "        -0.01529005, -0.03749679],\n",
      "       [-0.06940326, -0.17130263,  0.05035452, ..., -0.02230266,\n",
      "         0.00677326, -0.02428322],\n",
      "       [-0.00121677,  0.01501781,  0.02003335, ...,  0.1201079 ,\n",
      "        -0.07271571, -0.11541343],\n",
      "       ...,\n",
      "       [ 0.01076903,  0.01727399,  0.12826657, ..., -0.00467723,\n",
      "         0.17389432, -0.01102956],\n",
      "       [-0.17446235,  0.03258137,  0.027579  , ..., -0.00282586,\n",
      "         0.00757899,  0.00976236],\n",
      "       [-0.03972442, -0.00661537,  0.05556774, ...,  0.00842652,\n",
      "         0.01168924, -0.01175023]], dtype=float32))\n",
      "(array([ 9.25580566e+02,  3.69244009e-01,  1.42488211e-01,  6.67682886e-02,\n",
      "        5.65400012e-02,  4.34268899e-02,  2.28717085e-02,  1.52828870e-02,\n",
      "        8.09331611e-03,  4.37171897e-03,  2.69217486e-03,  1.63328834e-03,\n",
      "        8.61006498e-04,  7.72315660e-04,  5.12703322e-04,  3.62051826e-04,\n",
      "        2.39737274e-04,  2.04286058e-04,  1.58589552e-04,  1.13886825e-04,\n",
      "        1.00059457e-04,  8.09840058e-05,  6.79945078e-05,  5.70696466e-05,\n",
      "        4.58550385e-05, -3.21819643e-05,  3.68571891e-05,  3.05887625e-05,\n",
      "        2.86763225e-05,  2.76062892e-05, -2.09069021e-05,  2.51687379e-05,\n",
      "        2.16242461e-05,  1.99362894e-05, -1.44291207e-05,  1.68733641e-05,\n",
      "       -1.36492645e-05, -1.14004852e-05,  1.43716697e-05,  1.32928762e-05,\n",
      "        1.28756628e-05, -1.05715790e-05,  1.17673699e-05,  1.15801322e-05,\n",
      "       -8.92766911e-06,  9.89879300e-06, -7.34762034e-06,  8.55016060e-06,\n",
      "       -5.93062987e-06,  7.50135814e-06,  6.47516754e-06,  5.79826155e-06,\n",
      "       -4.93733478e-06, -4.67316158e-06,  5.01421118e-06,  4.55015743e-06,\n",
      "       -3.83409042e-06,  4.15275463e-06,  3.96937912e-06,  3.74666251e-06,\n",
      "        2.81879807e-06, -2.76208834e-06, -2.38123835e-06, -1.86155921e-06,\n",
      "       -1.50336768e-06,  2.65797280e-06,  2.37686686e-06,  2.12175405e-06,\n",
      "        1.75483149e-06, -1.38597511e-06,  1.34246193e-06,  1.23528162e-06,\n",
      "       -8.77681316e-07,  1.01527246e-06,  8.83749124e-07, -7.25905522e-07,\n",
      "        7.85174166e-07,  7.43136866e-07, -6.41857412e-07, -5.93777713e-07,\n",
      "        5.79551227e-07, -3.80676454e-07, -4.73427889e-07, -4.40122989e-07,\n",
      "        4.82292705e-07,  4.32891824e-07,  4.05655953e-07,  3.46715041e-07,\n",
      "       -2.33747812e-07, -1.99227074e-07,  2.44818551e-07,  2.28219321e-07,\n",
      "        2.11226279e-07, -1.25550443e-07,  1.56960596e-07, -8.35244620e-08,\n",
      "        1.26369997e-07,  1.07406926e-07,  9.82069324e-08,  8.15119847e-08,\n",
      "       -5.96313612e-08, -4.34925802e-08,  5.23390327e-08,  4.93045107e-08,\n",
      "        4.38038974e-08, -2.58247592e-08, -2.51224410e-08,  3.14731814e-08,\n",
      "       -1.51711053e-08, -1.18504975e-08,  2.07926014e-08,  1.84755073e-08,\n",
      "       -8.76102746e-09, -2.36678077e-09, -4.36818887e-10,  3.99128419e-09,\n",
      "        2.94094238e-09,  1.49331694e-08,  1.46350239e-08,  9.35116962e-09],\n",
      "      dtype=float32), array([[-0.08161826, -0.280283  , -0.00248777, ..., -0.01094505,\n",
      "        -0.01014813,  0.02463949],\n",
      "       [-0.06496529, -0.1372903 , -0.17000784, ..., -0.01319193,\n",
      "        -0.00237233, -0.01649725],\n",
      "       [-0.00087513,  0.00120781,  0.02403204, ...,  0.2418249 ,\n",
      "         0.09809708, -0.08204455],\n",
      "       ...,\n",
      "       [ 0.00944819,  0.06294317,  0.0705804 , ...,  0.01080235,\n",
      "         0.0319852 , -0.11345533],\n",
      "       [-0.17376865, -0.00424048,  0.04413308, ..., -0.00143783,\n",
      "        -0.00864224,  0.00127234],\n",
      "       [-0.0394375 ,  0.00333636,  0.05054734, ..., -0.05496776,\n",
      "        -0.05156968, -0.03503412]], dtype=float32))\n",
      "(array([ 9.34886353e+02,  8.12294543e-01,  1.72189862e-01,  1.31059363e-01,\n",
      "        1.03826560e-01,  3.58063430e-02,  2.00791825e-02,  1.40701849e-02,\n",
      "        7.97324348e-03,  6.47115614e-03,  2.98713869e-03,  1.77339895e-03,\n",
      "        1.53806398e-03,  1.10705337e-03,  7.06214865e-04,  5.97155071e-04,\n",
      "        5.46861324e-04,  4.10453213e-04,  3.52420611e-04,  2.52898375e-04,\n",
      "        2.13997613e-04,  1.95405140e-04,  1.60273397e-04,  1.35171562e-04,\n",
      "        1.27250751e-04,  1.19627854e-04,  8.99924416e-05,  6.52371964e-05,\n",
      "        4.75031156e-05,  3.91986250e-05, -2.56088224e-05,  3.05098438e-05,\n",
      "        2.78899315e-05,  2.65431154e-05, -2.29467587e-05,  2.48516899e-05,\n",
      "       -2.10029339e-05, -1.91406543e-05, -1.50753394e-05,  2.22428298e-05,\n",
      "        1.89748334e-05,  1.81687865e-05,  1.72350210e-05,  1.66472837e-05,\n",
      "        1.38027299e-05, -1.22067167e-05,  1.26896002e-05, -1.00267780e-05,\n",
      "        1.16983201e-05,  1.05794315e-05, -7.20266917e-06,  8.77174170e-06,\n",
      "        8.34855473e-06,  7.48757566e-06,  6.51618893e-06,  6.18242757e-06,\n",
      "       -5.11367125e-06, -4.30179489e-06,  5.30215402e-06,  4.78782249e-06,\n",
      "       -4.08420010e-06,  4.13308317e-06, -3.50180153e-06, -3.32087325e-06,\n",
      "       -2.94277606e-06,  3.59907267e-06,  3.39916710e-06,  3.01248292e-06,\n",
      "        2.51346728e-06,  2.42427382e-06,  1.93463620e-06,  1.80071368e-06,\n",
      "       -1.51202619e-06, -1.80266727e-06, -1.19650394e-06, -8.50503454e-07,\n",
      "       -7.89240573e-07,  1.21049209e-06,  1.20406685e-06,  1.01958005e-06,\n",
      "        8.36241952e-07,  7.31767102e-07, -5.48044909e-07,  5.96305767e-07,\n",
      "       -3.96479805e-07,  5.01426769e-07,  4.73324889e-07, -3.45965077e-07,\n",
      "        4.18443278e-07,  3.42224695e-07, -2.97335077e-07, -2.12719016e-07,\n",
      "        3.23188544e-07,  2.89952879e-07, -1.64720277e-07,  1.94339563e-07,\n",
      "        1.69219732e-07,  1.38396331e-07, -1.07778966e-07,  1.05442794e-07,\n",
      "       -7.59173275e-08,  8.26135604e-08, -6.09261477e-08,  6.70397498e-08,\n",
      "       -4.94668768e-08,  5.20271826e-08,  4.37257839e-08, -3.38417223e-08,\n",
      "        3.47826195e-08,  2.94021039e-08,  2.11683933e-08,  1.27459865e-08,\n",
      "       -1.38926630e-08, -1.07859153e-08,  8.66263505e-09, -8.12801826e-09,\n",
      "       -5.24584154e-09, -2.13029749e-09,  3.90853616e-09,  3.06253423e-09],\n",
      "      dtype=float32), array([[-0.0842805 ,  0.17921826,  0.07376736, ..., -0.00117956,\n",
      "         0.00473878,  0.00376959],\n",
      "       [-0.06730989,  0.10325962,  0.25423986, ...,  0.00093627,\n",
      "         0.01480589,  0.00211538],\n",
      "       [-0.00152776, -0.00612229,  0.00603362, ..., -0.14399172,\n",
      "         0.10042128,  0.3829052 ],\n",
      "       ...,\n",
      "       [ 0.01071408, -0.00504501, -0.06459361, ..., -0.02454249,\n",
      "         0.09706371,  0.04363811],\n",
      "       [-0.17429994, -0.0245368 ,  0.02009236, ..., -0.00230289,\n",
      "        -0.00159006, -0.00669841],\n",
      "       [-0.03892417,  0.03280054, -0.0291023 , ...,  0.01289079,\n",
      "        -0.01766929,  0.00900235]], dtype=float32))\n",
      "(array([ 9.10983398e+02,  4.96122837e-01,  1.46823645e-01,  1.02227166e-01,\n",
      "        7.67949000e-02,  4.53295745e-02,  1.84466783e-02,  1.33400531e-02,\n",
      "        1.24017177e-02,  8.45059659e-03,  5.12732100e-03,  2.63665221e-03,\n",
      "        1.55183009e-03,  1.29447819e-03,  1.01903779e-03,  7.00055098e-04,\n",
      "        6.77368371e-04,  5.14110085e-04,  4.08456166e-04,  3.07161594e-04,\n",
      "        2.55414430e-04,  2.11267194e-04,  1.20639423e-04,  9.48470042e-05,\n",
      "        8.38664491e-05,  8.21036883e-05,  5.91911448e-05,  5.47089076e-05,\n",
      "        4.26361876e-05, -2.52204882e-05,  3.42547428e-05,  3.35116274e-05,\n",
      "        2.93081157e-05,  2.60159286e-05, -2.14911925e-05, -1.95541743e-05,\n",
      "        2.32018283e-05,  2.15028231e-05,  2.01336024e-05, -1.54995178e-05,\n",
      "        1.82127751e-05,  1.67574435e-05,  1.52345056e-05, -1.09168313e-05,\n",
      "        1.33077683e-05,  1.18942780e-05,  1.08735003e-05, -8.73869885e-06,\n",
      "       -6.29155647e-06,  7.72174371e-06,  7.46437081e-06,  7.30512284e-06,\n",
      "       -5.66331619e-06, -5.15607098e-06,  5.98981433e-06,  6.22672997e-06,\n",
      "        5.73396665e-06, -4.34730873e-06,  5.04727768e-06, -3.87150249e-06,\n",
      "        4.70013720e-06, -2.88966248e-06,  3.73403327e-06,  3.43398938e-06,\n",
      "        2.79680717e-06, -2.10932103e-06,  2.46655077e-06, -1.81196617e-06,\n",
      "       -1.65770962e-06,  2.09332757e-06,  1.93256619e-06,  1.83809118e-06,\n",
      "       -1.34101617e-06,  1.49435596e-06,  1.26672944e-06,  1.21772325e-06,\n",
      "       -9.75674652e-07, -8.24261122e-07, -6.22922641e-07,  1.02386468e-06,\n",
      "        9.07249671e-07,  7.08445725e-07,  6.37013443e-07, -4.60490270e-07,\n",
      "        5.06818310e-07,  4.40522115e-07,  4.04690951e-07, -3.18189677e-07,\n",
      "       -2.94349547e-07,  3.56418155e-07,  3.34113224e-07, -2.55534417e-07,\n",
      "        2.80217620e-07, -2.24396629e-07, -1.72078828e-07, -1.13183063e-07,\n",
      "        1.87151500e-07,  1.56695904e-07,  1.30316138e-07,  1.17859685e-07,\n",
      "       -7.54833422e-08,  8.23811703e-08, -6.80412811e-08,  6.73455247e-08,\n",
      "       -3.90591453e-08, -3.68666591e-08,  4.29320615e-08,  4.18389092e-08,\n",
      "       -2.09452420e-08,  2.85749771e-08,  2.41329552e-08, -1.44338621e-08,\n",
      "        2.03991473e-08, -7.29619476e-09, -5.25871746e-09, -1.07839260e-09,\n",
      "        1.84357107e-09,  1.23317614e-08,  8.93480401e-09,  7.17916082e-09],\n",
      "      dtype=float32), array([[-0.0844586 , -0.13081673, -0.07392433, ..., -0.01541022,\n",
      "        -0.03522609,  0.01289139],\n",
      "       [-0.06695578,  0.04669826, -0.1830145 , ..., -0.02201058,\n",
      "        -0.01653082,  0.00419025],\n",
      "       [-0.00145041,  0.0214348 , -0.0308286 , ...,  0.22488746,\n",
      "         0.19177228, -0.08583905],\n",
      "       ...,\n",
      "       [ 0.01066103,  0.01617663,  0.08715654, ..., -0.07364062,\n",
      "         0.00268465, -0.01287048],\n",
      "       [-0.17338608,  0.0297928 ,  0.00725974, ...,  0.0206074 ,\n",
      "         0.00992993,  0.01553358],\n",
      "       [-0.03956195, -0.01539662, -0.02275082, ...,  0.02467121,\n",
      "        -0.05614969, -0.06002429]], dtype=float32))\n",
      "(array([ 9.14178650e+02,  6.82218671e-01,  3.11025143e-01,  1.13371864e-01,\n",
      "        9.64529812e-02,  6.33311421e-02,  3.52553986e-02,  2.17622183e-02,\n",
      "        1.36340633e-02,  8.93287081e-03,  7.71844899e-03,  5.40373055e-03,\n",
      "        3.53625137e-03,  2.48097046e-03,  1.73352042e-03,  1.23813958e-03,\n",
      "        1.18341413e-03,  7.48331891e-04,  5.80530032e-04,  4.07846586e-04,\n",
      "        3.82742030e-04,  3.55285883e-04,  2.44317402e-04,  1.60010211e-04,\n",
      "        1.55001413e-04,  1.46022867e-04,  1.15848612e-04,  1.03410413e-04,\n",
      "        7.14702401e-05,  6.71811140e-05,  6.11686992e-05, -3.45071458e-05,\n",
      "        4.64886580e-05,  4.40849872e-05,  3.69417539e-05, -2.38347220e-05,\n",
      "        3.20154140e-05,  2.97672759e-05,  2.83663085e-05, -2.11614770e-05,\n",
      "        2.48610359e-05,  2.35851348e-05,  2.21862447e-05,  1.94167878e-05,\n",
      "        1.77638285e-05, -1.37020224e-05, -1.09206312e-05,  1.39272815e-05,\n",
      "        1.32509394e-05, -9.42488623e-06,  1.12386306e-05,  1.03174689e-05,\n",
      "       -7.73571992e-06,  9.00934720e-06,  8.78648643e-06, -5.38077484e-06,\n",
      "       -5.04045192e-06,  7.80936261e-06,  6.87017837e-06,  5.41320242e-06,\n",
      "        5.67218513e-06,  5.76690582e-06,  4.94182359e-06, -3.65740539e-06,\n",
      "        3.80868210e-06, -3.20848949e-06,  3.19745891e-06,  2.88562410e-06,\n",
      "       -2.92912614e-06, -2.65038716e-06, -2.05598371e-06,  2.45106662e-06,\n",
      "        2.08975007e-06,  1.85241879e-06, -1.59424724e-06, -1.39491954e-06,\n",
      "        1.50880089e-06,  1.24319115e-06,  1.08915731e-06, -8.98555243e-07,\n",
      "        9.23889615e-07,  8.15838064e-07, -7.14208397e-07, -5.87001978e-07,\n",
      "        6.89275623e-07,  5.27519660e-07, -4.71490210e-07,  4.92980803e-07,\n",
      "        4.61424122e-07, -4.08604222e-07,  3.91648143e-07, -3.45316920e-07,\n",
      "        2.82042350e-07, -2.44062306e-07, -2.06653610e-07, -1.53983621e-07,\n",
      "        1.94889324e-07,  1.42605217e-07, -1.20908041e-07,  1.08272417e-07,\n",
      "       -8.41941201e-08, -7.43607629e-08,  8.06779354e-08,  7.33239247e-08,\n",
      "       -6.21802769e-08,  5.67975640e-08, -4.43776926e-08,  4.41368826e-08,\n",
      "        3.28338317e-08,  2.32323991e-08, -2.22865406e-08,  1.37815261e-08,\n",
      "       -1.45814418e-08, -1.63725691e-08,  6.93463198e-09,  3.23196225e-09,\n",
      "        2.80951351e-09, -6.13237638e-09, -4.53771865e-09, -2.64738542e-09],\n",
      "      dtype=float32), array([[-0.08787967,  0.13549255,  0.0360151 , ..., -0.0149844 ,\n",
      "        -0.00483176,  0.01061083],\n",
      "       [-0.0664155 ,  0.11463863, -0.1686664 , ..., -0.00640122,\n",
      "         0.00103804, -0.01380315],\n",
      "       [-0.00112347, -0.00415322,  0.01267517, ..., -0.13543884,\n",
      "         0.281011  ,  0.41408223],\n",
      "       ...,\n",
      "       [ 0.0116139 , -0.05553864,  0.01664257, ..., -0.07338848,\n",
      "        -0.06537829, -0.08193145],\n",
      "       [-0.1727573 , -0.02751733,  0.01592029, ..., -0.00547911,\n",
      "        -0.00444344,  0.00247212],\n",
      "       [-0.03938704,  0.01370452,  0.07592711, ...,  0.00649428,\n",
      "        -0.02314965,  0.01537641]], dtype=float32))\n",
      "(array([ 8.98333801e+02,  3.18069041e-01,  1.90897793e-01,  1.21703953e-01,\n",
      "        7.12452978e-02,  6.15822487e-02,  1.63102075e-02,  1.26138264e-02,\n",
      "        8.25004186e-03,  3.72215756e-03,  2.71687866e-03,  2.02267733e-03,\n",
      "        1.64867949e-03,  1.11044676e-03,  6.97632495e-04,  5.53857593e-04,\n",
      "        3.91614070e-04,  3.45375622e-04,  2.85042130e-04,  2.07041376e-04,\n",
      "        1.65907215e-04,  1.39247655e-04,  1.12821217e-04,  1.00756617e-04,\n",
      "        7.15690767e-05,  6.23599044e-05,  4.51831875e-05,  4.34491594e-05,\n",
      "       -2.75065631e-05,  3.79041849e-05, -2.52327100e-05,  2.98306695e-05,\n",
      "        2.82396741e-05,  2.58351029e-05,  2.48763845e-05, -1.76197027e-05,\n",
      "       -1.50742935e-05,  1.87756250e-05,  1.77522561e-05,  1.63554269e-05,\n",
      "       -1.28476158e-05,  1.51739277e-05,  1.46428565e-05, -1.16590500e-05,\n",
      "        1.34772808e-05,  1.31795787e-05,  1.14539307e-05, -8.54632435e-06,\n",
      "        9.77465697e-06, -7.36585343e-06,  8.48815398e-06,  7.53236782e-06,\n",
      "       -5.52093752e-06,  7.42208294e-06,  7.01584304e-06,  5.87243767e-06,\n",
      "        5.48082335e-06, -4.30296313e-06, -3.56702276e-06, -2.83863665e-06,\n",
      "        4.56997668e-06,  4.10829807e-06,  3.50985306e-06,  3.39340932e-06,\n",
      "        2.93999460e-06, -2.51967776e-06,  2.49444815e-06,  2.26919383e-06,\n",
      "       -1.77428853e-06, -1.62483025e-06,  1.43389764e-06,  1.56131091e-06,\n",
      "        1.62453387e-06, -1.29268676e-06, -1.05752247e-06,  1.11654106e-06,\n",
      "        1.09021892e-06,  9.91664365e-07, -8.18149658e-07,  7.88079660e-07,\n",
      "        7.44928855e-07, -6.45978218e-07, -5.75195202e-07,  6.70414579e-07,\n",
      "       -4.97165445e-07,  5.36441689e-07,  4.21976409e-07, -3.52762470e-07,\n",
      "        3.68266626e-07, -2.91034951e-07,  3.17065656e-07,  2.67917102e-07,\n",
      "        2.54465249e-07, -2.36353458e-07, -2.15925539e-07, -1.64405705e-07,\n",
      "       -1.33314046e-07,  1.86437035e-07,  1.50636012e-07,  1.26208448e-07,\n",
      "        1.12405495e-07,  1.01680570e-07,  6.70689744e-08, -6.64147919e-08,\n",
      "       -6.43030162e-08, -4.99149095e-08,  5.69254297e-08,  5.20339363e-08,\n",
      "       -3.54077123e-08,  2.45334917e-08, -2.07727222e-08,  1.65858314e-08,\n",
      "        1.53085740e-08, -1.27415811e-08,  8.97359964e-09,  5.10324583e-09,\n",
      "       -7.70431452e-09, -5.79664539e-09, -1.25636679e-09,  9.95612037e-10],\n",
      "      dtype=float32), array([[-0.08323954,  0.04679702,  0.15739553, ..., -0.02224056,\n",
      "         0.02312335, -0.00545629],\n",
      "       [-0.0624563 ,  0.10681285,  0.15299907, ..., -0.00870895,\n",
      "         0.02581185, -0.00960121],\n",
      "       [-0.00123139, -0.02520938,  0.00721277, ...,  0.09269117,\n",
      "        -0.13054138, -0.2882526 ],\n",
      "       ...,\n",
      "       [ 0.00877482,  0.01082748, -0.17336872, ...,  0.0861081 ,\n",
      "        -0.06116401,  0.03094877],\n",
      "       [-0.17351058, -0.09280609,  0.0052774 , ..., -0.00534722,\n",
      "        -0.00767485, -0.00434489],\n",
      "       [-0.03844477, -0.00250859, -0.01315903, ...,  0.03899051,\n",
      "        -0.018276  ,  0.03645811]], dtype=float32))\n",
      "(array([ 8.9293616e+02,  6.3701224e-01,  1.7720117e-01,  1.6907689e-01,\n",
      "        1.2993453e-01,  7.8956030e-02,  4.4069111e-02,  4.0480878e-02,\n",
      "        1.7424451e-02,  8.7918080e-03,  5.8478503e-03,  4.4771810e-03,\n",
      "        3.7510134e-03,  2.7971629e-03,  2.3791702e-03,  1.8043815e-03,\n",
      "        1.4045489e-03,  1.2443296e-03,  1.0421223e-03,  8.3281886e-04,\n",
      "        5.6171120e-04,  5.2345067e-04,  3.6887903e-04,  2.9059532e-04,\n",
      "        2.3401098e-04,  1.9704828e-04,  1.6327242e-04,  1.4254096e-04,\n",
      "        1.1441543e-04,  1.0149939e-04,  8.3601750e-05,  7.4856653e-05,\n",
      "        6.6270826e-05,  5.5049393e-05,  4.8203969e-05,  3.6882670e-05,\n",
      "        3.2273674e-05, -2.2309287e-05,  2.9268072e-05, -1.8038276e-05,\n",
      "        2.2534099e-05,  2.1866086e-05,  2.0248441e-05,  1.9208090e-05,\n",
      "       -1.5848544e-05,  1.6910877e-05,  1.5687750e-05,  1.4497153e-05,\n",
      "       -1.2464899e-05, -1.1792086e-05, -1.0745997e-05,  1.0515501e-05,\n",
      "        9.5151190e-06,  9.0424001e-06,  8.6015743e-06, -6.6721063e-06,\n",
      "       -6.4158530e-06,  7.8533467e-06,  6.9603811e-06,  6.6433595e-06,\n",
      "        4.9946793e-06, -4.3830223e-06, -4.4371177e-06,  4.6741307e-06,\n",
      "        4.3519722e-06,  3.8447702e-06, -3.1870206e-06, -2.9270545e-06,\n",
      "       -2.5104155e-06,  3.0997435e-06,  2.9016328e-06,  2.4082740e-06,\n",
      "       -1.9637732e-06, -1.7354624e-06,  1.9795957e-06,  1.8387261e-06,\n",
      "        1.5366547e-06, -1.3384353e-06, -1.1294524e-06, -9.3478423e-07,\n",
      "        1.1852356e-06,  1.0497566e-06,  8.2243156e-07, -7.5317649e-07,\n",
      "        6.7531829e-07, -5.5193419e-07,  5.0071264e-07, -4.3502899e-07,\n",
      "       -3.7328991e-07,  4.2315068e-07,  3.7685845e-07, -2.6344392e-07,\n",
      "        2.8705350e-07,  2.6479947e-07, -2.2094963e-07,  2.3368145e-07,\n",
      "        1.9332181e-07, -1.6279478e-07,  1.3538794e-07, -1.2762460e-07,\n",
      "       -1.0190496e-07, -9.0595528e-08,  9.6294364e-08,  8.3502826e-08,\n",
      "        6.1724052e-08,  4.9981985e-08, -5.1149033e-08, -4.4747441e-08,\n",
      "       -3.8507579e-08,  3.6733347e-08, -2.8634396e-08,  2.7134345e-08,\n",
      "       -1.6265792e-08,  1.6574011e-08, -1.0847647e-08,  5.2815561e-09,\n",
      "        8.5278575e-09, -2.3340314e-09,  1.6204135e-09, -4.3837373e-10],\n",
      "      dtype=float32), array([[-0.08347734, -0.10725461,  0.2776648 , ...,  0.00401006,\n",
      "         0.01530615, -0.00568139],\n",
      "       [-0.06294441, -0.20487455, -0.03031047, ...,  0.0096718 ,\n",
      "         0.01798369, -0.01925094],\n",
      "       [-0.00143861,  0.01875545, -0.00452709, ...,  0.09396915,\n",
      "         0.19985266, -0.18047099],\n",
      "       ...,\n",
      "       [ 0.00916693,  0.04758308, -0.10489967, ..., -0.0221477 ,\n",
      "        -0.03809137, -0.06638385],\n",
      "       [-0.17336121,  0.04183094, -0.00878419, ...,  0.0018189 ,\n",
      "         0.0036031 , -0.00812272],\n",
      "       [-0.03875709,  0.04008   , -0.04358731, ...,  0.01550392,\n",
      "         0.07095826, -0.02764779]], dtype=float32))\n",
      "(array([ 8.27014954e+02,  1.29321337e+00,  4.32465762e-01,  2.74603456e-01,\n",
      "        2.18499541e-01,  5.90775497e-02,  5.36230393e-02,  2.65474413e-02,\n",
      "        2.21899208e-02,  1.63183175e-02,  1.02870055e-02,  8.37603118e-03,\n",
      "        6.36389898e-03,  5.69141051e-03,  3.70125915e-03,  2.40252586e-03,\n",
      "        2.02791579e-03,  1.48736010e-03,  1.32161716e-03,  1.09119376e-03,\n",
      "        8.98720347e-04,  7.53749511e-04,  5.68884425e-04,  5.27427823e-04,\n",
      "        4.93157946e-04,  3.70245572e-04,  3.20252730e-04,  2.21334762e-04,\n",
      "        2.07158606e-04,  1.66691898e-04,  1.35388749e-04,  1.10950677e-04,\n",
      "        9.73562564e-05,  7.52272972e-05,  6.77965509e-05,  5.97827275e-05,\n",
      "        5.86125243e-05,  4.49104264e-05,  4.25925282e-05,  3.42417952e-05,\n",
      "        3.17823287e-05, -2.05961860e-05,  2.64631890e-05,  2.33792052e-05,\n",
      "       -1.61446496e-05, -1.37753259e-05,  1.97908139e-05,  1.71403408e-05,\n",
      "        1.66735517e-05,  1.30918588e-05, -1.00719899e-05, -8.35205265e-06,\n",
      "        1.23513346e-05,  9.66575953e-06,  9.20179718e-06, -7.08721382e-06,\n",
      "        8.28404154e-06, -6.24213453e-06,  6.78759488e-06, -4.54032261e-06,\n",
      "        5.82793746e-06,  5.66241852e-06,  5.28093005e-06, -3.54172630e-06,\n",
      "       -2.94264555e-06,  4.07274365e-06,  3.94786730e-06,  3.70939506e-06,\n",
      "        3.08996687e-06,  2.91450647e-06, -2.25643294e-06, -1.76671517e-06,\n",
      "        1.91138247e-06,  1.53402232e-06, -1.43108321e-06, -1.26264251e-06,\n",
      "       -1.13011333e-06,  1.26982093e-06,  1.19428739e-06,  1.10216456e-06,\n",
      "        8.14901739e-07,  7.63721289e-07, -8.16900126e-07,  5.64917514e-07,\n",
      "       -7.31455600e-07, -6.42485588e-07, -6.10057498e-07, -4.19735045e-07,\n",
      "        3.54053867e-07, -3.31428907e-07,  3.23801970e-07,  3.13273858e-07,\n",
      "       -2.66939196e-07,  2.32005618e-07, -2.16479137e-07, -2.06784833e-07,\n",
      "        1.79155990e-07, -1.25181330e-07, -1.12930728e-07, -8.36052791e-08,\n",
      "        1.25869917e-07,  1.19052956e-07,  9.04740887e-08,  8.17336812e-08,\n",
      "       -6.36313970e-08, -4.08916634e-08,  4.47710136e-08,  4.15718020e-08,\n",
      "        3.84426571e-08, -2.84493815e-08,  2.20879510e-08, -2.36896120e-08,\n",
      "        1.66934804e-08, -1.49908850e-08, -1.18282975e-08,  1.15311609e-08,\n",
      "       -6.14197582e-09, -2.66345146e-09,  2.63680106e-10,  5.97263217e-09],\n",
      "      dtype=float32), array([[-0.06808086,  0.2514489 , -0.08169705, ...,  0.02259416,\n",
      "        -0.01045889,  0.01393933],\n",
      "       [-0.06603239,  0.16680817,  0.13858178, ...,  0.01895626,\n",
      "        -0.01320699, -0.01112547],\n",
      "       [-0.00207053,  0.00907938, -0.0451795 , ..., -0.4203599 ,\n",
      "         0.21759303, -0.02204634],\n",
      "       ...,\n",
      "       [ 0.00793866, -0.04997549, -0.0666336 , ...,  0.08130124,\n",
      "        -0.15522276,  0.12001996],\n",
      "       [-0.17268522,  0.04175078, -0.09699891, ..., -0.0041889 ,\n",
      "         0.01301643,  0.00380053],\n",
      "       [-0.03680206, -0.01007084, -0.04902807, ...,  0.04327374,\n",
      "        -0.08663736,  0.04938677]], dtype=float32))\n",
      "(array([ 4.66755768e+02,  1.38809371e+00,  6.95423663e-01,  5.16886890e-01,\n",
      "        3.05456847e-01,  9.38670188e-02,  7.78642222e-02,  6.34070188e-02,\n",
      "        5.21446429e-02,  2.77150311e-02,  1.45431198e-02,  1.17992219e-02,\n",
      "        8.03585816e-03,  5.74622629e-03,  4.69209254e-03,  3.51059949e-03,\n",
      "        2.93458742e-03,  2.59633572e-03,  1.90352986e-03,  1.56782125e-03,\n",
      "        1.24912837e-03,  1.13829225e-03,  9.88713116e-04,  6.94249233e-04,\n",
      "        6.34460885e-04,  5.57369960e-04,  5.19379566e-04,  3.86411528e-04,\n",
      "        3.64893785e-04,  3.40367260e-04,  3.06250382e-04,  2.54838116e-04,\n",
      "        2.13209598e-04,  1.64171230e-04,  1.25831080e-04,  1.05606559e-04,\n",
      "        9.09167065e-05,  7.91598359e-05,  7.34351343e-05,  5.01945833e-05,\n",
      "        4.14274837e-05,  3.84167506e-05,  3.38221871e-05,  2.83775662e-05,\n",
      "        2.36469568e-05, -1.26567447e-05,  1.48300724e-05,  1.27407375e-05,\n",
      "        1.16025785e-05, -7.30861802e-06,  9.39532492e-06,  8.69732230e-06,\n",
      "        7.84112035e-06, -5.77804667e-06,  5.66400149e-06, -3.83960150e-06,\n",
      "        4.41823522e-06,  3.67151665e-06, -3.02578064e-06, -3.15902867e-06,\n",
      "        2.91652145e-06,  2.69020688e-06,  2.36355527e-06, -2.22407220e-06,\n",
      "        2.03454761e-06, -2.02136903e-06,  1.61880303e-06,  1.48026072e-06,\n",
      "       -1.69025100e-06, -1.39168526e-06, -1.23325299e-06,  1.15994885e-06,\n",
      "       -1.05228969e-06,  1.05669528e-06,  8.43731584e-07, -8.54914106e-07,\n",
      "       -7.27015220e-07,  6.96316590e-07, -6.37608593e-07,  6.38890867e-07,\n",
      "       -5.71398914e-07, -4.78424283e-07,  5.12406643e-07, -4.33343644e-07,\n",
      "        4.12725882e-07, -3.44936296e-07, -3.25125939e-07, -2.84753810e-07,\n",
      "        3.65714072e-07,  3.55376642e-07,  3.05832316e-07,  2.83983525e-07,\n",
      "       -2.47409588e-07, -1.95584008e-07,  1.85745677e-07, -1.49714921e-07,\n",
      "        1.53364482e-07,  1.37343235e-07, -1.06588779e-07, -9.22480936e-08,\n",
      "       -8.41267180e-08,  7.53471241e-08,  6.79170498e-08, -5.14518810e-08,\n",
      "        5.39357892e-08, -4.19473274e-08,  4.77715396e-08,  4.07029930e-08,\n",
      "        3.46109239e-08, -2.77763785e-08, -2.51894559e-08, -2.16938005e-08,\n",
      "       -1.30203723e-08, -8.03220868e-09, -2.24822203e-10,  1.11192444e-09,\n",
      "        6.64641941e-09,  1.47555088e-08,  1.39419951e-08,  1.09665317e-08],\n",
      "      dtype=float32), array([[ 0.04701568, -0.03805937, -0.03203556, ..., -0.01086149,\n",
      "         0.0303493 , -0.00307188],\n",
      "       [ 0.04680729, -0.05507946,  0.1984878 , ..., -0.00119019,\n",
      "         0.01845969, -0.00634723],\n",
      "       [ 0.00141459,  0.02751994,  0.00928003, ...,  0.11131582,\n",
      "        -0.13651711,  0.14899267],\n",
      "       ...,\n",
      "       [ 0.00646995, -0.02600466, -0.15128991, ..., -0.03952098,\n",
      "         0.00832779,  0.1347174 ],\n",
      "       [ 0.16557252,  0.0441917 ,  0.00823446, ...,  0.00740519,\n",
      "        -0.00539006,  0.01018598],\n",
      "       [ 0.0314014 ,  0.10362902,  0.00699597, ..., -0.07323026,\n",
      "        -0.0153543 , -0.01984193]], dtype=float32))\n",
      "(array([ 3.59266235e+02,  1.78950691e+00,  9.07707334e-01,  2.15419084e-01,\n",
      "        9.67320874e-02,  5.22021800e-02,  2.91979462e-02,  2.53004991e-02,\n",
      "        1.97794735e-02,  1.13119949e-02,  8.41023307e-03,  6.54187659e-03,\n",
      "        5.03897620e-03,  3.76642728e-03,  2.71861511e-03,  2.18948908e-03,\n",
      "        1.92330289e-03,  1.45540747e-03,  1.35284930e-03,  8.90966156e-04,\n",
      "        7.12206704e-04,  6.57632132e-04,  5.64391783e-04,  4.95098997e-04,\n",
      "        3.56438191e-04,  3.23754008e-04,  2.52245751e-04,  2.25373093e-04,\n",
      "        2.03659001e-04,  1.42686244e-04,  1.11960719e-04,  1.02185033e-04,\n",
      "        7.49366882e-05,  7.33710331e-05,  5.92688993e-05,  5.68050709e-05,\n",
      "        4.73731707e-05,  4.07207808e-05,  3.42196727e-05,  2.91800625e-05,\n",
      "        2.44941330e-05,  2.05538290e-05,  1.65520432e-05,  1.49911884e-05,\n",
      "        1.45832773e-05, -9.58022702e-06,  1.00782518e-05,  9.16152203e-06,\n",
      "        7.84773147e-06, -6.50608672e-06,  7.37900427e-06, -5.46246611e-06,\n",
      "        6.29367287e-06,  5.08727089e-06,  4.52201675e-06, -3.81418818e-06,\n",
      "       -3.00451597e-06,  3.32953823e-06,  2.86299701e-06,  2.84057501e-06,\n",
      "       -2.18271225e-06, -2.00221348e-06,  2.17952947e-06, -1.81518703e-06,\n",
      "       -1.51380311e-06,  1.66030941e-06,  1.55353314e-06,  1.38348594e-06,\n",
      "       -1.32841978e-06, -1.16751198e-06,  1.08137567e-06, -1.04363983e-06,\n",
      "        9.43143561e-07, -7.95452706e-07,  7.32746855e-07,  7.54452969e-07,\n",
      "       -6.61811157e-07,  5.74102955e-07,  5.43882777e-07,  4.65396340e-07,\n",
      "       -5.75294166e-07, -5.30331079e-07, -4.84176724e-07, -4.15351337e-07,\n",
      "        3.51972602e-07, -2.98929479e-07,  3.27830833e-07, -2.74383467e-07,\n",
      "        2.96159811e-07,  2.65797951e-07, -2.10536385e-07, -1.83154668e-07,\n",
      "        1.70270695e-07,  1.83425811e-07,  1.53194080e-07, -1.52398755e-07,\n",
      "       -1.38689401e-07,  1.10947063e-07, -1.02118392e-07, -9.22497421e-08,\n",
      "        8.34936316e-08,  6.63311894e-08, -7.82714267e-08, -6.41303188e-08,\n",
      "       -4.92179737e-08, -4.25522479e-08, -3.46002018e-08,  4.02739886e-08,\n",
      "        3.98978948e-08,  3.77778449e-08,  2.44970977e-08, -2.03509476e-08,\n",
      "       -1.30777256e-08, -1.48370036e-08,  1.71563102e-08,  1.03508455e-08,\n",
      "        5.82600279e-09,  2.27665686e-09, -5.08536813e-09, -3.95919075e-09],\n",
      "      dtype=float32), array([[ 0.03119905, -0.09816412,  0.08199751, ...,  0.01421528,\n",
      "        -0.01176114,  0.0144966 ],\n",
      "       [ 0.0544159 ,  0.09391221, -0.17849159, ..., -0.00935041,\n",
      "         0.01081099,  0.04894557],\n",
      "       [ 0.00493714,  0.00431094,  0.06980693, ...,  0.12567484,\n",
      "         0.12090851,  0.04187319],\n",
      "       ...,\n",
      "       [-0.00350819, -0.02022663,  0.02338065, ..., -0.02852334,\n",
      "         0.07566693,  0.02936766],\n",
      "       [ 0.16288278, -0.09468001,  0.07987776, ..., -0.0051959 ,\n",
      "         0.00574476, -0.00734275],\n",
      "       [ 0.03899422,  0.00522603,  0.04632408, ..., -0.0353312 ,\n",
      "        -0.04525426, -0.05694534]], dtype=float32))\n",
      "(array([ 3.05452515e+02,  8.33993971e-01,  4.22051400e-01,  7.09434152e-02,\n",
      "        3.95676829e-02,  3.46476734e-02,  1.39771365e-02,  1.22478185e-02,\n",
      "        1.03725605e-02,  9.08391923e-03,  4.74882638e-03,  4.23801504e-03,\n",
      "        2.11768108e-03,  1.75394001e-03,  1.37592771e-03,  1.27508654e-03,\n",
      "        9.03547450e-04,  8.97331978e-04,  6.08750735e-04,  5.19158551e-04,\n",
      "        4.60281852e-04,  3.99043522e-04,  2.71454803e-04,  2.43044691e-04,\n",
      "        2.34660722e-04,  1.49909261e-04,  1.34078393e-04,  1.31284425e-04,\n",
      "        9.80351761e-05,  8.58318890e-05,  7.12598339e-05,  5.40705987e-05,\n",
      "        3.75436357e-05,  3.43624233e-05,  3.06197653e-05,  2.73853857e-05,\n",
      "        2.48215183e-05,  2.19570993e-05,  1.96160054e-05,  1.79137805e-05,\n",
      "        1.07716542e-05,  1.08941585e-05, -7.02090347e-06,  8.97660721e-06,\n",
      "       -6.15908630e-06,  8.11484369e-06,  6.93252832e-06,  5.96672771e-06,\n",
      "        5.04970149e-06, -4.31619401e-06,  4.42819919e-06,  4.09349559e-06,\n",
      "       -3.20270692e-06,  3.35393634e-06, -2.88903902e-06, -2.19256322e-06,\n",
      "        2.73142587e-06,  2.61614673e-06,  2.25038025e-06,  2.04746334e-06,\n",
      "        1.85531758e-06, -1.50899416e-06,  1.61866103e-06, -1.28893896e-06,\n",
      "        1.35406401e-06, -1.16155718e-06,  1.03372838e-06, -1.05331173e-06,\n",
      "       -9.00312557e-07,  8.59870511e-07,  7.62568220e-07,  7.11493101e-07,\n",
      "        6.09030110e-07, -7.41237329e-07, -6.74598994e-07, -6.57292446e-07,\n",
      "       -5.92686945e-07,  5.93808863e-07, -4.97736892e-07,  4.93363757e-07,\n",
      "        4.30090154e-07, -4.24055543e-07, -3.71191163e-07, -3.43679716e-07,\n",
      "        3.48638849e-07,  3.06783193e-07, -2.96375958e-07, -2.72543673e-07,\n",
      "        2.69465062e-07,  2.42894828e-07, -2.06885048e-07, -2.00239811e-07,\n",
      "        1.89847384e-07, -1.58411822e-07,  1.73664120e-07,  1.37325287e-07,\n",
      "       -1.19069597e-07,  1.21821500e-07, -1.05559771e-07,  8.39158005e-08,\n",
      "       -7.16621713e-08, -6.09984170e-08, -4.77575561e-08, -3.67532031e-08,\n",
      "        6.36670805e-08,  5.85562852e-08,  5.30059516e-08,  4.13545145e-08,\n",
      "        3.40446284e-08,  2.62515574e-08, -2.50572398e-08,  1.98238954e-08,\n",
      "       -1.92144078e-08, -1.14265015e-08, -1.04908455e-08,  1.19977042e-08,\n",
      "       -3.01363379e-09,  4.63392186e-10,  5.08640641e-09,  3.46666229e-09],\n",
      "      dtype=float32), array([[ 0.02615363, -0.07685933,  0.10326475, ..., -0.04740893,\n",
      "        -0.02988142, -0.03660147],\n",
      "       [ 0.05708323,  0.07968498, -0.1730843 , ..., -0.00980484,\n",
      "         0.03395239,  0.0068737 ],\n",
      "       [ 0.0058127 , -0.00455838,  0.07775359, ..., -0.02178673,\n",
      "         0.11891395, -0.09464593],\n",
      "       ...,\n",
      "       [-0.00354726, -0.01036491,  0.04012843, ..., -0.01658217,\n",
      "         0.02591622, -0.00516018],\n",
      "       [ 0.15839781, -0.08730356,  0.0890791 , ..., -0.00126661,\n",
      "         0.00102082, -0.00690733],\n",
      "       [ 0.03878605,  0.00088213,  0.04959794, ...,  0.09424574,\n",
      "         0.06937679, -0.02352199]], dtype=float32))\n",
      "(array([ 4.06183777e+02,  6.85058355e-01,  3.11911106e-01,  3.85449752e-02,\n",
      "        2.43328512e-02,  1.96743906e-02,  1.50192576e-02,  7.56727532e-03,\n",
      "        5.19214058e-03,  4.37438954e-03,  3.53087066e-03,  2.22122204e-03,\n",
      "        1.84824702e-03,  1.43650104e-03,  9.62783815e-04,  6.43943029e-04,\n",
      "        4.00099729e-04,  3.60429927e-04,  3.32653464e-04,  2.44396215e-04,\n",
      "        2.05924342e-04,  1.84036588e-04,  1.88160178e-04,  1.19733289e-04,\n",
      "        1.09525841e-04,  9.87561216e-05,  7.89902915e-05,  7.02956822e-05,\n",
      "        5.37325650e-05,  4.51438646e-05,  3.96947507e-05,  3.72404756e-05,\n",
      "        2.53874587e-05,  2.21533155e-05,  1.70563926e-05,  1.73679327e-05,\n",
      "       -1.11100480e-05,  1.50383548e-05,  1.38928435e-05,  1.14679269e-05,\n",
      "        1.02395807e-05,  9.51416769e-06, -7.29478234e-06, -6.07142283e-06,\n",
      "        7.52898495e-06,  6.89815079e-06,  6.53562483e-06, -4.72451757e-06,\n",
      "        5.74447586e-06,  5.00571696e-06, -3.65919459e-06,  4.53262282e-06,\n",
      "        3.85281055e-06,  3.72189970e-06, -3.13923306e-06, -2.88855017e-06,\n",
      "        3.38443215e-06, -2.38380244e-06,  2.97606948e-06,  2.57548686e-06,\n",
      "        2.51846927e-06, -1.98950283e-06,  2.04953380e-06, -1.67182520e-06,\n",
      "        1.80514235e-06,  1.54277029e-06, -1.20932805e-06, -1.14196314e-06,\n",
      "        1.27409066e-06,  1.20647894e-06,  1.13090221e-06, -9.38388439e-07,\n",
      "       -8.48702143e-07,  9.29627276e-07,  9.02306510e-07, -6.32631100e-07,\n",
      "       -5.76147499e-07,  7.33053128e-07,  6.53591428e-07,  6.88686441e-07,\n",
      "       -6.49635467e-07, -4.62620307e-07,  5.77519586e-07,  5.46341653e-07,\n",
      "        3.73931556e-07, -3.33460918e-07,  3.33250256e-07,  2.81406585e-07,\n",
      "        2.47051020e-07,  2.25547780e-07, -2.63294112e-07, -2.19715815e-07,\n",
      "       -1.98518748e-07,  1.87339040e-07,  1.57898654e-07, -1.53232833e-07,\n",
      "        1.01576241e-07, -1.13649442e-07, -1.02753248e-07,  8.31565004e-08,\n",
      "        7.03892979e-08, -8.29004421e-08, -6.78788012e-08, -5.81431649e-08,\n",
      "        4.53332589e-08, -3.54462308e-08,  3.92026145e-08,  3.29983045e-08,\n",
      "       -2.63418158e-08, -2.58358845e-08,  2.19584493e-08, -1.45478376e-08,\n",
      "        1.58352655e-08, -1.12642864e-08,  1.43285490e-08,  6.65030253e-09,\n",
      "        4.64026018e-09, -2.93418156e-09,  1.14323029e-09, -1.04596243e-09],\n",
      "      dtype=float32), array([[-0.03657362,  0.08887806, -0.07330312, ...,  0.03939542,\n",
      "        -0.04808286,  0.00203469],\n",
      "       [-0.05572937, -0.03291301,  0.1889516 , ..., -0.02309968,\n",
      "         0.00439379,  0.02660288],\n",
      "       [-0.00392115, -0.00633437, -0.06545357, ...,  0.29964292,\n",
      "        -0.16034998, -0.12770276],\n",
      "       ...,\n",
      "       [ 0.00706329, -0.01135984, -0.04980244, ..., -0.02338307,\n",
      "         0.04115568, -0.1039297 ],\n",
      "       [-0.16454652,  0.05532999, -0.09382706, ...,  0.0181782 ,\n",
      "        -0.0047352 , -0.0110845 ],\n",
      "       [-0.03905904, -0.00404874, -0.04352344, ..., -0.01237239,\n",
      "        -0.04772124, -0.07749555]], dtype=float32))\n",
      "(array([ 4.08661621e+02,  1.39294100e+00,  5.17465413e-01,  1.66793674e-01,\n",
      "        6.90050200e-02,  4.62654680e-02,  1.81528442e-02,  1.16303740e-02,\n",
      "        7.13757193e-03,  4.45947191e-03,  3.85969435e-03,  3.43962177e-03,\n",
      "        3.13174468e-03,  2.78352178e-03,  1.85882754e-03,  1.16366730e-03,\n",
      "        9.52912436e-04,  9.01442429e-04,  5.39442757e-04,  5.24066971e-04,\n",
      "        4.15189366e-04,  3.43098451e-04,  2.86591181e-04,  2.24087795e-04,\n",
      "        1.56861410e-04,  1.34021524e-04,  1.25570572e-04,  1.06092259e-04,\n",
      "        8.42011650e-05,  7.54435023e-05,  6.54043833e-05,  4.85697965e-05,\n",
      "        4.12679074e-05,  3.42815183e-05,  2.95912505e-05,  2.81392513e-05,\n",
      "        1.97205045e-05,  1.54941281e-05,  1.47756627e-05, -9.80249570e-06,\n",
      "        1.11435575e-05,  1.00211846e-05,  9.48571324e-06, -7.94041898e-06,\n",
      "       -6.20522587e-06, -5.14441763e-06,  6.81383563e-06,  6.12577878e-06,\n",
      "        5.73413945e-06,  4.80998551e-06, -4.04104094e-06,  4.27605073e-06,\n",
      "       -3.33703929e-06,  3.55739371e-06,  3.32699688e-06, -2.72613192e-06,\n",
      "        2.82444239e-06, -1.84307169e-06,  2.46313834e-06,  2.30753835e-06,\n",
      "        2.05198921e-06, -1.93043320e-06,  1.78991820e-06,  1.49879531e-06,\n",
      "       -1.33963431e-06,  1.31442516e-06,  1.19653112e-06, -1.21319670e-06,\n",
      "       -1.12727685e-06, -1.07296535e-06, -8.34192576e-07, -8.21357276e-07,\n",
      "        9.76243086e-07,  8.69266387e-07,  8.10784115e-07,  6.91102457e-07,\n",
      "       -6.07207085e-07,  5.99955115e-07,  5.52896381e-07, -4.95976963e-07,\n",
      "       -4.71978666e-07, -3.97061370e-07, -2.96811578e-07,  4.54530635e-07,\n",
      "        3.85696666e-07,  3.72306857e-07,  3.20826302e-07,  2.91449282e-07,\n",
      "       -2.69367206e-07,  2.33685796e-07, -2.42133012e-07, -2.20378439e-07,\n",
      "       -1.88965828e-07,  1.91327288e-07,  1.74596096e-07,  1.44568574e-07,\n",
      "       -1.16050657e-07,  1.20418363e-07,  1.12304093e-07, -8.68090879e-08,\n",
      "       -7.58259873e-08,  8.74823058e-08,  7.81440548e-08,  4.97552541e-08,\n",
      "        4.38650467e-08, -5.30793187e-08, -4.61982061e-08, -4.37970122e-08,\n",
      "       -3.05023704e-08,  2.68991300e-08, -2.27842492e-08,  2.42522766e-08,\n",
      "        1.37532794e-08, -1.08135394e-08, -3.19844506e-09, -5.27717825e-09,\n",
      "        1.45164936e-09,  4.50244553e-09,  5.68481573e-09,  5.13912468e-09],\n",
      "      dtype=float32), array([[ 0.03803762,  0.12045382,  0.05552365, ...,  0.03328859,\n",
      "         0.01508215, -0.003967  ],\n",
      "       [ 0.05590115, -0.17492618, -0.08318596, ..., -0.05153799,\n",
      "        -0.03922795, -0.04045164],\n",
      "       [ 0.00414436,  0.04425566,  0.06001071, ...,  0.16762969,\n",
      "        -0.04343276, -0.18115552],\n",
      "       ...,\n",
      "       [-0.00596222,  0.03181035,  0.021782  , ..., -0.09186773,\n",
      "        -0.33127445, -0.07303128],\n",
      "       [ 0.162907  ,  0.11129733,  0.02456799, ...,  0.00965662,\n",
      "        -0.00645212,  0.00250214],\n",
      "       [ 0.03807446,  0.04067636,  0.0439111 , ...,  0.05514649,\n",
      "         0.04361825,  0.01114509]], dtype=float32))\n",
      "(array([ 5.31238953e+02,  8.48592520e-01,  2.34543830e-01,  1.55442581e-01,\n",
      "        1.12869307e-01,  7.08373711e-02,  4.73666638e-02,  2.87777465e-02,\n",
      "        1.79360248e-02,  1.17785009e-02,  6.02632854e-03,  4.88372752e-03,\n",
      "        3.98014719e-03,  2.55641202e-03,  2.40275776e-03,  1.78413908e-03,\n",
      "        1.26575364e-03,  1.15690893e-03,  1.04082236e-03,  6.47770124e-04,\n",
      "        5.34763793e-04,  3.95659794e-04,  3.09110677e-04,  2.70268123e-04,\n",
      "        2.04102718e-04,  1.70656320e-04,  1.48004503e-04,  1.35732815e-04,\n",
      "        1.07128522e-04,  1.02946069e-04,  9.02649044e-05,  6.33734817e-05,\n",
      "        5.75054655e-05,  5.01567301e-05,  4.40379990e-05,  4.31040280e-05,\n",
      "        3.04882233e-05,  2.34337786e-05,  2.00448521e-05,  1.76720660e-05,\n",
      "       -1.48957915e-05, -1.12562439e-05,  1.34594666e-05,  1.27835283e-05,\n",
      "       -8.50331799e-06,  9.62353442e-06,  9.03602267e-06,  8.81825417e-06,\n",
      "       -5.82254779e-06, -5.47532409e-06,  5.83204746e-06,  4.82999167e-06,\n",
      "       -4.19895377e-06, -3.78905088e-06,  4.58533395e-06,  4.14868146e-06,\n",
      "       -2.95920904e-06,  3.49281163e-06,  3.18927960e-06,  2.85199530e-06,\n",
      "        2.64986397e-06, -2.45042202e-06, -2.26776092e-06, -1.61713649e-06,\n",
      "       -1.53579560e-06,  1.99978535e-06,  1.80435973e-06,  1.70396515e-06,\n",
      "        1.54937584e-06,  1.30651176e-06, -9.02554632e-07,  1.15542389e-06,\n",
      "        9.27701365e-07, -8.09472908e-07,  9.19567867e-07, -7.13721363e-07,\n",
      "       -6.71666612e-07,  7.32261753e-07,  6.79995821e-07, -5.36378252e-07,\n",
      "        5.78521735e-07, -4.41291746e-07,  4.91812159e-07, -3.70305628e-07,\n",
      "        4.15753505e-07,  3.45527070e-07,  3.24906893e-07, -2.14363368e-07,\n",
      "       -2.37901290e-07, -2.44627387e-07,  2.67522040e-07,  2.36920570e-07,\n",
      "        2.16717098e-07, -1.79099715e-07, -1.53285271e-07,  1.61950041e-07,\n",
      "        1.47340984e-07, -1.14213151e-07,  1.10232335e-07, -8.76071695e-08,\n",
      "        8.59366125e-08,  6.87080899e-08, -6.48295426e-08, -5.61644029e-08,\n",
      "        4.54075249e-08, -3.78731322e-08,  4.12983390e-08,  3.01165137e-08,\n",
      "       -2.58953907e-08,  2.62351119e-08, -1.97034069e-08, -1.31963018e-08,\n",
      "        1.53217314e-08,  1.03671951e-08,  8.53845794e-09, -3.35959971e-09,\n",
      "        3.78029379e-11, -1.12228316e-09,  6.14607343e-09,  4.43462556e-09],\n",
      "      dtype=float32), array([[-4.65193726e-02,  2.27951687e-02, -3.65655348e-02, ...,\n",
      "         3.36963870e-02,  1.32381247e-05,  3.25182540e-04],\n",
      "       [-4.75716516e-02, -2.25487962e-01, -4.97987457e-02, ...,\n",
      "         1.85894761e-02, -6.85167462e-02,  1.08273672e-02],\n",
      "       [-1.30606536e-03,  2.44487599e-02, -1.08232861e-03, ...,\n",
      "         1.84962954e-02,  8.28740597e-02, -1.19485497e-01],\n",
      "       ...,\n",
      "       [-5.81905525e-03,  5.74378017e-03,  1.15252234e-01, ...,\n",
      "        -1.23344809e-02,  2.24816166e-02, -6.54582283e-04],\n",
      "       [-1.65066645e-01,  1.02745041e-01, -5.33837527e-02, ...,\n",
      "        -7.39830360e-03, -5.69531275e-03, -1.37372036e-03],\n",
      "       [-3.38740870e-02,  4.07707840e-02,  6.83287308e-02, ...,\n",
      "         6.36688694e-02, -5.46853542e-02,  5.87071385e-03]], dtype=float32))\n",
      "(array([ 5.86713867e+02,  1.06014264e+00,  6.73024893e-01,  2.12573245e-01,\n",
      "        1.86085865e-01,  8.12674016e-02,  5.50197735e-02,  3.66946384e-02,\n",
      "        2.02087499e-02,  1.89626906e-02,  1.29426671e-02,  9.49952286e-03,\n",
      "        7.66916620e-03,  5.90187777e-03,  4.95702168e-03,  4.26066155e-03,\n",
      "        3.65303038e-03,  2.82201287e-03,  1.60675810e-03,  1.14175933e-03,\n",
      "        1.02097669e-03,  8.57058796e-04,  8.03754607e-04,  5.42946684e-04,\n",
      "        4.97872592e-04,  4.79165989e-04,  4.34308255e-04,  3.65449319e-04,\n",
      "        3.25287168e-04,  2.82630412e-04,  2.22452407e-04,  2.04986485e-04,\n",
      "        1.76805886e-04,  1.36257222e-04,  1.30536064e-04,  1.13534676e-04,\n",
      "        1.04660547e-04,  9.24897540e-05,  8.43772796e-05,  6.19187049e-05,\n",
      "        4.78782022e-05,  4.19078533e-05,  3.45965163e-05,  3.32022464e-05,\n",
      "        2.09586851e-05,  1.86834568e-05,  1.78918290e-05, -1.34023585e-05,\n",
      "        1.33123103e-05, -9.63581715e-06, -9.71243935e-06,  1.20135501e-05,\n",
      "        8.84673955e-06,  8.13354745e-06, -6.46467151e-06,  6.70777217e-06,\n",
      "        5.09981555e-06, -4.86953240e-06, -4.02647220e-06, -3.48091635e-06,\n",
      "        3.89481693e-06,  3.57939189e-06, -2.72557440e-06,  3.03923321e-06,\n",
      "        2.68363374e-06, -2.27526834e-06,  2.34277604e-06,  2.11240763e-06,\n",
      "       -1.63019160e-06, -1.41167561e-06,  1.83234738e-06,  1.48270203e-06,\n",
      "       -1.08292022e-06,  1.23347456e-06,  1.13792885e-06, -1.06890730e-06,\n",
      "       -9.32042497e-07,  8.41931069e-07, -7.41645749e-07,  7.35033325e-07,\n",
      "       -6.47813238e-07,  6.68173413e-07,  5.80489882e-07, -4.54861009e-07,\n",
      "       -4.89971740e-07, -4.12185472e-07, -3.81679655e-07,  3.99848062e-07,\n",
      "        3.22291925e-07,  3.12053317e-07, -2.90839836e-07, -2.40374106e-07,\n",
      "        2.63052272e-07,  2.15850818e-07,  1.90695772e-07, -1.80247525e-07,\n",
      "       -1.53084741e-07,  1.65350926e-07, -1.34217927e-07,  1.16997072e-07,\n",
      "        9.41655003e-08,  7.99856181e-08, -7.68410473e-08, -6.44322782e-08,\n",
      "        5.80429607e-08, -5.36330909e-08, -3.78038898e-08,  4.02574720e-08,\n",
      "       -3.08554178e-08,  3.12339203e-08,  2.88992936e-08,  2.62520068e-08,\n",
      "       -2.02030943e-08,  1.79673005e-08, -1.53843338e-08, -1.16087060e-08,\n",
      "       -4.64211736e-09, -1.18567489e-09,  6.36759867e-10,  5.59790925e-09],\n",
      "      dtype=float32), array([[-5.1054668e-02,  6.7364745e-02,  1.8941863e-01, ...,\n",
      "        -1.2030594e-02,  1.1600253e-02,  1.6882598e-02],\n",
      "       [-5.0244235e-02, -2.4636282e-01, -1.5295333e-04, ...,\n",
      "        -7.8925909e-03, -9.7545749e-03, -2.2622317e-02],\n",
      "       [-1.1490724e-03,  2.5979474e-02,  1.1465856e-04, ...,\n",
      "        -1.2886924e-01,  2.4100761e-01, -1.7946698e-01],\n",
      "       ...,\n",
      "       [-2.3085086e-03,  7.6816673e-03, -3.9039016e-02, ...,\n",
      "         9.7999029e-02, -3.8085513e-02, -4.0436406e-02],\n",
      "       [-1.6839164e-01,  1.2012473e-01,  1.2738582e-01, ...,\n",
      "         1.3779654e-02, -2.4527588e-03, -1.6475855e-03],\n",
      "       [-3.6547028e-02,  6.4654976e-02,  8.8494428e-02, ...,\n",
      "         1.6053184e-03, -1.9608209e-02, -2.6659731e-02]], dtype=float32))\n",
      "(array([ 4.96529175e+02,  2.01467299e+00,  1.02598929e+00,  7.33584404e-01,\n",
      "        2.38443643e-01,  1.42320275e-01,  9.50366482e-02,  4.24750373e-02,\n",
      "        3.74800228e-02,  2.35322230e-02,  1.83747280e-02,  1.52808661e-02,\n",
      "        1.24235330e-02,  8.02528858e-03,  6.90668961e-03,  6.24551065e-03,\n",
      "        5.04238391e-03,  3.68342362e-03,  3.04095005e-03,  2.97521031e-03,\n",
      "        2.43321829e-03,  1.49361917e-03,  1.00771792e-03,  9.06822970e-04,\n",
      "        8.08413723e-04,  6.37936697e-04,  5.65416820e-04,  4.49554500e-04,\n",
      "        3.72607348e-04,  3.37873877e-04,  2.97693303e-04,  2.27213779e-04,\n",
      "        1.83151540e-04,  1.71572130e-04,  1.54049805e-04,  1.17627453e-04,\n",
      "        1.15467177e-04,  9.05799461e-05,  7.05156708e-05,  6.95560084e-05,\n",
      "        5.67879724e-05,  4.58127288e-05,  3.45877052e-05,  3.05587273e-05,\n",
      "        2.48243305e-05,  1.98445341e-05, -1.32844234e-05,  1.42670242e-05,\n",
      "        1.21349603e-05,  1.10396850e-05, -8.85365262e-06,  8.50045217e-06,\n",
      "        6.89634680e-06, -5.54119970e-06, -5.31527530e-06,  5.85837233e-06,\n",
      "        5.26538633e-06, -3.55164821e-06,  3.99356531e-06, -3.19398578e-06,\n",
      "        3.37931624e-06,  2.97012184e-06,  2.72265538e-06, -2.45200113e-06,\n",
      "       -2.09491509e-06,  2.10379312e-06, -1.63200673e-06,  1.71665056e-06,\n",
      "        1.48578624e-06, -1.34795880e-06, -1.30412127e-06, -1.00693046e-06,\n",
      "       -9.80838877e-07,  1.08487075e-06,  1.06180869e-06,  9.62099875e-07,\n",
      "       -7.39131906e-07,  8.41166241e-07,  7.89985222e-07, -6.50688037e-07,\n",
      "       -5.54859355e-07,  6.49939807e-07,  5.12628674e-07, -4.59266971e-07,\n",
      "        3.99979882e-07,  3.58764282e-07, -3.77289751e-07, -3.06230987e-07,\n",
      "       -2.06763247e-07, -1.95258636e-07,  2.64019775e-07,  2.46135926e-07,\n",
      "        2.02739059e-07, -1.70159453e-07,  1.31248626e-07, -1.23521332e-07,\n",
      "        1.18043424e-07,  1.00851139e-07,  9.97962530e-08, -1.03513287e-07,\n",
      "       -9.00320103e-08, -7.86833354e-08,  8.05314997e-08, -5.82861901e-08,\n",
      "        5.34086801e-08, -4.65148666e-08, -3.87002039e-08,  3.74567968e-08,\n",
      "        2.80032193e-08, -1.83355233e-08,  1.97290646e-08,  1.56900679e-08,\n",
      "        1.28800304e-08,  1.00553752e-08,  3.37274364e-09,  1.68957648e-09,\n",
      "       -2.24762120e-09, -4.04399181e-09, -9.01036401e-09, -7.89111532e-09],\n",
      "      dtype=float32), array([[ 0.0527433 , -0.02889019,  0.02675345, ..., -0.0110989 ,\n",
      "         0.03711948, -0.02627409],\n",
      "       [ 0.04937737,  0.12302011,  0.19604117, ..., -0.02967586,\n",
      "         0.01972337,  0.01972897],\n",
      "       [ 0.00091269, -0.00320397, -0.0176541 , ..., -0.10160205,\n",
      "         0.01827255, -0.22044034],\n",
      "       ...,\n",
      "       [ 0.00408582, -0.06831384, -0.01374183, ..., -0.10721822,\n",
      "         0.06314176, -0.0426028 ],\n",
      "       [ 0.1632115 ,  0.08588321, -0.16340727, ..., -0.01087881,\n",
      "         0.0133505 , -0.00049843],\n",
      "       [ 0.03363815,  0.0496994 , -0.06826498, ...,  0.10043856,\n",
      "        -0.08504673,  0.05891009]], dtype=float32))\n",
      "(array([ 4.20291138e+02,  4.20680106e-01,  2.55712658e-01,  1.63391054e-01,\n",
      "        7.46222436e-02,  5.09541556e-02,  2.22952235e-02,  1.33707644e-02,\n",
      "        8.33013747e-03,  6.01613196e-03,  5.35413111e-03,  2.81934207e-03,\n",
      "        1.99279538e-03,  1.72559894e-03,  1.15205604e-03,  6.99819589e-04,\n",
      "        6.58515259e-04,  4.41918295e-04,  3.51792347e-04,  2.78623629e-04,\n",
      "        2.37909378e-04,  1.91650979e-04,  1.84353295e-04,  1.49750093e-04,\n",
      "        1.28526401e-04,  1.10447399e-04,  9.58578312e-05,  8.66643386e-05,\n",
      "        7.53634740e-05,  6.41804290e-05,  5.26847180e-05,  4.30084219e-05,\n",
      "        3.74741467e-05,  3.34552569e-05,  2.40870286e-05, -1.18323032e-05,\n",
      "        1.86808356e-05,  1.74155430e-05,  1.66241989e-05,  1.26947734e-05,\n",
      "        1.19772158e-05,  1.15017065e-05,  9.05775778e-06, -8.77124603e-06,\n",
      "       -7.81322706e-06,  7.64667584e-06,  6.15210229e-06,  5.64071252e-06,\n",
      "       -4.30656564e-06,  4.88526757e-06, -2.91677316e-06,  4.11157816e-06,\n",
      "        3.85384101e-06,  3.07297523e-06,  2.96221901e-06, -2.51335882e-06,\n",
      "       -2.33608466e-06,  2.52843961e-06,  2.42608894e-06,  2.24924497e-06,\n",
      "        2.06572849e-06, -1.68350311e-06, -1.58626278e-06,  1.69522173e-06,\n",
      "       -1.60455022e-06,  1.46707805e-06, -1.28305135e-06,  1.19440051e-06,\n",
      "       -1.04671687e-06,  1.02773663e-06, -8.84204781e-07,  8.57194550e-07,\n",
      "        7.86674093e-07, -6.67309166e-07,  6.96925269e-07,  5.82835412e-07,\n",
      "       -5.17481908e-07,  5.54867199e-07,  5.02569605e-07, -4.39433819e-07,\n",
      "       -4.15252174e-07,  3.81643162e-07,  3.50881919e-07,  3.40176086e-07,\n",
      "       -3.07956753e-07, -2.52407688e-07,  2.59325759e-07, -1.98983912e-07,\n",
      "       -1.68641733e-07, -1.63720983e-07,  1.87466242e-07,  1.69089489e-07,\n",
      "        1.47440133e-07,  1.14249680e-07,  1.06463219e-07, -1.19225447e-07,\n",
      "       -1.05179438e-07, -9.26692536e-08, -8.11834511e-08,  8.72136638e-08,\n",
      "        6.86597517e-08,  6.12891213e-08, -6.02484391e-08, -4.63953960e-08,\n",
      "       -3.54608893e-08,  4.14988790e-08,  3.86333063e-08, -2.66699232e-08,\n",
      "        3.47192284e-08,  2.40594016e-08,  1.75884072e-08, -1.42491290e-08,\n",
      "       -1.20697736e-08,  1.03628404e-08,  8.83462370e-09, -5.78357007e-09,\n",
      "       -4.46052395e-09,  2.35726966e-10,  1.33738365e-09,  3.28695693e-09],\n",
      "      dtype=float32), array([[-5.19238897e-02,  4.56702709e-03, -4.73885983e-02, ...,\n",
      "        -2.81845387e-02, -7.62717193e-03, -2.83040721e-02],\n",
      "       [-4.35899459e-02,  4.42239121e-02,  1.64565831e-01, ...,\n",
      "         1.67477725e-03,  3.36579010e-02,  2.82001812e-02],\n",
      "       [ 4.21644654e-04, -2.98751816e-02, -2.95158271e-02, ...,\n",
      "        -2.96492316e-02,  8.85890722e-02,  1.12788692e-01],\n",
      "       ...,\n",
      "       [-1.15889320e-02,  2.31343210e-02,  1.22077977e-02, ...,\n",
      "        -8.48429576e-02, -8.86348076e-03,  7.20629394e-02],\n",
      "       [-1.53882906e-01,  2.28905573e-01, -1.13418996e-01, ...,\n",
      "        -7.77224777e-03, -1.22299241e-02,  1.11415125e-02],\n",
      "       [-2.51835883e-02,  1.09226174e-04, -4.29201312e-02, ...,\n",
      "         4.30919267e-02, -5.24229035e-02, -5.40818311e-02]], dtype=float32))\n",
      "(array([ 3.91203979e+02,  5.10887444e-01,  3.65513653e-01,  1.76438019e-01,\n",
      "        1.31326601e-01,  1.07883856e-01,  2.60750148e-02,  1.42544191e-02,\n",
      "        1.04763359e-02,  6.48730248e-03,  6.31807419e-03,  2.93520116e-03,\n",
      "        2.14677164e-03,  1.91844790e-03,  1.27571973e-03,  8.71389231e-04,\n",
      "        6.46388275e-04,  5.92820463e-04,  4.79407085e-04,  3.56084871e-04,\n",
      "        3.25186906e-04,  2.66995019e-04,  2.36367006e-04,  1.75730136e-04,\n",
      "        1.46442530e-04,  1.00527701e-04,  9.55205760e-05,  8.38053966e-05,\n",
      "        6.62841849e-05,  4.68372600e-05,  4.13109046e-05,  3.56703749e-05,\n",
      "        2.69676675e-05,  2.64158934e-05,  2.28941899e-05,  1.96223791e-05,\n",
      "        1.76445174e-05, -1.23131085e-05,  1.52222219e-05,  1.50910082e-05,\n",
      "        1.20923660e-05, -8.64629692e-06,  1.01943324e-05,  7.33270554e-06,\n",
      "       -6.43058638e-06,  6.44248530e-06,  5.99105670e-06, -4.42052169e-06,\n",
      "       -4.17697856e-06,  5.34012997e-06,  4.84188968e-06,  4.27239684e-06,\n",
      "       -3.19004653e-06,  3.58643751e-06,  3.16586966e-06,  2.65833023e-06,\n",
      "       -2.23968891e-06, -2.04835010e-06, -1.81359530e-06,  2.07575295e-06,\n",
      "        1.87509738e-06,  1.47571632e-06,  1.35141374e-06, -1.33121114e-06,\n",
      "       -1.16528827e-06,  1.03702462e-06, -8.36334777e-07, -7.21892889e-07,\n",
      "        8.66889650e-07,  8.31533498e-07,  7.87134979e-07, -6.12366136e-07,\n",
      "        6.45901480e-07,  5.78573406e-07, -4.63231260e-07,  4.69944780e-07,\n",
      "        4.88065837e-07, -3.92054801e-07,  3.82424048e-07, -3.45862588e-07,\n",
      "       -3.09314714e-07, -2.52420222e-07, -2.37053953e-07,  3.20381588e-07,\n",
      "        2.83752854e-07,  2.56478614e-07,  2.22209323e-07,  2.16887869e-07,\n",
      "       -1.72579320e-07, -1.74066130e-07,  1.89782156e-07,  1.77235449e-07,\n",
      "       -1.36419999e-07,  1.41834036e-07, -1.22668936e-07,  9.27593931e-08,\n",
      "       -9.30539485e-08, -7.89138852e-08,  7.37745793e-08, -5.23270955e-08,\n",
      "       -4.46691857e-08,  6.48059242e-08,  5.20032870e-08,  4.62829348e-08,\n",
      "       -3.56395979e-08,  3.93985715e-08, -3.04344816e-08, -2.48033167e-08,\n",
      "        2.75032246e-08, -1.62939173e-08,  1.88941875e-08, -1.23622792e-08,\n",
      "       -1.05177183e-08,  1.43705208e-08,  1.57633604e-08, -3.51283891e-09,\n",
      "        7.85102650e-09,  5.28262944e-09,  2.47532728e-09,  8.84721518e-10],\n",
      "      dtype=float32), array([[-0.05419736,  0.02514097,  0.00683124, ..., -0.02212124,\n",
      "         0.04538722, -0.00245166],\n",
      "       [-0.04185683, -0.07488269,  0.04962203, ...,  0.0082988 ,\n",
      "         0.03423196, -0.00497112],\n",
      "       [ 0.00198562, -0.01416588, -0.05005686, ...,  0.21520138,\n",
      "         0.02374144,  0.02046801],\n",
      "       ...,\n",
      "       [-0.01544711,  0.01718261,  0.12630752, ..., -0.05763952,\n",
      "         0.02873091,  0.03098514],\n",
      "       [-0.15055564,  0.13969709,  0.1535436 , ..., -0.00737451,\n",
      "         0.00456729,  0.00904062],\n",
      "       [-0.02365727,  0.04889853, -0.03943627, ..., -0.08057306,\n",
      "        -0.03252988,  0.05398709]], dtype=float32))\n",
      "(array([ 3.99459656e+02,  6.19595170e-01,  2.20777273e-01,  1.96747169e-01,\n",
      "        1.22330859e-01,  7.56095797e-02,  2.08578538e-02,  1.50737008e-02,\n",
      "        1.37980515e-02,  5.87061187e-03,  3.61948134e-03,  2.82526715e-03,\n",
      "        1.91005261e-03,  1.50138489e-03,  1.24635873e-03,  9.38997720e-04,\n",
      "        6.54233037e-04,  5.38207765e-04,  3.92458489e-04,  2.89356656e-04,\n",
      "        2.58610409e-04,  1.81400508e-04,  1.48288687e-04,  1.22500060e-04,\n",
      "        1.07839791e-04,  9.47740773e-05,  7.27105580e-05,  6.29468777e-05,\n",
      "        5.10613027e-05,  4.02531296e-05,  2.82187029e-05,  2.52124646e-05,\n",
      "        2.17855741e-05,  1.77827660e-05, -1.06193802e-05,  1.52531402e-05,\n",
      "        1.46286420e-05,  1.23973768e-05,  1.22669408e-05,  1.01965898e-05,\n",
      "       -9.33140291e-06, -6.72300439e-06,  8.56473343e-06,  7.62566697e-06,\n",
      "        6.49926005e-06,  5.94283301e-06,  4.73247155e-06, -4.07248763e-06,\n",
      "       -3.81320979e-06,  3.67899452e-06, -2.73399473e-06,  3.41786631e-06,\n",
      "        2.78129914e-06,  2.65359949e-06, -2.17094316e-06, -1.80989730e-06,\n",
      "        2.10861776e-06,  1.82955569e-06,  1.75555647e-06, -1.48203821e-06,\n",
      "       -1.32584148e-06,  1.35419521e-06, -9.70811811e-07,  1.13897386e-06,\n",
      "        1.02127422e-06, -7.66587050e-07, -7.48718037e-07,  9.46563148e-07,\n",
      "        8.93809499e-07,  8.21768936e-07,  7.69153530e-07, -6.34494825e-07,\n",
      "        6.24601512e-07,  6.03235833e-07, -5.39412213e-07, -4.71611855e-07,\n",
      "       -4.14037231e-07,  4.76558881e-07,  4.42077550e-07, -3.58729352e-07,\n",
      "        3.18295349e-07, -3.06143562e-07,  2.97558870e-07,  2.78561799e-07,\n",
      "        2.18666770e-07,  2.10367347e-07, -2.12448384e-07, -2.03038098e-07,\n",
      "       -1.79262003e-07,  1.73735998e-07,  1.50460806e-07,  1.41391411e-07,\n",
      "       -1.18786929e-07, -1.13554059e-07, -9.52372332e-08,  9.09829794e-08,\n",
      "        9.35164337e-08, -8.03377276e-08,  7.59784982e-08,  7.08105716e-08,\n",
      "       -5.90210512e-08, -4.45153070e-08, -4.70316586e-08,  5.45050973e-08,\n",
      "        5.28604858e-08,  3.90039006e-08,  2.67178280e-08, -2.53708770e-08,\n",
      "        2.95250882e-08,  1.71072951e-08, -1.95192040e-08, -2.13597779e-08,\n",
      "       -1.45963952e-08,  9.76424985e-09,  6.27349017e-09,  3.05481151e-09,\n",
      "        7.22664539e-10, -7.32962047e-09, -3.31082406e-09, -5.53461277e-09],\n",
      "      dtype=float32), array([[-0.05171726,  0.09072763,  0.16402546, ...,  0.00433716,\n",
      "        -0.01710391, -0.00172149],\n",
      "       [-0.03920326, -0.06081479,  0.04661544, ...,  0.02421006,\n",
      "        -0.00884021, -0.07588188],\n",
      "       [ 0.00372105, -0.00378028, -0.04976691, ..., -0.0597246 ,\n",
      "        -0.12377177, -0.05345662],\n",
      "       ...,\n",
      "       [-0.01892808, -0.09510464, -0.06241167, ...,  0.05725787,\n",
      "        -0.01238456,  0.11483802],\n",
      "       [-0.1541376 ,  0.15445192,  0.03133025, ...,  0.01067013,\n",
      "        -0.00930624,  0.00763098],\n",
      "       [-0.02178741,  0.05463827, -0.04767939, ..., -0.06283145,\n",
      "         0.01311754,  0.09281747]], dtype=float32))\n",
      "(array([ 3.46755157e+02,  8.55828106e-01,  3.42363298e-01,  2.00595096e-01,\n",
      "        8.04777145e-02,  6.65903986e-02,  3.51877920e-02,  2.23963540e-02,\n",
      "        1.09470170e-02,  9.87547822e-03,  8.67716782e-03,  5.10348286e-03,\n",
      "        1.98093802e-03,  1.88461912e-03,  1.52618205e-03,  1.27462565e-03,\n",
      "        9.53443407e-04,  7.86421588e-04,  4.31481603e-04,  3.83532315e-04,\n",
      "        3.00219050e-04,  2.19227251e-04,  1.87773156e-04,  1.67636812e-04,\n",
      "        1.50209278e-04,  1.36946110e-04,  1.03375874e-04,  9.15806158e-05,\n",
      "        8.31147627e-05,  6.49150024e-05,  5.97972357e-05,  5.19616588e-05,\n",
      "        3.95623501e-05,  3.37268939e-05,  3.19863502e-05,  2.84207727e-05,\n",
      "        2.56800595e-05,  1.66177124e-05,  1.60909349e-05,  1.39874946e-05,\n",
      "       -9.10167728e-06,  1.11863774e-05,  8.71726479e-06,  7.19261016e-06,\n",
      "        7.93566051e-06, -5.43842953e-06, -4.87102125e-06, -3.86871170e-06,\n",
      "       -3.55788734e-06,  5.00317265e-06,  4.56221733e-06,  4.45285423e-06,\n",
      "        3.74671299e-06,  2.65600829e-06,  2.74887589e-06, -2.38781263e-06,\n",
      "       -2.20158381e-06,  2.25861754e-06,  2.04118737e-06,  1.80118616e-06,\n",
      "        1.70492069e-06, -1.34609468e-06, -1.29042678e-06,  1.48016147e-06,\n",
      "        1.20996060e-06, -9.23744892e-07,  9.94427182e-07,  8.86253758e-07,\n",
      "       -8.04476599e-07, -7.89085220e-07,  7.78940034e-07, -6.80708013e-07,\n",
      "       -6.45551154e-07,  6.70723125e-07, -5.03009403e-07,  5.62097000e-07,\n",
      "        4.78768982e-07, -4.17580054e-07,  4.06803878e-07, -3.43279709e-07,\n",
      "        3.37775504e-07,  3.14784415e-07, -2.73459023e-07,  2.78891832e-07,\n",
      "        2.63094762e-07, -2.30501854e-07, -1.94488948e-07,  1.92457208e-07,\n",
      "       -1.70681631e-07,  1.86412336e-07,  1.63080955e-07, -1.38178493e-07,\n",
      "       -1.18793984e-07, -7.96013069e-08,  1.11789490e-07,  9.21862195e-08,\n",
      "        8.37111926e-08,  8.10759673e-08, -6.52959784e-08, -6.04879133e-08,\n",
      "        5.75891939e-08, -4.74958171e-08, -4.39114913e-08,  4.99356752e-08,\n",
      "        4.37106529e-08, -3.62173083e-08,  3.62868953e-08,  3.03811980e-08,\n",
      "       -2.76459655e-08,  2.51518646e-08, -2.11830784e-08,  2.14929212e-08,\n",
      "       -1.62438010e-08, -9.57270796e-09,  1.01803215e-08, -5.13349141e-09,\n",
      "        7.19448900e-09, -3.62111008e-10,  3.22025429e-09,  1.51416735e-09],\n",
      "      dtype=float32), array([[ 0.0532318 , -0.12051088,  0.05640669, ..., -0.02638131,\n",
      "         0.0354217 , -0.01676641],\n",
      "       [ 0.03987666,  0.01699283, -0.04242539, ..., -0.06413886,\n",
      "         0.01836747, -0.0282492 ],\n",
      "       [-0.00566188,  0.06653091, -0.01957415, ...,  0.10513841,\n",
      "        -0.16341618,  0.00344009],\n",
      "       ...,\n",
      "       [ 0.0255708 , -0.19577095,  0.00961219, ...,  0.03683314,\n",
      "         0.10437004,  0.05433465],\n",
      "       [ 0.14682056, -0.05183633,  0.22034867, ...,  0.00826913,\n",
      "         0.00386016, -0.00303905],\n",
      "       [ 0.02013016,  0.02182974,  0.04289841, ..., -0.04427392,\n",
      "         0.04516356,  0.04288538]], dtype=float32))\n",
      "(array([ 3.47201508e+02,  8.47501993e-01,  4.08714473e-01,  1.48221210e-01,\n",
      "        1.30160928e-01,  9.88724753e-02,  4.96191867e-02,  2.83517726e-02,\n",
      "        1.65546685e-02,  1.39569603e-02,  8.40057153e-03,  6.35546306e-03,\n",
      "        3.83481150e-03,  2.77673663e-03,  2.04098457e-03,  1.99167500e-03,\n",
      "        1.14705076e-03,  8.81463347e-04,  7.85279844e-04,  6.96176081e-04,\n",
      "        5.06616430e-04,  4.60675627e-04,  3.56012140e-04,  3.32344440e-04,\n",
      "        2.92558776e-04,  2.46530835e-04,  2.11124163e-04,  1.86552861e-04,\n",
      "        1.59276751e-04,  1.50263280e-04,  1.05020888e-04,  9.51203474e-05,\n",
      "        7.30047395e-05,  6.91172827e-05,  5.14069070e-05,  4.72656466e-05,\n",
      "        4.23329657e-05,  3.45122317e-05,  2.96611943e-05,  2.00869326e-05,\n",
      "        1.87767255e-05,  1.75765636e-05,  1.28744596e-05,  1.11332020e-05,\n",
      "       -7.20080789e-06, -6.76194850e-06,  7.99533154e-06,  7.56974805e-06,\n",
      "        7.07732488e-06, -4.50875405e-06,  5.32824470e-06,  4.35253423e-06,\n",
      "        3.65732672e-06, -2.72293687e-06,  3.03101820e-06, -2.16553985e-06,\n",
      "        2.48953393e-06,  2.25678787e-06, -1.80743370e-06,  1.89296168e-06,\n",
      "        1.66663017e-06, -1.62286051e-06, -1.41142175e-06,  1.40665577e-06,\n",
      "        1.34760148e-06,  1.16784918e-06,  1.12568182e-06, -1.02634624e-06,\n",
      "       -9.05245713e-07,  8.52745814e-07,  6.71764326e-07,  6.47640093e-07,\n",
      "       -7.56281850e-07, -7.26478049e-07, -6.14705186e-07, -5.61140610e-07,\n",
      "        5.48225671e-07, -4.56733119e-07,  3.98804190e-07, -3.48042931e-07,\n",
      "        3.38407204e-07, -2.93342964e-07,  3.07199002e-07,  3.16263055e-07,\n",
      "       -2.44652881e-07,  2.64780567e-07,  2.46132686e-07, -2.29464433e-07,\n",
      "       -1.98658526e-07,  1.96595522e-07, -2.10046792e-07, -1.35666696e-07,\n",
      "        1.48558527e-07, -1.17224815e-07,  1.25117936e-07,  1.15323182e-07,\n",
      "       -1.02245146e-07,  1.00090134e-07,  6.85051305e-08, -7.39219530e-08,\n",
      "       -5.86686326e-08, -5.36293392e-08, -4.33835829e-08,  4.61571830e-08,\n",
      "        4.15473060e-08,  3.53778091e-08,  3.13202335e-08,  2.36520030e-08,\n",
      "       -2.28890418e-08, -1.92028313e-08,  1.72914216e-08,  1.43779602e-08,\n",
      "        1.12052581e-08, -1.49668562e-08, -1.30659616e-08,  4.09527123e-09,\n",
      "       -6.67047129e-09, -5.37932765e-09, -1.01412845e-09, -2.11131757e-09],\n",
      "      dtype=float32), array([[-0.05081144,  0.03896417,  0.04740043, ..., -0.01388334,\n",
      "         0.00852966,  0.00203571],\n",
      "       [-0.03802417, -0.03082862, -0.14928572, ...,  0.01499029,\n",
      "         0.00437548,  0.07458764],\n",
      "       [ 0.00453948, -0.00716158,  0.05187403, ..., -0.07160258,\n",
      "         0.05331235,  0.04858259],\n",
      "       ...,\n",
      "       [-0.02019973, -0.03242676, -0.03835489, ..., -0.06902373,\n",
      "        -0.06306902,  0.00100471],\n",
      "       [-0.14656541,  0.1870887 ,  0.03058934, ...,  0.00254249,\n",
      "        -0.00879004,  0.00840662],\n",
      "       [-0.01887052,  0.0479393 ,  0.04650954, ..., -0.03436939,\n",
      "         0.01326549,  0.02901522]], dtype=float32))\n",
      "(array([ 3.23238190e+02,  4.12187785e-01,  2.35563532e-01,  1.32238403e-01,\n",
      "        9.07400995e-02,  7.69858882e-02,  5.33565953e-02,  1.88295487e-02,\n",
      "        8.77500419e-03,  5.73343132e-03,  4.15525399e-03,  2.97438214e-03,\n",
      "        2.57253647e-03,  1.61890942e-03,  1.32850150e-03,  9.27529356e-04,\n",
      "        5.73494181e-04,  5.15178661e-04,  3.92318150e-04,  3.32418014e-04,\n",
      "        2.71931436e-04,  2.14588974e-04,  1.64632642e-04,  1.45929735e-04,\n",
      "        1.40576652e-04,  1.04942294e-04,  9.23897023e-05,  7.07075887e-05,\n",
      "        6.21964718e-05,  5.42830567e-05,  4.37421404e-05,  3.85355670e-05,\n",
      "        3.70258094e-05,  3.23056775e-05,  2.46227246e-05,  1.89554157e-05,\n",
      "        1.64729299e-05,  1.53976998e-05, -9.08261063e-06,  1.28656748e-05,\n",
      "        1.10335450e-05,  8.96728670e-06,  8.26690757e-06,  7.38656308e-06,\n",
      "        7.09760980e-06,  6.25960956e-06, -4.79491564e-06, -4.27205123e-06,\n",
      "       -3.67726238e-06,  4.13367661e-06,  4.05896708e-06, -2.51623578e-06,\n",
      "        3.56299188e-06,  2.93507583e-06,  3.00437432e-06,  2.30701130e-06,\n",
      "       -2.02141973e-06, -1.65591871e-06,  2.06375717e-06,  1.89165155e-06,\n",
      "        1.67824953e-06,  1.31679269e-06, -1.20360994e-06, -1.09116093e-06,\n",
      "        1.16112176e-06,  9.21498156e-07, -8.15539750e-07, -6.64176071e-07,\n",
      "       -6.02012221e-07,  7.51938899e-07,  7.15447754e-07,  6.47617753e-07,\n",
      "       -5.37026210e-07, -5.41692316e-07,  5.10759207e-07,  4.88182536e-07,\n",
      "       -4.13349397e-07,  4.02900895e-07, -3.68321025e-07,  3.82874987e-07,\n",
      "        3.10638114e-07,  2.89464225e-07, -3.14502643e-07, -2.65732695e-07,\n",
      "       -2.39920411e-07, -2.09854960e-07, -1.71964658e-07,  1.92165658e-07,\n",
      "        1.78186298e-07, -1.31350134e-07,  1.54751987e-07,  1.47997852e-07,\n",
      "        1.26278707e-07, -9.80265540e-08, -8.07921694e-08,  1.17839896e-07,\n",
      "        9.78005374e-08,  9.37754194e-08, -7.57488365e-08,  6.55185346e-08,\n",
      "        5.91100964e-08, -5.91271458e-08, -4.72724579e-08, -3.76847886e-08,\n",
      "        4.39747083e-08,  3.99118782e-08, -4.39390213e-08, -1.97945926e-08,\n",
      "       -1.61124412e-08,  2.73489142e-08, -1.00451913e-08, -6.82011914e-09,\n",
      "       -1.73295855e-09,  5.02450637e-10,  2.20780478e-08,  2.01181116e-08,\n",
      "        5.61572300e-09,  1.68186336e-08,  1.30618343e-08,  9.96084726e-09],\n",
      "      dtype=float32), array([[-0.0482051 , -0.11173574,  0.11244042, ..., -0.03861653,\n",
      "         0.04692994, -0.008567  ],\n",
      "       [-0.03773753, -0.00690907,  0.00497182, ...,  0.06423704,\n",
      "        -0.06129576, -0.06096361],\n",
      "       [ 0.0055884 ,  0.01861828, -0.04860217, ...,  0.25092492,\n",
      "         0.04923872,  0.00949634],\n",
      "       ...,\n",
      "       [-0.01982505,  0.0456505 ,  0.21983023, ...,  0.0183777 ,\n",
      "        -0.02904229,  0.00267973],\n",
      "       [-0.14240293, -0.1977783 ,  0.06190823, ..., -0.00106548,\n",
      "         0.01242223,  0.01366483],\n",
      "       [-0.01742056, -0.04886141,  0.01157234, ...,  0.01112725,\n",
      "        -0.03679688,  0.04568107]], dtype=float32))\n",
      "(array([ 3.1437967e+02,  6.7519087e-01,  2.7979270e-01,  1.6229267e-01,\n",
      "        1.0942220e-01,  8.3071522e-02,  5.0703336e-02,  1.2043562e-02,\n",
      "        8.8646701e-03,  6.4639198e-03,  4.9167848e-03,  4.4547189e-03,\n",
      "        2.4836597e-03,  2.2088713e-03,  1.6246552e-03,  9.4095519e-04,\n",
      "        7.9708558e-04,  7.8628684e-04,  6.1164179e-04,  4.4756255e-04,\n",
      "        3.3720629e-04,  2.8380036e-04,  2.3040296e-04,  1.8941499e-04,\n",
      "        1.4879921e-04,  1.1313069e-04,  9.9198958e-05,  8.9217509e-05,\n",
      "        7.9532736e-05,  6.6994864e-05,  5.6050605e-05,  4.1890551e-05,\n",
      "        3.8978091e-05,  3.0851901e-05,  3.0215824e-05,  2.4579749e-05,\n",
      "        1.9533225e-05,  1.5467769e-05,  1.4410902e-05,  1.1908541e-05,\n",
      "        1.0103040e-05, -7.3558836e-06,  8.7701710e-06,  7.3454912e-06,\n",
      "        6.2648614e-06, -4.6460073e-06,  5.0718099e-06,  4.9419036e-06,\n",
      "        4.2271918e-06, -3.2835753e-06, -3.1305362e-06,  3.4429290e-06,\n",
      "        2.7461140e-06,  2.6727294e-06, -1.9729907e-06, -1.8987223e-06,\n",
      "        1.9822685e-06, -1.5830889e-06,  1.6943053e-06, -1.3714719e-06,\n",
      "       -1.2451064e-06, -1.1167981e-06,  1.5542146e-06,  1.3593738e-06,\n",
      "        1.1468775e-06,  1.0010879e-06, -8.9649961e-07,  9.4804625e-07,\n",
      "        8.2509206e-07,  7.2801720e-07, -6.1469518e-07,  6.1483706e-07,\n",
      "        5.3972263e-07, -5.4655146e-07, -5.0449762e-07, -4.3264458e-07,\n",
      "        4.5866437e-07, -3.4396408e-07,  3.5838823e-07,  3.1900692e-07,\n",
      "       -2.9139568e-07,  2.6679257e-07,  2.4446467e-07, -2.0024028e-07,\n",
      "       -1.7925147e-07,  2.0122462e-07,  1.8752263e-07,  1.6411339e-07,\n",
      "       -1.4403760e-07, -1.5162402e-07, -1.1974093e-07,  1.2982852e-07,\n",
      "       -9.7279873e-08,  1.1440659e-07, -7.8783678e-08,  9.0490097e-08,\n",
      "        7.4245975e-08,  6.8798677e-08,  5.8326293e-08, -5.5625428e-08,\n",
      "       -4.8944344e-08, -4.3897160e-08,  4.6671762e-08,  4.0870674e-08,\n",
      "       -3.6862225e-08, -3.2072819e-08,  2.9433968e-08, -2.0577964e-08,\n",
      "       -1.7801135e-08,  1.4976244e-08,  1.9497230e-08,  2.2111983e-08,\n",
      "       -9.9361710e-09, -3.7737218e-09, -6.9871398e-09,  1.2022562e-08,\n",
      "        5.4034395e-09,  3.4563092e-09, -4.8711518e-10,  5.0964694e-10],\n",
      "      dtype=float32), array([[-0.05023701,  0.10020361, -0.02519476, ..., -0.03012946,\n",
      "        -0.02742576, -0.03403213],\n",
      "       [-0.03661813, -0.05181909,  0.08463851, ..., -0.11169264,\n",
      "        -0.01546506,  0.04197624],\n",
      "       [ 0.00791706, -0.03468101, -0.07258932, ..., -0.17325307,\n",
      "         0.01600289,  0.10005118],\n",
      "       ...,\n",
      "       [-0.02784522,  0.10710418,  0.16426817, ...,  0.09657109,\n",
      "        -0.01713168, -0.00109797],\n",
      "       [-0.14238922,  0.17301977, -0.08683621, ...,  0.01184787,\n",
      "         0.01211478,  0.01066142],\n",
      "       [-0.01665732,  0.03816235, -0.06182338, ..., -0.08523346,\n",
      "        -0.04005901,  0.04120703]], dtype=float32))\n",
      "(array([ 3.33635010e+02,  2.71158695e-01,  1.72725484e-01,  1.32794365e-01,\n",
      "        9.23937783e-02,  5.55748530e-02,  2.24210620e-02,  1.74311120e-02,\n",
      "        8.68916139e-03,  6.45740936e-03,  4.69407346e-03,  2.33584922e-03,\n",
      "        1.48638966e-03,  1.24633685e-03,  7.70166283e-04,  7.31055101e-04,\n",
      "        3.78935452e-04,  3.19715531e-04,  2.51389574e-04,  2.25644646e-04,\n",
      "        1.65823381e-04,  1.33188980e-04,  9.90955450e-05,  9.20621023e-05,\n",
      "        6.85644845e-05,  4.49634463e-05,  4.26229089e-05,  3.90238529e-05,\n",
      "        3.26214758e-05,  2.14334432e-05,  1.84472246e-05,  1.40563579e-05,\n",
      "        1.24145690e-05, -9.51249240e-06, -7.87759654e-06,  7.99286045e-06,\n",
      "        7.04313379e-06,  6.52899234e-06, -5.45359444e-06,  5.51646963e-06,\n",
      "       -3.93852497e-06,  4.35704487e-06,  4.18044419e-06, -3.23747236e-06,\n",
      "       -2.98250325e-06,  3.40960560e-06,  3.20462982e-06,  2.86433465e-06,\n",
      "        2.49758796e-06, -1.95588291e-06,  2.06550180e-06, -1.78148287e-06,\n",
      "       -1.50341702e-06,  1.77955360e-06,  1.68584916e-06,  1.57644467e-06,\n",
      "        1.53492908e-06, -1.28371539e-06, -1.05636070e-06, -8.98584233e-07,\n",
      "        1.27992269e-06,  1.18960247e-06,  1.04264336e-06,  1.02686272e-06,\n",
      "        8.77231912e-07, -6.70178906e-07, -5.82926305e-07,  6.88901594e-07,\n",
      "        5.97524831e-07,  5.68682822e-07, -4.46793536e-07, -3.91931707e-07,\n",
      "        4.66730654e-07,  4.19794475e-07, -3.17803085e-07,  4.11463787e-07,\n",
      "        3.38492356e-07, -2.58607287e-07, -2.17008122e-07, -2.00717011e-07,\n",
      "        2.67138745e-07,  2.52495227e-07,  2.33953699e-07, -1.70502076e-07,\n",
      "        2.12281762e-07,  1.95597366e-07,  1.72951374e-07, -1.43961884e-07,\n",
      "       -1.19083090e-07, -1.26902279e-07,  1.48342508e-07,  1.39260237e-07,\n",
      "        1.02070466e-07, -8.15476469e-08, -7.16050721e-08,  8.36605523e-08,\n",
      "        7.34531795e-08, -5.91344431e-08, -4.77464290e-08,  7.17216935e-08,\n",
      "        5.56302275e-08,  4.24943529e-08, -2.75165917e-08, -2.41514435e-08,\n",
      "        4.48841462e-08,  2.99670084e-08, -2.08388151e-08, -1.90804599e-08,\n",
      "        1.88077713e-08,  1.73514074e-08, -1.15957297e-08,  1.17913235e-08,\n",
      "       -6.20873442e-09, -5.81403592e-09,  1.02351319e-08,  8.49848014e-09,\n",
      "        5.18767074e-09,  4.15586099e-09, -8.31857153e-11, -5.55541779e-10],\n",
      "      dtype=float32), array([[-0.05049031,  0.03187564, -0.04585703, ..., -0.05423804,\n",
      "        -0.01357822,  0.00258352],\n",
      "       [-0.03349369,  0.00128695,  0.09173767, ...,  0.0013891 ,\n",
      "         0.02150016,  0.01971794],\n",
      "       [ 0.00901327,  0.01464736, -0.08760484, ...,  0.13361107,\n",
      "         0.10714787, -0.11742631],\n",
      "       ...,\n",
      "       [-0.02961297, -0.14233576,  0.17489348, ..., -0.06150823,\n",
      "        -0.06083719,  0.00910849],\n",
      "       [-0.14447397,  0.18287846,  0.01492066, ..., -0.00221839,\n",
      "         0.02524492, -0.01313205],\n",
      "       [-0.0157837 ,  0.03988407, -0.04062079, ...,  0.08707655,\n",
      "        -0.06291688, -0.10091722]], dtype=float32))\n",
      "(array([ 2.81377563e+02,  1.56122780e+00,  1.81701183e-01,  1.59396842e-01,\n",
      "        9.10028890e-02,  8.33731741e-02,  5.00998385e-02,  2.97104008e-02,\n",
      "        1.32502690e-02,  9.82075371e-03,  6.36764942e-03,  4.39921254e-03,\n",
      "        3.65727535e-03,  2.51448108e-03,  1.37880829e-03,  1.19874731e-03,\n",
      "        9.08013666e-04,  6.72689523e-04,  5.71616285e-04,  4.65851947e-04,\n",
      "        4.36475093e-04,  3.47066438e-04,  3.06456466e-04,  2.35880885e-04,\n",
      "        1.56093476e-04,  1.36518953e-04,  1.19047916e-04,  1.12103713e-04,\n",
      "        8.28050324e-05,  6.94917762e-05,  5.19000641e-05,  4.65424346e-05,\n",
      "        4.36793925e-05,  3.16273909e-05,  2.87902876e-05,  2.16074350e-05,\n",
      "        1.87659462e-05,  1.57333307e-05,  1.17497748e-05,  1.04311921e-05,\n",
      "       -6.25582970e-06,  8.85037025e-06,  8.28498833e-06,  7.71510804e-06,\n",
      "        6.01669399e-06, -5.35395657e-06,  5.60785702e-06, -3.26014651e-06,\n",
      "        4.96887787e-06,  4.44264879e-06,  3.76465641e-06, -2.79445567e-06,\n",
      "        3.10249834e-06,  2.67259043e-06, -2.13781118e-06,  2.23761594e-06,\n",
      "       -1.59763715e-06,  1.89302580e-06,  1.69559758e-06,  1.61743515e-06,\n",
      "       -1.35194250e-06, -1.13129875e-06, -1.00421255e-06,  1.13859426e-06,\n",
      "        1.07336132e-06,  8.43331691e-07,  7.32460308e-07, -7.11466328e-07,\n",
      "       -6.54175324e-07,  6.22036112e-07,  5.68440782e-07, -5.51624396e-07,\n",
      "       -4.76490754e-07,  4.72153801e-07,  4.08436478e-07, -4.00796921e-07,\n",
      "        3.69062604e-07, -3.57490507e-07,  3.35169091e-07,  2.61854552e-07,\n",
      "       -3.04864898e-07, -2.87134839e-07,  2.09015582e-07, -2.16733284e-07,\n",
      "       -2.08537344e-07,  1.95162286e-07,  1.57759445e-07,  1.50071060e-07,\n",
      "       -1.42261669e-07,  1.25374768e-07, -1.05390193e-07, -9.89781554e-08,\n",
      "       -8.45739123e-08,  1.01701900e-07,  8.48670325e-08,  8.83103652e-08,\n",
      "       -6.96297349e-08, -5.14153768e-08,  6.54987176e-08,  5.59628184e-08,\n",
      "       -4.80967053e-08,  4.43202275e-08,  3.17390594e-08, -3.48182638e-08,\n",
      "       -3.24240617e-08,  2.03546406e-08,  1.83325888e-08, -2.73949770e-08,\n",
      "       -2.17558611e-08, -1.33892097e-08, -1.39988963e-08, -8.40608116e-09,\n",
      "        1.53780331e-08, -3.70121311e-09,  1.15010259e-08, -2.52876109e-10,\n",
      "        1.79834336e-09,  3.10348569e-09,  6.27757046e-09,  9.07888520e-09],\n",
      "      dtype=float32), array([[ 0.05307961, -0.06205679, -0.25788885, ...,  0.05034004,\n",
      "         0.01798948, -0.01616207],\n",
      "       [ 0.03767548, -0.02172401,  0.01640585, ..., -0.02155167,\n",
      "         0.01507646,  0.07287087],\n",
      "       [-0.00828813,  0.00292236,  0.04528418, ...,  0.0611697 ,\n",
      "         0.17435732,  0.13079827],\n",
      "       ...,\n",
      "       [ 0.02501475, -0.06238136, -0.04064316, ..., -0.08212321,\n",
      "         0.07139336, -0.02289763],\n",
      "       [ 0.13672131,  0.12806445, -0.2062973 , ...,  0.00576926,\n",
      "        -0.03634994, -0.02471847],\n",
      "       [ 0.01443588,  0.0369385 , -0.01984526, ...,  0.08095992,\n",
      "        -0.00998246, -0.0058081 ]], dtype=float32))\n",
      "(array([ 3.3457382e+02,  3.6483198e-01,  2.5478545e-01,  1.5654647e-01,\n",
      "        6.5705404e-02,  3.1193770e-02,  1.9318368e-02,  1.8441629e-02,\n",
      "        8.2870051e-03,  5.3885933e-03,  3.4526521e-03,  2.0315645e-03,\n",
      "        1.4786357e-03,  9.9762413e-04,  6.6616823e-04,  4.8203385e-04,\n",
      "        3.9566361e-04,  3.4604146e-04,  2.8776214e-04,  2.4966229e-04,\n",
      "        2.1301756e-04,  1.6924410e-04,  1.3782733e-04,  1.0807799e-04,\n",
      "        7.9540718e-05,  6.1819257e-05,  5.8207101e-05,  4.9710576e-05,\n",
      "        3.7176786e-05,  3.5839683e-05,  2.8225342e-05,  2.2667482e-05,\n",
      "        1.8686136e-05,  1.6664528e-05,  1.3041081e-05, -9.5280966e-06,\n",
      "        1.1232885e-05,  9.7118527e-06,  8.8282277e-06,  8.1949829e-06,\n",
      "       -6.1087430e-06,  6.8446493e-06, -4.6893729e-06, -4.3259106e-06,\n",
      "        5.6212511e-06,  4.9519690e-06,  4.4671056e-06, -3.2679159e-06,\n",
      "        3.4448753e-06,  3.2179814e-06,  2.8808679e-06, -2.1147453e-06,\n",
      "        2.6340135e-06,  2.4695607e-06,  1.9953111e-06,  1.8629310e-06,\n",
      "       -1.5881711e-06, -1.4243384e-06,  1.3672192e-06,  1.2848714e-06,\n",
      "       -1.1148543e-06, -1.0245706e-06,  1.1568292e-06, -7.7177668e-07,\n",
      "        8.7757149e-07,  8.3923641e-07, -6.7570187e-07,  6.2243436e-07,\n",
      "       -5.8041439e-07, -4.3854391e-07,  5.5199962e-07,  5.3594579e-07,\n",
      "        5.0125499e-07,  4.6195146e-07, -3.8808153e-07, -3.3648917e-07,\n",
      "        4.2802571e-07,  3.5642609e-07, -2.7807047e-07,  2.8648407e-07,\n",
      "        2.4435707e-07, -2.3478748e-07, -2.1304906e-07, -1.8622059e-07,\n",
      "        2.1737266e-07,  1.8793270e-07, -1.6980081e-07,  1.7940033e-07,\n",
      "        1.7211413e-07, -1.4772263e-07,  1.4421499e-07,  1.3333916e-07,\n",
      "       -1.1444229e-07, -9.8948576e-08,  1.0356738e-07, -9.4300930e-08,\n",
      "        8.5257298e-08, -7.1531844e-08, -6.2022863e-08, -4.7982965e-08,\n",
      "       -3.8392653e-08,  6.7143660e-08,  5.7117688e-08, -2.0568169e-08,\n",
      "       -1.6949690e-08, -2.2337163e-08,  4.1108979e-08,  3.6387142e-08,\n",
      "       -9.1466603e-09,  2.9567051e-08,  2.6428845e-08, -5.0786211e-09,\n",
      "       -3.7181942e-09,  2.2561466e-08,  1.8840128e-08,  1.3932034e-08,\n",
      "        9.4350092e-09,  6.7894450e-09,  2.0864286e-09,  2.3927917e-09],\n",
      "      dtype=float32), array([[-0.051726  , -0.03239635, -0.07709713, ..., -0.07521544,\n",
      "         0.06910025,  0.017454  ],\n",
      "       [-0.03224624, -0.0127175 , -0.00640475, ..., -0.01333931,\n",
      "        -0.03803387, -0.05357156],\n",
      "       [ 0.0109729 ,  0.04633105,  0.07963853, ...,  0.05597965,\n",
      "         0.21860147, -0.05708394],\n",
      "       ...,\n",
      "       [-0.03287978, -0.15893126, -0.18536657, ..., -0.04203751,\n",
      "         0.00524067,  0.04310956],\n",
      "       [-0.14505927,  0.14744206, -0.15543862, ...,  0.00113464,\n",
      "        -0.00310904,  0.00665086],\n",
      "       [-0.01513435,  0.06844053, -0.00168439, ...,  0.04835688,\n",
      "        -0.06648762,  0.03997814]], dtype=float32))\n",
      "(array([ 2.91964935e+02,  4.22874808e-01,  1.54239148e-01,  1.25312120e-01,\n",
      "        7.68957287e-02,  5.19532524e-02,  2.62123235e-02,  1.27927605e-02,\n",
      "        7.66773662e-03,  4.85320482e-03,  4.01837518e-03,  2.37359200e-03,\n",
      "        1.66524155e-03,  1.08731003e-03,  9.86150117e-04,  6.81147387e-04,\n",
      "        4.48894454e-04,  4.00897552e-04,  2.84521782e-04,  2.71125231e-04,\n",
      "        2.34886946e-04,  2.03506686e-04,  1.83115291e-04,  1.46186270e-04,\n",
      "        1.31777677e-04,  1.16168507e-04,  8.93197575e-05,  6.23371234e-05,\n",
      "        5.44173818e-05,  4.90082275e-05,  3.36860176e-05,  3.16534060e-05,\n",
      "        3.00358752e-05,  2.44175299e-05,  1.92016287e-05,  1.72457403e-05,\n",
      "        1.41905639e-05,  1.35920382e-05, -8.03675357e-06,  1.11440013e-05,\n",
      "        1.15474832e-05,  8.83542634e-06,  7.48213961e-06, -6.47113757e-06,\n",
      "        7.28926761e-06,  5.62443347e-06,  4.96946632e-06,  4.43569797e-06,\n",
      "        4.30308046e-06, -3.44079399e-06, -3.00871943e-06,  3.36176981e-06,\n",
      "        2.86203522e-06, -2.19210892e-06,  2.47181674e-06,  2.19237859e-06,\n",
      "       -1.41420537e-06,  1.82358042e-06, -1.18819378e-06,  1.47668163e-06,\n",
      "        1.36098799e-06,  1.22538222e-06,  1.10248914e-06, -1.00248121e-06,\n",
      "       -8.88946659e-07,  9.19272679e-07, -7.55231895e-07,  8.56667384e-07,\n",
      "        7.21481683e-07, -6.23638527e-07,  6.63095761e-07, -5.39460871e-07,\n",
      "        5.70276711e-07, -4.66846359e-07, -4.07581808e-07,  5.08503319e-07,\n",
      "        4.45137232e-07, -3.43671559e-07,  2.96895422e-07, -2.81359746e-07,\n",
      "       -2.35381435e-07,  2.63796522e-07,  2.49624179e-07,  2.04776001e-07,\n",
      "        2.19602597e-07, -2.00558901e-07, -1.84280310e-07,  1.81057956e-07,\n",
      "       -1.62529773e-07, -1.16998812e-07,  1.50789788e-07,  1.19385021e-07,\n",
      "        1.02316314e-07,  9.02713779e-08, -1.04499108e-07, -9.62466160e-08,\n",
      "       -9.04463207e-08,  7.06626651e-08,  6.60166108e-08, -5.05481204e-08,\n",
      "        5.52430492e-08,  4.25765059e-08, -4.62423522e-08, -4.40769377e-08,\n",
      "       -3.71740931e-08, -2.83503674e-08, -1.67702776e-08,  3.02449159e-08,\n",
      "        2.83013968e-08, -2.02195434e-08, -1.07884004e-08,  1.95209005e-08,\n",
      "       -6.48507914e-09,  1.68540062e-08,  1.23072539e-08, -3.93846067e-10,\n",
      "        7.45739648e-09,  7.84789456e-10,  4.83408957e-09,  5.10646903e-09],\n",
      "      dtype=float32), array([[-0.04998725, -0.0233166 ,  0.19244142, ..., -0.02087422,\n",
      "        -0.03047463,  0.00131739],\n",
      "       [-0.03405302,  0.07012106,  0.09927405, ..., -0.00112499,\n",
      "        -0.01484378,  0.05346438],\n",
      "       [ 0.01060318,  0.02631307, -0.04177691, ...,  0.0387563 ,\n",
      "        -0.05556377,  0.11788446],\n",
      "       ...,\n",
      "       [-0.03213065, -0.03221767,  0.17435683, ..., -0.06616043,\n",
      "         0.03426996, -0.02455972],\n",
      "       [-0.13702106, -0.23922554, -0.02858853, ...,  0.00157382,\n",
      "        -0.01931278,  0.00030082],\n",
      "       [-0.01412409, -0.03067019,  0.01169607, ...,  0.1825995 ,\n",
      "        -0.11754674,  0.000324  ]], dtype=float32))\n",
      "(array([ 3.16472656e+02,  5.73457479e-01,  2.56538242e-01,  9.05214846e-02,\n",
      "        4.08587642e-02,  2.09952891e-02,  1.20582907e-02,  5.05375117e-03,\n",
      "        2.77126837e-03,  2.06687977e-03,  1.70338620e-03,  1.27891218e-03,\n",
      "        7.93382234e-04,  5.31448051e-04,  4.06138512e-04,  3.41813080e-04,\n",
      "        2.72605830e-04,  2.31434591e-04,  1.62481927e-04,  1.19552984e-04,\n",
      "        9.93614740e-05,  7.74979853e-05,  6.87576321e-05,  5.03283554e-05,\n",
      "        4.69055121e-05,  3.64867701e-05,  2.92320292e-05,  2.75743350e-05,\n",
      "        2.06073946e-05, -1.29002856e-05,  1.48015706e-05,  1.30244762e-05,\n",
      "        1.14850309e-05,  1.07378137e-05,  1.02389786e-05, -8.15789735e-06,\n",
      "        8.20615878e-06,  7.30991178e-06, -6.14812143e-06, -4.43019462e-06,\n",
      "        5.58496413e-06,  5.01084287e-06,  4.87258421e-06,  4.44818352e-06,\n",
      "        4.19780008e-06, -3.35553409e-06,  3.17123545e-06, -2.16724334e-06,\n",
      "        2.64871278e-06, -1.66530197e-06,  2.44703233e-06,  2.17946831e-06,\n",
      "        1.92863604e-06,  1.82926021e-06, -1.39450049e-06, -1.25901556e-06,\n",
      "        1.52967368e-06,  1.50195274e-06, -1.12527778e-06,  1.10275539e-06,\n",
      "       -9.06486548e-07, -8.94788855e-07,  9.81142193e-07,  8.48504385e-07,\n",
      "        8.04731769e-07, -6.68525104e-07, -4.68971535e-07,  7.47339470e-07,\n",
      "        7.21678248e-07,  6.12882502e-07,  5.33442744e-07,  4.84070142e-07,\n",
      "        4.49064117e-07, -4.03911088e-07,  3.98374539e-07, -3.68538252e-07,\n",
      "        3.56246915e-07,  3.13416535e-07, -2.73543208e-07,  2.65195553e-07,\n",
      "       -2.40241604e-07, -2.22665534e-07, -2.03853503e-07,  2.24208748e-07,\n",
      "       -1.45028878e-07,  1.94394190e-07,  1.82081578e-07,  1.71460400e-07,\n",
      "        1.37064774e-07,  1.26292193e-07, -1.03088873e-07,  1.10929250e-07,\n",
      "       -9.29882802e-08,  8.91453809e-08, -7.68324213e-08,  7.64338921e-08,\n",
      "        7.04196026e-08, -6.30229380e-08,  5.82499702e-08,  5.26881472e-08,\n",
      "        4.93989987e-08, -4.56887044e-08, -3.08296642e-08, -3.59174344e-08,\n",
      "       -3.98406037e-08,  3.91124040e-08, -2.01056327e-08, -1.75091230e-08,\n",
      "       -1.39648515e-08,  2.44769911e-08,  2.20680754e-08, -6.19292750e-09,\n",
      "       -3.27383365e-09, -2.18510521e-09,  2.74461054e-09,  1.34233904e-08,\n",
      "        1.28203856e-08,  1.01917568e-08,  5.31428990e-09,  7.05840231e-09],\n",
      "      dtype=float32), array([[-0.04804883,  0.11084278,  0.08243226, ...,  0.0295477 ,\n",
      "        -0.02863827, -0.01235696],\n",
      "       [-0.03170649,  0.05219436, -0.15576933, ..., -0.02431121,\n",
      "        -0.0184873 , -0.00087467],\n",
      "       [ 0.01151439, -0.06955282,  0.02246724, ...,  0.13499452,\n",
      "        -0.10589971, -0.15700392],\n",
      "       ...,\n",
      "       [-0.03548621,  0.15772398, -0.02118506, ...,  0.04029577,\n",
      "         0.06647921,  0.04153712],\n",
      "       [-0.14031811,  0.1108117 ,  0.17098919, ...,  0.00754778,\n",
      "         0.00671147, -0.00498708],\n",
      "       [-0.01520362,  0.00260367,  0.07669344, ..., -0.03067348,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -0.02355327, -0.0436883 ]], dtype=float32))\n",
      "(array([ 2.9081570e+02,  9.7612369e-01,  3.1586269e-01,  1.6311249e-01,\n",
      "        6.3194931e-02,  2.4296343e-02,  2.2146940e-02,  9.9969758e-03,\n",
      "        6.4920029e-03,  3.9543607e-03,  3.3725847e-03,  2.4688758e-03,\n",
      "        1.4978368e-03,  1.0209063e-03,  8.1929727e-04,  6.9744157e-04,\n",
      "        5.2162039e-04,  3.7155423e-04,  2.8941123e-04,  2.2121772e-04,\n",
      "        1.8166167e-04,  1.7137922e-04,  1.1981924e-04,  1.0054288e-04,\n",
      "        8.9231333e-05,  7.1724753e-05,  6.0566599e-05,  5.3665834e-05,\n",
      "        4.8962502e-05,  4.2654021e-05,  3.3456508e-05,  3.1866206e-05,\n",
      "        2.8604722e-05,  2.3663817e-05,  1.6278702e-05,  1.5364561e-05,\n",
      "        1.3716172e-05,  1.2403722e-05, -7.6539936e-06,  9.9899462e-06,\n",
      "        9.0150570e-06,  8.8999868e-06, -5.1747957e-06,  6.1917794e-06,\n",
      "        5.9124259e-06, -4.5464221e-06,  4.5326906e-06, -3.9612228e-06,\n",
      "        4.3608147e-06, -2.8174923e-06,  3.4836380e-06,  3.0532337e-06,\n",
      "        2.7556721e-06, -2.0256296e-06,  2.2244346e-06,  2.0800101e-06,\n",
      "        1.8615970e-06, -1.5660308e-06, -1.4312744e-06,  1.4713806e-06,\n",
      "       -1.2072632e-06,  1.2359884e-06,  1.0375153e-06, -9.1914234e-07,\n",
      "        8.9700660e-07, -7.4263028e-07,  7.6517466e-07, -5.8135947e-07,\n",
      "       -5.3961816e-07,  6.4270967e-07,  6.1952170e-07,  5.5098980e-07,\n",
      "       -4.6161927e-07,  4.8041261e-07,  4.5222581e-07,  4.0083745e-07,\n",
      "        3.4006641e-07, -3.3643229e-07, -3.4857268e-07, -3.0873267e-07,\n",
      "       -2.5809246e-07,  2.7772268e-07,  2.4698770e-07,  2.3689287e-07,\n",
      "        2.2768540e-07, -2.1029102e-07, -1.9400673e-07, -1.5171784e-07,\n",
      "        1.7558865e-07,  1.5721037e-07, -9.7250755e-08,  1.4876223e-07,\n",
      "        1.1635089e-07,  1.0000905e-07, -8.1180033e-08, -7.1095741e-08,\n",
      "        7.6737528e-08, -5.9214695e-08,  6.8883885e-08,  5.7914509e-08,\n",
      "        4.7803375e-08, -4.4600949e-08, -3.7883716e-08,  3.9273196e-08,\n",
      "        3.3689854e-08, -2.9916574e-08, -2.6415124e-08,  2.6023987e-08,\n",
      "        2.1765741e-08, -2.0193710e-08, -1.6100127e-08, -1.1965595e-08,\n",
      "       -9.4380601e-09,  1.7165556e-08, -4.2725650e-09,  1.0200027e-08,\n",
      "        7.1008084e-09,  1.1894824e-10,  1.2281927e-09,  4.9738231e-09],\n",
      "      dtype=float32), array([[ 0.06015585, -0.12666433, -0.01849187, ..., -0.03594633,\n",
      "        -0.04094972, -0.02569732],\n",
      "       [ 0.03308048, -0.04653095, -0.00066957, ..., -0.02418775,\n",
      "         0.05764285, -0.00972513],\n",
      "       [-0.01205631,  0.02848445,  0.07273138, ..., -0.03047398,\n",
      "         0.02211056, -0.13829286],\n",
      "       ...,\n",
      "       [ 0.03454476, -0.07469159, -0.18438597, ...,  0.02640363,\n",
      "         0.07293471,  0.01374472],\n",
      "       [ 0.13730744,  0.03938806, -0.15731908, ..., -0.00861299,\n",
      "         0.00829037, -0.01332468],\n",
      "       [ 0.01210764,  0.03624104, -0.02789402, ..., -0.01552409,\n",
      "        -0.04927485, -0.08930446]], dtype=float32))\n",
      "(array([ 2.55197052e+02,  1.08035398e+00,  3.20136100e-02,  2.30643936e-02,\n",
      "        1.74306221e-02,  1.52471373e-02,  8.40281788e-03,  2.15937919e-03,\n",
      "        7.88923586e-04,  7.53702421e-04,  4.58940602e-04,  3.90131347e-04,\n",
      "        2.90081633e-04,  2.55684310e-04,  1.70152402e-04,  5.40683905e-05,\n",
      "        2.94557613e-05,  2.64502851e-05,  1.71487500e-05,  1.49658290e-05,\n",
      "       -8.18261560e-06,  9.58086912e-06,  8.30184672e-06,  7.08991502e-06,\n",
      "       -5.66689323e-06,  5.70998918e-06,  5.45723151e-06,  4.79755818e-06,\n",
      "        3.99978080e-06, -3.79138555e-06, -3.24922530e-06,  3.07945288e-06,\n",
      "       -2.03352511e-06,  2.31385638e-06,  2.45611386e-06,  2.42087322e-06,\n",
      "        2.03363243e-06, -1.73542696e-06, -1.70931605e-06,  1.78111259e-06,\n",
      "        1.52302312e-06,  1.35623293e-06, -1.21102005e-06,  1.15938235e-06,\n",
      "        1.09078042e-06, -1.02410502e-06, -9.64811079e-07,  9.74171144e-07,\n",
      "        9.46427576e-07, -7.55722681e-07, -7.32140791e-07,  7.77697664e-07,\n",
      "       -6.50172865e-07,  6.52480253e-07,  6.22721529e-07, -5.15422755e-07,\n",
      "        5.47959530e-07, -4.46494994e-07,  4.95787845e-07,  4.55469348e-07,\n",
      "       -3.59893988e-07,  4.19168117e-07,  3.89143366e-07,  3.75848941e-07,\n",
      "       -2.75649569e-07, -2.51017326e-07, -2.32515035e-07,  3.26054305e-07,\n",
      "        2.90946787e-07,  2.73378618e-07,  2.50086600e-07,  2.08901383e-07,\n",
      "       -1.75921485e-07, -1.66548674e-07,  1.91328439e-07,  1.80892158e-07,\n",
      "       -1.53070417e-07,  1.41055196e-07,  1.29190994e-07,  1.14201576e-07,\n",
      "       -1.21354418e-07,  1.05010571e-07, -9.70427010e-08, -9.16411267e-08,\n",
      "       -8.53566036e-08, -6.73125271e-08,  7.43820721e-08,  7.10467560e-08,\n",
      "        6.88211159e-08, -5.31323998e-08,  5.76954484e-08, -4.80468252e-08,\n",
      "       -4.22544986e-08, -3.37214274e-08,  5.33986757e-08,  5.13494420e-08,\n",
      "        4.31116653e-08,  3.64786494e-08,  3.22289964e-08, -2.32140565e-08,\n",
      "        2.60090420e-08,  2.26141239e-08,  1.99162411e-08, -1.97333776e-08,\n",
      "       -1.71780528e-08, -1.45275072e-08, -1.08358824e-08,  1.51664015e-08,\n",
      "       -5.19368948e-09, -1.20541213e-08,  1.31178117e-08, -3.56529117e-09,\n",
      "        9.66067759e-09, -1.09369280e-09,  7.69376651e-09,  8.71922534e-09,\n",
      "        2.03638639e-09,  8.76604511e-10,  3.57366292e-09,  5.09773246e-09],\n",
      "      dtype=float32), array([[ 0.04767226, -0.10781197, -0.02110798, ...,  0.00070825,\n",
      "         0.00637173, -0.00262368],\n",
      "       [ 0.03190102, -0.05763078, -0.08434018, ..., -0.08613586,\n",
      "         0.09251389,  0.02236271],\n",
      "       [-0.00826913,  0.00339072, -0.08341894, ...,  0.08473506,\n",
      "         0.01806616, -0.06884409],\n",
      "       ...,\n",
      "       [ 0.02026919, -0.02486919,  0.1508878 , ...,  0.03511912,\n",
      "        -0.05844673, -0.05548291],\n",
      "       [ 0.12602668,  0.05494045,  0.10360529, ..., -0.00754292,\n",
      "        -0.00016142,  0.02003787],\n",
      "       [ 0.00884665,  0.03564368, -0.01693945, ...,  0.14733051,\n",
      "        -0.10621792,  0.00319186]], dtype=float32))\n",
      "(array([ 2.80215729e+02,  2.98549712e-01,  1.56169429e-01,  9.80561450e-02,\n",
      "        2.29052771e-02,  1.10421861e-02,  8.81754793e-03,  5.23224939e-03,\n",
      "        4.44070855e-03,  2.55987304e-03,  1.59511296e-03,  1.31246715e-03,\n",
      "        6.94408664e-04,  4.62516415e-04,  2.86682451e-04,  2.24366508e-04,\n",
      "        1.40239732e-04,  1.09003588e-04,  9.03252076e-05,  8.46350158e-05,\n",
      "        5.11405742e-05,  4.76703972e-05,  2.96613980e-05,  2.54502611e-05,\n",
      "        2.36359920e-05,  1.37295119e-05,  1.32569094e-05,  1.02095000e-05,\n",
      "       -6.12024905e-06,  7.29554131e-06,  6.98671420e-06, -5.49695324e-06,\n",
      "        5.91480512e-06,  5.36624202e-06, -4.55023883e-06,  4.57812303e-06,\n",
      "       -2.95729797e-06,  4.10231996e-06,  3.89743309e-06,  3.27131283e-06,\n",
      "        3.02140757e-06, -2.50520020e-06,  2.71409999e-06,  2.63524748e-06,\n",
      "       -1.94386325e-06,  2.11744032e-06, -1.46839443e-06,  1.74442050e-06,\n",
      "        1.60118122e-06,  1.48682375e-06, -1.23160487e-06, -9.77792752e-07,\n",
      "        1.27804469e-06,  1.20197274e-06,  1.15002058e-06,  1.10968483e-06,\n",
      "       -8.34679440e-07,  9.30094643e-07,  8.92810419e-07,  7.93705112e-07,\n",
      "       -6.78409663e-07, -5.74001660e-07,  5.63237109e-07,  5.48827131e-07,\n",
      "        5.34433582e-07, -5.01721274e-07, -4.87312718e-07, -4.03893665e-07,\n",
      "       -3.39363481e-07, -2.82659840e-07,  3.91312511e-07,  4.08705574e-07,\n",
      "        3.35786098e-07,  3.16429578e-07,  2.96498627e-07, -2.17718409e-07,\n",
      "        2.46659965e-07,  2.44242699e-07,  2.09338708e-07,  2.00814199e-07,\n",
      "       -1.95952111e-07, -1.89951791e-07, -1.69637872e-07, -1.57745419e-07,\n",
      "        1.61982555e-07,  1.41077834e-07, -1.20272588e-07, -9.37283318e-08,\n",
      "        1.24351942e-07,  1.02437646e-07, -7.37451060e-08, -6.81184389e-08,\n",
      "        9.57954285e-08,  8.32867002e-08,  7.63987700e-08,  5.82697233e-08,\n",
      "       -4.78009490e-08, -4.36964385e-08,  5.06328703e-08, -3.54957344e-08,\n",
      "       -2.83807413e-08,  3.97113169e-08,  3.56161678e-08,  3.23619851e-08,\n",
      "        2.90123374e-08, -1.73947896e-08, -1.46623673e-08, -1.09510108e-08,\n",
      "        1.89994616e-08,  2.03291624e-08,  2.06132942e-08, -5.94419314e-09,\n",
      "       -4.10190371e-09,  1.02481286e-08,  9.02669228e-09, -1.18265719e-09,\n",
      "        4.91180829e-09,  4.42898473e-09,  6.38681552e-10,  2.24466956e-09],\n",
      "      dtype=float32), array([[-0.05069494,  0.14396253,  0.091087  , ..., -0.06821534,\n",
      "         0.02895735, -0.01503096],\n",
      "       [-0.02986648,  0.00709618, -0.14667109, ...,  0.01603958,\n",
      "         0.00583631, -0.00823354],\n",
      "       [ 0.0093144 , -0.05944198,  0.03128797, ..., -0.17026904,\n",
      "         0.01551679,  0.10135125],\n",
      "       ...,\n",
      "       [-0.02270944,  0.16870669, -0.0231328 , ..., -0.03504504,\n",
      "        -0.01879053,  0.01258756],\n",
      "       [-0.1302295 ,  0.21780092,  0.12858659, ..., -0.03400687,\n",
      "        -0.01897621, -0.02072174],\n",
      "       [-0.00823   ,  0.02187317,  0.07057415, ..., -0.11435393,\n",
      "         0.17707364, -0.00023576]], dtype=float32))\n",
      "(array([ 2.69638763e+02,  2.50948429e-01,  1.12021670e-01,  3.58074307e-02,\n",
      "        1.14426007e-02,  7.65870418e-03,  5.58980042e-03,  4.49955417e-03,\n",
      "        3.60302744e-03,  2.37628887e-03,  1.79480400e-03,  3.44647415e-04,\n",
      "        1.78999966e-04,  1.30161803e-04,  1.18174350e-04,  6.63829705e-05,\n",
      "        5.50073783e-05,  4.70034902e-05,  3.27538983e-05,  2.77114614e-05,\n",
      "        1.84837372e-05,  1.51645563e-05, -9.45161173e-06,  1.17856853e-05,\n",
      "        1.14623772e-05,  9.62563809e-06,  8.83841676e-06, -6.41373617e-06,\n",
      "        6.45391356e-06,  6.32598358e-06,  5.88690409e-06, -4.30254431e-06,\n",
      "        4.32568686e-06, -3.95434245e-06,  4.17792262e-06,  3.68868564e-06,\n",
      "        3.22995447e-06, -2.57570696e-06,  2.78776929e-06, -2.38238613e-06,\n",
      "        2.18749346e-06,  1.91563458e-06,  1.65397205e-06, -1.48027891e-06,\n",
      "       -1.42024135e-06,  1.47746528e-06, -1.22059180e-06, -1.17985019e-06,\n",
      "        1.20203310e-06,  1.14391969e-06,  1.02627996e-06, -7.57829980e-07,\n",
      "        8.59231193e-07,  8.15126214e-07,  7.76210186e-07,  7.04797571e-07,\n",
      "       -6.66229425e-07, -6.31809428e-07, -5.79085054e-07,  6.05082391e-07,\n",
      "        5.58912973e-07, -4.55494529e-07,  5.02284649e-07, -3.66058231e-07,\n",
      "       -3.48849738e-07,  4.46699772e-07,  3.76563037e-07,  3.69597274e-07,\n",
      "        3.56516551e-07,  3.07554558e-07,  2.84764837e-07, -2.26782447e-07,\n",
      "       -2.03638152e-07, -1.90816991e-07,  2.51433391e-07,  2.23610499e-07,\n",
      "       -1.65098342e-07,  2.02839757e-07,  1.86729906e-07, -1.36186983e-07,\n",
      "       -1.41101552e-07, -1.14412671e-07,  1.69789701e-07,  1.57355231e-07,\n",
      "       -9.57166790e-08,  1.22336132e-07,  1.12662704e-07, -7.52704707e-08,\n",
      "        9.33760376e-08, -6.92035584e-08, -4.32813643e-08, -3.99302529e-08,\n",
      "        8.39172003e-08,  7.93662167e-08,  7.49514086e-08,  5.81377506e-08,\n",
      "        5.51729222e-08, -3.12366062e-08, -2.86663706e-08,  4.53787194e-08,\n",
      "        4.16084731e-08,  3.83481868e-08, -2.24917489e-08, -1.63043410e-08,\n",
      "        3.09364765e-08, -1.03646736e-08, -6.23599039e-09, -3.60803232e-09,\n",
      "        2.50151135e-08,  2.33446809e-08, -1.22659278e-08,  1.82109172e-08,\n",
      "        1.60200972e-08,  9.33071487e-09,  1.18238406e-08,  1.22927331e-08,\n",
      "        1.95025907e-09,  7.14131365e-10,  3.17956572e-09,  5.06034370e-09],\n",
      "      dtype=float32), array([[-0.06002223,  0.06288178,  0.05325319, ..., -0.04040084,\n",
      "         0.01431391, -0.00176734],\n",
      "       [-0.03014384, -0.00621856, -0.161205  , ..., -0.00487005,\n",
      "        -0.01194537, -0.0617481 ],\n",
      "       [ 0.01067438, -0.00190639,  0.03483001, ..., -0.04615941,\n",
      "        -0.14178205,  0.00758405],\n",
      "       ...,\n",
      "       [-0.02866936, -0.05214135, -0.01550375, ...,  0.11658687,\n",
      "         0.00339196,  0.02833011],\n",
      "       [-0.13111392,  0.16403556,  0.07703215, ..., -0.01265783,\n",
      "        -0.00735288,  0.00848438],\n",
      "       [-0.00623656,  0.06393906,  0.0416344 , ..., -0.05385412,\n",
      "        -0.00952323,  0.04440837]], dtype=float32))\n",
      "(array([ 2.6129156e+02,  3.2328074e+00,  4.8953819e-01,  7.9341941e-02,\n",
      "        6.0533538e-02,  3.3382628e-02,  2.6838681e-02,  2.0177048e-02,\n",
      "        1.2607880e-02,  6.5402281e-03,  5.1236921e-03,  4.6019764e-03,\n",
      "        2.5522318e-03,  2.1167174e-03,  1.5713141e-03,  1.4164255e-03,\n",
      "        1.0764711e-03,  8.0083957e-04,  6.7254435e-04,  4.4584271e-04,\n",
      "        3.4339345e-04,  3.0093055e-04,  2.5848881e-04,  2.1359448e-04,\n",
      "        1.6688045e-04,  1.2584109e-04,  1.0971886e-04,  8.5412474e-05,\n",
      "        8.0699712e-05,  7.4833049e-05,  6.9127957e-05,  5.1002702e-05,\n",
      "        3.4301640e-05,  3.0138410e-05,  2.3710014e-05,  2.1388450e-05,\n",
      "        1.8102890e-05,  1.6178608e-05,  1.2680191e-05,  1.2158638e-05,\n",
      "        1.0629629e-05,  8.9668720e-06,  7.4403342e-06, -5.2959394e-06,\n",
      "        5.9540380e-06,  5.0139715e-06, -4.1887765e-06, -3.6306697e-06,\n",
      "        4.1256412e-06,  4.0800055e-06,  3.1762979e-06,  3.1306236e-06,\n",
      "        2.7917026e-06,  2.5919273e-06, -2.2948113e-06, -2.1182973e-06,\n",
      "       -1.6308381e-06,  2.0138020e-06,  1.8877827e-06,  1.7488080e-06,\n",
      "        1.6082660e-06, -1.3154729e-06, -1.0839354e-06,  1.1245805e-06,\n",
      "       -8.8405773e-07,  9.5292677e-07,  8.6096344e-07, -7.9328225e-07,\n",
      "        7.0554671e-07, -6.5055451e-07,  6.1836613e-07, -5.8432164e-07,\n",
      "       -5.2426219e-07, -5.1026160e-07,  5.7250708e-07,  4.8583979e-07,\n",
      "       -3.9077355e-07,  4.2136304e-07,  4.0349079e-07, -3.3770385e-07,\n",
      "       -2.8567393e-07,  3.0702978e-07,  2.8969001e-07, -2.6227684e-07,\n",
      "        2.3688473e-07, -2.1772624e-07,  2.0429347e-07, -1.9793970e-07,\n",
      "        1.7787146e-07,  1.7128950e-07, -1.5884331e-07, -1.4238725e-07,\n",
      "        1.4298729e-07,  1.3150475e-07, -1.3272573e-07,  1.1082260e-07,\n",
      "       -1.1447754e-07, -9.9082783e-08,  8.8617647e-08, -7.4534853e-08,\n",
      "        8.1229665e-08,  6.1923785e-08,  5.2454620e-08,  4.4220663e-08,\n",
      "       -5.4682786e-08, -5.1397418e-08, -4.2838884e-08, -2.6161576e-08,\n",
      "       -3.7039730e-08,  3.0253442e-08, -1.5552327e-08,  2.1294266e-08,\n",
      "        1.7326110e-08, -9.5886206e-09, -7.5642799e-09, -3.5012904e-09,\n",
      "        1.4415382e-08,  1.0701536e-08,  5.2762341e-09,  4.2198467e-09],\n",
      "      dtype=float32), array([[-0.03190551,  0.11028388,  0.09089451, ...,  0.03087361,\n",
      "        -0.00347477,  0.07119489],\n",
      "       [-0.04572031, -0.07425923, -0.16731949, ...,  0.01613056,\n",
      "        -0.00738295,  0.01618495],\n",
      "       [ 0.00448729, -0.06526005,  0.06691059, ...,  0.01622033,\n",
      "        -0.04053459,  0.10078192],\n",
      "       ...,\n",
      "       [-0.01416074,  0.16846731,  0.00244771, ..., -0.14223638,\n",
      "        -0.02786545,  0.02668167],\n",
      "       [-0.14875247, -0.00522738,  0.15344797, ...,  0.0114724 ,\n",
      "        -0.02109978, -0.01624603],\n",
      "       [-0.02823276, -0.07123169,  0.0752525 , ...,  0.15991649,\n",
      "        -0.20565483, -0.04930726]], dtype=float32))\n",
      "(array([ 2.34297821e+02,  2.97310144e-01,  1.22519754e-01,  2.53475122e-02,\n",
      "        1.24148708e-02,  9.24815144e-03,  5.35439607e-03,  3.90719203e-03,\n",
      "        2.35234830e-03,  2.04800698e-03,  1.62255543e-03,  1.37014606e-03,\n",
      "        8.57271836e-04,  7.05189595e-04,  5.79014828e-04,  3.44176486e-04,\n",
      "        2.45300937e-04,  2.11840219e-04,  1.63022894e-04,  1.27775231e-04,\n",
      "        1.08694141e-04,  7.87468889e-05,  6.37822523e-05,  5.52352394e-05,\n",
      "        4.79655573e-05,  4.37167146e-05,  3.71036658e-05,  3.01616528e-05,\n",
      "        2.51011625e-05,  2.31922259e-05,  1.75337009e-05,  1.58720832e-05,\n",
      "        1.33919639e-05,  1.26945915e-05,  1.07977221e-05,  9.06210698e-06,\n",
      "        8.48674244e-06,  6.87338161e-06,  6.35217248e-06, -4.43304043e-06,\n",
      "        5.20067761e-06,  4.94397545e-06,  4.34973254e-06, -3.00716397e-06,\n",
      "       -2.65533822e-06,  3.54252575e-06,  3.28784631e-06,  2.83501276e-06,\n",
      "        2.72496959e-06, -2.26314364e-06, -1.84433793e-06,  2.53057442e-06,\n",
      "        2.44415332e-06,  2.21365303e-06,  2.03238301e-06, -1.65859490e-06,\n",
      "        1.62818696e-06,  1.46366153e-06, -1.39417455e-06, -1.29536045e-06,\n",
      "        1.10724307e-06, -1.01930186e-06,  9.53349115e-07, -9.14634256e-07,\n",
      "       -8.06964124e-07, -6.82500740e-07,  9.20124478e-07,  7.55536917e-07,\n",
      "        7.93159245e-07,  8.04127524e-07, -6.05609614e-07,  6.39534960e-07,\n",
      "       -5.08835285e-07, -4.48929285e-07,  5.09481822e-07,  5.32861179e-07,\n",
      "        4.61305120e-07, -3.46563979e-07, -3.20710257e-07, -3.02225828e-07,\n",
      "        3.80325304e-07,  3.37455617e-07,  2.83875153e-07,  2.58139011e-07,\n",
      "       -2.52130576e-07, -2.43851474e-07, -2.00277000e-07,  2.20910394e-07,\n",
      "        1.85133729e-07,  1.98826584e-07, -1.38066937e-07, -1.26513299e-07,\n",
      "        1.45128354e-07, -1.06797195e-07,  1.10559171e-07, -9.30820079e-08,\n",
      "        1.05973307e-07, -7.49433013e-08,  8.95292445e-08,  7.95695598e-08,\n",
      "        7.66762653e-08, -6.83205030e-08, -5.23342045e-08, -4.33876153e-08,\n",
      "        5.42087726e-08,  4.27975202e-08, -3.19109290e-08,  3.35553381e-08,\n",
      "       -1.91711802e-08,  2.55328008e-08,  2.26428263e-08,  1.82840676e-08,\n",
      "       -1.31512019e-08, -1.17382379e-08, -8.89948826e-09,  1.00753255e-08,\n",
      "       -1.77822201e-09,  5.75158943e-09,  2.85335222e-09,  1.94959870e-09],\n",
      "      dtype=float32), array([[-0.0214367 , -0.13437603, -0.04258685, ..., -0.00667064,\n",
      "         0.00219754, -0.02698566],\n",
      "       [-0.05197927,  0.14312115,  0.09530813, ...,  0.09838247,\n",
      "         0.08397739,  0.01359098],\n",
      "       [-0.00252095, -0.04568903, -0.08116199, ..., -0.21989807,\n",
      "        -0.01215185,  0.27070576],\n",
      "       ...,\n",
      "       [ 0.0051369 , -0.00469307,  0.0084654 , ..., -0.08074185,\n",
      "        -0.14280233, -0.02880352],\n",
      "       [-0.1516569 , -0.12514317, -0.08658442, ...,  0.01869193,\n",
      "        -0.00401124,  0.02919354],\n",
      "       [-0.03613095, -0.01062819, -0.13084175, ..., -0.00533764,\n",
      "        -0.01926982,  0.03255354]], dtype=float32))\n",
      "(array([ 3.15311646e+02,  2.48784512e-01,  1.19638987e-01,  2.83871535e-02,\n",
      "        1.62430461e-02,  9.60008893e-03,  7.36811943e-03,  5.30246692e-03,\n",
      "        3.28176026e-03,  2.90965894e-03,  2.11810926e-03,  1.24886725e-03,\n",
      "        6.95744820e-04,  5.41697547e-04,  4.64375480e-04,  3.47960158e-04,\n",
      "        3.14060540e-04,  2.32207050e-04,  2.09340869e-04,  1.40426244e-04,\n",
      "        1.17459807e-04,  1.03368155e-04,  8.10010170e-05,  6.19029743e-05,\n",
      "        5.09009151e-05,  4.42670316e-05,  4.12695554e-05,  3.10843716e-05,\n",
      "        3.05441317e-05,  2.30361911e-05,  2.01900002e-05,  1.53825258e-05,\n",
      "       -1.10420324e-05,  1.33024159e-05,  1.07384813e-05,  9.98854921e-06,\n",
      "       -6.57159990e-06,  8.56249153e-06,  7.62177206e-06,  7.35614094e-06,\n",
      "        6.88074078e-06, -5.21513675e-06,  5.59433693e-06, -3.78000391e-06,\n",
      "        5.20506865e-06,  4.55963664e-06,  3.72656655e-06,  3.84207397e-06,\n",
      "       -2.42730812e-06,  3.03633874e-06,  2.79359028e-06, -2.06086474e-06,\n",
      "        2.46542390e-06, -1.86374632e-06,  2.20361471e-06, -1.57302486e-06,\n",
      "        1.98379644e-06,  1.76059871e-06,  1.59391095e-06, -1.45453566e-06,\n",
      "       -1.31785589e-06, -8.59304066e-07,  1.50514120e-06,  1.33357128e-06,\n",
      "        1.24003463e-06,  1.18130617e-06,  1.02044191e-06, -7.72469321e-07,\n",
      "        8.29908629e-07,  7.93259744e-07, -6.72948147e-07, -6.05736432e-07,\n",
      "        6.88102432e-07,  6.32513093e-07, -5.34193816e-07, -4.40829723e-07,\n",
      "        5.68702035e-07,  5.27202928e-07,  4.68862567e-07,  3.98916313e-07,\n",
      "        3.47798618e-07, -3.18925345e-07, -2.78651584e-07,  2.89791473e-07,\n",
      "       -2.54532011e-07,  2.57033179e-07, -2.32659161e-07, -2.15614520e-07,\n",
      "       -1.67847958e-07, -1.36434423e-07,  2.11009265e-07,  2.00109412e-07,\n",
      "        1.69327834e-07, -1.28717872e-07,  1.36391463e-07,  1.23799822e-07,\n",
      "        1.07242599e-07, -9.69951444e-08, -8.03954023e-08,  9.25526820e-08,\n",
      "        8.20471797e-08,  7.08297634e-08, -6.29896633e-08, -5.18350447e-08,\n",
      "        5.74305936e-08, -4.49203377e-08,  3.70920787e-08, -3.37931887e-08,\n",
      "        3.22005071e-08,  2.59933692e-08, -1.91212841e-08, -1.75453341e-08,\n",
      "        1.78376123e-08, -1.05624940e-08, -8.76673401e-09,  1.20059580e-08,\n",
      "        4.00895139e-09,  3.54557028e-09, -1.75482151e-09, -2.09714801e-09],\n",
      "      dtype=float32), array([[-0.0311489 , -0.08647159,  0.10738172, ..., -0.02988685,\n",
      "        -0.09189873, -0.01335288],\n",
      "       [-0.05192215,  0.02572775, -0.16762991, ...,  0.07267595,\n",
      "         0.02968818,  0.01177034],\n",
      "       [-0.00290213,  0.00724462,  0.07120381, ..., -0.05731524,\n",
      "         0.03248589, -0.0430101 ],\n",
      "       ...,\n",
      "       [ 0.01175177,  0.0165902 ,  0.03333861, ..., -0.00829121,\n",
      "         0.07420376, -0.04330611],\n",
      "       [-0.16034307, -0.05992406,  0.07870577, ..., -0.01141115,\n",
      "         0.03504793,  0.01389569],\n",
      "       [-0.0384483 ,  0.01569161,  0.05756243, ...,  0.02487658,\n",
      "        -0.00846894, -0.00505571]], dtype=float32))\n",
      "(array([ 3.6891376e+02,  1.5784533e-01,  9.4114900e-02,  2.1488290e-02,\n",
      "        1.5279014e-02,  9.5743518e-03,  7.8360196e-03,  6.0492987e-03,\n",
      "        3.8078846e-03,  2.4686155e-03,  1.8253101e-03,  1.5636011e-03,\n",
      "        7.6358696e-04,  6.6890189e-04,  5.2883697e-04,  3.9530365e-04,\n",
      "        2.9008012e-04,  2.0691346e-04,  1.6665491e-04,  1.3144789e-04,\n",
      "        1.1031638e-04,  8.2278784e-05,  8.0848367e-05,  6.5227563e-05,\n",
      "        6.1136816e-05,  5.0618273e-05,  3.5452940e-05,  3.2151456e-05,\n",
      "        2.1399548e-05,  1.9178695e-05,  1.6609911e-05,  1.5174677e-05,\n",
      "        1.2521010e-05,  1.2231805e-05, -8.6657383e-06, -7.0747965e-06,\n",
      "        9.6725271e-06,  8.6383588e-06,  7.5392531e-06, -5.8337982e-06,\n",
      "        6.8532563e-06,  6.0523012e-06,  5.6409081e-06,  5.3508193e-06,\n",
      "        5.0061772e-06, -3.6640060e-06, -3.0965534e-06,  3.9964943e-06,\n",
      "        3.6867561e-06,  3.5826229e-06, -2.7237757e-06,  2.7900664e-06,\n",
      "        2.7034871e-06, -2.2082502e-06, -2.0656021e-06,  2.1075991e-06,\n",
      "        2.0100149e-06, -1.6983436e-06, -1.6108874e-06,  1.8335988e-06,\n",
      "        1.7663180e-06, -1.3744850e-06,  1.6137918e-06, -1.1337960e-06,\n",
      "        1.3891504e-06, -9.1807203e-07,  1.2578272e-06,  1.0541918e-06,\n",
      "        1.0271568e-06, -8.5577705e-07,  9.0894338e-07, -7.1902190e-07,\n",
      "       -5.8989173e-07,  7.6931519e-07,  7.0551420e-07, -5.0776180e-07,\n",
      "        5.9174602e-07,  5.6575192e-07, -3.9881544e-07, -3.7385408e-07,\n",
      "       -3.1578847e-07,  4.6526804e-07,  4.3626170e-07,  3.9327153e-07,\n",
      "        3.3033362e-07, -2.7075876e-07,  2.8001213e-07, -1.8525374e-07,\n",
      "       -1.8003180e-07, -1.4655438e-07,  2.3671920e-07,  2.2070566e-07,\n",
      "        2.0505352e-07,  1.5977228e-07,  1.4546350e-07,  1.0617885e-07,\n",
      "       -1.0611013e-07, -9.9566456e-08, -8.8450825e-08,  9.9957965e-08,\n",
      "        8.4344194e-08, -6.2408247e-08, -5.2218997e-08,  5.3794842e-08,\n",
      "        4.8023974e-08, -3.8931208e-08, -4.3494847e-08,  3.6721982e-08,\n",
      "       -1.9525647e-08, -2.4927266e-08,  3.1044557e-08,  2.2376321e-08,\n",
      "        1.9479558e-08, -8.0394571e-09, -8.6326084e-09,  1.4206632e-08,\n",
      "       -2.2509093e-10, -3.9286010e-09,  4.3075490e-09,  7.5184978e-09],\n",
      "      dtype=float32), array([[-3.6289077e-02, -6.2330894e-02,  1.2749149e-01, ...,\n",
      "         5.4145884e-03, -1.7547568e-03,  1.3755716e-04],\n",
      "       [-5.1539715e-02,  5.7156388e-02, -1.7456692e-01, ...,\n",
      "        -3.6742862e-02,  1.2761642e-02, -1.0378376e-02],\n",
      "       [-2.5098433e-03, -5.4364931e-04,  6.9943346e-02, ...,\n",
      "         3.6201221e-01, -1.2908675e-01, -9.3096513e-03],\n",
      "       ...,\n",
      "       [ 1.3750070e-02,  2.3296410e-03,  3.0948000e-02, ...,\n",
      "         1.1896379e-01, -4.5414489e-02, -5.5992857e-02],\n",
      "       [-1.6331504e-01, -7.4707650e-02,  8.4194846e-02, ...,\n",
      "        -1.3598962e-02, -2.7669625e-02,  1.7591437e-02],\n",
      "       [-3.8727846e-02,  1.9555041e-03,  8.5812472e-02, ...,\n",
      "        -2.2446195e-02,  7.8505732e-02,  3.9113417e-02]], dtype=float32))\n",
      "(array([ 3.93998566e+02,  7.07543492e-01,  3.18400562e-01,  6.02361821e-02,\n",
      "        3.90335545e-02,  2.63922326e-02,  1.83631685e-02,  1.26689691e-02,\n",
      "        4.97416221e-03,  3.76405311e-03,  3.52390972e-03,  2.01483769e-03,\n",
      "        1.58418342e-03,  1.29837322e-03,  1.10469107e-03,  8.94809666e-04,\n",
      "        6.70084963e-04,  4.55126894e-04,  4.13009402e-04,  3.47744877e-04,\n",
      "        3.06524569e-04,  2.18499816e-04,  1.88624865e-04,  1.32731875e-04,\n",
      "        1.18822965e-04,  9.62305057e-05,  8.46998810e-05,  6.42929153e-05,\n",
      "        5.78416002e-05,  4.83073673e-05,  4.25363141e-05,  3.67898792e-05,\n",
      "        2.91223932e-05,  2.52461523e-05,  2.06926179e-05,  1.82368294e-05,\n",
      "        1.65293332e-05, -9.94106722e-06,  1.18907683e-05,  1.02829781e-05,\n",
      "        9.13976692e-06, -5.92698098e-06,  7.71264877e-06,  7.05547336e-06,\n",
      "        6.18430386e-06, -4.42087503e-06, -3.80826827e-06,  4.92642175e-06,\n",
      "        4.98632107e-06,  4.30977434e-06,  3.92235006e-06, -2.94582514e-06,\n",
      "       -2.74003605e-06,  2.85711940e-06, -2.39394262e-06, -2.10838948e-06,\n",
      "       -1.80776885e-06,  2.81887560e-06,  2.71150520e-06,  2.48151946e-06,\n",
      "        2.09740392e-06,  2.00828890e-06,  1.66325572e-06, -1.30066132e-06,\n",
      "        1.49607376e-06,  1.43387570e-06, -1.10601707e-06, -1.02917727e-06,\n",
      "        1.24472047e-06,  1.14246541e-06, -9.76954880e-07,  1.02544732e-06,\n",
      "       -7.39142479e-07,  8.45190414e-07,  8.07210881e-07, -6.15660781e-07,\n",
      "       -5.26651320e-07, -4.80710582e-07,  7.13994666e-07,  6.60423893e-07,\n",
      "        6.20957053e-07,  5.35902871e-07, -3.67638592e-07,  3.86053472e-07,\n",
      "        3.54941847e-07, -3.30934938e-07, -3.05129163e-07, -2.50797058e-07,\n",
      "        2.96609471e-07,  2.87719843e-07,  2.27189616e-07, -2.08134637e-07,\n",
      "       -1.74174289e-07,  1.76222912e-07, -1.45168499e-07,  1.53178107e-07,\n",
      "       -1.19881975e-07,  1.37796505e-07,  1.19761353e-07, -9.66065912e-08,\n",
      "       -6.61847039e-08,  8.85885356e-08,  7.56044969e-08, -5.43509913e-08,\n",
      "        5.01045889e-08, -4.03471923e-08,  4.31615774e-08,  3.95444992e-08,\n",
      "       -3.32731211e-08,  2.80535488e-08, -2.02801527e-08,  1.66488441e-08,\n",
      "       -1.29427908e-08,  9.46230294e-09,  7.37936912e-09,  2.96874636e-09,\n",
      "       -5.29375388e-09, -2.61341815e-09,  1.36423886e-10, -1.05229525e-09],\n",
      "      dtype=float32), array([[-0.03924378, -0.11120595,  0.0859483 , ...,  0.00983142,\n",
      "         0.01815245,  0.00308528],\n",
      "       [-0.05177463,  0.06770888, -0.1751644 , ..., -0.04013332,\n",
      "         0.0033052 , -0.00455208],\n",
      "       [-0.00290259, -0.00800732,  0.07036883, ..., -0.0378289 ,\n",
      "        -0.09042421, -0.02626871],\n",
      "       ...,\n",
      "       [ 0.01496855, -0.02546364,  0.0013038 , ..., -0.07402087,\n",
      "         0.00927897, -0.15014006],\n",
      "       [-0.16538398, -0.0683294 ,  0.11014633, ...,  0.02766647,\n",
      "        -0.00549638,  0.00592739],\n",
      "       [-0.04068512, -0.01593587,  0.07744747, ...,  0.0190562 ,\n",
      "        -0.02348899,  0.02936291]], dtype=float32))\n",
      "(array([ 4.12904633e+02,  1.32648361e+00,  5.33857286e-01,  1.63699508e-01,\n",
      "        4.87003513e-02,  2.55853105e-02,  2.16820184e-02,  1.13471355e-02,\n",
      "        1.01384632e-02,  8.54930002e-03,  5.14480285e-03,  2.88942223e-03,\n",
      "        2.25232868e-03,  1.98649126e-03,  1.81602803e-03,  1.57636998e-03,\n",
      "        8.77618091e-04,  6.20192324e-04,  5.21627371e-04,  4.76144371e-04,\n",
      "        3.70834372e-04,  3.54496035e-04,  2.47765507e-04,  1.94986584e-04,\n",
      "        1.61816220e-04,  1.40455406e-04,  1.19311786e-04,  1.03968945e-04,\n",
      "        7.35468057e-05,  6.40418948e-05,  4.68709841e-05,  3.95838833e-05,\n",
      "        3.36769663e-05,  2.76158207e-05,  2.25742133e-05,  2.14324828e-05,\n",
      "        1.88365229e-05,  1.76008671e-05, -1.08291333e-05,  1.43498028e-05,\n",
      "        1.26628747e-05,  1.09699977e-05,  9.45054580e-06,  8.71583143e-06,\n",
      "        7.51993321e-06, -6.27178997e-06, -5.59926730e-06, -4.91950641e-06,\n",
      "        6.56423072e-06,  6.08325854e-06,  5.02820012e-06, -3.62004448e-06,\n",
      "        4.10836992e-06,  3.70788530e-06,  3.00385773e-06, -2.33790229e-06,\n",
      "       -2.38402390e-06, -2.07325775e-06,  2.38879147e-06,  2.37496465e-06,\n",
      "        2.20087622e-06,  2.01490525e-06, -1.60279569e-06,  1.83485326e-06,\n",
      "       -1.49588141e-06,  1.38043720e-06,  1.18553862e-06, -1.19394679e-06,\n",
      "       -1.07289634e-06,  1.12134978e-06, -1.02586273e-06,  1.01693081e-06,\n",
      "        9.80950858e-07,  8.21683557e-07, -6.98880967e-07,  7.03010414e-07,\n",
      "       -5.54718781e-07,  6.24253857e-07, -4.23816516e-07, -3.94659764e-07,\n",
      "       -3.61250187e-07, -3.38311139e-07,  4.84983104e-07,  4.60459631e-07,\n",
      "        4.16555878e-07,  3.75467721e-07,  3.14722172e-07,  2.76107357e-07,\n",
      "       -2.78058479e-07, -2.29998378e-07, -1.90737637e-07,  2.50191533e-07,\n",
      "        2.06649133e-07, -1.54645065e-07, -1.24760874e-07,  1.68618712e-07,\n",
      "        1.43158076e-07,  1.22994976e-07,  9.00002135e-08,  9.94665896e-08,\n",
      "       -9.87656605e-08, -8.17467054e-08, -7.38345420e-08, -4.69023291e-08,\n",
      "        6.72982736e-08,  5.70271652e-08,  4.31108447e-08, -3.57495900e-08,\n",
      "        3.57868473e-08,  2.94186044e-08, -2.60402437e-08,  2.28446471e-08,\n",
      "       -1.85963280e-08,  1.50854138e-08, -8.73475248e-09, -4.59128024e-09,\n",
      "       -2.90570079e-09,  1.42961407e-10,  4.40068826e-09,  7.50612372e-09],\n",
      "      dtype=float32), array([[ 0.04225494, -0.16576938,  0.02512646, ..., -0.02056881,\n",
      "         0.03800427,  0.05081453],\n",
      "       [ 0.05211352,  0.07060562, -0.16653442, ..., -0.00737958,\n",
      "        -0.00961308, -0.0547273 ],\n",
      "       [ 0.0032152 , -0.02826147,  0.05381251, ..., -0.00162646,\n",
      "         0.11919795, -0.19152564],\n",
      "       ...,\n",
      "       [-0.0150592 ,  0.01563581,  0.06539269, ...,  0.00408566,\n",
      "         0.04390399, -0.07799176],\n",
      "       [ 0.16732094, -0.12462443,  0.02147676, ..., -0.01008821,\n",
      "        -0.01032373, -0.00759738],\n",
      "       [ 0.04140033, -0.05484942,  0.0175767 , ...,  0.01816579,\n",
      "        -0.0206271 , -0.06155215]], dtype=float32))\n",
      "(array([ 4.03314209e+02,  2.17427254e-01,  7.98572078e-02,  1.80249680e-02,\n",
      "        1.50243761e-02,  1.12428376e-02,  9.96725820e-03,  6.12584641e-03,\n",
      "        4.42806119e-03,  3.07241827e-03,  2.34073377e-03,  1.49201567e-03,\n",
      "        9.76324023e-04,  7.95929926e-04,  6.19853963e-04,  4.93167492e-04,\n",
      "        4.03437822e-04,  2.49009579e-04,  2.08662401e-04,  1.58286304e-04,\n",
      "        1.25994324e-04,  1.11856920e-04,  8.55589242e-05,  7.27632432e-05,\n",
      "        6.85350169e-05,  6.37797493e-05,  4.85279888e-05,  3.99655473e-05,\n",
      "        3.25175497e-05,  2.97327006e-05,  2.70190121e-05,  2.42046699e-05,\n",
      "        1.75292171e-05,  1.42221252e-05, -9.62078593e-06, -9.05655543e-06,\n",
      "        1.16926822e-05,  1.10151659e-05,  9.14227621e-06,  8.74825673e-06,\n",
      "        7.29977955e-06, -5.50437881e-06,  6.28703083e-06, -4.95343556e-06,\n",
      "       -4.38587267e-06,  4.96139137e-06,  4.43799036e-06,  3.93843266e-06,\n",
      "       -3.12676207e-06,  3.48063327e-06, -2.76494370e-06,  3.34417564e-06,\n",
      "       -2.38592884e-06,  2.99815406e-06,  2.71160843e-06,  2.28587373e-06,\n",
      "        2.31637114e-06,  2.47498519e-06, -1.93084816e-06, -1.53699273e-06,\n",
      "        1.73694650e-06,  1.68627639e-06, -1.30463343e-06, -1.12246551e-06,\n",
      "        1.45137847e-06,  1.40868542e-06, -9.16914075e-07,  1.06049549e-06,\n",
      "        1.31445347e-06, -8.94430741e-07,  1.00048555e-06,  8.87936608e-07,\n",
      "       -7.38963706e-07, -6.12923827e-07, -5.65668074e-07,  7.11122595e-07,\n",
      "        6.35314223e-07,  5.82644304e-07,  5.00034616e-07, -4.47541765e-07,\n",
      "       -4.03044197e-07,  4.63883310e-07, -3.20928763e-07, -2.72270995e-07,\n",
      "        3.99235631e-07,  3.85189935e-07,  3.06981406e-07,  2.74274498e-07,\n",
      "       -2.03342182e-07, -2.32078932e-07, -1.53765910e-07,  2.42764798e-07,\n",
      "        2.22291732e-07,  1.99011183e-07,  1.54823297e-07,  1.48425784e-07,\n",
      "       -1.09686439e-07,  1.17949682e-07, -1.04150409e-07, -9.25607750e-08,\n",
      "       -7.84889806e-08, -6.65487789e-08,  8.58734097e-08,  7.06359558e-08,\n",
      "       -4.80730442e-08,  5.75500430e-08,  5.09180538e-08, -3.51516718e-08,\n",
      "        3.59541552e-08, -2.38168401e-08, -1.76796107e-08,  2.23593499e-08,\n",
      "       -1.24242705e-08,  1.93387155e-08, -6.76455825e-09, -1.86188487e-09,\n",
      "        1.27229685e-08,  8.49271675e-09,  6.84817136e-09,  2.42665421e-09],\n",
      "      dtype=float32), array([[-3.78712006e-02, -1.18547574e-01, -5.00820875e-02, ...,\n",
      "         3.20517942e-02, -1.34135494e-02,  1.72121860e-02],\n",
      "       [-5.24434112e-02,  1.54582426e-01,  1.20105714e-01, ...,\n",
      "         2.90122647e-02,  1.28658460e-02,  1.99998785e-02],\n",
      "       [-2.09212676e-03, -4.05915566e-02, -6.29200414e-02, ...,\n",
      "         4.95737791e-02, -1.85665756e-01,  1.49646208e-01],\n",
      "       ...,\n",
      "       [ 1.30160032e-02, -1.37538500e-02, -1.96811724e-02, ...,\n",
      "         2.04046294e-02, -6.14678711e-02,  5.06077483e-02],\n",
      "       [-1.64300174e-01, -1.15383185e-01, -1.70820430e-02, ...,\n",
      "         1.60071751e-04, -6.20640675e-03,  1.37052257e-02],\n",
      "       [-3.84438112e-02, -2.40432732e-02, -8.59950781e-02, ...,\n",
      "        -6.18757568e-02,  5.17575480e-02, -6.69679046e-02]], dtype=float32))\n",
      "(array([ 4.1567386e+02,  1.5076030e+00,  9.1765352e-02,  6.6507146e-02,\n",
      "        3.6621436e-02,  1.9861864e-02,  1.5983528e-02,  1.3396085e-02,\n",
      "        8.9864237e-03,  6.3369912e-03,  3.4899812e-03,  2.3416127e-03,\n",
      "        2.1940521e-03,  1.6901649e-03,  1.2714410e-03,  1.0373566e-03,\n",
      "        9.0388558e-04,  7.4280461e-04,  3.8166792e-04,  3.4090187e-04,\n",
      "        2.6297692e-04,  2.4098088e-04,  1.7588126e-04,  1.4115349e-04,\n",
      "        1.3857754e-04,  1.1323710e-04,  7.4685202e-05,  7.0594899e-05,\n",
      "        5.5433131e-05,  5.1046267e-05,  3.8576301e-05,  3.4342713e-05,\n",
      "        2.6429461e-05,  2.1470789e-05,  2.0690653e-05,  1.8628472e-05,\n",
      "        1.4458002e-05,  1.2214488e-05, -8.8949673e-06, -7.0853412e-06,\n",
      "        1.0367039e-05,  1.0173142e-05,  9.7915663e-06,  7.8693529e-06,\n",
      "        6.9780290e-06, -5.0465687e-06, -4.8204652e-06,  6.0175071e-06,\n",
      "        5.1483603e-06, -4.3022824e-06,  4.9396904e-06,  4.0576019e-06,\n",
      "        3.8676562e-06, -2.6640121e-06,  3.1247978e-06,  2.8238587e-06,\n",
      "       -2.5006207e-06,  2.5988745e-06,  2.4095909e-06, -2.0772461e-06,\n",
      "       -1.6279022e-06,  2.0472041e-06,  1.8914210e-06,  1.8093247e-06,\n",
      "        1.3933493e-06, -1.5129942e-06, -1.3519247e-06, -1.3882351e-06,\n",
      "       -1.1372601e-06,  1.3158116e-06,  1.1933635e-06,  1.0107626e-06,\n",
      "       -8.2216616e-07,  8.5213179e-07,  7.4956938e-07, -6.3962125e-07,\n",
      "        6.7867524e-07, -5.9438202e-07,  6.1066601e-07, -4.8020758e-07,\n",
      "        4.9192073e-07, -4.3370287e-07,  4.2834657e-07, -3.4636238e-07,\n",
      "        3.9007037e-07,  3.2858915e-07, -2.9082875e-07,  2.8399865e-07,\n",
      "        2.5760070e-07, -2.4227930e-07, -1.6595170e-07, -1.9638648e-07,\n",
      "        1.8502801e-07,  2.0048635e-07,  1.4836341e-07,  1.3233155e-07,\n",
      "       -1.0772311e-07, -9.4146593e-08, -7.4146826e-08,  9.3057196e-08,\n",
      "        8.3372562e-08,  6.3003895e-08,  5.7142106e-08,  3.8888171e-08,\n",
      "       -4.0941160e-08, -4.9231566e-08, -4.6774836e-08, -3.1494135e-08,\n",
      "       -1.9605782e-08,  2.5245409e-08,  2.2664352e-08, -1.2929821e-08,\n",
      "        1.8687883e-08, -7.4401179e-09, -5.0815818e-09,  6.2189037e-10,\n",
      "        1.7792026e-09,  1.2146142e-08,  6.1097354e-09,  7.9864266e-09],\n",
      "      dtype=float32), array([[ 0.04183999, -0.10322992,  0.2367868 , ..., -0.01408845,\n",
      "         0.0311383 ,  0.01462286],\n",
      "       [ 0.05211836,  0.01498076, -0.18743853, ..., -0.02961532,\n",
      "        -0.0243897 ,  0.00643817],\n",
      "       [ 0.00210532,  0.01127637,  0.04793126, ...,  0.15417361,\n",
      "         0.10742854,  0.03212129],\n",
      "       ...,\n",
      "       [-0.01336695, -0.02000503, -0.00721146, ..., -0.05337333,\n",
      "         0.03370595,  0.08897404],\n",
      "       [ 0.16460404, -0.03402292,  0.0857636 , ..., -0.00284065,\n",
      "         0.00167592,  0.00308607],\n",
      "       [ 0.03861326,  0.02589106,  0.04949165, ..., -0.06560247,\n",
      "        -0.00992435, -0.00778572]], dtype=float32))\n",
      "(array([ 5.60379150e+02,  2.49192953e+00,  1.57380477e-01,  9.84655246e-02,\n",
      "        7.12845251e-02,  4.44441028e-02,  3.41056958e-02,  1.66949425e-02,\n",
      "        1.07283071e-02,  9.13463347e-03,  6.40367111e-03,  4.22563544e-03,\n",
      "        3.78089328e-03,  3.23261600e-03,  2.56824633e-03,  2.24502035e-03,\n",
      "        1.48657837e-03,  1.29143801e-03,  8.75693746e-04,  6.17284793e-04,\n",
      "        5.16856031e-04,  4.71829902e-04,  4.15700604e-04,  3.48832313e-04,\n",
      "        3.04750254e-04,  2.56035622e-04,  1.97677233e-04,  1.81678086e-04,\n",
      "        1.66563550e-04,  1.32379195e-04,  1.24408893e-04,  8.75021942e-05,\n",
      "        7.38394228e-05,  7.13804693e-05,  5.44533723e-05,  5.01839313e-05,\n",
      "        4.28882704e-05,  3.37003039e-05,  3.29359646e-05,  2.61228633e-05,\n",
      "        2.34845193e-05,  2.09284699e-05, -1.30930212e-05,  1.59307747e-05,\n",
      "        1.52345729e-05,  1.30816188e-05,  1.19967835e-05, -9.04820081e-06,\n",
      "        9.91646812e-06, -6.93589664e-06, -6.02366026e-06,  8.13754741e-06,\n",
      "        7.67141864e-06,  6.84259658e-06,  5.41435747e-06, -4.34278127e-06,\n",
      "       -4.08817414e-06,  4.77346566e-06,  4.32435945e-06, -3.32337595e-06,\n",
      "        3.47982905e-06, -2.79077835e-06,  2.75505477e-06,  2.52675409e-06,\n",
      "       -1.87576779e-06, -1.95548296e-06, -1.58467185e-06, -1.57395345e-06,\n",
      "        2.10422672e-06,  1.91368167e-06,  1.78295181e-06,  1.50991525e-06,\n",
      "       -1.25255065e-06, -1.07178425e-06,  1.11433121e-06,  1.02513934e-06,\n",
      "        9.81515313e-07,  8.43464363e-07, -6.64052948e-07,  6.39313782e-07,\n",
      "       -5.56575628e-07, -4.98088184e-07,  5.69424230e-07,  5.23592860e-07,\n",
      "       -4.03786572e-07, -3.38617923e-07,  3.89703956e-07,  3.93180386e-07,\n",
      "        3.53182259e-07,  2.87688266e-07, -3.04638519e-07, -2.46647630e-07,\n",
      "       -1.88295701e-07,  1.67110940e-07, -1.46797689e-07,  1.39493721e-07,\n",
      "        1.20340573e-07, -1.10657489e-07, -9.87907143e-08,  1.01176767e-07,\n",
      "        9.02973909e-08, -7.74578979e-08, -5.58285578e-08,  6.50338379e-08,\n",
      "        5.32810915e-08, -4.28334985e-08, -3.45009354e-08, -4.04049345e-08,\n",
      "        3.53250620e-08, -2.30366890e-08,  1.93749727e-08, -1.62129812e-08,\n",
      "       -1.32059848e-08,  1.77808719e-08, -3.60182706e-09, -1.72369541e-09,\n",
      "        3.88270438e-09,  4.12380663e-09,  1.06361586e-08,  8.90910279e-09],\n",
      "      dtype=float32), array([[ 0.04927789, -0.07052941,  0.08826227, ...,  0.01664051,\n",
      "         0.0148247 ,  0.02727457],\n",
      "       [ 0.05219109,  0.02964026, -0.18345653, ...,  0.02005089,\n",
      "        -0.01257598, -0.03997514],\n",
      "       [ 0.00071154,  0.0134875 ,  0.03902794, ..., -0.06232109,\n",
      "        -0.14139207,  0.09633329],\n",
      "       ...,\n",
      "       [-0.00983896, -0.07510127, -0.07949972, ...,  0.04908564,\n",
      "        -0.06689622, -0.03467825],\n",
      "       [ 0.1691715 , -0.0341151 ,  0.09009614, ...,  0.01814331,\n",
      "         0.00251761,  0.00151572],\n",
      "       [ 0.03645418,  0.05364956,  0.04790116, ..., -0.00341372,\n",
      "        -0.02003146,  0.13143402]], dtype=float32))\n",
      "(array([ 5.62710510e+02,  9.68718827e-01,  9.21519935e-01,  3.62037092e-01,\n",
      "        1.62048742e-01,  1.17697030e-01,  7.10916370e-02,  2.77206618e-02,\n",
      "        2.30390485e-02,  1.73434578e-02,  1.46555891e-02,  8.65435414e-03,\n",
      "        7.41213793e-03,  4.70665377e-03,  3.48764099e-03,  2.83703185e-03,\n",
      "        2.36596703e-03,  1.91213028e-03,  1.49564573e-03,  1.22036447e-03,\n",
      "        1.08567683e-03,  8.68190196e-04,  8.41260829e-04,  4.82859352e-04,\n",
      "        4.30865592e-04,  3.59972648e-04,  2.46565847e-04,  1.98690192e-04,\n",
      "        2.05037490e-04,  1.50694861e-04,  1.22191675e-04,  9.29705056e-05,\n",
      "        8.20979694e-05,  6.85650666e-05,  4.88402075e-05,  4.42093951e-05,\n",
      "        3.58950856e-05,  3.39651451e-05,  1.97051104e-05,  1.85779681e-05,\n",
      "       -1.43423131e-05,  1.51105751e-05,  1.27021885e-05,  1.22541196e-05,\n",
      "       -1.05775398e-05, -9.97952520e-06,  9.92850164e-06,  9.19329614e-06,\n",
      "       -7.40376572e-06,  7.25706423e-06, -4.93499192e-06,  5.42451653e-06,\n",
      "        4.85938153e-06,  4.65659150e-06, -4.04021739e-06, -3.36579433e-06,\n",
      "       -3.08502285e-06,  3.61014622e-06,  3.60255353e-06,  3.13368332e-06,\n",
      "       -2.68462941e-06,  2.76216656e-06, -1.80654911e-06,  2.13866019e-06,\n",
      "        1.91565823e-06,  1.67195424e-06,  1.56791259e-06, -1.31114246e-06,\n",
      "        1.46501793e-06,  1.25211147e-06,  1.17951402e-06, -1.14620116e-06,\n",
      "       -1.01854039e-06, -9.65077561e-07,  9.53171877e-07,  8.71688769e-07,\n",
      "       -7.73287013e-07, -7.02175726e-07, -6.32245872e-07,  7.63412629e-07,\n",
      "        6.73564841e-07, -4.50429013e-07,  5.51745643e-07,  4.85771238e-07,\n",
      "        4.31367937e-07,  4.12070051e-07, -3.68149216e-07,  2.88008124e-07,\n",
      "        2.26226646e-07,  2.39290983e-07, -2.48543103e-07, -2.22677485e-07,\n",
      "       -1.99109408e-07,  2.02645623e-07, -1.64475523e-07, -1.37208346e-07,\n",
      "        1.34331955e-07,  1.04718836e-07, -1.03476012e-07, -1.04875262e-07,\n",
      "       -8.58489955e-08,  8.33315283e-08, -5.40508438e-08,  6.47183924e-08,\n",
      "        6.05182535e-08, -4.61465142e-08, -3.70637672e-08,  3.91887625e-08,\n",
      "        3.67906168e-08, -1.91043501e-08, -1.43238603e-08,  2.03121910e-08,\n",
      "       -1.00359872e-08, -5.21471044e-09,  1.46736214e-08,  2.80950846e-10,\n",
      "        2.20245822e-09,  5.25252153e-09,  6.98837166e-09,  8.01000599e-09],\n",
      "      dtype=float32), array([[-0.05927463, -0.1786009 ,  0.06127985, ...,  0.01582952,\n",
      "        -0.02097313,  0.00566914],\n",
      "       [-0.05326916, -0.07751421,  0.07649356, ..., -0.01637355,\n",
      "        -0.01851796,  0.00594354],\n",
      "       [-0.00151549, -0.0138096 , -0.03170971, ...,  0.17733438,\n",
      "        -0.23504393, -0.06722297],\n",
      "       ...,\n",
      "       [ 0.01032971,  0.07489956,  0.07779932, ...,  0.05135683,\n",
      "         0.00332205,  0.04422451],\n",
      "       [-0.1614294 , -0.07573927,  0.10445498, ..., -0.00519466,\n",
      "         0.00942545, -0.00692856],\n",
      "       [-0.03665685, -0.0885428 , -0.09048906, ...,  0.02662577,\n",
      "         0.04210937,  0.05111181]], dtype=float32))\n",
      "(array([ 5.60304016e+02,  9.22484517e-01,  4.11298305e-01,  3.05846214e-01,\n",
      "        1.83383077e-01,  9.01325941e-02,  5.48878647e-02,  3.46468836e-02,\n",
      "        1.80225149e-02,  1.27324620e-02,  8.27449653e-03,  6.63658977e-03,\n",
      "        4.20608092e-03,  4.29059891e-03,  2.77726608e-03,  1.96427642e-03,\n",
      "        1.37791410e-03,  1.08235842e-03,  9.03699722e-04,  6.60203747e-04,\n",
      "        3.91467416e-04,  2.78220483e-04,  2.62117333e-04,  2.59205292e-04,\n",
      "        1.72939617e-04,  1.14838353e-04,  8.74885736e-05,  8.78634528e-05,\n",
      "        7.33366833e-05,  6.16455000e-05,  4.42147684e-05,  3.89965680e-05,\n",
      "        3.42323729e-05,  2.39084366e-05,  2.00980048e-05,  1.80179868e-05,\n",
      "        1.54834925e-05,  1.37474735e-05,  1.12966909e-05, -1.01661690e-05,\n",
      "       -9.37363257e-06, -8.42791360e-06,  9.64360333e-06,  8.66862683e-06,\n",
      "       -5.56374471e-06,  6.88029058e-06,  6.27175586e-06,  6.03131275e-06,\n",
      "        5.48716571e-06, -4.73299770e-06,  4.61206355e-06,  4.00309409e-06,\n",
      "       -3.79025005e-06, -3.62050855e-06, -2.84000953e-06,  3.51619860e-06,\n",
      "        3.03291586e-06,  2.63133734e-06, -2.12766440e-06,  2.22651829e-06,\n",
      "        2.36503456e-06,  1.96623409e-06, -1.73600279e-06, -1.50883625e-06,\n",
      "        1.69742600e-06, -1.37209577e-06, -1.30579360e-06,  1.45053468e-06,\n",
      "        1.36683707e-06,  1.23105349e-06, -1.01871888e-06,  1.00721752e-06,\n",
      "        8.56038298e-07,  7.95361245e-07,  6.86703459e-07, -7.91611797e-07,\n",
      "       -6.70520819e-07, -5.47666843e-07,  5.76734578e-07, -4.47249846e-07,\n",
      "        4.99162695e-07,  4.04729036e-07, -3.54139274e-07, -3.14053977e-07,\n",
      "       -2.46009222e-07,  3.51282040e-07,  3.21005274e-07,  2.81698391e-07,\n",
      "        2.28580873e-07,  2.08195914e-07, -1.91892624e-07,  1.60327644e-07,\n",
      "       -1.46571267e-07, -1.36366992e-07, -1.07824256e-07,  1.22930430e-07,\n",
      "        1.14346378e-07,  9.51208818e-08, -1.00034342e-07, -6.80966110e-08,\n",
      "       -5.54173702e-08,  6.71646703e-08,  5.89851048e-08,  5.34620561e-08,\n",
      "       -3.74064051e-08,  4.14974792e-08, -3.10816084e-08, -2.31491608e-08,\n",
      "       -1.88781755e-08,  2.07873754e-08,  1.76261619e-08,  1.33214053e-08,\n",
      "       -9.08744635e-09,  1.02028697e-08, -5.78602322e-09, -4.05650225e-09,\n",
      "        5.02363751e-09, -2.07606776e-09,  1.74063208e-09, -8.75251371e-10],\n",
      "      dtype=float32), array([[-5.76018095e-02,  8.73868633e-03, -1.78405628e-01, ...,\n",
      "        -2.13782471e-02,  1.00577259e-02,  1.35302516e-02],\n",
      "       [-3.91403623e-02, -1.93194374e-01, -4.90115099e-02, ...,\n",
      "         8.17318819e-03,  2.27292255e-02,  1.16451215e-02],\n",
      "       [ 1.98602839e-03,  7.23541854e-03, -5.89723140e-02, ...,\n",
      "        -8.35243911e-02,  3.86429317e-02,  3.20207467e-03],\n",
      "       ...,\n",
      "       [-3.12764867e-04,  9.35647190e-02,  2.11978883e-01, ...,\n",
      "        -7.78295770e-02,  1.02983609e-01, -1.67526320e-01],\n",
      "       [-1.64791495e-01,  1.29714370e-01,  3.75061296e-02, ...,\n",
      "        -1.18340785e-02,  3.87629122e-03,  9.70510373e-05],\n",
      "       [-2.68922001e-02,  9.18041617e-02, -5.55333719e-02, ...,\n",
      "        -1.29693327e-02, -6.22100057e-03, -1.29251024e-02]], dtype=float32))\n",
      "(array([ 4.82797729e+02,  7.68232703e-01,  2.03243926e-01,  8.32534656e-02,\n",
      "        5.95930517e-02,  1.06739681e-02,  7.23323785e-03,  5.96031453e-03,\n",
      "        3.32480087e-03,  1.73444883e-03,  8.69751617e-04,  7.44830177e-04,\n",
      "        5.09854290e-04,  3.96086718e-04,  3.78247118e-04,  2.75234488e-04,\n",
      "        1.72507964e-04,  1.66505473e-04,  1.28781307e-04,  1.09714165e-04,\n",
      "        7.28246305e-05,  5.79675070e-05,  4.22347621e-05,  3.51669332e-05,\n",
      "        2.64918453e-05,  2.27988294e-05, -1.47338051e-05,  1.97035970e-05,\n",
      "        1.79114177e-05,  1.58046514e-05,  1.35680420e-05, -9.80954519e-06,\n",
      "       -7.75628359e-06,  1.07001388e-05,  9.84211783e-06,  9.00599571e-06,\n",
      "        8.28552311e-06,  6.73173918e-06, -5.35327581e-06, -5.05596245e-06,\n",
      "        6.00909470e-06,  5.47819218e-06, -4.22977337e-06, -3.87693217e-06,\n",
      "        4.71446765e-06,  4.15647492e-06, -2.88589877e-06,  3.40284623e-06,\n",
      "        3.25860196e-06, -2.43034970e-06,  2.88507226e-06,  2.69323573e-06,\n",
      "        2.40753116e-06, -1.98156476e-06, -1.94162544e-06,  2.19214212e-06,\n",
      "        1.99809074e-06, -1.34918878e-06,  1.68823965e-06,  1.50841925e-06,\n",
      "       -1.19284687e-06,  1.44075034e-06,  1.21986386e-06, -9.42932502e-07,\n",
      "        1.06664731e-06,  9.24389781e-07,  9.02328395e-07, -6.66683604e-07,\n",
      "        7.94994264e-07,  7.35458627e-07,  6.93147854e-07, -6.29395629e-07,\n",
      "       -6.05074661e-07, -4.44170638e-07, -3.74804785e-07,  5.12971667e-07,\n",
      "        4.64087123e-07,  4.37966605e-07,  3.75872787e-07, -2.88105014e-07,\n",
      "       -3.02098613e-07,  3.13658916e-07,  2.96128235e-07,  2.53369706e-07,\n",
      "       -2.18172204e-07, -1.82648336e-07, -1.71174179e-07, -1.37277993e-07,\n",
      "        2.36244986e-07,  1.97008049e-07,  1.85017512e-07,  1.57346676e-07,\n",
      "        1.47108835e-07, -1.02813260e-07,  1.14970433e-07, -9.15688503e-08,\n",
      "       -8.21581452e-08,  9.69599228e-08,  8.67195595e-08, -5.56927695e-08,\n",
      "       -5.27142348e-08,  5.94219571e-08, -3.34864971e-08,  4.93119607e-08,\n",
      "        4.57516514e-08, -2.14269598e-08, -1.81863431e-08, -1.38985401e-08,\n",
      "        3.74015272e-08, -7.96281352e-09,  2.99314564e-08,  2.41373268e-08,\n",
      "        2.72857559e-08, -2.25618635e-09,  1.38574796e-08,  8.44827375e-10,\n",
      "        1.17226895e-08,  5.25140731e-09,  8.77402773e-09,  9.01302766e-09],\n",
      "      dtype=float32), array([[-0.05457308, -0.02594641, -0.14883833, ..., -0.0132546 ,\n",
      "         0.01030922,  0.00388728],\n",
      "       [-0.03311927, -0.0029042 , -0.06045117, ...,  0.00487793,\n",
      "        -0.06105052, -0.06604372],\n",
      "       [ 0.00510308, -0.0239681 , -0.02281704, ...,  0.01113054,\n",
      "         0.0540215 ,  0.0050667 ],\n",
      "       ...,\n",
      "       [-0.00535246,  0.18018049,  0.20848764, ...,  0.01640291,\n",
      "         0.13329142,  0.00422927],\n",
      "       [-0.15876727,  0.24575467,  0.01225111, ..., -0.00898947,\n",
      "        -0.02506207, -0.00894914],\n",
      "       [-0.01985802,  0.06037676, -0.03071246, ..., -0.03926686,\n",
      "         0.00673007, -0.10180244]], dtype=float32))\n",
      "(array([ 4.07077728e+02,  1.42450437e-01,  9.98136848e-02,  5.45993894e-02,\n",
      "        1.20454375e-02,  7.29655242e-03,  4.62596444e-03,  2.68295081e-03,\n",
      "        1.48160313e-03,  8.16566346e-04,  4.45761689e-04,  3.62920924e-04,\n",
      "        3.33342032e-04,  2.14844142e-04,  2.19510039e-04,  1.73094697e-04,\n",
      "        1.42000135e-04,  1.04586659e-04,  7.44674762e-05,  5.47867785e-05,\n",
      "        4.54542787e-05,  3.83321458e-05,  2.65860617e-05,  2.21248119e-05,\n",
      "        1.78744431e-05, -1.17088803e-05,  1.41030869e-05, -9.85770384e-06,\n",
      "        1.18747612e-05,  1.13804263e-05,  9.43511350e-06, -7.08268044e-06,\n",
      "        7.41841222e-06, -5.12784663e-06,  6.50850416e-06,  6.25138864e-06,\n",
      "        5.74915202e-06, -4.06723848e-06, -3.75041941e-06,  4.58915656e-06,\n",
      "        4.45419255e-06,  4.11871315e-06,  3.96009182e-06, -2.88231831e-06,\n",
      "        3.46770571e-06,  3.23304221e-06,  2.64938649e-06, -2.26359680e-06,\n",
      "        2.29234956e-06, -1.55741589e-06,  2.18237119e-06,  1.97792110e-06,\n",
      "        1.88876277e-06, -1.39166377e-06, -1.24997484e-06,  1.65123129e-06,\n",
      "        1.52931273e-06,  1.41129260e-06,  1.29063972e-06, -9.29652856e-07,\n",
      "       -9.06188234e-07, -7.95349081e-07,  1.19475737e-06,  1.02340709e-06,\n",
      "        9.45243414e-07,  8.50527954e-07, -5.97474241e-07,  7.33747640e-07,\n",
      "        6.75091314e-07,  5.81025802e-07, -4.84676491e-07, -4.52302743e-07,\n",
      "        5.05996979e-07, -3.82619959e-07,  4.20429245e-07,  4.09637721e-07,\n",
      "       -3.36758035e-07, -3.10704138e-07,  3.40179355e-07, -2.53973298e-07,\n",
      "       -2.17471651e-07,  3.13505723e-07,  2.81752477e-07,  2.19088520e-07,\n",
      "        2.26034331e-07,  1.98520482e-07, -1.62133603e-07,  1.66111278e-07,\n",
      "       -1.42059747e-07,  1.48548011e-07, -1.22040319e-07, -9.08322804e-08,\n",
      "       -7.53780256e-08,  1.11577599e-07,  8.82365754e-08,  9.16261413e-08,\n",
      "        8.21682278e-08, -5.63230991e-08, -4.60344545e-08,  6.70769822e-08,\n",
      "        6.26459524e-08,  5.18796490e-08, -3.80039324e-08, -3.09013437e-08,\n",
      "       -2.26541754e-08, -1.49575943e-08,  3.88451085e-08,  3.51393830e-08,\n",
      "       -1.12437482e-08,  3.29078205e-08,  2.34349322e-08, -5.00622388e-09,\n",
      "       -7.12661430e-10, -5.51948265e-10,  7.58168195e-09,  2.87490742e-09,\n",
      "        4.55681715e-09,  1.25754980e-08,  1.45945744e-08,  1.50631401e-08],\n",
      "      dtype=float32), array([[-0.05532233,  0.14621742, -0.15732852, ..., -0.00239241,\n",
      "         0.05087889,  0.00309247],\n",
      "       [-0.03126279, -0.08655689, -0.00632801, ...,  0.09473788,\n",
      "         0.02616744,  0.11057502],\n",
      "       [ 0.00538856,  0.00979514, -0.00351411, ..., -0.01419396,\n",
      "        -0.07789765,  0.07324243],\n",
      "       ...,\n",
      "       [-0.0023979 , -0.10779948,  0.08789935, ...,  0.04936214,\n",
      "         0.07031509, -0.05771824],\n",
      "       [-0.14509012,  0.06592187, -0.11859085, ..., -0.01676896,\n",
      "        -0.00794643, -0.01098099],\n",
      "       [-0.01495498, -0.04076736, -0.06077037, ...,  0.0155625 ,\n",
      "        -0.00627135,  0.04272497]], dtype=float32))\n",
      "(array([ 3.98855133e+02,  6.54779971e-01,  3.05855185e-01,  1.07240275e-01,\n",
      "        5.40347099e-02,  3.00537981e-02,  2.11551115e-02,  1.24065140e-02,\n",
      "        6.49308367e-03,  4.23058402e-03,  2.66070710e-03,  2.17528665e-03,\n",
      "        1.47156720e-03,  1.06049248e-03,  7.77393056e-04,  7.22060155e-04,\n",
      "        5.52568759e-04,  3.87904613e-04,  2.74460093e-04,  2.30429214e-04,\n",
      "        1.47429484e-04,  1.09958244e-04,  9.91658744e-05,  8.67866911e-05,\n",
      "        6.70541849e-05,  5.38358145e-05,  4.33250643e-05,  3.27492962e-05,\n",
      "        2.64530900e-05,  2.06859768e-05,  1.37643347e-05,  1.18655316e-05,\n",
      "       -9.60126999e-06,  1.04705405e-05, -7.99381360e-06,  8.53181064e-06,\n",
      "        7.87013505e-06, -6.38265328e-06,  6.87394822e-06, -5.66722656e-06,\n",
      "       -4.01954549e-06,  5.11075541e-06,  4.60409501e-06,  4.43317367e-06,\n",
      "        3.76178969e-06, -3.09946154e-06, -2.74664581e-06,  2.93607036e-06,\n",
      "        2.57699912e-06, -2.20851825e-06,  2.39749534e-06, -1.92891662e-06,\n",
      "        2.09271411e-06, -1.41122871e-06,  1.60256070e-06,  1.45539673e-06,\n",
      "       -1.25584268e-06,  1.25862789e-06,  1.12945327e-06,  1.00941395e-06,\n",
      "        9.14190650e-07, -1.01358444e-06, -8.84899976e-07, -8.20112348e-07,\n",
      "        7.92271692e-07,  7.39510028e-07,  6.79745256e-07,  5.63478636e-07,\n",
      "       -5.41163558e-07, -4.71051436e-07,  4.81850805e-07,  4.19766678e-07,\n",
      "       -4.21558781e-07, -3.65711713e-07, -3.54124950e-07,  3.53600285e-07,\n",
      "       -3.30509096e-07,  3.05599229e-07, -2.62587747e-07, -1.90344167e-07,\n",
      "       -1.76642047e-07,  2.75631152e-07,  2.59076302e-07,  2.23186447e-07,\n",
      "        2.06216811e-07,  1.91281529e-07,  1.79672170e-07, -1.45945876e-07,\n",
      "       -1.40548380e-07,  1.56148516e-07,  1.38676242e-07,  1.14483527e-07,\n",
      "       -8.25349389e-08, -7.04817325e-08,  8.65563337e-08,  7.98563065e-08,\n",
      "       -5.71378820e-08,  6.10142692e-08,  5.62589015e-08,  5.10287528e-08,\n",
      "       -4.46649793e-08, -4.05139886e-08,  4.73187782e-08, -3.18262536e-08,\n",
      "        4.32490630e-08,  3.31653816e-08,  2.78007839e-08, -1.85921891e-08,\n",
      "       -1.58560098e-08, -1.18831736e-08,  1.54931161e-08,  1.59658153e-08,\n",
      "        1.20819257e-08, -6.94879176e-09, -2.71913447e-09, -1.94006256e-09,\n",
      "       -3.18155259e-11,  7.27465288e-09,  4.19424184e-09,  4.75842166e-09],\n",
      "      dtype=float32), array([[-0.05171995,  0.05198564, -0.15626162, ...,  0.03138327,\n",
      "        -0.01359685,  0.02242761],\n",
      "       [-0.0320853 ,  0.02913641,  0.18113738, ...,  0.02495318,\n",
      "        -0.07119381, -0.00890788],\n",
      "       [ 0.0055936 ,  0.01979882, -0.01195425, ...,  0.15115039,\n",
      "        -0.05894756,  0.04241108],\n",
      "       ...,\n",
      "       [-0.00666083,  0.04357866, -0.03680182, ..., -0.14240247,\n",
      "         0.09158193, -0.20429948],\n",
      "       [-0.14896497,  0.2225483 , -0.05893826, ..., -0.00481012,\n",
      "        -0.00918083,  0.01790692],\n",
      "       [-0.01515305,  0.10708493, -0.03151159, ...,  0.11530712,\n",
      "         0.04487057,  0.01551168]], dtype=float32))\n",
      "(array([ 4.23775269e+02,  3.80637616e-01,  1.55309319e-01,  4.83896956e-02,\n",
      "        2.94140708e-02,  1.70772485e-02,  1.17721129e-02,  6.23037992e-03,\n",
      "        5.52059244e-03,  3.69636039e-03,  3.34350602e-03,  2.92643346e-03,\n",
      "        1.29291858e-03,  8.33514263e-04,  7.37785769e-04,  6.33608666e-04,\n",
      "        3.51953437e-04,  3.26934038e-04,  2.58278102e-04,  2.39047033e-04,\n",
      "        1.61643286e-04,  1.31306035e-04,  9.76946540e-05,  8.88859868e-05,\n",
      "        6.37574267e-05,  4.82179494e-05,  3.87503205e-05,  2.84639264e-05,\n",
      "        2.71299305e-05,  2.52206210e-05,  2.12771793e-05, -1.43423558e-05,\n",
      "        1.64052926e-05,  1.46536604e-05, -9.16924819e-06,  1.21704861e-05,\n",
      "        1.13966171e-05, -8.14083887e-06,  9.47272747e-06,  8.69776250e-06,\n",
      "        7.52207598e-06,  6.71789621e-06, -5.46687215e-06,  5.60850640e-06,\n",
      "        5.45149487e-06,  4.61368472e-06,  4.84911334e-06, -3.80270626e-06,\n",
      "        3.72685508e-06, -2.71657223e-06,  3.28774240e-06,  2.91427477e-06,\n",
      "       -2.12866257e-06, -2.22871176e-06,  2.44739249e-06, -1.84064766e-06,\n",
      "       -1.61987191e-06,  2.17150910e-06,  2.09745758e-06,  1.74359923e-06,\n",
      "        1.38113819e-06, -1.21578341e-06,  1.20315894e-06,  1.20593461e-06,\n",
      "       -9.07275819e-07,  9.89854925e-07,  9.41789494e-07,  8.97800305e-07,\n",
      "        8.43299119e-07, -7.20909384e-07, -6.43507121e-07,  6.29040301e-07,\n",
      "       -5.39406471e-07, -4.87998648e-07,  5.84358474e-07,  4.70489965e-07,\n",
      "       -3.95116302e-07, -3.71917395e-07,  4.40092634e-07, -3.01971397e-07,\n",
      "        4.15360802e-07,  3.57052528e-07,  3.08655302e-07,  2.91565698e-07,\n",
      "        2.46278375e-07, -1.98398226e-07,  1.94030051e-07, -1.82419910e-07,\n",
      "       -1.44676676e-07, -1.31968648e-07, -1.08397074e-07,  1.60152709e-07,\n",
      "        1.64559083e-07,  1.20543589e-07,  1.28799968e-07, -8.72944739e-08,\n",
      "        8.64302265e-08,  7.89541517e-08, -7.03756555e-08,  6.83386432e-08,\n",
      "       -5.56350130e-08,  5.52876287e-08, -3.82684178e-08, -3.44079290e-08,\n",
      "       -2.85562471e-08,  4.52682691e-08,  3.95912423e-08,  3.72883058e-08,\n",
      "       -2.34259581e-08,  2.87878503e-08,  2.47787764e-08, -1.49818344e-08,\n",
      "       -1.17089831e-08,  1.47128647e-08,  1.35642253e-08, -4.51368187e-09,\n",
      "        9.44479694e-09,  4.36719150e-09, -1.44014589e-09,  8.90104102e-10],\n",
      "      dtype=float32), array([[-0.05402799,  0.06024762, -0.06272386, ...,  0.02786455,\n",
      "        -0.00906918,  0.00078349],\n",
      "       [-0.03067189, -0.15407488,  0.04099001, ...,  0.04109564,\n",
      "        -0.00406717, -0.01729743],\n",
      "       [ 0.0057812 ,  0.0281448 ,  0.04634078, ...,  0.03618977,\n",
      "         0.04957429,  0.10843559],\n",
      "       ...,\n",
      "       [-0.01041837, -0.04626255, -0.2518869 , ..., -0.09907497,\n",
      "        -0.03979611, -0.00081543],\n",
      "       [-0.15241925,  0.05849063, -0.22499375, ..., -0.0188606 ,\n",
      "         0.01964604, -0.01871327],\n",
      "       [-0.01567105,  0.05853539, -0.02319922, ..., -0.07280383,\n",
      "         0.10518233, -0.00693401]], dtype=float32))\n",
      "(array([ 4.19918365e+02,  1.70287386e-01,  3.62607166e-02,  2.65133772e-02,\n",
      "        1.26530929e-02,  1.21724969e-02,  4.76371171e-03,  3.28885787e-03,\n",
      "        1.47956412e-03,  9.11177252e-04,  5.50804834e-04,  3.83219711e-04,\n",
      "        2.84387468e-04,  2.04726864e-04,  1.80399584e-04,  1.45562779e-04,\n",
      "        8.81238520e-05,  6.97446885e-05,  4.91499959e-05,  4.03263584e-05,\n",
      "        3.07466835e-05,  2.35964435e-05,  2.07245921e-05,  2.01299335e-05,\n",
      "       -1.39662161e-05,  1.36426179e-05,  1.21463981e-05,  1.13442711e-05,\n",
      "        1.01309879e-05, -7.93510935e-06,  8.92501885e-06, -6.91337891e-06,\n",
      "        7.39093912e-06, -5.35520621e-06, -4.64165578e-06,  5.82748225e-06,\n",
      "        5.66233712e-06,  4.78555103e-06,  4.60060937e-06, -4.00333920e-06,\n",
      "       -3.04957734e-06,  3.92690890e-06,  3.58683633e-06,  3.26422014e-06,\n",
      "        2.80783001e-06, -2.43223462e-06, -2.07934704e-06,  2.26525253e-06,\n",
      "        1.87702551e-06, -1.69272005e-06, -1.61631738e-06,  1.64808853e-06,\n",
      "        1.54040663e-06, -1.26192697e-06, -1.02726062e-06,  1.33191111e-06,\n",
      "        1.30300691e-06,  1.12027669e-06,  1.05691731e-06, -9.27643669e-07,\n",
      "       -8.92205435e-07,  9.73677061e-07,  9.24732774e-07, -7.85718271e-07,\n",
      "       -7.29632575e-07, -5.81464121e-07,  7.95386200e-07,  6.69325516e-07,\n",
      "        6.36418520e-07,  5.94859216e-07,  5.23382027e-07, -4.12483217e-07,\n",
      "        4.39381239e-07,  4.09787816e-07,  3.94876992e-07, -3.04424390e-07,\n",
      "       -2.68317052e-07,  3.35328394e-07,  3.01542741e-07, -2.24842722e-07,\n",
      "       -2.13499888e-07,  2.59509903e-07,  2.35100401e-07,  2.17995236e-07,\n",
      "       -1.55442081e-07,  1.79422287e-07, -1.26441094e-07, -1.14579322e-07,\n",
      "        1.43291714e-07,  1.37202662e-07,  1.26672887e-07,  1.11577485e-07,\n",
      "        1.03885299e-07, -8.59878426e-08, -7.69351090e-08,  8.39846379e-08,\n",
      "       -5.80712474e-08,  6.51220162e-08,  5.65401983e-08, -4.83619438e-08,\n",
      "       -4.51565683e-08, -2.95408853e-08,  4.74464876e-08,  5.02945738e-08,\n",
      "        4.09893879e-08,  3.55350558e-08, -1.69985448e-08,  2.32808102e-08,\n",
      "        1.99619148e-08, -8.66772432e-09, -1.07020863e-08,  1.43837653e-08,\n",
      "       -5.19091259e-09, -4.28501945e-09, -6.57791543e-10,  1.28988620e-09,\n",
      "        7.30151184e-09,  9.56176649e-09,  9.26211285e-09,  6.18114582e-09],\n",
      "      dtype=float32), array([[-5.1663056e-02,  4.3234363e-02, -7.2492890e-02, ...,\n",
      "        -7.1785473e-03,  1.2877127e-02,  7.6598073e-05],\n",
      "       [-2.7260043e-02, -1.4763796e-01,  1.0336353e-01, ...,\n",
      "        -2.8622577e-02,  8.1685903e-03,  3.6174301e-02],\n",
      "       [ 8.5723717e-03,  2.7628265e-02,  1.3105904e-02, ...,\n",
      "        -9.3542010e-02, -1.9751686e-01,  2.6564397e-02],\n",
      "       ...,\n",
      "       [-1.9550612e-02, -3.5176780e-02, -1.3513002e-01, ...,\n",
      "         4.2355850e-02, -8.1049971e-02, -2.8657280e-02],\n",
      "       [-1.5341622e-01,  8.5750826e-02,  7.1769603e-02, ...,\n",
      "        -1.3897498e-03, -4.4117682e-03, -3.7269713e-03],\n",
      "       [-1.5624972e-02,  8.7253831e-02,  2.5638381e-02, ...,\n",
      "        -4.9761884e-02, -6.5700606e-02,  1.1771082e-02]], dtype=float32))\n",
      "(array([ 4.1343030e+02,  1.7839487e+00,  1.3690125e+00,  3.6518711e-01,\n",
      "        8.8001885e-02,  7.3126435e-02,  5.0823402e-02,  2.9701050e-02,\n",
      "        2.1981601e-02,  1.2232702e-02,  7.8353463e-03,  6.3671819e-03,\n",
      "        4.2162044e-03,  3.4718316e-03,  2.6530456e-03,  2.0795828e-03,\n",
      "        1.2086052e-03,  9.4515050e-04,  8.8434026e-04,  5.9133605e-04,\n",
      "        4.6570750e-04,  3.1829526e-04,  2.4933869e-04,  1.0628216e-04,\n",
      "        9.9940880e-05,  6.6321190e-05,  4.7420355e-05,  3.5769739e-05,\n",
      "        2.6336606e-05,  2.2268307e-05,  1.8551029e-05,  1.6228627e-05,\n",
      "        1.3323425e-05, -1.1196840e-05,  9.2691107e-06,  8.7336903e-06,\n",
      "        8.4040685e-06, -7.5752173e-06,  7.4673658e-06, -6.1249793e-06,\n",
      "        6.1315022e-06,  5.5443102e-06,  4.4930193e-06, -4.2155075e-06,\n",
      "       -3.8139194e-06, -3.2897158e-06,  3.7710900e-06,  3.4556258e-06,\n",
      "        2.7919782e-06,  2.3057185e-06, -2.1048975e-06, -1.9492941e-06,\n",
      "       -1.7547765e-06,  2.0910725e-06,  1.8805556e-06,  1.7618493e-06,\n",
      "       -1.2048406e-06, -1.1292282e-06,  1.2937232e-06,  1.2278559e-06,\n",
      "        1.1775600e-06, -1.0233452e-06,  9.6512179e-07,  1.0088870e-06,\n",
      "       -7.8032963e-07, -6.7015816e-07, -6.2728179e-07,  8.2626701e-07,\n",
      "        7.3697663e-07,  6.2391894e-07,  5.5752139e-07, -5.0880976e-07,\n",
      "       -4.6175163e-07,  4.5975057e-07, -3.8534685e-07,  4.2655134e-07,\n",
      "        3.9789748e-07,  3.7578360e-07, -3.2410190e-07, -2.7581143e-07,\n",
      "        3.1095368e-07,  2.9283311e-07, -2.3008731e-07, -2.0494713e-07,\n",
      "        2.5253874e-07,  2.4402067e-07,  1.8547021e-07, -1.7249279e-07,\n",
      "       -1.5307450e-07, -1.4894891e-07,  1.5944315e-07,  1.4318144e-07,\n",
      "       -1.0076295e-07, -8.9376393e-08,  1.3708804e-07,  1.2305844e-07,\n",
      "        9.8523124e-08,  8.2159517e-08,  7.9027117e-08,  6.4620878e-08,\n",
      "       -6.5963661e-08, -3.4478887e-08, -4.7105690e-08, -2.7926951e-08,\n",
      "       -2.2207157e-08,  3.0031043e-08,  4.6652524e-08,  4.0170203e-08,\n",
      "       -1.7651956e-08, -1.2645875e-08, -8.7246894e-09, -5.4405027e-09,\n",
      "       -1.9654127e-09,  1.4569701e-08,  1.2417167e-08,  1.1013579e-08,\n",
      "        6.7530816e-09,  5.6516001e-09,  2.6050382e-09,  3.6104988e-09],\n",
      "      dtype=float32), array([[ 0.05403452,  0.07201441, -0.0066775 , ..., -0.01573662,\n",
      "        -0.0397219 , -0.00746821],\n",
      "       [ 0.02633988,  0.0156943 ,  0.18230312, ..., -0.06584116,\n",
      "         0.002826  ,  0.04414991],\n",
      "       [-0.00915566,  0.01902507, -0.04395247, ..., -0.00153634,\n",
      "        -0.10466543, -0.16383597],\n",
      "       ...,\n",
      "       [ 0.02354389,  0.0559539 ,  0.02933601, ...,  0.00702389,\n",
      "         0.00269134,  0.00825336],\n",
      "       [ 0.15410566, -0.01571663, -0.11722973, ...,  0.00894224,\n",
      "        -0.005462  , -0.01528102],\n",
      "       [ 0.01603034,  0.09985591, -0.09221543, ..., -0.14986542,\n",
      "        -0.13109773,  0.12344538]], dtype=float32))\n",
      "(array([ 4.14495239e+02,  6.79080188e-02,  1.55169368e-02,  9.25418176e-03,\n",
      "        6.52068853e-03,  2.33870302e-03,  1.15367281e-03,  4.40704549e-04,\n",
      "        2.17957160e-04,  1.74654662e-04,  1.25217513e-04,  9.11973402e-05,\n",
      "        6.38349011e-05,  4.64105979e-05,  3.77290671e-05,  2.45205774e-05,\n",
      "        2.39734873e-05,  2.24890300e-05, -1.39348049e-05, -1.04222518e-05,\n",
      "        1.29461305e-05,  1.30035487e-05,  1.14647728e-05, -8.39962104e-06,\n",
      "        1.00890520e-05,  8.99329643e-06,  7.74736600e-06,  6.98381245e-06,\n",
      "       -6.60803244e-06, -6.09328663e-06,  5.96125938e-06, -5.02299008e-06,\n",
      "        5.56390205e-06,  3.99924420e-06,  3.81489508e-06, -3.09416828e-06,\n",
      "       -2.68904409e-06,  3.27734051e-06,  2.90801859e-06,  2.77623258e-06,\n",
      "        2.42626243e-06, -2.12825125e-06, -1.86197144e-06,  2.24150904e-06,\n",
      "        1.90896776e-06,  1.85787871e-06, -1.52061989e-06, -1.43032878e-06,\n",
      "        1.54996530e-06, -1.15629894e-06,  1.37319068e-06,  1.30788510e-06,\n",
      "        1.20395998e-06, -9.86246164e-07,  1.03581897e-06,  9.69203597e-07,\n",
      "       -7.96072868e-07,  8.41968074e-07,  7.30708393e-07,  7.20873800e-07,\n",
      "       -6.50475215e-07, -6.25654479e-07, -5.95720394e-07,  6.16490865e-07,\n",
      "        5.96271832e-07, -4.80269989e-07, -3.79301156e-07,  4.51887018e-07,\n",
      "        4.60811236e-07,  3.83368985e-07, -2.90806554e-07,  3.60684595e-07,\n",
      "        3.35924994e-07,  2.91278326e-07, -2.40391870e-07, -1.97136956e-07,\n",
      "        2.61552202e-07,  2.45263891e-07, -1.56751398e-07,  1.86863545e-07,\n",
      "       -1.49305151e-07,  1.83101733e-07,  1.69373905e-07,  1.63328039e-07,\n",
      "        1.45261367e-07, -1.22806256e-07, -1.21502126e-07,  1.15124408e-07,\n",
      "       -9.45986542e-08,  1.04923068e-07, -8.76385258e-08,  8.60748557e-08,\n",
      "       -7.44147073e-08, -6.41416875e-08,  7.31910106e-08,  6.73239171e-08,\n",
      "       -4.17620285e-08,  5.49812178e-08,  4.76713069e-08,  3.67204649e-08,\n",
      "       -3.14970023e-08, -2.67662479e-08, -2.41644091e-08, -1.93791507e-08,\n",
      "       -1.34470461e-08,  3.47540947e-08,  2.89188637e-08,  2.27748842e-08,\n",
      "        2.64965117e-08,  1.22694344e-08,  1.54620352e-08, -9.44555811e-09,\n",
      "       -3.31395977e-09, -2.17876295e-09, -5.17756860e-09,  1.61147443e-10,\n",
      "        1.85522131e-09,  8.02425149e-09,  6.49074838e-09,  5.53255797e-09],\n",
      "      dtype=float32), array([[-0.06040003, -0.03815624, -0.11714458, ..., -0.00389199,\n",
      "         0.01035011, -0.00270784],\n",
      "       [-0.02852798, -0.14058028,  0.07405927, ...,  0.04896725,\n",
      "         0.04513669, -0.12290926],\n",
      "       [ 0.01119655,  0.05088373,  0.01797202, ...,  0.08707611,\n",
      "         0.16162056, -0.1594773 ],\n",
      "       ...,\n",
      "       [-0.02816693, -0.02286735,  0.01982027, ..., -0.01625928,\n",
      "        -0.00653895, -0.06851837],\n",
      "       [-0.15743576,  0.06845298, -0.11685139, ...,  0.00610023,\n",
      "         0.00727033, -0.00956944],\n",
      "       [-0.01287811,  0.05553415,  0.03852311, ..., -0.06684111,\n",
      "         0.06452902,  0.19351847]], dtype=float32))\n",
      "(array([ 3.6646649e+02,  8.2596618e-01,  3.8148966e-01,  3.4752429e-01,\n",
      "        7.0247330e-02,  3.7761450e-02,  2.8485201e-02,  1.3919256e-02,\n",
      "        1.0085866e-02,  4.0800367e-03,  2.7341838e-03,  1.3655428e-03,\n",
      "        1.2513680e-03,  1.0627059e-03,  6.2397873e-04,  4.9812213e-04,\n",
      "        3.1189513e-04,  1.8882702e-04,  1.5734824e-04,  1.3287802e-04,\n",
      "        1.1426104e-04,  7.0393377e-05,  6.0271446e-05,  3.8960858e-05,\n",
      "        3.2952168e-05,  2.8530318e-05,  2.0424319e-05,  1.5728072e-05,\n",
      "        1.4563426e-05, -1.0730402e-05,  1.0248456e-05, -7.4701347e-06,\n",
      "        8.8150809e-06, -6.6522653e-06,  7.6348961e-06,  7.3346391e-06,\n",
      "        5.9154995e-06,  5.1432157e-06, -4.4555491e-06, -3.4342577e-06,\n",
      "        4.3693581e-06,  3.6486915e-06,  3.5597818e-06,  3.1041543e-06,\n",
      "       -2.5997044e-06,  2.7458279e-06,  2.2761640e-06, -2.1236731e-06,\n",
      "       -1.8574633e-06,  2.0139857e-06,  1.8036236e-06, -1.6669353e-06,\n",
      "       -1.5623962e-06,  1.5736202e-06, -1.2638353e-06,  1.3900625e-06,\n",
      "        1.2447986e-06,  1.2085080e-06, -1.1237108e-06, -1.0085124e-06,\n",
      "       -8.3522292e-07, -7.5611359e-07,  1.0136451e-06,  9.4174089e-07,\n",
      "        8.5908795e-07,  7.8970555e-07, -5.6425506e-07,  6.0282326e-07,\n",
      "        5.5646802e-07, -4.7965312e-07, -3.7396779e-07,  4.8998231e-07,\n",
      "        4.3352244e-07, -2.8509180e-07,  3.4704456e-07,  3.2083554e-07,\n",
      "       -2.4923588e-07,  2.9737117e-07,  2.8760692e-07, -2.1775466e-07,\n",
      "       -2.0925171e-07,  2.3621963e-07, -1.5928019e-07,  2.2340338e-07,\n",
      "        1.9088264e-07,  1.6977019e-07, -1.2877958e-07,  1.5903044e-07,\n",
      "        1.4469107e-07, -9.8083170e-08, -8.2446093e-08,  1.2085245e-07,\n",
      "        9.6785207e-08,  9.9401241e-08, -7.2175062e-08, -6.4036165e-08,\n",
      "       -5.3222877e-08,  6.7482802e-08,  5.8697985e-08, -3.6292523e-08,\n",
      "       -2.7002020e-08,  4.8253639e-08,  4.3909072e-08,  3.4285573e-08,\n",
      "       -2.0205031e-08,  3.1288383e-08, -1.4503630e-08,  2.4922311e-08,\n",
      "        2.1201354e-08,  1.9561565e-08, -8.9542338e-09, -6.4436008e-09,\n",
      "        1.5866986e-08,  1.2266958e-08, -1.9789252e-09, -2.0348483e-09,\n",
      "        2.3704543e-09,  8.3233607e-09,  7.2102879e-09,  3.7109142e-09],\n",
      "      dtype=float32), array([[ 0.055618  , -0.1440738 , -0.00257274, ...,  0.02178828,\n",
      "         0.00702787,  0.01062294],\n",
      "       [ 0.03049731, -0.02767181,  0.04280739, ...,  0.02211067,\n",
      "         0.0227928 ,  0.0081001 ],\n",
      "       [-0.00782852, -0.03006636,  0.0669399 , ..., -0.1075068 ,\n",
      "         0.06315404,  0.01079353],\n",
      "       ...,\n",
      "       [ 0.01314346, -0.02242966, -0.31868657, ..., -0.05069048,\n",
      "         0.09382219, -0.10397637],\n",
      "       [ 0.14759992, -0.2318635 , -0.09559276, ..., -0.0052553 ,\n",
      "         0.00956635, -0.00163141],\n",
      "       [ 0.01111655, -0.0979723 , -0.00260696, ...,  0.04672782,\n",
      "        -0.14842162, -0.10943808]], dtype=float32))\n",
      "(array([ 3.4941388e+02,  1.6796415e-01,  1.2597711e-01,  4.2535435e-02,\n",
      "        9.9898828e-03,  5.0565940e-03,  4.8571671e-03,  1.2704959e-03,\n",
      "        8.4147468e-04,  6.2951009e-04,  5.7543279e-04,  3.1265069e-04,\n",
      "        2.3396203e-04,  1.7207178e-04,  1.3267754e-04,  1.0837504e-04,\n",
      "        1.0173405e-04,  6.6060849e-05,  5.7985864e-05,  4.7638292e-05,\n",
      "        4.1407337e-05,  2.5941925e-05,  2.2043727e-05,  1.9315643e-05,\n",
      "        1.6128573e-05,  1.5801923e-05, -1.0211210e-05,  1.2601674e-05,\n",
      "        1.1537362e-05,  9.8285245e-06,  9.6774129e-06,  8.7559974e-06,\n",
      "       -6.5963245e-06,  7.3520687e-06,  6.9076418e-06, -4.6261976e-06,\n",
      "        5.2164796e-06, -4.0528662e-06,  4.5082925e-06,  4.0123173e-06,\n",
      "        3.6077881e-06, -3.1266177e-06, -2.5826107e-06,  3.2063967e-06,\n",
      "        3.0530423e-06,  2.6947096e-06,  2.5741058e-06, -2.0600837e-06,\n",
      "       -1.8912351e-06,  2.0524380e-06,  2.1563596e-06, -1.5998884e-06,\n",
      "        1.7332549e-06,  1.5496627e-06,  1.4290049e-06, -1.2157433e-06,\n",
      "        1.3435218e-06,  1.2133106e-06, -9.5667303e-07,  1.1649292e-06,\n",
      "        1.0327465e-06, -6.9682233e-07,  8.1123267e-07,  7.3145867e-07,\n",
      "       -5.9745622e-07, -5.9589678e-07, -4.7353578e-07,  6.7744776e-07,\n",
      "        6.0433416e-07,  5.7050374e-07,  4.8795243e-07,  4.6470902e-07,\n",
      "       -3.7103916e-07, -3.2554578e-07,  3.7364833e-07,  3.4302204e-07,\n",
      "       -2.9901938e-07,  3.2698031e-07,  2.6011674e-07,  2.3553409e-07,\n",
      "       -1.9789469e-07, -1.7493291e-07, -1.7986994e-07,  1.9288836e-07,\n",
      "       -1.4951758e-07,  1.7239279e-07, -1.3726090e-07, -1.2158763e-07,\n",
      "        1.4726356e-07,  1.3053379e-07,  1.1765672e-07, -9.8826931e-08,\n",
      "       -8.5895174e-08,  9.2379516e-08, -7.5217947e-08, -5.7168727e-08,\n",
      "        7.7070588e-08, -5.1742660e-08,  6.9109454e-08,  6.5019137e-08,\n",
      "        5.7526123e-08,  5.1674682e-08, -2.9881839e-08, -2.8569659e-08,\n",
      "        4.0663238e-08, -1.7034040e-08,  3.2889300e-08, -1.2328536e-08,\n",
      "        2.8866779e-08, -7.5323685e-09,  1.9991177e-08, -4.5939306e-09,\n",
      "       -2.2838396e-09,  8.7554547e-11,  1.5010759e-08,  1.3102456e-08,\n",
      "        9.5268087e-09,  2.5718574e-09,  5.7312977e-09,  4.7780691e-09],\n",
      "      dtype=float32), array([[-0.05303736,  0.07383003, -0.17382991, ..., -0.04487436,\n",
      "         0.02791626,  0.0003312 ],\n",
      "       [-0.02858471,  0.05237576,  0.0825469 , ..., -0.00583449,\n",
      "        -0.0412975 , -0.03911439],\n",
      "       [ 0.00826113,  0.00980587, -0.0054732 , ..., -0.04171395,\n",
      "        -0.07867756, -0.14780839],\n",
      "       ...,\n",
      "       [-0.00802271, -0.06808358,  0.11078966, ..., -0.13311   ,\n",
      "         0.12607174,  0.11488272],\n",
      "       [-0.1385119 ,  0.06933583, -0.10472321, ...,  0.00474818,\n",
      "         0.00078532, -0.00932711],\n",
      "       [-0.00823704,  0.06178529,  0.0179149 , ..., -0.13828652,\n",
      "        -0.11515398,  0.0825294 ]], dtype=float32))\n",
      "(array([ 3.38659241e+02,  7.47334883e-02,  5.62997088e-02,  4.47561927e-02,\n",
      "        5.44105517e-03,  4.30621859e-03,  2.64307088e-03,  2.01578904e-03,\n",
      "        1.33568281e-03,  4.00330056e-04,  2.74975668e-04,  1.98983907e-04,\n",
      "        9.61973346e-05,  6.54656615e-05,  5.81625609e-05,  4.20086435e-05,\n",
      "        3.43812208e-05,  3.03450161e-05,  2.06420336e-05,  1.55716807e-05,\n",
      "        1.37096667e-05, -9.95700066e-06,  1.20712784e-05, -8.48635955e-06,\n",
      "        1.01564528e-05,  9.13462191e-06,  8.42939608e-06, -5.58903730e-06,\n",
      "        6.41350607e-06,  5.85622911e-06, -4.98887584e-06,  5.66030803e-06,\n",
      "        4.63876813e-06, -3.65330607e-06,  4.09445647e-06,  3.45716376e-06,\n",
      "       -2.83678196e-06,  3.16966339e-06,  2.50359631e-06, -2.21490609e-06,\n",
      "        2.24832297e-06, -2.05372885e-06,  2.14642228e-06, -1.50011488e-06,\n",
      "        1.91554182e-06,  1.75338380e-06,  1.66192899e-06, -1.33008155e-06,\n",
      "        1.54027907e-06, -1.22362542e-06, -1.04372737e-06,  1.31121112e-06,\n",
      "        1.22934807e-06,  1.20175957e-06,  1.03130333e-06,  9.60321472e-07,\n",
      "        8.15327269e-07, -7.29002409e-07, -6.96080917e-07, -6.06111143e-07,\n",
      "        7.33359002e-07,  6.91511104e-07, -4.31027871e-07,  5.49969116e-07,\n",
      "        5.77777143e-07,  4.63865717e-07, -4.09465457e-07,  4.13201406e-07,\n",
      "       -2.93731830e-07,  3.58900792e-07,  3.29802589e-07, -2.66380596e-07,\n",
      "       -2.52918312e-07,  2.92108808e-07,  2.42415979e-07,  2.13540488e-07,\n",
      "       -1.82858344e-07,  1.88168258e-07, -1.64401101e-07, -1.50729136e-07,\n",
      "       -1.15284784e-07, -1.00439273e-07,  1.61765044e-07,  1.49254447e-07,\n",
      "        1.36238341e-07,  1.20726213e-07,  1.08857193e-07, -9.72503926e-08,\n",
      "        9.13457967e-08, -7.27986986e-08, -6.41168398e-08,  8.30523774e-08,\n",
      "        7.65727037e-08, -4.38446932e-08,  6.53462280e-08,  5.53670567e-08,\n",
      "        5.09155988e-08, -3.72853997e-08,  4.06331253e-08,  3.66995820e-08,\n",
      "        3.14758175e-08, -1.99480095e-08, -1.78690058e-08, -1.58386477e-08,\n",
      "        2.63361759e-08,  1.80973245e-08,  2.12747100e-08,  1.99345926e-08,\n",
      "       -1.03967839e-08,  1.19810375e-08, -1.11361942e-08,  1.06443920e-08,\n",
      "        8.15861689e-09, -5.13879028e-09,  5.54909629e-09,  4.02924405e-09,\n",
      "        1.90021132e-09,  9.79582040e-11, -2.31456121e-09, -1.51286517e-09],\n",
      "      dtype=float32), array([[-0.05064097, -0.1866893 ,  0.02464732, ..., -0.03238166,\n",
      "        -0.01519355, -0.04523665],\n",
      "       [-0.02722177,  0.08936892, -0.09836774, ...,  0.01570839,\n",
      "         0.01614364,  0.00640712],\n",
      "       [ 0.00903679, -0.02700456,  0.0056347 , ..., -0.0200647 ,\n",
      "         0.06591531,  0.0646731 ],\n",
      "       ...,\n",
      "       [-0.01269225,  0.08456912, -0.00650822, ...,  0.00921565,\n",
      "        -0.01284154, -0.12397809],\n",
      "       [-0.13828716, -0.1539401 ,  0.04587175, ..., -0.00357698,\n",
      "        -0.00327772,  0.00910987],\n",
      "       [-0.0077717 , -0.0534483 , -0.05204244, ..., -0.07524476,\n",
      "        -0.1253499 , -0.03024258]], dtype=float32))\n",
      "(array([ 2.64387543e+02,  2.71923685e+00,  5.45284092e-01,  3.81587327e-01,\n",
      "        2.10078597e-01,  9.57423076e-02,  5.24090379e-02,  4.60012630e-02,\n",
      "        3.62961926e-02,  2.79861633e-02,  1.98720954e-02,  1.41908955e-02,\n",
      "        8.93222634e-03,  5.32786502e-03,  4.32382803e-03,  3.15331691e-03,\n",
      "        2.62157433e-03,  2.52850726e-03,  1.91284285e-03,  1.63609895e-03,\n",
      "        1.22841401e-03,  1.02053152e-03,  8.96689948e-04,  7.47058599e-04,\n",
      "        6.51349837e-04,  5.24723786e-04,  4.65376273e-04,  4.02195787e-04,\n",
      "        2.84508744e-04,  2.36481224e-04,  1.78881193e-04,  1.68630693e-04,\n",
      "        1.48824649e-04,  1.24720900e-04,  8.43757007e-05,  7.32500484e-05,\n",
      "        6.18356135e-05,  5.65377268e-05,  4.37175331e-05,  3.94480776e-05,\n",
      "        3.02123226e-05,  1.97234658e-05,  1.74119541e-05,  1.39508929e-05,\n",
      "        1.10921064e-05,  9.21034643e-06,  7.16676004e-06,  6.57269220e-06,\n",
      "       -5.05490289e-06,  5.09286747e-06,  4.64962568e-06, -3.26483791e-06,\n",
      "       -2.95110726e-06,  3.40721112e-06,  2.89663512e-06, -2.37536005e-06,\n",
      "       -2.02257274e-06,  2.19269486e-06,  2.04263006e-06,  1.57539637e-06,\n",
      "        1.40878217e-06, -1.32495995e-06, -1.25325823e-06,  1.24862606e-06,\n",
      "       -1.00999034e-06,  8.33105219e-07, -8.28022507e-07, -6.06772744e-07,\n",
      "       -5.96773305e-07,  6.64320339e-07, -4.68601286e-07,  5.87229636e-07,\n",
      "        5.20248420e-07,  5.05730327e-07, -3.99435606e-07,  3.66778607e-07,\n",
      "        3.52286094e-07, -3.05123280e-07,  2.48024776e-07, -2.69055732e-07,\n",
      "       -2.31995713e-07,  2.12325432e-07, -2.09603243e-07,  1.91527164e-07,\n",
      "        1.59657887e-07, -1.50324624e-07, -1.41879610e-07, -1.28773451e-07,\n",
      "        1.36687419e-07,  1.31040323e-07, -1.10223553e-07,  1.01525444e-07,\n",
      "        9.06454574e-08, -8.44368415e-08,  7.44487423e-08, -6.90281254e-08,\n",
      "        5.63492364e-08, -5.36554872e-08, -4.44281412e-08,  4.44909922e-08,\n",
      "        4.21123154e-08,  3.69904640e-08, -3.77723097e-08,  2.95510354e-08,\n",
      "       -2.54335308e-08,  2.23400693e-08, -1.98098355e-08, -1.82402982e-08,\n",
      "        1.76634583e-08,  1.17434542e-08, -1.13729888e-08,  7.90187737e-09,\n",
      "        5.39188694e-09,  3.69750763e-09,  2.52120169e-09,  7.19976301e-11,\n",
      "       -7.74235520e-09, -1.93452321e-09, -5.96232486e-09, -4.17954338e-09],\n",
      "      dtype=float32), array([[ 0.04678443,  0.05664987,  0.09436678, ..., -0.00804085,\n",
      "        -0.03919167,  0.01813431],\n",
      "       [ 0.02824369, -0.03936211, -0.16236134, ..., -0.03959924,\n",
      "        -0.05267841,  0.00475212],\n",
      "       [-0.02037419, -0.06038996,  0.05761378, ...,  0.00357533,\n",
      "         0.01153269,  0.01313187],\n",
      "       ...,\n",
      "       [ 0.02603006,  0.11010946, -0.05064393, ..., -0.03595169,\n",
      "         0.02272253,  0.03247796],\n",
      "       [ 0.12911116,  0.01831926,  0.16703767, ..., -0.01983376,\n",
      "         0.00511272, -0.01974119],\n",
      "       [ 0.01288357, -0.07692778,  0.11060181, ..., -0.00513682,\n",
      "         0.06937064, -0.09722905]], dtype=float32))\n",
      "(array([ 2.86259155e+02,  6.67164922e-02,  5.86190727e-03,  1.65319641e-03,\n",
      "        7.41002674e-04,  2.96698097e-04,  2.18495989e-04,  1.01186088e-04,\n",
      "        5.78552535e-05,  3.65645647e-05,  1.91261861e-05, -1.48065892e-05,\n",
      "        1.19989008e-05, -1.03248049e-05,  1.08822442e-05,  8.79865820e-06,\n",
      "        8.09061657e-06, -7.66301673e-06, -6.86884050e-06,  6.90142906e-06,\n",
      "       -5.55985343e-06,  5.23892095e-06,  4.01155694e-06,  3.41937039e-06,\n",
      "       -3.06811262e-06,  3.02157378e-06, -2.52461996e-06,  2.51893289e-06,\n",
      "        2.22619860e-06, -1.79265930e-06,  2.02835031e-06, -1.56276542e-06,\n",
      "        1.63409732e-06, -1.31022978e-06,  1.48227048e-06,  1.34092068e-06,\n",
      "        1.31253205e-06,  1.15611999e-06, -9.80994855e-07, -9.27981773e-07,\n",
      "        1.03224909e-06,  9.72483235e-07, -7.66989388e-07,  8.17057298e-07,\n",
      "       -5.96051621e-07,  7.85594921e-07,  7.10554957e-07,  6.49550771e-07,\n",
      "       -5.31266494e-07, -4.59291613e-07,  4.98649968e-07, -3.89413685e-07,\n",
      "        4.42302962e-07,  4.23791846e-07, -3.42470116e-07,  3.78578562e-07,\n",
      "       -3.17778699e-07, -2.59181178e-07, -2.33508501e-07,  3.26915426e-07,\n",
      "        2.90518983e-07,  2.85345180e-07,  3.13000214e-07,  2.30503119e-07,\n",
      "        2.08573141e-07,  1.90807640e-07,  1.77145154e-07, -1.57714481e-07,\n",
      "        1.55705564e-07,  1.34563223e-07, -1.34124051e-07, -1.20652516e-07,\n",
      "       -1.05262181e-07,  1.21803893e-07, -8.78999771e-08,  1.05778476e-07,\n",
      "        9.93253195e-08, -8.26619342e-08, -7.03799330e-08, -4.88690652e-08,\n",
      "        8.54590994e-08,  7.86533221e-08,  6.86805350e-08,  6.60133068e-08,\n",
      "        5.56263622e-08,  5.17223349e-08, -4.09256664e-08, -3.98094393e-08,\n",
      "        4.68623576e-08,  4.15260040e-08, -3.16968034e-08, -2.40920812e-08,\n",
      "       -2.85712876e-08, -2.32274875e-08,  3.55724197e-08,  3.05645251e-08,\n",
      "        2.98445215e-08, -1.52685864e-08,  2.32095552e-08, -1.26358692e-08,\n",
      "        2.13342428e-08,  1.96149621e-08, -7.97942157e-09, -5.68328984e-09,\n",
      "        1.48168589e-08,  1.28656596e-08, -3.41286222e-09,  1.11935980e-08,\n",
      "       -3.13890225e-09, -1.44130696e-09,  8.89486262e-09, -4.05946499e-10,\n",
      "        1.00685771e-09,  4.24296209e-10,  7.39733697e-09,  1.72826775e-09,\n",
      "        5.87359184e-09,  3.29848460e-09,  3.80327991e-09,  4.39680115e-09],\n",
      "      dtype=float32), array([[-0.05293943,  0.07131378,  0.10246476, ..., -0.02472556,\n",
      "         0.0091903 ,  0.00346353],\n",
      "       [-0.01871126, -0.1290508 , -0.02956137, ...,  0.01509331,\n",
      "        -0.0176791 , -0.02877341],\n",
      "       [ 0.03076538,  0.05020282, -0.03784088, ...,  0.0055161 ,\n",
      "         0.0060957 , -0.03005469],\n",
      "       ...,\n",
      "       [-0.04536654, -0.08974803, -0.03353786, ...,  0.00174538,\n",
      "        -0.03305554, -0.02724854],\n",
      "       [-0.12381058,  0.14224088, -0.05225946, ..., -0.00256362,\n",
      "         0.00738687, -0.00785957],\n",
      "       [ 0.00108647,  0.10352624,  0.04574892, ..., -0.05992989,\n",
      "        -0.05071887,  0.0847503 ]], dtype=float32))\n",
      "(array([ 2.88143463e+02,  3.89686413e-02,  3.92964296e-03,  1.70843815e-03,\n",
      "        4.01050958e-04,  1.60585769e-04,  1.09577508e-04,  3.17820814e-05,\n",
      "        2.18085606e-05, -1.44132027e-05,  1.20771474e-05,  1.07299247e-05,\n",
      "        1.01952792e-05,  8.23242772e-06,  8.00912130e-06, -6.81224856e-06,\n",
      "       -5.06052038e-06,  5.80061396e-06, -3.49319612e-06,  4.44289572e-06,\n",
      "        3.74070623e-06,  3.65119240e-06, -3.20903905e-06,  3.17699619e-06,\n",
      "       -2.48675542e-06, -2.40516374e-06,  2.60756337e-06,  2.38140410e-06,\n",
      "        2.15177943e-06,  1.86491400e-06,  1.54231668e-06, -1.64735707e-06,\n",
      "       -1.48339484e-06,  1.29894840e-06, -1.20552886e-06, -1.14365116e-06,\n",
      "       -1.04345543e-06,  1.21316077e-06,  1.13333795e-06,  9.68573431e-07,\n",
      "       -7.76024820e-07,  8.65933941e-07,  8.25956874e-07,  8.10769848e-07,\n",
      "       -6.11292990e-07,  5.84711529e-07,  5.40524752e-07,  5.09609606e-07,\n",
      "       -5.32760453e-07, -4.37522630e-07, -4.12739212e-07, -3.39357655e-07,\n",
      "       -3.03498979e-07,  3.88038359e-07,  3.30644497e-07,  3.33373123e-07,\n",
      "       -2.53408274e-07,  2.99622229e-07, -2.47692242e-07,  2.85977450e-07,\n",
      "        2.58254147e-07,  2.41794623e-07, -2.03187469e-07, -1.72668948e-07,\n",
      "       -1.59465230e-07,  1.99995696e-07,  1.84196537e-07,  1.64388709e-07,\n",
      "        1.48217495e-07, -1.22653276e-07,  1.18624371e-07, -1.09122560e-07,\n",
      "        1.06889722e-07, -9.52107158e-08,  8.84555149e-08, -8.61068301e-08,\n",
      "       -7.36906216e-08, -5.67360310e-08,  8.13643979e-08, -4.84964637e-08,\n",
      "        7.51986704e-08,  6.66143336e-08,  5.94595306e-08,  5.19591303e-08,\n",
      "        4.52739926e-08,  4.56169715e-08, -3.46084015e-08, -3.29272467e-08,\n",
      "        4.00337612e-08, -2.88120710e-08,  3.24313731e-08,  3.02394021e-08,\n",
      "        2.69048890e-08,  2.12779181e-08, -2.13501501e-08, -1.84603497e-08,\n",
      "       -1.66290857e-08, -1.39656988e-08, -1.30177140e-08,  1.85267925e-08,\n",
      "        1.66688512e-08,  1.48452592e-08,  1.32999149e-08,  1.14373675e-08,\n",
      "       -5.40938672e-09, -2.79470602e-09, -4.16288426e-09, -4.00617051e-09,\n",
      "        9.94459093e-09,  4.94764577e-11, -4.92557439e-10,  7.99303290e-09,\n",
      "        6.26675245e-09,  1.27671651e-09,  1.72040338e-09,  1.88844029e-09,\n",
      "        5.46357581e-09,  3.04516035e-09,  3.60272789e-09,  4.29824976e-09],\n",
      "      dtype=float32), array([[-0.0529484 ,  0.06807727,  0.12671676, ..., -0.01113963,\n",
      "        -0.02634175,  0.00369218],\n",
      "       [-0.01906979, -0.13017373, -0.05215847, ..., -0.06865205,\n",
      "        -0.05438829, -0.00285022],\n",
      "       [ 0.03041633,  0.05166231, -0.04631847, ..., -0.01725284,\n",
      "        -0.0340801 ,  0.01403669],\n",
      "       ...,\n",
      "       [-0.04560545, -0.09037147, -0.03464102, ...,  0.0212048 ,\n",
      "        -0.00284111, -0.01146463],\n",
      "       [-0.12435937,  0.14138061, -0.05352549, ...,  0.00782647,\n",
      "         0.0026021 , -0.00319502],\n",
      "       [ 0.00040118,  0.09862894,  0.02023363, ...,  0.25854805,\n",
      "        -0.20100312, -0.21792029]], dtype=float32))\n",
      "(array([ 2.92091431e+02,  4.56370622e-01,  5.56848161e-02,  1.85835231e-02,\n",
      "        1.14854313e-02,  1.75571570e-03,  1.26658357e-03,  6.92127680e-04,\n",
      "        3.26796842e-04,  3.06650385e-04,  1.17975891e-04,  1.09962741e-04,\n",
      "        9.41187755e-05,  5.54264989e-05,  3.86577958e-05,  3.12027150e-05,\n",
      "        1.90237879e-05,  1.20771738e-05, -1.00047855e-05,  1.02877020e-05,\n",
      "       -8.52297308e-06,  8.36047548e-06, -6.64893196e-06,  6.87657257e-06,\n",
      "        5.83311521e-06, -3.90745436e-06,  4.93093467e-06,  4.17230513e-06,\n",
      "        3.99443070e-06, -3.11595477e-06,  3.43495026e-06,  2.87125386e-06,\n",
      "       -1.99489068e-06,  2.13581234e-06,  1.98804719e-06, -1.75671710e-06,\n",
      "        1.79985648e-06,  1.69649081e-06, -1.40383565e-06, -1.35935443e-06,\n",
      "        1.28302042e-06, -1.12936470e-06, -1.02454851e-06,  1.07030121e-06,\n",
      "        1.04958690e-06,  9.20007778e-07,  8.02235547e-07, -8.57868258e-07,\n",
      "       -7.68957534e-07, -6.61996467e-07,  7.15076794e-07,  6.56856287e-07,\n",
      "        5.34014362e-07,  4.69512059e-07, -4.66221394e-07, -4.10725676e-07,\n",
      "       -3.91909623e-07,  3.83702456e-07, -3.03746020e-07, -2.96409638e-07,\n",
      "        3.61248965e-07,  3.41476209e-07,  2.99502517e-07,  2.52057191e-07,\n",
      "       -2.06584019e-07,  2.17751221e-07,  2.00823550e-07, -1.78598853e-07,\n",
      "        1.74316213e-07, -1.65752255e-07, -1.46101399e-07, -1.44824355e-07,\n",
      "       -1.23507903e-07,  1.63661980e-07,  1.46614070e-07,  1.40950434e-07,\n",
      "        1.19512876e-07,  1.12530799e-07, -9.32725044e-08, -8.31421474e-08,\n",
      "        9.40594802e-08,  8.91396610e-08, -6.61934720e-08, -5.97021028e-08,\n",
      "        6.73109852e-08,  6.20032381e-08, -4.76699995e-08,  5.69431933e-08,\n",
      "        5.16609582e-08, -3.91979356e-08,  4.37562555e-08, -3.43341569e-08,\n",
      "       -2.92020914e-08, -2.55436383e-08, -1.60991824e-08,  3.47818165e-08,\n",
      "        3.02858041e-08,  2.62572737e-08,  2.55301469e-08, -1.26155699e-08,\n",
      "       -1.03177298e-08,  1.96513117e-08,  1.72578289e-08, -5.78445203e-09,\n",
      "       -4.70217598e-09, -5.27719912e-09, -2.14483564e-09,  1.25891066e-08,\n",
      "        1.16670398e-08,  1.02733481e-10,  1.45090802e-08,  9.24060217e-10,\n",
      "        1.38912915e-09,  1.02669917e-08,  2.47766985e-09,  9.09061715e-09,\n",
      "        3.40224005e-09,  5.43543832e-09,  6.19485574e-09,  7.56555707e-09],\n",
      "      dtype=float32), array([[-0.05321061, -0.08571845,  0.01399635, ..., -0.02846665,\n",
      "        -0.00815543, -0.00999033],\n",
      "       [-0.01989208,  0.13071416,  0.06668327, ..., -0.03017403,\n",
      "         0.09062598,  0.01112382],\n",
      "       [ 0.02966111, -0.05104554,  0.04083424, ...,  0.02537663,\n",
      "         0.00402863, -0.01408754],\n",
      "       ...,\n",
      "       [-0.04563446,  0.07990461,  0.00050485, ..., -0.04579644,\n",
      "         0.03227315, -0.00087935],\n",
      "       [-0.12556142, -0.14237675,  0.07191187, ..., -0.01029264,\n",
      "         0.00713169, -0.00337597],\n",
      "       [-0.00087286, -0.09988944,  0.11227378, ...,  0.22524777,\n",
      "        -0.18346375, -0.13585308]], dtype=float32))\n",
      "(array([ 3.04931458e+02,  5.65737784e-02,  4.68359003e-03,  2.28979369e-03,\n",
      "        9.09673865e-04,  2.49727978e-04,  2.10259619e-04,  7.98084366e-05,\n",
      "        3.81374448e-05,  2.34396939e-05, -1.24202952e-05,  1.39182939e-05,\n",
      "       -9.07158756e-06,  1.13347915e-05,  1.06152438e-05,  1.00401339e-05,\n",
      "        8.70649001e-06, -6.31560306e-06,  6.60741216e-06, -5.16184082e-06,\n",
      "        5.70540897e-06,  4.71503563e-06,  4.34632784e-06, -3.50736605e-06,\n",
      "        3.46534080e-06, -3.10688165e-06, -2.62157027e-06,  3.28726787e-06,\n",
      "        2.99945600e-06,  2.52759742e-06,  2.10739859e-06, -1.79327503e-06,\n",
      "       -1.55065618e-06, -1.42268038e-06,  1.68817098e-06,  1.62179072e-06,\n",
      "        1.37460756e-06,  1.24974872e-06,  1.05665310e-06, -1.03148125e-06,\n",
      "       -9.69859911e-07, -9.50744379e-07,  9.03907164e-07, -7.68252278e-07,\n",
      "        8.14451596e-07,  7.18441584e-07,  6.66139954e-07, -5.65618052e-07,\n",
      "       -4.81091831e-07,  6.14029375e-07,  5.29509293e-07,  5.04991874e-07,\n",
      "        4.47634108e-07, -4.22035811e-07, -3.87375934e-07, -3.36699060e-07,\n",
      "        3.76947952e-07,  3.89792433e-07,  3.15869102e-07, -2.68538656e-07,\n",
      "       -2.30035468e-07,  2.78623787e-07,  2.71109315e-07,  2.58022880e-07,\n",
      "       -2.07324177e-07, -1.88277156e-07, -1.79793616e-07,  2.23356537e-07,\n",
      "        1.78359059e-07,  1.72704830e-07,  1.59593895e-07, -1.20975287e-07,\n",
      "       -1.14279615e-07,  1.33915236e-07,  1.18193981e-07, -8.51180104e-08,\n",
      "       -7.54640865e-08, -6.21465617e-08,  9.40211535e-08,  9.02020290e-08,\n",
      "        8.65590124e-08,  8.02992020e-08,  6.51056595e-08, -4.99949770e-08,\n",
      "       -4.50129605e-08,  5.38062466e-08, -3.77556830e-08, -3.59215591e-08,\n",
      "        4.69037928e-08,  4.31873310e-08,  4.43745272e-08, -2.45392844e-08,\n",
      "       -2.23403802e-08,  3.43309026e-08,  3.21042464e-08,  2.88304474e-08,\n",
      "        2.47807375e-08, -1.83422273e-08, -1.50267017e-08,  2.01544612e-08,\n",
      "        1.73715726e-08, -1.14922063e-08,  1.41997809e-08, -4.81743534e-09,\n",
      "       -7.54871454e-09, -7.33570316e-09,  1.12123422e-08, -3.22139448e-09,\n",
      "       -1.15366050e-09,  1.03522835e-08, -2.71609313e-09,  5.34525357e-09,\n",
      "        9.19947940e-09,  7.78777665e-09,  6.79435264e-09,  2.80137158e-09,\n",
      "        6.75444034e-10,  4.31265068e-09,  1.51330370e-09,  1.59756031e-09],\n",
      "      dtype=float32), array([[-0.0529992 ,  0.04764734, -0.09750519, ...,  0.0014859 ,\n",
      "         0.01500707,  0.00320589],\n",
      "       [-0.02056095, -0.13033842,  0.02736706, ...,  0.00418263,\n",
      "        -0.03931209, -0.07026323],\n",
      "       [ 0.03078893,  0.0564854 ,  0.00501131, ...,  0.05564369,\n",
      "        -0.06536801, -0.03678723],\n",
      "       ...,\n",
      "       [-0.04878892, -0.098085  ,  0.0995925 , ..., -0.02305912,\n",
      "         0.03069304,  0.0174159 ],\n",
      "       [-0.12913188,  0.12556584,  0.03362672, ..., -0.0047766 ,\n",
      "         0.01133386,  0.00985871],\n",
      "       [-0.00255035,  0.09319171, -0.04175153, ..., -0.04677417,\n",
      "        -0.23824657, -0.22313704]], dtype=float32))\n",
      "(array([ 3.04196594e+02,  1.65749669e-01,  1.22649679e-02,  4.79245558e-03,\n",
      "        1.85238454e-03,  1.15131121e-03,  9.80021432e-04,  5.34726889e-04,\n",
      "        1.62642842e-04,  6.62412494e-05,  4.44474244e-05,  2.72100006e-05,\n",
      "        2.11849765e-05,  1.73465578e-05,  1.67617600e-05, -1.43860207e-05,\n",
      "        9.18867318e-06,  8.42080590e-06, -6.36884852e-06,  7.52644110e-06,\n",
      "        7.10009044e-06, -4.98920508e-06,  5.38874838e-06,  4.71495059e-06,\n",
      "       -3.91243157e-06, -3.50599521e-06,  4.14143005e-06,  3.61536877e-06,\n",
      "        3.42861085e-06,  3.24889334e-06,  3.03327238e-06, -2.59398826e-06,\n",
      "       -2.23942493e-06,  2.46026070e-06,  2.22612266e-06, -1.84819908e-06,\n",
      "       -1.63008076e-06,  1.91336676e-06,  1.83780992e-06,  1.60336094e-06,\n",
      "       -1.19905349e-06,  1.21842311e-06,  1.11884117e-06,  1.08589450e-06,\n",
      "       -9.21342803e-07, -8.55799385e-07, -7.92745482e-07,  8.53541223e-07,\n",
      "        8.00422811e-07,  7.85603902e-07, -6.25181826e-07,  6.09281301e-07,\n",
      "       -5.70273016e-07, -5.06236972e-07,  5.69840154e-07,  5.22315133e-07,\n",
      "       -4.48319668e-07,  4.60549103e-07,  4.11969665e-07, -3.84459554e-07,\n",
      "        3.79535379e-07, -3.36076113e-07, -2.95993033e-07,  3.13675542e-07,\n",
      "        2.95776829e-07,  2.79880567e-07, -2.35078559e-07,  2.41839842e-07,\n",
      "        2.09241605e-07, -2.02343216e-07, -1.77640644e-07, -1.58720198e-07,\n",
      "       -1.41879667e-07,  1.70443130e-07, -1.14155760e-07,  1.41588146e-07,\n",
      "        1.32257938e-07,  1.26935717e-07,  1.16315348e-07, -9.21748722e-08,\n",
      "        1.05316055e-07, -8.04299560e-08,  9.49939292e-08, -7.42029584e-08,\n",
      "       -6.59769412e-08, -5.62874405e-08,  7.88567789e-08,  7.09167551e-08,\n",
      "        6.51655370e-08,  5.85394062e-08,  5.49852182e-08, -5.09636386e-08,\n",
      "       -4.40036949e-08, -3.43111424e-08,  4.86788387e-08,  4.57951757e-08,\n",
      "        4.02250109e-08,  3.52858969e-08,  3.28085648e-08, -2.34025279e-08,\n",
      "       -1.43735184e-08,  2.57071768e-08,  2.27408332e-08,  1.78917237e-08,\n",
      "        1.56501603e-08, -1.08269438e-08,  1.27313706e-08, -8.84549856e-09,\n",
      "        1.11408198e-08,  1.01210729e-08, -6.72509515e-09, -4.85537566e-09,\n",
      "       -3.54967677e-09,  5.59259838e-09, -1.81551285e-09, -2.86971419e-10,\n",
      "        3.62505803e-10,  4.13628376e-09,  3.26120264e-09,  1.28033073e-09],\n",
      "      dtype=float32), array([[-0.05443864,  0.06614476, -0.12717143, ...,  0.05808429,\n",
      "         0.00924052,  0.00259833],\n",
      "       [-0.02064942, -0.1431648 ,  0.02497423, ...,  0.01000541,\n",
      "         0.04416567, -0.02278907],\n",
      "       [ 0.03107529,  0.05412522,  0.00387347, ..., -0.00239027,\n",
      "         0.00527686,  0.06298066],\n",
      "       ...,\n",
      "       [-0.05049951, -0.09130046,  0.05889983, ..., -0.05343242,\n",
      "        -0.01366753, -0.03472953],\n",
      "       [-0.1280414 ,  0.13982919,  0.01955001, ...,  0.03588606,\n",
      "         0.00723135,  0.01206527],\n",
      "       [-0.00375158,  0.09586295, -0.09099533, ...,  0.17557265,\n",
      "        -0.14335029, -0.03652639]], dtype=float32))\n",
      "(array([ 3.06359711e+02,  1.01010948e-01,  1.36735691e-02,  9.56571288e-03,\n",
      "        6.86473446e-03,  1.20917556e-03,  7.40342657e-04,  3.43356980e-04,\n",
      "        2.79739907e-04,  1.23860504e-04,  5.59352156e-05,  2.83441859e-05,\n",
      "        1.89332713e-05,  1.39362310e-05,  1.16408219e-05, -9.79123706e-06,\n",
      "        1.00169291e-05, -7.45313582e-06,  8.07334163e-06, -6.38899337e-06,\n",
      "        6.62672483e-06,  5.97804910e-06,  5.82769599e-06, -4.70913437e-06,\n",
      "        4.93487642e-06, -4.12562213e-06, -3.35322216e-06,  3.77613014e-06,\n",
      "        3.38149971e-06,  2.89929380e-06, -2.23245684e-06, -2.01269040e-06,\n",
      "       -1.78217215e-06,  2.45636738e-06,  2.30724277e-06,  2.04214189e-06,\n",
      "        1.97103782e-06,  1.63859215e-06, -1.45265369e-06, -1.23235054e-06,\n",
      "        1.35580160e-06, -9.55015935e-07, -7.96074346e-07,  1.05619245e-06,\n",
      "        1.04147944e-06,  9.06445052e-07,  8.76440652e-07, -7.16392151e-07,\n",
      "       -6.07922686e-07,  6.58102181e-07,  6.08918810e-07,  5.95775759e-07,\n",
      "       -5.47790080e-07,  5.25446751e-07, -4.47161739e-07,  4.61244866e-07,\n",
      "       -3.68712506e-07,  3.92857686e-07, -3.09277766e-07,  3.72653489e-07,\n",
      "        3.59605536e-07,  3.07831499e-07, -2.52510148e-07, -2.40986310e-07,\n",
      "       -1.98736217e-07,  2.43686628e-07, -1.74637705e-07,  2.18577767e-07,\n",
      "        1.97456245e-07, -1.45324705e-07, -1.33722111e-07,  1.66512706e-07,\n",
      "        1.55820061e-07, -1.16741653e-07,  1.37148646e-07,  1.29654396e-07,\n",
      "       -1.00521291e-07,  1.13824960e-07, -8.05202944e-08,  1.02363991e-07,\n",
      "       -6.11106543e-08, -5.52600916e-08,  9.30763377e-08,  8.65737206e-08,\n",
      "        8.41364596e-08,  7.13660810e-08, -5.36666178e-08, -4.78711542e-08,\n",
      "        6.15092688e-08, -3.54790117e-08, -3.14300479e-08,  5.38305791e-08,\n",
      "        4.97944157e-08,  4.44243966e-08,  3.57419552e-08,  3.33480088e-08,\n",
      "       -1.87709777e-08,  2.86493602e-08,  2.50549430e-08, -1.47636658e-08,\n",
      "       -1.18289485e-08, -1.01834887e-08,  2.30686084e-08,  2.09143636e-08,\n",
      "       -1.39233620e-08, -4.50360593e-09,  1.69343597e-08,  1.29759314e-08,\n",
      "        1.60311338e-08, -1.88384286e-09, -5.55236024e-10,  1.05543787e-08,\n",
      "        4.58717148e-10,  3.84279097e-09,  1.94351846e-09,  5.06706099e-09,\n",
      "        1.25418331e-09,  9.18964638e-09,  7.43307593e-09,  6.81299772e-09],\n",
      "      dtype=float32), array([[-0.05492743,  0.03631024,  0.11900835, ...,  0.0003261 ,\n",
      "        -0.00808385, -0.0009999 ],\n",
      "       [-0.02020689, -0.1392771 , -0.05279599, ...,  0.08690631,\n",
      "         0.00714837,  0.03039663],\n",
      "       [ 0.03145484,  0.05783185, -0.02924808, ..., -0.04233829,\n",
      "         0.02556736, -0.01591207],\n",
      "       ...,\n",
      "       [-0.05109717, -0.09728116,  0.20864706, ..., -0.03068339,\n",
      "         0.01437048,  0.0443493 ],\n",
      "       [-0.12865883,  0.10874116, -0.161302  , ...,  0.00658006,\n",
      "        -0.00252636, -0.00273273],\n",
      "       [-0.00288528,  0.09381476,  0.02544811, ..., -0.08332942,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.00750265,  0.02388577]], dtype=float32))\n",
      "(array([ 2.82992920e+02,  2.61681288e-01,  1.61752000e-01,  8.12885687e-02,\n",
      "        1.02627873e-02,  6.48820307e-03,  3.11277830e-03,  1.88658899e-03,\n",
      "        1.05195725e-03,  6.96086150e-04,  5.69514639e-04,  2.89243442e-04,\n",
      "        1.72839587e-04,  1.45490689e-04,  1.16208212e-04,  7.09893357e-05,\n",
      "        5.60439657e-05,  4.15800059e-05,  2.87321018e-05,  2.24167925e-05,\n",
      "        1.56852075e-05, -1.25529723e-05,  1.22617448e-05,  1.16535793e-05,\n",
      "        8.64924732e-06,  7.65449204e-06, -5.60897206e-06, -4.85192322e-06,\n",
      "        6.15490080e-06,  5.68096038e-06,  5.44692421e-06, -4.43330964e-06,\n",
      "        4.68217240e-06, -3.45005947e-06,  3.67205894e-06,  3.33435082e-06,\n",
      "        3.05627941e-06,  2.84491398e-06, -2.59890362e-06,  2.35457333e-06,\n",
      "        2.07492508e-06, -1.67777580e-06, -1.65144559e-06, -1.24856217e-06,\n",
      "        1.62458309e-06,  1.29369835e-06, -9.63693196e-07,  1.24301550e-06,\n",
      "        1.11840154e-06,  1.15298974e-06, -8.61807791e-07, -8.19767990e-07,\n",
      "       -6.50130005e-07,  9.67238975e-07,  8.66834966e-07,  7.55548513e-07,\n",
      "        7.03071805e-07, -6.00696922e-07,  5.82268740e-07, -5.16320654e-07,\n",
      "        5.44812224e-07, -4.75023199e-07,  4.69288381e-07,  4.83517340e-07,\n",
      "        4.19126650e-07, -3.64940007e-07,  4.00001227e-07,  3.58904117e-07,\n",
      "       -2.86804294e-07, -2.52680991e-07, -2.36493861e-07,  3.07275627e-07,\n",
      "        2.66193581e-07,  2.41369690e-07,  2.27109794e-07, -1.74575447e-07,\n",
      "       -1.62201687e-07,  1.91857765e-07,  1.73044711e-07, -1.15964120e-07,\n",
      "       -1.07832825e-07, -1.01560481e-07, -8.87695535e-08,  1.46860756e-07,\n",
      "        1.35181608e-07,  1.28081695e-07,  1.12406369e-07,  1.02288162e-07,\n",
      "        8.29986391e-08, -6.83424801e-08, -6.18370279e-08, -5.50473729e-08,\n",
      "       -4.17693258e-08, -5.71669041e-08,  7.05156893e-08,  6.70835192e-08,\n",
      "        5.53417934e-08,  5.20358761e-08, -3.24676748e-08,  4.51711237e-08,\n",
      "        3.89131287e-08, -2.03473967e-08,  3.07998285e-08,  3.21845910e-08,\n",
      "       -1.62213354e-08, -1.00088133e-08, -1.12467831e-08, -1.39731995e-08,\n",
      "        2.83501063e-08, -6.47899467e-09,  2.03083772e-08,  2.38500455e-08,\n",
      "        9.23675536e-09,  1.56649769e-08,  7.02025948e-09,  5.23808241e-09,\n",
      "       -1.04937492e-09, -3.25328708e-10,  2.40253040e-09,  9.56433710e-10],\n",
      "      dtype=float32), array([[-6.2938772e-02, -1.0521126e-01, -2.1650890e-01, ...,\n",
      "        -3.2666977e-02, -2.8331449e-02,  1.8632472e-02],\n",
      "       [-2.0995062e-02,  1.4881703e-01,  3.2817987e-03, ...,\n",
      "        -2.2426227e-02, -8.9902379e-02,  6.7113981e-02],\n",
      "       [ 5.0676607e-02, -8.1103198e-02,  8.5154675e-02, ...,\n",
      "         9.2276046e-03, -2.2624414e-02, -3.9208889e-02],\n",
      "       ...,\n",
      "       [-8.0522038e-02,  1.1705586e-01, -2.5247255e-01, ...,\n",
      "         1.4228700e-02,  1.0359653e-02, -2.8522076e-02],\n",
      "       [-1.2301964e-01, -9.9363200e-02,  1.1636456e-01, ...,\n",
      "         9.0686306e-03, -1.3208506e-02,  2.4488799e-02],\n",
      "       [ 1.0665986e-04, -9.3885317e-02,  2.7355853e-02, ...,\n",
      "        -3.1725429e-02,  1.8133582e-01,  1.3967037e-02]], dtype=float32))\n",
      "(array([ 2.78723175e+02,  2.76284695e+00,  9.67515588e-01,  4.00854439e-01,\n",
      "        1.03511997e-01,  6.85795844e-02,  2.81234942e-02,  2.20506005e-02,\n",
      "        1.88684836e-02,  1.66544728e-02,  1.42901596e-02,  1.06292032e-02,\n",
      "        5.91080729e-03,  4.57138428e-03,  3.40145850e-03,  3.01776477e-03,\n",
      "        1.93374429e-03,  1.69074233e-03,  1.60696881e-03,  1.21804932e-03,\n",
      "        1.15780253e-03,  7.30379950e-04,  5.48607553e-04,  4.70400817e-04,\n",
      "        3.91963928e-04,  3.56902601e-04,  3.32767231e-04,  2.74862192e-04,\n",
      "        2.18861896e-04,  1.75750989e-04,  1.55445028e-04,  1.20668010e-04,\n",
      "        1.16064584e-04,  1.04174185e-04,  8.10505007e-05,  7.57283487e-05,\n",
      "        6.25379034e-05,  5.97080252e-05,  5.24582792e-05,  4.49459403e-05,\n",
      "        3.39872277e-05,  2.69851753e-05,  2.27548353e-05,  2.09805930e-05,\n",
      "        1.60039381e-05,  1.33312606e-05, -1.07093465e-05,  1.15807916e-05,\n",
      "        7.75080025e-06,  6.86352541e-06,  6.33769650e-06, -4.71005296e-06,\n",
      "       -4.04848879e-06,  3.17784588e-06, -2.76989340e-06, -2.52118684e-06,\n",
      "        2.55584632e-06,  2.21227538e-06, -1.84721023e-06,  1.79609378e-06,\n",
      "        1.64504820e-06, -1.40963994e-06, -1.24966027e-06,  1.08501592e-06,\n",
      "       -9.38233029e-07,  8.62899753e-07, -8.16531497e-07,  7.47586739e-07,\n",
      "        6.17614319e-07, -6.49494325e-07, -5.80764606e-07, -4.73631360e-07,\n",
      "        5.24493657e-07,  4.87135992e-07,  4.30527848e-07, -3.39026514e-07,\n",
      "       -3.06547804e-07,  3.47913470e-07,  3.35553523e-07,  2.93433970e-07,\n",
      "        2.48614469e-07, -2.40450532e-07, -2.34989798e-07,  2.15995058e-07,\n",
      "       -2.02402646e-07,  1.66488789e-07,  1.54366418e-07, -1.50161881e-07,\n",
      "       -1.24796983e-07, -1.09799686e-07, -8.95070116e-08,  9.98287035e-08,\n",
      "        8.88710190e-08,  8.76327846e-08, -7.57943184e-08,  7.20685875e-08,\n",
      "        6.15473184e-08, -6.39600728e-08, -6.05833677e-08, -5.13472962e-08,\n",
      "       -3.59969512e-08, -4.30244818e-08,  5.08064204e-08,  4.22412008e-08,\n",
      "        3.53155905e-08,  2.95474720e-08, -2.96340730e-08,  2.52988226e-08,\n",
      "        1.48947450e-08,  1.18707506e-08,  8.83778561e-09, -1.53287818e-08,\n",
      "       -1.36059288e-08, -1.15867573e-08, -6.41330988e-09, -4.26566960e-09,\n",
      "       -2.39089237e-09, -7.62678087e-10,  3.68307829e-09,  2.01764205e-09],\n",
      "      dtype=float32), array([[ 0.04653717,  0.10655732,  0.06607877, ..., -0.03990176,\n",
      "         0.00575723,  0.0012657 ],\n",
      "       [ 0.03215466, -0.07855772, -0.14889804, ..., -0.01631341,\n",
      "        -0.10468942,  0.0510456 ],\n",
      "       [-0.01789116, -0.12719603,  0.10302608, ...,  0.01033613,\n",
      "        -0.03792933,  0.0135182 ],\n",
      "       ...,\n",
      "       [ 0.0212842 ,  0.27884924, -0.10788516, ..., -0.04276603,\n",
      "        -0.0290523 , -0.00687686],\n",
      "       [ 0.13680412, -0.07041338,  0.13611005, ...,  0.02042449,\n",
      "        -0.01300794,  0.0106156 ],\n",
      "       [ 0.01925097, -0.12231853,  0.11996111, ..., -0.08186086,\n",
      "        -0.02255408,  0.02855816]], dtype=float32))\n",
      "(array([ 2.72045807e+02,  1.38558924e+00,  4.99403149e-01,  1.46377847e-01,\n",
      "        8.49677548e-02,  5.32215647e-02,  2.93315407e-02,  1.75986346e-02,\n",
      "        1.62552446e-02,  1.01244776e-02,  8.26763548e-03,  4.88729961e-03,\n",
      "        4.11249883e-03,  3.66845564e-03,  2.05107965e-03,  1.76263379e-03,\n",
      "        1.62076810e-03,  1.32670067e-03,  7.79837661e-04,  7.25696911e-04,\n",
      "        6.25779387e-04,  5.44626615e-04,  4.40503616e-04,  4.24118334e-04,\n",
      "        2.73601850e-04,  2.28378296e-04,  2.11320788e-04,  1.79823124e-04,\n",
      "        1.53073648e-04,  1.12281443e-04,  9.59540412e-05,  8.79937579e-05,\n",
      "        5.90861055e-05,  5.59833097e-05,  4.69932493e-05,  4.12235349e-05,\n",
      "        3.38277350e-05,  3.28620372e-05,  2.59972185e-05,  2.12100986e-05,\n",
      "        1.72248401e-05,  1.59508090e-05,  1.13245915e-05,  9.74937211e-06,\n",
      "        8.44797614e-06,  7.24235861e-06, -4.70651412e-06,  5.47143054e-06,\n",
      "        5.19677724e-06,  4.89263402e-06, -3.76163825e-06, -3.08843960e-06,\n",
      "        3.38753966e-06,  2.96778830e-06, -2.31103036e-06, -1.82763370e-06,\n",
      "        2.29260081e-06,  2.11081397e-06,  2.04044932e-06,  1.75023104e-06,\n",
      "        1.57223747e-06, -1.40125462e-06, -1.14302952e-06,  9.95517098e-07,\n",
      "       -1.07751896e-06, -9.20761181e-07, -9.39351366e-07, -7.77815160e-07,\n",
      "       -7.08752395e-07,  8.49840490e-07,  7.65355992e-07,  6.83735152e-07,\n",
      "        6.18717934e-07, -4.77628248e-07, -4.40222948e-07,  5.81441498e-07,\n",
      "        4.57914780e-07,  4.33974520e-07, -3.69899908e-07, -3.33970576e-07,\n",
      "        3.24023205e-07,  3.03052360e-07, -2.79535300e-07,  2.51658491e-07,\n",
      "       -2.30673095e-07,  2.09997424e-07,  1.78649714e-07, -2.02293279e-07,\n",
      "       -1.68086174e-07, -1.55348630e-07,  1.58264740e-07,  1.46775662e-07,\n",
      "        1.25461014e-07, -1.19058072e-07, -1.13019347e-07,  9.95394913e-08,\n",
      "        9.43057756e-08, -7.14356005e-08, -9.17592757e-08, -6.23682084e-08,\n",
      "        6.10538748e-08,  5.41367484e-08, -5.04131918e-08, -4.35145040e-08,\n",
      "       -2.97509342e-08,  3.85201773e-08, -2.18252492e-08,  2.89782136e-08,\n",
      "       -1.42945948e-08,  2.18245777e-08,  2.00960546e-08, -1.13206973e-08,\n",
      "       -7.83813636e-09,  1.13182441e-08,  7.18348270e-09,  6.19656459e-09,\n",
      "        3.98986844e-09, -2.86183188e-09, -6.84794887e-10,  4.74841997e-12],\n",
      "      dtype=float32), array([[ 3.33786197e-02, -5.78626618e-02,  9.03668255e-02, ...,\n",
      "         4.13152017e-02, -1.09587647e-02, -4.66803962e-04],\n",
      "       [ 4.07093614e-02,  1.10190604e-02, -1.45259172e-01, ...,\n",
      "         1.82750951e-02,  2.75929999e-02, -5.32009713e-02],\n",
      "       [-1.03552820e-05,  6.94353431e-02,  9.17450711e-02, ...,\n",
      "        -2.12398842e-02,  3.02295480e-02,  4.58867326e-02],\n",
      "       ...,\n",
      "       [-1.66445058e-02, -1.45899564e-01, -2.48597991e-02, ...,\n",
      "         1.17561415e-01,  1.42668411e-02, -3.51429470e-02],\n",
      "       [ 1.53623879e-01,  4.97095138e-02,  1.74231976e-01, ...,\n",
      "        -1.32564025e-03, -9.22562461e-03,  2.34207371e-03],\n",
      "       [ 3.82031575e-02,  9.50531214e-02,  8.31767917e-02, ...,\n",
      "         2.58369874e-02,  5.85623644e-02, -9.08263028e-03]], dtype=float32))\n",
      "(array([ 3.1149951e+02,  2.2162161e+00,  1.6032536e+00,  2.4511059e-01,\n",
      "        1.5472202e-01,  8.1168987e-02,  5.6802906e-02,  3.4056693e-02,\n",
      "        2.0228822e-02,  1.6356751e-02,  1.1429475e-02,  9.5084952e-03,\n",
      "        6.3036289e-03,  5.6508854e-03,  3.4084267e-03,  2.9056319e-03,\n",
      "        2.4382947e-03,  1.8367497e-03,  1.6673628e-03,  1.5638954e-03,\n",
      "        1.1247185e-03,  7.7956688e-04,  6.9115032e-04,  6.1322021e-04,\n",
      "        5.3981581e-04,  5.1351206e-04,  3.9982115e-04,  3.7649463e-04,\n",
      "        3.0658534e-04,  2.4855178e-04,  2.1279238e-04,  1.9103843e-04,\n",
      "        1.6485687e-04,  1.3542363e-04,  1.2674186e-04,  1.0682523e-04,\n",
      "        9.6490468e-05,  7.4631120e-05,  6.5934721e-05,  6.4045715e-05,\n",
      "        4.5681492e-05,  4.0887127e-05,  3.3657907e-05,  2.8036769e-05,\n",
      "        1.8622357e-05,  1.7435352e-05,  1.4667865e-05,  1.1473777e-05,\n",
      "        9.3986810e-06, -7.5180888e-06,  7.1539384e-06,  6.2332447e-06,\n",
      "       -4.3819864e-06,  4.3771652e-06, -3.3600111e-06,  3.2808648e-06,\n",
      "       -2.6018668e-06, -2.4763515e-06,  2.2421802e-06, -1.9022245e-06,\n",
      "        1.8817091e-06,  1.7644435e-06, -1.7457653e-06,  1.6043216e-06,\n",
      "        1.4600090e-06, -1.4672993e-06, -1.3927389e-06, -1.2120749e-06,\n",
      "       -1.1169298e-06,  1.2231658e-06,  1.0606376e-06,  1.0815315e-06,\n",
      "       -9.1005501e-07,  8.3820356e-07, -7.1949438e-07, -6.3457219e-07,\n",
      "        7.2126994e-07,  6.6022147e-07,  5.6976882e-07, -4.2211093e-07,\n",
      "        4.2197507e-07,  4.0644144e-07,  3.7034746e-07,  3.2776089e-07,\n",
      "       -3.9295978e-07, -3.5886771e-07, -3.0303016e-07, -2.6342980e-07,\n",
      "       -2.4736434e-07,  2.3331795e-07, -2.1686340e-07, -1.8038273e-07,\n",
      "        1.9706462e-07,  1.7354674e-07, -1.4835399e-07, -1.2818803e-07,\n",
      "        1.4420783e-07, -1.0222882e-07, -6.8245043e-08,  1.0106517e-07,\n",
      "        9.2399361e-08,  8.0840508e-08, -6.4262068e-08, -4.6171010e-08,\n",
      "        6.8606113e-08,  6.4251239e-08,  4.2902776e-08,  3.9252761e-08,\n",
      "       -3.3543820e-08, -3.0621738e-08,  3.0059010e-08, -2.8706577e-08,\n",
      "       -2.3605711e-08,  2.2591347e-08, -1.0344047e-08, -2.7909468e-09,\n",
      "       -6.4777839e-10,  5.6173466e-09,  8.1187510e-09,  1.4092982e-08],\n",
      "      dtype=float32), array([[ 0.03723836, -0.11440567, -0.03867613, ..., -0.06136718,\n",
      "        -0.01733635,  0.00932561],\n",
      "       [ 0.04276131,  0.13618436, -0.11164484, ..., -0.00477735,\n",
      "        -0.02959156, -0.05712757],\n",
      "       [ 0.00898336, -0.05066658,  0.07301053, ...,  0.02251434,\n",
      "        -0.1126532 ,  0.02080246],\n",
      "       ...,\n",
      "       [-0.03073769, -0.04577637,  0.01471543, ...,  0.05400779,\n",
      "        -0.02645525, -0.02372059],\n",
      "       [ 0.17109151, -0.1208849 ,  0.02853668, ...,  0.01123804,\n",
      "         0.01331095,  0.01728984],\n",
      "       [ 0.0516364 , -0.03400221,  0.06507672, ..., -0.02473986,\n",
      "        -0.01710874, -0.031204  ]], dtype=float32))\n",
      "(array([ 3.42037537e+02,  9.11745489e-01,  8.37976694e-01,  5.29318571e-01,\n",
      "        1.00084476e-01,  8.10163617e-02,  5.33068255e-02,  3.86695452e-02,\n",
      "        2.01793648e-02,  1.51218921e-02,  1.17008099e-02,  8.21294822e-03,\n",
      "        6.83098100e-03,  5.00467652e-03,  4.21442138e-03,  3.10722995e-03,\n",
      "        2.62962212e-03,  2.44981935e-03,  1.92143570e-03,  1.51088578e-03,\n",
      "        1.36118790e-03,  1.06300588e-03,  9.49552690e-04,  7.88349600e-04,\n",
      "        7.35034526e-04,  6.14484423e-04,  5.59870270e-04,  4.15562128e-04,\n",
      "        4.04826511e-04,  3.76461074e-04,  3.01820255e-04,  2.51518708e-04,\n",
      "        2.09306920e-04,  1.71769658e-04,  1.56676106e-04,  1.39802258e-04,\n",
      "        1.19474360e-04,  9.79711767e-05,  8.65757320e-05,  6.72474052e-05,\n",
      "        5.50568802e-05,  5.33611892e-05,  4.66525053e-05,  3.93485061e-05,\n",
      "        3.59727455e-05,  3.26482368e-05,  2.78467596e-05,  2.25011445e-05,\n",
      "        1.95518696e-05,  1.17092395e-05,  8.40920075e-06, -6.29108035e-06,\n",
      "        4.72853890e-06, -3.78549771e-06,  3.60280796e-06, -3.06103584e-06,\n",
      "        3.11313443e-06, -2.47178536e-06, -2.12089913e-06,  2.51191773e-06,\n",
      "        2.13297744e-06,  1.96507608e-06, -1.83038401e-06, -1.50154631e-06,\n",
      "        1.53599456e-06,  1.33057688e-06, -1.28595752e-06,  1.04635990e-06,\n",
      "       -1.12414739e-06, -1.05637116e-06, -9.05044828e-07,  9.40638927e-07,\n",
      "        8.81028143e-07,  8.23748337e-07,  7.49601668e-07, -6.96293966e-07,\n",
      "        6.73113220e-07, -6.06069136e-07, -5.38555469e-07,  5.32592423e-07,\n",
      "        4.52431948e-07,  3.99443564e-07, -4.43150981e-07,  3.20945134e-07,\n",
      "       -3.87602114e-07, -3.48164860e-07, -3.07373625e-07,  2.70348210e-07,\n",
      "        2.18888573e-07, -2.57186429e-07, -2.42358169e-07, -2.08370153e-07,\n",
      "        1.84635084e-07,  1.49417104e-07,  1.32032397e-07, -1.62996656e-07,\n",
      "       -1.37563646e-07, -1.30970079e-07,  1.00317514e-07, -9.58763522e-08,\n",
      "       -7.77060976e-08,  8.00654050e-08,  7.45525099e-08,  5.41874599e-08,\n",
      "       -6.63460114e-08, -5.13567784e-08, -4.26020037e-08,  3.30384111e-08,\n",
      "       -2.91537798e-08,  2.65300653e-08,  1.85501090e-08, -2.35893225e-08,\n",
      "        1.46645478e-08,  8.74475248e-09, -1.94753085e-08, -1.44719294e-08,\n",
      "        2.57037214e-09, -3.60032615e-10, -4.98572783e-09, -3.08833670e-09],\n",
      "      dtype=float32), array([[ 0.04467259,  0.04441071,  0.10079846, ...,  0.02109869,\n",
      "         0.01813283,  0.01082714],\n",
      "       [ 0.03980538, -0.14019406, -0.09452795, ...,  0.03866133,\n",
      "         0.05771507, -0.02616932],\n",
      "       [ 0.00583834,  0.10850757,  0.01851629, ..., -0.07206623,\n",
      "         0.30581653,  0.10059484],\n",
      "       ...,\n",
      "       [-0.02053064, -0.02181281,  0.06530638, ...,  0.03180527,\n",
      "         0.06096583, -0.01946759],\n",
      "       [ 0.16790067,  0.11994539,  0.06936216, ...,  0.00290907,\n",
      "        -0.00675544, -0.00180775],\n",
      "       [ 0.04870208,  0.11568528,  0.0066094 , ..., -0.00753778,\n",
      "        -0.00653631,  0.06872834]], dtype=float32))\n",
      "(array([ 3.79605225e+02,  2.48206568e+00,  1.54357946e+00,  8.52696359e-01,\n",
      "        2.13061661e-01,  1.63880914e-01,  1.16239354e-01,  4.75406758e-02,\n",
      "        3.82237770e-02,  3.20753120e-02,  2.41360441e-02,  2.13551540e-02,\n",
      "        1.60439294e-02,  1.28512932e-02,  8.59483052e-03,  7.54320342e-03,\n",
      "        5.97912259e-03,  4.48258454e-03,  3.74189089e-03,  3.52333765e-03,\n",
      "        2.89198593e-03,  2.58037844e-03,  2.03885138e-03,  1.64970418e-03,\n",
      "        1.57152989e-03,  1.21218606e-03,  1.10120198e-03,  8.35178129e-04,\n",
      "        8.01748189e-04,  7.54767098e-04,  6.48887828e-04,  6.27059373e-04,\n",
      "        4.56260343e-04,  4.10748500e-04,  3.16843973e-04,  2.94766680e-04,\n",
      "        2.82526365e-04,  2.59728258e-04,  2.13535983e-04,  2.07976598e-04,\n",
      "        1.79416325e-04,  1.65587757e-04,  1.19573771e-04,  1.02431251e-04,\n",
      "        8.60197761e-05,  7.81684139e-05,  5.06665165e-05,  4.35584079e-05,\n",
      "        4.18246345e-05,  2.81394823e-05,  1.02464719e-05, -8.38379765e-06,\n",
      "       -8.05636955e-06, -5.47330501e-06, -4.09942731e-06,  4.16944158e-06,\n",
      "       -3.25917881e-06,  3.35742584e-06,  3.08421227e-06,  2.61931518e-06,\n",
      "       -2.45208957e-06,  2.07307880e-06,  1.91377376e-06, -1.90637707e-06,\n",
      "       -1.64185553e-06,  1.61192975e-06, -1.38175858e-06, -1.27314729e-06,\n",
      "        1.29125272e-06,  1.18732044e-06, -1.02549745e-06, -9.10666131e-07,\n",
      "        9.17965565e-07,  9.01206818e-07,  8.40225255e-07, -6.36528398e-07,\n",
      "        5.60244018e-07, -5.95005872e-07, -5.48391938e-07,  4.84621467e-07,\n",
      "       -4.46803170e-07, -4.63347504e-07,  3.80613983e-07,  3.52695508e-07,\n",
      "       -3.33885367e-07,  3.11364431e-07, -2.81299378e-07, -2.49597804e-07,\n",
      "        2.44219024e-07,  2.22968083e-07,  1.69330264e-07, -2.00066978e-07,\n",
      "       -1.82426973e-07, -1.69108731e-07,  1.44452855e-07,  1.21377354e-07,\n",
      "        9.08927689e-08, -9.95463054e-08, -9.41215106e-08,  7.70459323e-08,\n",
      "       -8.49578683e-08, -6.59977033e-08,  5.29852286e-08, -5.07985725e-08,\n",
      "        4.10677927e-08,  3.35297692e-08,  2.97096641e-08, -3.97935480e-08,\n",
      "       -3.22583844e-08, -2.77411676e-08, -1.90710310e-08,  1.98326564e-08,\n",
      "        1.44598120e-08, -1.08941247e-08, -8.01058508e-09, -5.21134558e-09,\n",
      "       -6.92373270e-10,  8.92939500e-09,  4.52252946e-09,  6.07793638e-09],\n",
      "      dtype=float32), array([[ 0.04721691,  0.0925314 , -0.08793605, ..., -0.00917299,\n",
      "        -0.02139469,  0.01425077],\n",
      "       [ 0.0411175 , -0.09191427,  0.09121444, ..., -0.03704993,\n",
      "        -0.00278451,  0.00540002],\n",
      "       [-0.0008662 , -0.02044464, -0.08414201, ..., -0.08552666,\n",
      "         0.1673563 ,  0.013225  ],\n",
      "       ...,\n",
      "       [-0.01639612,  0.09586497,  0.13774751, ..., -0.06822833,\n",
      "         0.02534187, -0.00809824],\n",
      "       [ 0.16490416,  0.0510024 , -0.17367208, ..., -0.00724027,\n",
      "         0.0018528 , -0.00597808],\n",
      "       [ 0.03675301, -0.01862959, -0.15308566, ...,  0.01554366,\n",
      "         0.04773406, -0.07577533]], dtype=float32))\n",
      "(array([ 3.0930151e+02,  5.6120291e+00,  1.9859792e+00,  1.1508921e+00,\n",
      "        5.8185482e-01,  2.2055776e-01,  1.2379866e-01,  5.7943549e-02,\n",
      "        4.4873271e-02,  3.3407189e-02,  2.5166547e-02,  1.4588742e-02,\n",
      "        1.5185769e-02,  9.5306896e-03,  8.5736755e-03,  7.3391320e-03,\n",
      "        7.0617232e-03,  4.8189051e-03,  4.4554016e-03,  3.3615800e-03,\n",
      "        3.1754384e-03,  2.6731337e-03,  2.0462864e-03,  1.8619561e-03,\n",
      "        1.6897131e-03,  1.4970961e-03,  1.2068088e-03,  1.0507724e-03,\n",
      "        9.0515334e-04,  7.1618438e-04,  6.3698681e-04,  5.8519887e-04,\n",
      "        4.2379490e-04,  3.7540239e-04,  3.2310741e-04,  2.5101920e-04,\n",
      "        2.3173531e-04,  1.8992838e-04,  1.5356895e-04,  1.2265117e-04,\n",
      "        9.6015414e-05,  8.3493556e-05,  7.7026292e-05,  5.9883878e-05,\n",
      "        4.4232704e-05,  3.5110574e-05,  2.3426441e-05,  1.7795048e-05,\n",
      "        1.5524265e-05,  1.0421449e-05, -6.4209025e-06, -5.1767111e-06,\n",
      "       -4.7537105e-06,  5.2046571e-06,  4.6209007e-06,  4.2213846e-06,\n",
      "       -4.1866756e-06,  3.4971442e-06,  2.9098655e-06,  2.0710706e-06,\n",
      "       -2.0868374e-06, -1.9306767e-06, -1.6715883e-06,  1.3707686e-06,\n",
      "        1.2800125e-06,  1.1218026e-06, -1.2431647e-06, -1.1561879e-06,\n",
      "       -1.0858678e-06,  9.0820396e-07, -8.6988905e-07, -7.9852049e-07,\n",
      "       -7.1403502e-07,  6.9546786e-07,  6.7542391e-07,  5.9032379e-07,\n",
      "       -6.1906269e-07, -5.8041019e-07,  5.0123555e-07,  4.6143137e-07,\n",
      "       -4.8622940e-07, -4.6657021e-07,  3.8708319e-07, -3.7898258e-07,\n",
      "       -3.2126070e-07, -3.3039032e-07, -2.7219403e-07,  3.0683771e-07,\n",
      "        3.2195638e-07,  2.1496460e-07, -1.9042466e-07,  2.0435189e-07,\n",
      "        1.9494016e-07,  1.7289605e-07, -1.6776441e-07, -1.4213867e-07,\n",
      "        1.2560866e-07, -1.2867271e-07, -1.2242261e-07,  1.0628957e-07,\n",
      "       -9.0676288e-08,  8.3526544e-08, -6.9315703e-08,  6.4950363e-08,\n",
      "        5.6028291e-08,  4.9276206e-08, -4.4904411e-08, -4.1484054e-08,\n",
      "        3.9839662e-08, -3.1981553e-08, -1.8403753e-08, -1.5889867e-08,\n",
      "       -9.8204858e-09, -4.2490083e-09, -2.1151574e-09,  2.9683196e-09,\n",
      "        6.5270229e-09,  1.3414176e-08,  1.0203965e-08,  1.1191733e-08],\n",
      "      dtype=float32), array([[-4.90128957e-02,  2.33011823e-02, -1.49912357e-01, ...,\n",
      "        -3.15574370e-02,  3.75397280e-02, -3.71931568e-02],\n",
      "       [-4.03195322e-02, -2.68096142e-02,  5.68211861e-02, ...,\n",
      "        -8.26158375e-02,  1.32050775e-02, -3.73245329e-02],\n",
      "       [ 2.44803196e-05, -9.68801975e-02,  4.25321050e-02, ...,\n",
      "        -1.47529438e-01,  2.02430412e-01, -1.56253614e-02],\n",
      "       ...,\n",
      "       [ 1.76472645e-02,  1.83014795e-01, -1.11761652e-01, ...,\n",
      "        -6.66725859e-02,  3.34938690e-02,  6.67813001e-03],\n",
      "       [-1.63807213e-01, -1.79816067e-01, -6.53068349e-02, ...,\n",
      "        -1.70906913e-02,  1.78990066e-02, -4.18161647e-03],\n",
      "       [-3.98344174e-02, -1.45836234e-01,  1.51834004e-02, ...,\n",
      "         2.25840099e-02, -1.36044379e-02,  4.75797579e-02]], dtype=float32))\n",
      "(array([ 3.07351288e+02,  4.66822237e-01,  3.47301841e-01,  2.14833602e-01,\n",
      "        1.09219998e-01,  4.32667285e-02,  2.62538195e-02,  1.55637739e-02,\n",
      "        1.36969667e-02,  1.17399376e-02,  1.00963004e-02,  6.78075012e-03,\n",
      "        6.23074081e-03,  3.33397160e-03,  2.36034160e-03,  1.75594329e-03,\n",
      "        1.38938613e-03,  1.28111441e-03,  8.32005113e-04,  7.25633290e-04,\n",
      "        6.76860043e-04,  5.93236706e-04,  5.26117277e-04,  4.17760137e-04,\n",
      "        3.40876664e-04,  2.74435210e-04,  2.41991598e-04,  2.28637131e-04,\n",
      "        1.87553203e-04,  1.45695696e-04,  1.28917745e-04,  1.15160714e-04,\n",
      "        9.65568834e-05,  9.20147286e-05,  8.23611263e-05,  6.52045710e-05,\n",
      "        5.08262892e-05,  4.88618753e-05,  4.35024049e-05,  3.67881839e-05,\n",
      "        2.86189970e-05,  2.44862294e-05,  2.26913999e-05,  1.86653924e-05,\n",
      "        1.47129495e-05,  1.23791442e-05,  1.10178489e-05,  1.06933203e-05,\n",
      "       -7.77636160e-06, -6.82928658e-06,  8.70730310e-06,  6.74041667e-06,\n",
      "        5.98303632e-06,  5.62162768e-06, -4.53064558e-06,  4.85875807e-06,\n",
      "       -3.24893381e-06,  2.99450289e-06,  2.83440590e-06, -2.55763803e-06,\n",
      "       -1.78013408e-06,  1.77482048e-06,  1.39853967e-06, -1.36456663e-06,\n",
      "        1.18938340e-06, -1.13194244e-06, -1.01410455e-06, -8.05015304e-07,\n",
      "        7.71785267e-07,  7.13186580e-07, -6.56804445e-07,  5.72012482e-07,\n",
      "       -5.01232762e-07,  4.76197556e-07,  4.16230080e-07, -4.20180470e-07,\n",
      "        3.94959073e-07, -3.90624422e-07,  3.32351988e-07, -3.15981822e-07,\n",
      "       -2.89932359e-07,  3.18864380e-07,  2.63347175e-07, -2.40766525e-07,\n",
      "        2.17919762e-07, -1.83464522e-07,  2.07652661e-07,  1.76191151e-07,\n",
      "        1.14409033e-07, -1.48666999e-07, -1.22701650e-07, -1.20152492e-07,\n",
      "       -1.14195871e-07,  9.95290890e-08, -8.52416946e-08, -8.10420886e-08,\n",
      "       -5.72997614e-08,  7.42748725e-08,  6.85179700e-08,  6.34487165e-08,\n",
      "       -3.75054547e-08,  4.82844484e-08,  4.42100081e-08,  3.70885260e-08,\n",
      "       -3.29429390e-08, -2.45887968e-08, -2.34196769e-08,  2.54901042e-08,\n",
      "       -1.67331038e-08,  2.29305144e-08,  1.90174916e-08, -9.45201606e-09,\n",
      "       -1.14550494e-08, -2.77256063e-09, -1.17068755e-09,  9.88361615e-10,\n",
      "        1.31556339e-08,  4.74854378e-09,  5.39876632e-09,  9.98176120e-09],\n",
      "      dtype=float32), array([[-0.06386229,  0.08614429,  0.18254371, ..., -0.03501002,\n",
      "         0.01575615, -0.0232569 ],\n",
      "       [-0.02661841,  0.09142593, -0.14210965, ...,  0.01342415,\n",
      "        -0.08513984, -0.00518316],\n",
      "       [ 0.03482337, -0.17704391, -0.0843617 , ..., -0.06719439,\n",
      "         0.05431207,  0.06502087],\n",
      "       ...,\n",
      "       [-0.05247577,  0.27373105,  0.18486129, ..., -0.06378883,\n",
      "        -0.05108445, -0.01895523],\n",
      "       [-0.1333733 , -0.07379886,  0.10093005, ..., -0.00402132,\n",
      "        -0.00472746,  0.01540477],\n",
      "       [-0.00822189, -0.10858974,  0.03277789, ...,  0.0108028 ,\n",
      "         0.06938045, -0.16225563]], dtype=float32))\n",
      "(array([ 2.84271942e+02,  1.24482024e+00,  4.45964694e-01,  1.99421301e-01,\n",
      "        7.50800818e-02,  3.64730805e-02,  2.56791841e-02,  1.72433108e-02,\n",
      "        1.17040444e-02,  7.14976387e-03,  5.42098517e-03,  4.49057063e-03,\n",
      "        2.86410027e-03,  1.69997616e-03,  1.51030510e-03,  1.29741372e-03,\n",
      "        1.19613600e-03,  8.38788401e-04,  6.67786226e-04,  6.08539034e-04,\n",
      "        4.75947745e-04,  3.66272376e-04,  2.34677849e-04,  1.76231129e-04,\n",
      "        1.58445473e-04,  1.46506034e-04,  1.34001835e-04,  1.02030470e-04,\n",
      "        7.95429733e-05,  6.74040057e-05,  5.40863584e-05,  4.03046361e-05,\n",
      "        3.77485776e-05,  3.30624825e-05,  3.03533488e-05,  2.69839984e-05,\n",
      "        2.45561150e-05,  1.97455920e-05,  1.60110994e-05,  1.41826185e-05,\n",
      "        1.24808585e-05,  1.11361551e-05, -6.95810195e-06,  9.35199205e-06,\n",
      "        8.35593255e-06,  6.00730573e-06,  5.06143670e-06, -3.91157391e-06,\n",
      "        4.44410671e-06,  3.75656464e-06, -2.89304444e-06,  3.27680891e-06,\n",
      "       -2.35683024e-06,  2.70139913e-06,  2.44708599e-06, -1.91891922e-06,\n",
      "        1.91840286e-06, -1.52835810e-06, -1.37951668e-06,  1.60160107e-06,\n",
      "        1.52939344e-06,  1.34324966e-06, -1.07777998e-06,  1.10986230e-06,\n",
      "        1.01315288e-06, -9.13648250e-07, -8.76775857e-07,  8.48441914e-07,\n",
      "       -7.84244548e-07,  7.19325783e-07, -6.92892229e-07,  5.49923811e-07,\n",
      "        5.06315132e-07, -4.51603427e-07, -4.11246901e-07,  4.39275084e-07,\n",
      "       -3.70991046e-07,  4.16694292e-07,  3.55229304e-07, -2.99058712e-07,\n",
      "       -2.77946896e-07, -2.33733914e-07,  3.05782123e-07,  2.86741681e-07,\n",
      "        2.73339083e-07,  1.77491387e-07, -1.76386578e-07, -1.58968604e-07,\n",
      "       -1.43259598e-07,  1.34237283e-07,  1.36588369e-07, -1.14395554e-07,\n",
      "        1.09854717e-07,  8.72509531e-08, -9.52975796e-08, -8.64082068e-08,\n",
      "       -7.60221539e-08,  7.07839263e-08,  6.09393567e-08,  5.00202226e-08,\n",
      "       -4.36084449e-08, -3.64410297e-08, -3.19954161e-08,  3.59266181e-08,\n",
      "       -2.73821410e-08,  3.06851575e-08,  3.36792567e-08, -2.06775468e-08,\n",
      "       -8.20421064e-09, -5.22328270e-09,  2.46207432e-09, -8.78106643e-10,\n",
      "        3.37092659e-10,  7.69735609e-10, -1.51342050e-08,  6.29804164e-09,\n",
      "        1.09187273e-08,  2.13961506e-08,  1.95569996e-08,  1.35329392e-08],\n",
      "      dtype=float32), array([[ 0.03854283,  0.09373165,  0.09965285, ...,  0.00211666,\n",
      "         0.06720084,  0.03638224],\n",
      "       [ 0.03890732, -0.05946581, -0.02288342, ...,  0.01292439,\n",
      "        -0.05873   , -0.05739272],\n",
      "       [-0.00947797, -0.02710389, -0.1544332 , ..., -0.17595477,\n",
      "         0.05983032,  0.11116226],\n",
      "       ...,\n",
      "       [-0.00145067,  0.11049321,  0.3411466 , ..., -0.11705637,\n",
      "         0.06371633,  0.04514649],\n",
      "       [ 0.14297345,  0.06563421, -0.11036171, ..., -0.00791505,\n",
      "        -0.0099757 , -0.00137456],\n",
      "       [ 0.0232344 , -0.0042697 , -0.1239741 , ..., -0.03271753,\n",
      "        -0.10836488,  0.06008239]], dtype=float32))\n",
      "(array([ 2.83255188e+02,  1.09582496e+00,  4.62421089e-01,  2.17617720e-01,\n",
      "        5.58560081e-02,  3.74296755e-02,  2.70155426e-02,  2.32364088e-02,\n",
      "        1.41694332e-02,  1.11413775e-02,  7.02126743e-03,  4.74138325e-03,\n",
      "        3.80023383e-03,  2.80960603e-03,  2.34576082e-03,  1.75405771e-03,\n",
      "        1.17892108e-03,  1.01553090e-03,  8.45416856e-04,  5.60871325e-04,\n",
      "        4.70322469e-04,  3.74641590e-04,  3.45589186e-04,  2.77692976e-04,\n",
      "        2.11970939e-04,  1.73605644e-04,  1.55620524e-04,  1.50628664e-04,\n",
      "        1.28952815e-04,  1.02626043e-04,  9.34622803e-05,  7.48348539e-05,\n",
      "        6.77102798e-05,  5.75507838e-05,  4.72692846e-05,  3.93229930e-05,\n",
      "        3.71409624e-05,  3.05283138e-05,  2.25836648e-05,  2.15362816e-05,\n",
      "        1.71217071e-05,  1.58518906e-05,  1.31524748e-05,  1.19351398e-05,\n",
      "       -9.11636562e-06,  1.02770391e-05,  8.23077789e-06,  7.78791036e-06,\n",
      "       -5.47297168e-06,  6.57173041e-06,  4.66017627e-06,  3.82275675e-06,\n",
      "       -2.81047141e-06, -2.70778924e-06,  3.22970618e-06,  3.07092455e-06,\n",
      "        2.57249440e-06,  2.30319870e-06, -1.94204836e-06,  1.71220654e-06,\n",
      "       -1.58032117e-06, -1.42241811e-06,  1.55158227e-06,  1.42136651e-06,\n",
      "       -1.16320734e-06,  1.07561220e-06,  8.10288896e-07,  7.79140635e-07,\n",
      "       -8.57035559e-07, -8.19933632e-07, -7.50068352e-07, -6.34318212e-07,\n",
      "        5.95796109e-07,  5.33112882e-07, -4.64130920e-07,  4.64508105e-07,\n",
      "        4.05219254e-07, -3.89950316e-07, -3.36723929e-07,  3.58750412e-07,\n",
      "       -2.88690018e-07, -2.36286240e-07,  3.06135036e-07,  2.57757279e-07,\n",
      "        2.41685143e-07, -2.11039989e-07,  1.85460976e-07, -1.89471507e-07,\n",
      "       -1.62561690e-07, -1.54453176e-07,  1.47513063e-07,  1.34570428e-07,\n",
      "       -1.22554042e-07, -1.02256919e-07, -9.47617522e-08,  1.13270133e-07,\n",
      "        1.07556808e-07,  9.33840880e-08,  8.76959518e-08, -7.09096639e-08,\n",
      "        7.02327654e-08, -5.35909841e-08, -4.60627305e-08, -3.53345335e-08,\n",
      "        4.30894964e-08,  3.75134661e-08,  3.33857706e-08,  2.63093192e-08,\n",
      "       -2.34489477e-08, -1.96933847e-08,  1.81764612e-08,  1.44556696e-08,\n",
      "       -1.30222615e-08,  9.13307296e-09,  7.88073162e-09,  3.77845533e-09,\n",
      "       -1.44245238e-09, -6.53656818e-09, -7.61044294e-09, -8.53044746e-09],\n",
      "      dtype=float32), array([[ 0.03743758,  0.03329755,  0.11710516, ...,  0.04268979,\n",
      "        -0.05662356, -0.05048394],\n",
      "       [ 0.04218048, -0.07418463, -0.21048242, ..., -0.0154778 ,\n",
      "         0.05114017,  0.05667358],\n",
      "       [-0.01025446, -0.05129286,  0.05211062, ...,  0.04390191,\n",
      "         0.19032207,  0.13542262],\n",
      "       ...,\n",
      "       [ 0.00744049,  0.16470374,  0.03954448, ...,  0.00936   ,\n",
      "         0.07900147,  0.04401948],\n",
      "       [ 0.1471405 , -0.00544084,  0.09297179, ..., -0.00399191,\n",
      "         0.00733361,  0.01470212],\n",
      "       [ 0.03340435,  0.05651814,  0.09544523, ...,  0.06808317,\n",
      "        -0.03804527, -0.05822815]], dtype=float32))\n",
      "(array([ 2.97742493e+02,  1.87780964e+00,  8.24735403e-01,  3.43430609e-01,\n",
      "        1.04211912e-01,  6.12093024e-02,  4.35788855e-02,  3.41711566e-02,\n",
      "        1.91011429e-02,  1.51951630e-02,  1.46184759e-02,  9.53699928e-03,\n",
      "        7.27671618e-03,  5.66384709e-03,  3.76824173e-03,  3.11288889e-03,\n",
      "        2.10069027e-03,  1.93380064e-03,  1.65097904e-03,  1.58099027e-03,\n",
      "        9.84552782e-04,  7.89354963e-04,  6.98224700e-04,  5.23350434e-04,\n",
      "        4.59471601e-04,  4.23169520e-04,  3.95183015e-04,  3.62559455e-04,\n",
      "        2.86706840e-04,  2.06144017e-04,  1.79562703e-04,  1.38525967e-04,\n",
      "        1.32041620e-04,  1.15159186e-04,  9.01918320e-05,  7.99464469e-05,\n",
      "        7.69783583e-05,  5.80677333e-05,  5.02011462e-05,  5.05798489e-05,\n",
      "        3.75766977e-05,  3.36392550e-05,  2.88279989e-05,  1.84666060e-05,\n",
      "        1.80922525e-05,  1.47459232e-05, -8.96838992e-06,  9.74065097e-06,\n",
      "        8.36446452e-06,  7.77978221e-06,  5.22396795e-06,  4.81869392e-06,\n",
      "        4.00432009e-06, -3.66264726e-06, -3.33557614e-06,  3.14761473e-06,\n",
      "       -2.71132967e-06, -2.23943175e-06,  2.20242305e-06, -1.69082966e-06,\n",
      "        1.86599812e-06,  1.54825818e-06, -1.14686668e-06,  1.26096575e-06,\n",
      "        1.13788474e-06, -1.02405727e-06,  9.84525741e-07, -8.78996445e-07,\n",
      "       -8.36808738e-07,  8.16536499e-07,  6.44481702e-07,  5.71603891e-07,\n",
      "        5.51234734e-07, -6.50638640e-07, -6.00666567e-07, -5.07610764e-07,\n",
      "       -4.70385203e-07,  4.04080424e-07, -3.38767393e-07,  3.47667509e-07,\n",
      "        3.13865314e-07, -2.83665912e-07,  2.74030214e-07, -2.42977279e-07,\n",
      "        2.17499874e-07, -2.12004551e-07, -2.02504381e-07,  1.84770897e-07,\n",
      "       -1.62856438e-07, -1.44744462e-07,  1.52925978e-07,  1.49563817e-07,\n",
      "       -1.24746421e-07,  1.24772910e-07, -9.01137724e-08,  1.03552622e-07,\n",
      "       -9.71482379e-08, -7.51877778e-08,  6.94817643e-08, -6.89656758e-08,\n",
      "        6.62075621e-08,  6.19546228e-08, -4.53816291e-08,  4.75835833e-08,\n",
      "       -3.06323749e-08, -2.52840255e-08, -3.15334390e-08,  2.87921260e-08,\n",
      "        2.69690776e-08, -6.96459956e-09, -1.16701617e-08, -1.01661435e-08,\n",
      "       -1.08918796e-09,  1.11974174e-09,  3.45336382e-09,  6.24669561e-09,\n",
      "        1.84779996e-08,  1.44286112e-08,  1.12246710e-08,  1.01329451e-08],\n",
      "      dtype=float32), array([[ 3.94869633e-02,  6.52354136e-02,  1.11424059e-01, ...,\n",
      "         2.40837857e-02, -4.43220250e-02, -5.63520379e-03],\n",
      "       [ 4.36158255e-02, -3.17864940e-02, -2.29133725e-01, ...,\n",
      "        -1.21374615e-01,  1.59709924e-03, -2.92516854e-02],\n",
      "       [-5.60553651e-03, -9.00349021e-03,  6.98044747e-02, ...,\n",
      "         6.93267956e-02,  6.70672655e-02, -4.50555496e-02],\n",
      "       ...,\n",
      "       [ 2.23685798e-04, -1.56834582e-03,  5.68368435e-02, ...,\n",
      "         6.21264540e-02, -8.06627329e-03,  1.29489228e-02],\n",
      "       [ 1.46570548e-01, -1.46642048e-02,  1.30798459e-01, ...,\n",
      "         9.44595551e-04, -1.68409944e-02,  9.15860198e-03],\n",
      "       [ 3.31615731e-02, -4.52950001e-02,  1.26422346e-01, ...,\n",
      "        -1.68150961e-02,  1.29094407e-01, -3.08377128e-02]], dtype=float32))\n",
      "(array([ 3.21318146e+02,  9.99943614e-01,  4.97857332e-01,  1.56918660e-01,\n",
      "        7.57604837e-02,  4.46092151e-02,  3.55083458e-02,  3.46994177e-02,\n",
      "        1.76711790e-02,  9.89597291e-03,  5.61938854e-03,  4.29357123e-03,\n",
      "        3.53906746e-03,  2.74305511e-03,  2.05969252e-03,  1.86076283e-03,\n",
      "        1.33945630e-03,  1.13437569e-03,  8.68107774e-04,  7.56427238e-04,\n",
      "        5.98252111e-04,  4.73445834e-04,  3.87783715e-04,  2.87308969e-04,\n",
      "        2.31649814e-04,  2.22615185e-04,  1.93319167e-04,  1.77942551e-04,\n",
      "        1.66535610e-04,  1.38370917e-04,  1.07984961e-04,  1.05317391e-04,\n",
      "        8.61729786e-05,  7.38634044e-05,  6.63433893e-05,  6.29201386e-05,\n",
      "        4.96126086e-05,  4.60455994e-05,  3.47153982e-05,  3.24698267e-05,\n",
      "        2.65541803e-05,  2.09749433e-05,  1.76303238e-05,  1.62593769e-05,\n",
      "       -1.20403938e-05,  1.07559936e-05,  9.15760302e-06, -6.31200419e-06,\n",
      "       -5.74163187e-06,  7.33396791e-06,  6.28828775e-06,  5.78597701e-06,\n",
      "        4.62828348e-06, -3.86086867e-06,  3.75750642e-06, -2.84740645e-06,\n",
      "        3.25466226e-06, -1.93247865e-06,  2.25149893e-06,  2.14108741e-06,\n",
      "       -1.42287354e-06,  1.55917076e-06,  1.48994638e-06,  1.32697653e-06,\n",
      "       -1.15273826e-06,  1.08171810e-06,  9.52682910e-07,  8.94383447e-07,\n",
      "       -1.01380476e-06, -9.37924995e-07, -8.31723639e-07,  7.13736597e-07,\n",
      "       -7.18514684e-07, -6.21991376e-07,  5.79969424e-07,  5.40885367e-07,\n",
      "        4.77421736e-07, -4.37057707e-07, -3.56446975e-07,  3.70866587e-07,\n",
      "        3.10802591e-07,  2.99442462e-07, -3.02889447e-07, -2.85941979e-07,\n",
      "        2.15852040e-07,  1.91885178e-07, -2.18455426e-07,  1.66778406e-07,\n",
      "       -1.83995581e-07, -1.76702727e-07, -1.39742795e-07,  1.54885484e-07,\n",
      "       -1.24434237e-07,  1.14243882e-07, -9.35044540e-08, -8.85879530e-08,\n",
      "        7.71948692e-08, -6.22839877e-08, -5.49881030e-08, -4.40499868e-08,\n",
      "        6.94582809e-08,  6.63945627e-08,  6.12651618e-08,  4.24208402e-08,\n",
      "        4.85153890e-08,  3.22337605e-08, -2.80459762e-08,  2.27399930e-08,\n",
      "       -2.11441460e-08, -1.93633607e-08,  1.61211471e-08,  1.18282015e-08,\n",
      "       -1.00520845e-08,  8.72729800e-09, -7.82387666e-09, -6.15518880e-09,\n",
      "       -3.16720317e-09, -9.52349755e-10,  2.38277753e-09,  4.66101824e-09],\n",
      "      dtype=float32), array([[-0.04117834,  0.00612553,  0.18092428, ...,  0.01879727,\n",
      "         0.03891078, -0.00262857],\n",
      "       [-0.04533642, -0.12648334, -0.15942992, ...,  0.00105033,\n",
      "         0.01202484,  0.10366692],\n",
      "       [ 0.00678378,  0.07616844, -0.00726609, ..., -0.11077974,\n",
      "         0.03593646, -0.00349838],\n",
      "       ...,\n",
      "       [-0.00107923, -0.09973037,  0.1917103 , ..., -0.0260281 ,\n",
      "        -0.03628859,  0.02677307],\n",
      "       [-0.14627682,  0.12317418,  0.03074777, ..., -0.01432704,\n",
      "         0.01063196, -0.0041967 ],\n",
      "       [-0.03214072,  0.04163299,  0.0845094 , ..., -0.01732601,\n",
      "        -0.0032143 , -0.02046722]], dtype=float32))\n",
      "(array([ 3.35421631e+02,  9.79355395e-01,  4.60535020e-01,  2.06827492e-01,\n",
      "        9.60345268e-02,  4.50366475e-02,  3.64057273e-02,  2.63843890e-02,\n",
      "        1.79763120e-02,  1.56939123e-02,  1.20162284e-02,  9.77465697e-03,\n",
      "        5.60408412e-03,  3.19446553e-03,  2.75787921e-03,  2.19665468e-03,\n",
      "        1.88533741e-03,  1.66397146e-03,  1.35677715e-03,  8.49746924e-04,\n",
      "        7.26656173e-04,  6.04817818e-04,  4.98917361e-04,  4.05087747e-04,\n",
      "        3.15955520e-04,  2.83324829e-04,  2.45015457e-04,  1.76375004e-04,\n",
      "        1.63680641e-04,  1.33021036e-04,  1.14917988e-04,  1.04526363e-04,\n",
      "        9.22512409e-05,  7.72817657e-05,  7.42959892e-05,  5.58536231e-05,\n",
      "        5.18759407e-05,  3.83909501e-05,  3.68569999e-05,  3.32287018e-05,\n",
      "        2.71781992e-05,  2.12309733e-05,  1.57731938e-05,  1.36530198e-05,\n",
      "       -9.75261719e-06,  1.12566486e-05,  9.98503947e-06, -7.52347478e-06,\n",
      "        6.63540141e-06, -4.94122105e-06,  5.42465114e-06,  5.25663199e-06,\n",
      "        4.42791179e-06,  3.84351370e-06, -3.53689870e-06, -3.15064290e-06,\n",
      "        3.15772468e-06, -2.20196489e-06,  2.51682695e-06,  2.29374564e-06,\n",
      "        1.95043572e-06,  1.40683028e-06, -1.48515505e-06, -1.36806636e-06,\n",
      "       -1.29000568e-06, -1.12679936e-06, -9.69426083e-07,  9.98471364e-07,\n",
      "        9.32040280e-07, -7.54999576e-07,  7.49835294e-07,  7.80354526e-07,\n",
      "       -6.26768042e-07,  6.37869903e-07,  5.47131378e-07,  4.51776202e-07,\n",
      "        4.42027414e-07, -4.87025773e-07, -4.42598861e-07, -4.01380305e-07,\n",
      "       -3.19510178e-07, -2.87838191e-07,  3.05679265e-07,  2.65045969e-07,\n",
      "        2.41591181e-07,  2.25912046e-07, -1.92334511e-07, -2.10511161e-07,\n",
      "        1.79337277e-07, -1.66720596e-07, -1.42210126e-07,  1.26681044e-07,\n",
      "       -1.07835604e-07, -9.15679621e-08,  1.08779240e-07,  1.04512161e-07,\n",
      "        9.45917620e-08, -7.10859069e-08,  7.09065162e-08, -6.34558717e-08,\n",
      "        6.52792593e-08, -4.45670558e-08, -4.28628226e-08,  4.93890333e-08,\n",
      "        4.70253738e-08, -3.04865075e-08, -2.75172525e-08,  3.02441023e-08,\n",
      "        3.44653799e-08, -1.51383563e-08, -1.34287408e-08,  2.02364596e-08,\n",
      "        1.81179214e-08,  1.46656358e-08, -7.48501616e-09,  1.03644622e-08,\n",
      "       -3.11699422e-09, -1.87766558e-09,  6.65133948e-10,  1.40045586e-09],\n",
      "      dtype=float32), array([[ 0.03464266,  0.09779423, -0.0096571 , ..., -0.0004251 ,\n",
      "        -0.00470394,  0.00305039],\n",
      "       [ 0.04731901, -0.17015854, -0.05749639, ...,  0.03639803,\n",
      "         0.03910093, -0.02680478],\n",
      "       [-0.00301802,  0.03375424,  0.07593798, ..., -0.0491828 ,\n",
      "        -0.07127136, -0.01379415],\n",
      "       ...,\n",
      "       [-0.01074632,  0.03354977, -0.02793389, ..., -0.06261485,\n",
      "        -0.09041392,  0.1623967 ],\n",
      "       [ 0.14789978,  0.09805606,  0.10462227, ..., -0.00045921,\n",
      "         0.00607269,  0.00059233],\n",
      "       [ 0.02948696,  0.04494012,  0.1245432 , ...,  0.0326779 ,\n",
      "        -0.03740995,  0.00672428]], dtype=float32))\n",
      "(array([ 3.03189117e+02,  8.50103557e-01,  4.50396031e-01,  1.23601519e-01,\n",
      "        5.31676821e-02,  3.42445970e-02,  2.57442128e-02,  1.28247049e-02,\n",
      "        1.10121770e-02,  8.85567814e-03,  6.81922073e-03,  4.95254761e-03,\n",
      "        3.58049292e-03,  2.62867217e-03,  2.11256649e-03,  1.54277065e-03,\n",
      "        1.09459856e-03,  1.06430415e-03,  7.48140214e-04,  5.83814224e-04,\n",
      "        4.41625190e-04,  4.16880008e-04,  2.94111465e-04,  2.52288504e-04,\n",
      "        2.17746740e-04,  1.80769086e-04,  1.68172613e-04,  1.43824756e-04,\n",
      "        1.33527385e-04,  1.13177004e-04,  8.68202333e-05,  7.46837031e-05,\n",
      "        6.12175281e-05,  5.58427964e-05,  4.62788048e-05,  4.50284206e-05,\n",
      "        3.26158042e-05,  3.07379887e-05,  2.70806322e-05,  2.19361973e-05,\n",
      "        1.77525726e-05,  1.69967734e-05,  1.46624852e-05,  1.33790782e-05,\n",
      "       -7.63929711e-06,  9.23038260e-06,  7.93504023e-06, -4.95938093e-06,\n",
      "        6.61237482e-06,  5.77270976e-06,  5.63167714e-06,  4.97038172e-06,\n",
      "        4.03018021e-06, -3.85263866e-06, -3.64297875e-06, -3.02948865e-06,\n",
      "        2.89082982e-06,  2.72812031e-06,  2.28886665e-06, -1.81726182e-06,\n",
      "        1.98297289e-06,  1.55006694e-06, -1.32637638e-06, -1.02111051e-06,\n",
      "        1.14477746e-06, -8.76433944e-07,  9.81629228e-07,  8.96629103e-07,\n",
      "        7.49533569e-07, -7.21120443e-07,  6.37976996e-07, -6.38923495e-07,\n",
      "       -5.61795957e-07, -5.52537301e-07,  5.34030164e-07,  5.02953810e-07,\n",
      "        4.14179937e-07,  3.28206539e-07, -3.99733409e-07, -3.75202774e-07,\n",
      "       -3.42843151e-07, -2.94712493e-07,  2.64826639e-07, -2.15125766e-07,\n",
      "        2.31951105e-07,  2.06187963e-07,  1.98586534e-07, -1.82919507e-07,\n",
      "       -1.43207089e-07,  1.57052980e-07,  1.53948363e-07, -1.13777652e-07,\n",
      "       -1.02948185e-07, -8.46063770e-08,  1.14474986e-07,  1.00997710e-07,\n",
      "        1.05274474e-07,  8.40945518e-08, -6.84615387e-08, -5.82868296e-08,\n",
      "       -5.21424930e-08,  6.24525711e-08,  5.13019458e-08, -3.36423085e-08,\n",
      "        4.08463947e-08,  4.22264961e-08,  3.02473353e-08,  2.14371614e-08,\n",
      "       -2.27060113e-08, -2.14822276e-08, -1.74309118e-08,  1.52896877e-08,\n",
      "        1.21319630e-08, -1.04101021e-08, -9.13816489e-09,  7.74571429e-09,\n",
      "       -4.60614302e-09,  1.58889912e-09,  2.82821189e-09,  3.52199225e-09],\n",
      "      dtype=float32), array([[ 0.03348222, -0.09943099, -0.09557941, ...,  0.01959602,\n",
      "         0.02817313, -0.0375022 ],\n",
      "       [ 0.04480217,  0.08935905,  0.14142485, ..., -0.03710612,\n",
      "        -0.00339376,  0.04895113],\n",
      "       [-0.00087375, -0.01162851, -0.07369589, ..., -0.11946813,\n",
      "         0.242282  , -0.02384767],\n",
      "       ...,\n",
      "       [-0.01858109, -0.0670413 ,  0.02891023, ..., -0.08732376,\n",
      "         0.07010854, -0.00213813],\n",
      "       [ 0.14431606, -0.05147504, -0.10257147, ..., -0.00069926,\n",
      "         0.00930193,  0.02101468],\n",
      "       [ 0.02986798, -0.01376879, -0.08332309, ..., -0.05981847,\n",
      "         0.00538151, -0.04326769]], dtype=float32))\n",
      "(array([ 3.27365479e+02,  8.79844010e-01,  3.20817649e-01,  9.26561728e-02,\n",
      "        3.41301523e-02,  2.80387290e-02,  1.98286641e-02,  1.29331807e-02,\n",
      "        1.26668867e-02,  7.53100635e-03,  6.07430469e-03,  4.18932969e-03,\n",
      "        2.44085421e-03,  1.75593607e-03,  1.30811892e-03,  1.01337687e-03,\n",
      "        7.88793666e-04,  7.48912105e-04,  4.18198440e-04,  3.79167468e-04,\n",
      "        3.16635414e-04,  2.36549720e-04,  2.23772047e-04,  2.00874289e-04,\n",
      "        1.51862492e-04,  1.35289723e-04,  1.13944050e-04,  9.49346286e-05,\n",
      "        7.82651623e-05,  6.65171538e-05,  5.55821207e-05,  4.32247216e-05,\n",
      "        3.87593791e-05,  3.38667669e-05,  2.63120255e-05,  2.29059915e-05,\n",
      "        1.81027335e-05,  1.49510342e-05,  1.45571294e-05, -9.09930623e-06,\n",
      "        1.20354771e-05,  1.10649626e-05,  9.06121659e-06,  8.29950113e-06,\n",
      "        7.69449525e-06, -6.34977459e-06, -5.43512351e-06,  6.33348873e-06,\n",
      "        5.48503294e-06, -4.19714524e-06,  4.57935175e-06,  4.11922883e-06,\n",
      "        3.68605015e-06,  3.23779136e-06, -2.60198340e-06,  2.77133108e-06,\n",
      "       -2.04209573e-06, -1.92211564e-06,  2.43462637e-06,  2.12672398e-06,\n",
      "       -1.52374321e-06,  1.73838362e-06,  1.59132844e-06, -1.36679557e-06,\n",
      "        1.50505787e-06,  1.19708909e-06,  1.10010876e-06, -1.00455043e-06,\n",
      "       -9.37630205e-07,  8.98322469e-07,  8.15865235e-07, -7.59755039e-07,\n",
      "       -7.47745673e-07,  6.57690919e-07,  5.70785119e-07, -5.54654662e-07,\n",
      "       -4.78784102e-07, -4.60763658e-07,  4.78817185e-07,  3.94409824e-07,\n",
      "       -3.39737738e-07,  3.27171961e-07,  2.76361675e-07,  2.80510278e-07,\n",
      "       -2.52045652e-07, -2.41322709e-07, -2.28251224e-07,  2.24468025e-07,\n",
      "        2.02578079e-07,  1.91609857e-07, -1.71160224e-07, -1.32836519e-07,\n",
      "       -1.25998270e-07,  1.26585235e-07,  1.23463423e-07,  1.06401224e-07,\n",
      "       -1.08814135e-07, -9.15645728e-08,  9.09306479e-08,  6.87575081e-08,\n",
      "       -7.29561904e-08, -6.69769662e-08, -3.97067623e-08,  4.23304272e-08,\n",
      "        3.85033054e-08, -3.16147393e-08, -2.65188156e-08,  2.80175794e-08,\n",
      "       -2.15148752e-08,  2.33239543e-08,  2.09819735e-08, -1.78343953e-08,\n",
      "        1.31777798e-08, -7.36961114e-09, -5.74828984e-09,  7.98876076e-09,\n",
      "       -1.59019253e-09,  3.47950202e-09,  2.02885708e-09, -6.32605246e-10],\n",
      "      dtype=float32), array([[ 0.03409576, -0.14419714, -0.01495107, ..., -0.1007885 ,\n",
      "         0.03853503, -0.03534063],\n",
      "       [ 0.04730748,  0.11315179, -0.14624208, ...,  0.02969324,\n",
      "         0.01581842,  0.01697932],\n",
      "       [ 0.00175033, -0.0144035 ,  0.09325285, ..., -0.12357985,\n",
      "        -0.13671187,  0.24467504],\n",
      "       ...,\n",
      "       [-0.02340861, -0.0927357 , -0.08472869, ..., -0.00418308,\n",
      "         0.06550744,  0.07709858],\n",
      "       [ 0.15186414, -0.12148641,  0.0236124 , ..., -0.00322384,\n",
      "        -0.01406358, -0.00616423],\n",
      "       [ 0.03521517, -0.03115623,  0.05951854, ..., -0.03472399,\n",
      "        -0.00567785,  0.02757423]], dtype=float32))\n",
      "(array([ 3.12788666e+02,  1.17364573e+00,  3.21911424e-01,  1.87839046e-01,\n",
      "        8.33843872e-02,  3.65254469e-02,  2.73145400e-02,  1.69633515e-02,\n",
      "        1.44156525e-02,  9.95386764e-03,  8.02207459e-03,  4.27584490e-03,\n",
      "        3.65505437e-03,  2.14138092e-03,  2.01173848e-03,  1.48533145e-03,\n",
      "        1.45399314e-03,  1.23404537e-03,  9.87320673e-04,  7.55732297e-04,\n",
      "        5.65642258e-04,  4.86717792e-04,  3.63341853e-04,  3.14813573e-04,\n",
      "        2.67693365e-04,  2.31481856e-04,  1.85897647e-04,  1.55180358e-04,\n",
      "        1.40680771e-04,  1.28840926e-04,  1.06435204e-04,  7.74850196e-05,\n",
      "        6.34401586e-05,  5.49160432e-05,  4.50306106e-05,  4.24271057e-05,\n",
      "        3.53481228e-05,  3.01594991e-05,  2.90859916e-05,  2.09907521e-05,\n",
      "        1.69206396e-05,  1.04878818e-05,  9.78968546e-06, -7.65625555e-06,\n",
      "        8.95364246e-06, -5.66887911e-06,  8.06841126e-06,  6.88708724e-06,\n",
      "        6.01558668e-06,  5.81495397e-06,  5.16163936e-06, -4.02699379e-06,\n",
      "       -3.34743072e-06,  3.98456586e-06,  3.32119248e-06,  3.14776025e-06,\n",
      "        2.59899343e-06,  2.06492109e-06,  2.00959448e-06, -2.13659337e-06,\n",
      "       -1.85668171e-06, -1.73372371e-06, -1.33975186e-06,  1.22734514e-06,\n",
      "        1.13864701e-06, -1.08122742e-06, -1.01165801e-06, -7.89582828e-07,\n",
      "        9.63999014e-07,  8.48048046e-07, -6.77292007e-07,  6.81975621e-07,\n",
      "        6.20651690e-07, -6.07822301e-07, -4.93356310e-07, -5.13601890e-07,\n",
      "       -4.22786968e-07,  5.79878645e-07,  4.98512577e-07,  5.38837298e-07,\n",
      "        3.97827648e-07, -3.44237151e-07,  3.20206794e-07, -2.53609727e-07,\n",
      "       -2.69375448e-07, -1.71712728e-07,  2.62146443e-07,  2.35638836e-07,\n",
      "        1.90218245e-07,  1.81471023e-07, -1.46338238e-07,  1.40903950e-07,\n",
      "       -1.26026066e-07, -1.10215730e-07, -9.29807200e-08,  9.55483799e-08,\n",
      "       -7.32649141e-08,  7.88795589e-08,  7.43284190e-08,  6.95750018e-08,\n",
      "       -6.15435738e-08,  6.03324040e-08, -5.74092880e-08, -4.07239753e-08,\n",
      "        3.89674781e-08, -3.31850600e-08,  2.88606170e-08, -2.54183714e-08,\n",
      "       -2.08991757e-08,  2.13209983e-08,  2.05273327e-08,  1.53522137e-08,\n",
      "       -1.40403031e-08, -1.36957530e-08,  6.83618628e-09,  6.30943875e-09,\n",
      "        4.60079486e-09, -2.56712457e-10, -1.87394411e-09, -4.87247442e-09],\n",
      "      dtype=float32), array([[ 0.03197966,  0.1149162 , -0.08909011, ...,  0.01858183,\n",
      "        -0.01492679, -0.00227032],\n",
      "       [ 0.04722472, -0.05013325, -0.07428221, ...,  0.00465483,\n",
      "         0.03394726,  0.00191529],\n",
      "       [ 0.00164166, -0.03683968,  0.13333046, ...,  0.2149249 ,\n",
      "        -0.22908017,  0.18563144],\n",
      "       ...,\n",
      "       [-0.02340901,  0.12606767, -0.2194685 , ...,  0.09135781,\n",
      "        -0.01417994,  0.07927629],\n",
      "       [ 0.14973667,  0.03862925,  0.16522504, ...,  0.00793383,\n",
      "         0.00311477,  0.01373367],\n",
      "       [ 0.03443662, -0.02771247,  0.10301244, ..., -0.0210689 ,\n",
      "        -0.01275177,  0.00084054]], dtype=float32))\n",
      "(array([ 3.0100629e+02,  2.0319750e+00,  1.4484635e-01,  8.5145794e-02,\n",
      "        5.7939239e-02,  1.2679275e-02,  1.1502280e-02,  8.2619833e-03,\n",
      "        4.9471171e-03,  3.9105290e-03,  2.3549993e-03,  1.9510702e-03,\n",
      "        1.6663084e-03,  1.4508142e-03,  9.0889831e-04,  7.1295927e-04,\n",
      "        6.3191971e-04,  4.6185617e-04,  3.1374459e-04,  2.8338959e-04,\n",
      "        2.0034576e-04,  1.4655800e-04,  1.2246886e-04,  9.8134995e-05,\n",
      "        8.7277047e-05,  7.3255746e-05,  6.0947423e-05,  4.5120003e-05,\n",
      "        4.4542296e-05,  3.8043640e-05,  3.5963971e-05,  2.7324049e-05,\n",
      "        2.4905859e-05,  2.0338271e-05,  1.7242302e-05,  1.5700232e-05,\n",
      "        1.3695080e-05,  1.1600324e-05,  1.0154558e-05,  8.1075950e-06,\n",
      "        7.1415284e-06,  6.2994741e-06, -4.6033965e-06, -4.1181061e-06,\n",
      "        4.5381380e-06,  3.8786193e-06, -2.7685705e-06,  3.7105394e-06,\n",
      "        3.3688623e-06,  2.8379120e-06,  2.5697898e-06, -2.0176774e-06,\n",
      "       -1.6877473e-06,  2.0855227e-06,  1.8893275e-06, -1.5208843e-06,\n",
      "        1.7002293e-06,  1.6068036e-06,  1.3081349e-06, -1.1586121e-06,\n",
      "        1.1595928e-06, -1.0577465e-06, -8.7058709e-07,  1.0038630e-06,\n",
      "        9.0736336e-07, -6.6541594e-07,  8.2196095e-07,  7.5122512e-07,\n",
      "       -6.0691150e-07,  6.7565162e-07, -5.3072478e-07,  5.5382384e-07,\n",
      "       -4.4072067e-07,  4.6821489e-07,  4.3929160e-07, -3.5225975e-07,\n",
      "        3.8414024e-07,  3.4383990e-07,  3.3699018e-07, -3.1840216e-07,\n",
      "       -2.9439133e-07, -2.4803242e-07, -2.6985492e-07,  2.9423003e-07,\n",
      "        2.4838101e-07, -1.9984085e-07,  2.0824930e-07,  1.8923684e-07,\n",
      "       -1.7131990e-07,  1.6111390e-07,  1.4449711e-07, -1.3963128e-07,\n",
      "       -1.1382540e-07,  1.2534119e-07,  9.8390721e-08, -8.5258364e-08,\n",
      "       -8.0368117e-08, -7.5253723e-08,  7.3923140e-08, -6.1772766e-08,\n",
      "        5.9728968e-08, -3.8762401e-08, -3.2553174e-08,  4.7009845e-08,\n",
      "        4.7803518e-08,  4.3083837e-08,  3.1932338e-08,  2.6839515e-08,\n",
      "       -2.6574270e-08, -2.3315859e-08,  2.1392266e-08, -1.6217665e-08,\n",
      "       -5.8587961e-09, -4.8928990e-09,  7.9817104e-09, -1.5831043e-09,\n",
      "        2.0053782e-10,  1.6804486e-09,  4.8628399e-09,  4.0163277e-09],\n",
      "      dtype=float32), array([[ 0.03546589, -0.1416865 , -0.10123587, ...,  0.02637167,\n",
      "         0.04208885, -0.01178829],\n",
      "       [ 0.04393011,  0.04951767,  0.16740157, ..., -0.00756981,\n",
      "         0.09586568,  0.01445772],\n",
      "       [-0.0035538 ,  0.08816227, -0.05887989, ...,  0.23247218,\n",
      "         0.0230633 , -0.06807785],\n",
      "       ...,\n",
      "       [-0.01283957, -0.23067452, -0.03210736, ...,  0.09592434,\n",
      "        -0.05129061,  0.06081288],\n",
      "       [ 0.14425458, -0.01675282, -0.03030703, ..., -0.01642094,\n",
      "        -0.00042019, -0.01617826],\n",
      "       [ 0.02729079,  0.07345308, -0.06203527, ...,  0.05902611,\n",
      "        -0.04713622,  0.04799745]], dtype=float32))\n",
      "(array([ 2.54692535e+02,  6.15574265e+00,  2.84794956e-01,  1.63108289e-01,\n",
      "        7.44583756e-02,  5.39018549e-02,  4.25488316e-02,  2.88782101e-02,\n",
      "        1.44632366e-02,  1.13205807e-02,  5.99522423e-03,  4.61228518e-03,\n",
      "        3.98799637e-03,  2.76440335e-03,  2.51892000e-03,  1.75703270e-03,\n",
      "        1.33851601e-03,  1.17049308e-03,  7.21643271e-04,  5.61436813e-04,\n",
      "        5.44166134e-04,  4.52974724e-04,  4.04463673e-04,  2.78937805e-04,\n",
      "        2.66938529e-04,  1.92012216e-04,  1.44596779e-04,  1.17107316e-04,\n",
      "        9.70749752e-05,  6.82009340e-05,  5.68840624e-05,  5.29969329e-05,\n",
      "        4.65758931e-05,  4.02857513e-05,  2.93710254e-05,  2.65036542e-05,\n",
      "        2.18171772e-05,  1.68887509e-05,  1.41290793e-05,  1.22651691e-05,\n",
      "       -8.60505770e-06,  9.27109431e-06,  8.18039734e-06,  6.48275227e-06,\n",
      "        5.81380118e-06, -4.07030302e-06,  4.53966777e-06, -3.29052364e-06,\n",
      "        3.93633536e-06,  3.60416584e-06,  3.19043033e-06, -2.42861825e-06,\n",
      "        2.45756769e-06, -1.88881393e-06, -1.73797525e-06,  1.97693521e-06,\n",
      "        1.54520148e-06,  1.47274011e-06, -1.24643861e-06,  1.20893799e-06,\n",
      "       -1.07325900e-06,  1.08126812e-06, -9.42633449e-07, -8.70994597e-07,\n",
      "        9.93452204e-07,  8.56780957e-07,  8.04939418e-07, -7.01890144e-07,\n",
      "       -6.45068496e-07,  6.51374876e-07,  5.80941446e-07, -4.75399247e-07,\n",
      "        4.85313990e-07, -4.33289614e-07, -4.11782480e-07,  4.43322989e-07,\n",
      "        4.02297871e-07, -3.51081752e-07,  3.69281679e-07, -2.72725856e-07,\n",
      "        3.01456907e-07, -2.35413836e-07, -2.17947303e-07, -1.78152362e-07,\n",
      "        2.28000161e-07,  2.34852592e-07,  1.90910853e-07,  1.77798768e-07,\n",
      "       -1.48341002e-07, -1.40561482e-07,  1.40463342e-07, -1.10177432e-07,\n",
      "       -1.08677234e-07,  1.46613004e-07,  1.12702942e-07, -8.44692920e-08,\n",
      "        9.49996419e-08, -6.66550193e-08,  8.06010689e-08,  6.80096264e-08,\n",
      "        5.89080784e-08, -4.39531966e-08, -3.84466574e-08,  3.90013781e-08,\n",
      "        3.64088919e-08,  3.25512097e-08,  2.72751048e-08, -2.23325038e-08,\n",
      "       -1.72574008e-08, -1.61782534e-08,  1.90113845e-08, -9.04132502e-09,\n",
      "       -7.39702299e-09, -3.72453579e-09,  1.60007865e-08,  4.39942471e-10,\n",
      "        3.54235308e-09,  5.88010263e-09,  8.51886917e-09,  1.03020952e-08],\n",
      "      dtype=float32), array([[ 0.02634877,  0.10052669,  0.10154302, ..., -0.0277126 ,\n",
      "         0.01851867,  0.00660712],\n",
      "       [ 0.04582245, -0.00935436,  0.03351903, ..., -0.02594751,\n",
      "         0.05955052, -0.03390726],\n",
      "       [-0.00237628, -0.03554785, -0.08064054, ..., -0.12413337,\n",
      "         0.02907825, -0.19025058],\n",
      "       ...,\n",
      "       [-0.01761812,  0.11699199,  0.2352254 , ..., -0.03339774,\n",
      "         0.07216838,  0.01707513],\n",
      "       [ 0.13976271,  0.11029357, -0.11468336, ...,  0.00200137,\n",
      "         0.02824282,  0.0178711 ],\n",
      "       [ 0.02822681, -0.01071847,  0.00199314, ...,  0.140908  ,\n",
      "         0.00289036,  0.00570043]], dtype=float32))\n",
      "(array([ 2.07059189e+02,  4.49885798e+00,  1.89243400e+00,  3.43756020e-01,\n",
      "        8.34555104e-02,  5.89972176e-02,  3.52012925e-02,  2.63561253e-02,\n",
      "        1.99767072e-02,  1.35118244e-02,  1.04388138e-02,  7.23572727e-03,\n",
      "        6.31731097e-03,  3.81774665e-03,  3.62816826e-03,  2.23961729e-03,\n",
      "        2.03204527e-03,  1.09693350e-03,  9.92896152e-04,  7.08468258e-04,\n",
      "        5.27480559e-04,  5.08217723e-04,  4.18801414e-04,  3.04616027e-04,\n",
      "        2.37748813e-04,  1.98691923e-04,  1.30968154e-04,  1.17994081e-04,\n",
      "        8.85526897e-05,  7.14093112e-05,  6.37317644e-05,  5.05171665e-05,\n",
      "        3.84211671e-05,  2.58702876e-05,  1.95934626e-05,  1.85950339e-05,\n",
      "        1.35425016e-05,  8.82828954e-06,  7.44696536e-06,  6.40541384e-06,\n",
      "        6.03153558e-06, -4.88617798e-06,  5.07189316e-06, -3.97376198e-06,\n",
      "        3.50184928e-06,  3.11260283e-06,  2.95075984e-06, -2.37693371e-06,\n",
      "       -1.82730764e-06,  2.06697655e-06,  1.93463325e-06, -1.35073515e-06,\n",
      "       -1.34178697e-06,  1.58403122e-06,  1.53314954e-06,  1.30290402e-06,\n",
      "        1.19682954e-06,  1.09029065e-06,  1.03860384e-06, -9.46486466e-07,\n",
      "       -8.96083179e-07,  8.87435419e-07, -7.80621065e-07,  7.44757017e-07,\n",
      "       -6.65332664e-07, -5.98384815e-07, -5.20975448e-07, -4.63017216e-07,\n",
      "        7.19195725e-07,  6.53112636e-07,  5.50382538e-07,  4.87478758e-07,\n",
      "        6.04735590e-07,  4.50711326e-07, -3.47469836e-07, -3.35789053e-07,\n",
      "       -3.23061982e-07, -2.62407042e-07,  3.51563813e-07,  3.43099174e-07,\n",
      "        2.83979318e-07,  2.80237373e-07,  2.35419833e-07, -2.34483707e-07,\n",
      "        1.78075595e-07,  1.90983528e-07, -1.93319934e-07, -1.72504528e-07,\n",
      "       -1.34487749e-07, -1.30487592e-07,  1.34262407e-07, -1.11109969e-07,\n",
      "        1.08997668e-07,  1.12608383e-07,  9.76611219e-08,  8.31639753e-08,\n",
      "       -9.49494634e-08, -7.95106132e-08, -7.44810009e-08,  6.40425597e-08,\n",
      "       -6.29290895e-08,  4.96071380e-08,  4.08109813e-08, -3.87754042e-08,\n",
      "       -3.26995924e-08, -2.23251995e-08,  2.93801783e-08,  2.73731509e-08,\n",
      "        2.18287077e-08, -2.30206290e-08,  1.77159354e-08,  1.39973695e-08,\n",
      "        9.93436533e-09,  7.21103444e-09, -1.12237659e-08,  3.54442742e-09,\n",
      "       -9.65239888e-09, -7.47773754e-09, -4.53836657e-09,  1.40532763e-09],\n",
      "      dtype=float32), array([[-2.0209456e-02, -3.1741221e-02, -1.3100635e-01, ...,\n",
      "         1.4245165e-04,  5.7796752e-03,  7.2295917e-03],\n",
      "       [-4.2071607e-02, -4.9135000e-02,  3.5255995e-02, ...,\n",
      "        -5.8741070e-02, -9.4623398e-03, -4.7704384e-02],\n",
      "       [-8.6966599e-04, -1.0593056e-02,  6.0134526e-02, ...,\n",
      "         3.1893574e-02,  4.0865820e-02, -3.4243685e-01],\n",
      "       ...,\n",
      "       [ 2.1753108e-02,  6.6570550e-02, -1.8019299e-01, ...,\n",
      "        -1.5134177e-01,  7.5004265e-02, -1.4747474e-01],\n",
      "       [-1.4074792e-01,  7.4321710e-02, -1.8569835e-01, ...,\n",
      "        -1.0094425e-02, -4.7418615e-03, -2.4937972e-02],\n",
      "       [-3.4683920e-02,  4.0236317e-02, -1.6245233e-02, ...,\n",
      "        -9.7338473e-03, -1.5374487e-02, -6.9756277e-02]], dtype=float32))\n",
      "(array([ 2.27441635e+02,  1.44173455e+00,  8.40316057e-01,  2.64461070e-01,\n",
      "        1.54782444e-01,  7.92009234e-02,  2.56947950e-02,  2.12064534e-02,\n",
      "        1.55124925e-02,  9.27975494e-03,  6.34921389e-03,  5.82798850e-03,\n",
      "        3.66137456e-03,  2.51497608e-03,  2.20196415e-03,  1.87024137e-03,\n",
      "        1.52957533e-03,  1.35396968e-03,  1.07142609e-03,  9.42935178e-04,\n",
      "        7.20648444e-04,  5.48729964e-04,  4.52266482e-04,  4.43060213e-04,\n",
      "        3.88701592e-04,  3.53707466e-04,  2.97320163e-04,  2.32727121e-04,\n",
      "        2.05740944e-04,  1.80153074e-04,  1.63590215e-04,  1.29546796e-04,\n",
      "        9.59894824e-05,  8.49369681e-05,  6.95462732e-05,  5.83801921e-05,\n",
      "        5.05174357e-05,  4.39145224e-05,  3.40578918e-05,  3.07079681e-05,\n",
      "        2.83977297e-05,  2.18962341e-05,  1.89765487e-05,  1.17320496e-05,\n",
      "        1.04384926e-05,  8.31917350e-06,  8.06888147e-06,  6.61217427e-06,\n",
      "       -4.95420363e-06,  5.23886774e-06, -4.49353320e-06,  3.69070040e-06,\n",
      "       -2.51980327e-06,  3.05279127e-06,  2.76842115e-06,  2.28872500e-06,\n",
      "       -2.04977141e-06,  1.98055682e-06,  1.61090009e-06, -1.45514116e-06,\n",
      "        1.30482272e-06, -1.27361818e-06, -1.23792302e-06, -1.01509295e-06,\n",
      "        1.09506516e-06,  9.53046765e-07, -8.08355992e-07,  7.89351645e-07,\n",
      "       -7.43621683e-07, -7.12338760e-07, -6.17037585e-07,  6.84523172e-07,\n",
      "        6.60576916e-07,  5.99333987e-07,  5.23748213e-07,  4.63494302e-07,\n",
      "       -5.26608005e-07, -4.76552060e-07, -4.36096201e-07, -3.91735853e-07,\n",
      "        4.04686432e-07,  3.38863344e-07,  3.25320627e-07, -3.17459865e-07,\n",
      "        2.42702356e-07,  2.35711113e-07, -2.88737340e-07, -2.74592594e-07,\n",
      "       -2.28537431e-07,  2.22540933e-07,  1.85446311e-07, -1.74358803e-07,\n",
      "       -1.69014413e-07, -1.66519598e-07,  1.48578451e-07,  1.35962438e-07,\n",
      "        1.02860099e-07, -1.02290095e-07, -1.13097890e-07, -8.03575801e-08,\n",
      "        8.36526155e-08,  7.64530412e-08,  5.36130393e-08,  4.74075215e-08,\n",
      "       -6.21481675e-08, -4.61944119e-08, -4.30395914e-08,  2.66432068e-08,\n",
      "       -3.24456693e-08, -2.76585013e-08, -1.91578096e-08,  2.21076579e-08,\n",
      "        1.74044104e-08,  1.48165897e-08, -1.41330831e-08, -8.21333934e-09,\n",
      "        1.11885182e-10,  5.65256864e-09,  4.22847135e-09,  3.28217986e-09],\n",
      "      dtype=float32), array([[ 0.01916525,  0.11544386, -0.06739692, ..., -0.02293308,\n",
      "         0.01440811, -0.00213373],\n",
      "       [ 0.03663648, -0.00487533,  0.12717368, ...,  0.05232817,\n",
      "         0.02086459, -0.04805378],\n",
      "       [ 0.0266493 , -0.03494672, -0.10031909, ..., -0.07492847,\n",
      "         0.16901831, -0.07039157],\n",
      "       ...,\n",
      "       [-0.05551194,  0.05108934, -0.03714012, ...,  0.11346474,\n",
      "        -0.01794652,  0.05952028],\n",
      "       [ 0.15288134,  0.13612317, -0.1361681 , ...,  0.00787342,\n",
      "        -0.02052599,  0.01877122],\n",
      "       [ 0.0721394 , -0.02382719, -0.06141103, ...,  0.02958411,\n",
      "        -0.0689098 , -0.02873454]], dtype=float32))\n",
      "(array([ 3.7625668e+02,  1.9205723e+00,  1.0451099e+00,  7.9924273e-01,\n",
      "        1.5841794e-01,  6.7645967e-02,  3.1593632e-02,  2.3936799e-02,\n",
      "        1.7060999e-02,  1.1513069e-02,  8.7970095e-03,  5.4134442e-03,\n",
      "        4.7106063e-03,  3.4860794e-03,  3.1121774e-03,  2.5941227e-03,\n",
      "        2.0201348e-03,  1.6835273e-03,  1.3485231e-03,  1.1624972e-03,\n",
      "        1.0783254e-03,  8.6771266e-04,  6.0836406e-04,  5.0082977e-04,\n",
      "        4.7269757e-04,  3.3467068e-04,  2.6424247e-04,  2.2061354e-04,\n",
      "        1.8337759e-04,  1.6368793e-04,  1.6112182e-04,  1.3103674e-04,\n",
      "        1.0330978e-04,  9.7156088e-05,  9.3755101e-05,  6.3036903e-05,\n",
      "        5.9543305e-05,  5.1474410e-05,  4.5717061e-05,  4.0564781e-05,\n",
      "        3.0608713e-05,  2.9052018e-05,  2.5935762e-05,  2.0573381e-05,\n",
      "        1.7740975e-05,  1.3868904e-05,  1.2690673e-05,  1.0640115e-05,\n",
      "       -7.4125815e-06,  8.9840378e-06,  6.5922509e-06,  6.1051792e-06,\n",
      "       -5.0354838e-06, -4.7582425e-06, -3.6191323e-06,  4.3129594e-06,\n",
      "        3.8743783e-06,  3.4088068e-06, -2.9573957e-06,  2.6531588e-06,\n",
      "       -2.4567055e-06, -2.3269015e-06,  2.2362599e-06, -1.7577672e-06,\n",
      "        1.8417055e-06, -1.5477387e-06, -1.4486905e-06,  1.4142327e-06,\n",
      "        1.3697747e-06, -1.1517074e-06,  1.1937776e-06,  1.0764799e-06,\n",
      "        9.0939557e-07, -9.8685302e-07, -8.5331050e-07, -7.8976149e-07,\n",
      "        7.2660697e-07, -6.8581699e-07, -5.0480560e-07,  5.4340256e-07,\n",
      "        5.5161007e-07, -4.4079124e-07,  4.8600282e-07,  4.5134499e-07,\n",
      "       -3.9486909e-07,  4.3272794e-07, -3.3424425e-07,  3.3620299e-07,\n",
      "       -2.9818040e-07,  2.4748545e-07, -2.3423715e-07, -2.0555109e-07,\n",
      "       -1.9253469e-07,  2.0890975e-07,  2.1888302e-07,  1.6838953e-07,\n",
      "       -1.4017304e-07,  1.2362803e-07,  1.0532908e-07, -1.2202841e-07,\n",
      "       -1.0573071e-07, -8.6348876e-08, -7.6496242e-08,  9.4490382e-08,\n",
      "        6.9231135e-08, -4.7101540e-08, -3.8292040e-08,  4.8445958e-08,\n",
      "        4.7595602e-08,  3.4334331e-08,  2.8361555e-08, -2.2505549e-08,\n",
      "        1.8252218e-08,  1.1250395e-08,  8.1337825e-09,  3.4857937e-09,\n",
      "       -1.0785160e-08,  1.1670262e-10, -6.5515060e-09, -6.2664127e-09],\n",
      "      dtype=float32), array([[ 0.04494506,  0.13727526,  0.09721293, ..., -0.00369832,\n",
      "         0.0471925 ,  0.0005404 ],\n",
      "       [ 0.04281762,  0.0145203 , -0.149775  , ..., -0.06690347,\n",
      "        -0.03081306,  0.04232686],\n",
      "       [ 0.01661879, -0.02368602,  0.06879453, ...,  0.0222451 ,\n",
      "        -0.12660433, -0.04486825],\n",
      "       ...,\n",
      "       [-0.04608894,  0.02141465,  0.0515827 , ..., -0.041807  ,\n",
      "        -0.05478972,  0.05077569],\n",
      "       [ 0.17472416,  0.09058949,  0.13411236, ...,  0.01182797,\n",
      "        -0.00961527, -0.00961678],\n",
      "       [ 0.06607392, -0.01688813,  0.05482759, ...,  0.02179618,\n",
      "         0.01415728, -0.01938756]], dtype=float32))\n",
      "(array([ 2.9016467e+02,  2.1851449e+00,  5.4173726e-01,  1.3492003e-01,\n",
      "        5.2488510e-02,  2.8545469e-02,  1.7554639e-02,  1.2682856e-02,\n",
      "        5.2916924e-03,  4.7884304e-03,  4.5464435e-03,  3.1509965e-03,\n",
      "        2.8518417e-03,  2.3700553e-03,  2.0554541e-03,  1.8620525e-03,\n",
      "        1.1757049e-03,  9.4745302e-04,  7.1299291e-04,  6.5560808e-04,\n",
      "        3.8551292e-04,  3.7266509e-04,  3.1056438e-04,  3.1324523e-04,\n",
      "        2.2458687e-04,  1.8336352e-04,  1.5194627e-04,  1.2756274e-04,\n",
      "        1.3064430e-04,  1.0220877e-04,  8.2683538e-05,  7.5709577e-05,\n",
      "        7.2373798e-05,  5.7686237e-05,  4.0376752e-05,  3.8475879e-05,\n",
      "        3.5468136e-05,  2.9301340e-05,  2.7293258e-05,  2.3781540e-05,\n",
      "        1.8811905e-05,  1.6057847e-05,  1.3349993e-05,  1.0939998e-05,\n",
      "        9.6568974e-06,  9.3493318e-06, -5.4887410e-06,  7.2832386e-06,\n",
      "        6.0973211e-06,  5.7378884e-06, -4.3756895e-06,  4.5313832e-06,\n",
      "        3.8666321e-06, -3.2167775e-06,  3.2445405e-06,  2.9058315e-06,\n",
      "       -2.7580081e-06, -2.5036018e-06, -2.2688373e-06,  1.9097956e-06,\n",
      "        1.6265635e-06, -1.4816839e-06,  1.4052320e-06, -1.2997317e-06,\n",
      "       -1.2085263e-06, -1.1387392e-06,  1.1749903e-06,  1.0924016e-06,\n",
      "       -8.4917275e-07,  7.9513802e-07,  7.7278719e-07, -7.3707196e-07,\n",
      "        6.5157832e-07,  6.2427512e-07,  5.6363268e-07, -6.0956057e-07,\n",
      "       -5.8028809e-07, -4.8386573e-07, -4.5776284e-07, -4.2104492e-07,\n",
      "        4.0752897e-07,  3.8131000e-07,  3.6666344e-07, -3.3461203e-07,\n",
      "        2.9751072e-07,  2.7224806e-07, -2.7892816e-07, -2.4625672e-07,\n",
      "        2.0692578e-07,  1.9573277e-07, -1.9366017e-07, -2.0497725e-07,\n",
      "       -1.4842045e-07, -1.2359786e-07,  1.3277463e-07,  1.1911653e-07,\n",
      "        1.0028986e-07, -1.0127691e-07,  9.1946944e-08,  7.1655847e-08,\n",
      "       -7.8952937e-08, -6.8966351e-08,  4.8687834e-08,  4.3034657e-08,\n",
      "       -5.4241472e-08, -4.1332548e-08, -3.4083552e-08, -3.6665273e-08,\n",
      "       -2.7413899e-08,  3.0841306e-08,  2.1154923e-08, -1.9047754e-08,\n",
      "       -1.5130443e-08, -1.0040661e-08,  1.7056687e-08,  1.0827508e-08,\n",
      "        8.5146654e-09,  4.4603587e-09, -1.6917043e-09, -2.0584073e-10],\n",
      "      dtype=float32), array([[ 0.03693044,  0.04100912, -0.09676227, ..., -0.04483564,\n",
      "         0.01150159,  0.01417542],\n",
      "       [ 0.04355961,  0.01373025,  0.14382999, ...,  0.06057893,\n",
      "         0.00838495,  0.07151929],\n",
      "       [ 0.01459008, -0.05246904, -0.07551429, ...,  0.19597572,\n",
      "         0.03198868,  0.08872385],\n",
      "       ...,\n",
      "       [-0.04304908,  0.088985  , -0.02302222, ...,  0.03053412,\n",
      "         0.01279452, -0.02173715],\n",
      "       [ 0.15031537, -0.01401581, -0.17458977, ...,  0.00882037,\n",
      "         0.00593492,  0.01882637],\n",
      "       [ 0.0567973 , -0.07980361, -0.08291643, ...,  0.00625149,\n",
      "         0.03785424,  0.01712869]], dtype=float32))\n",
      "(array([ 4.99046600e+02,  1.19158192e+01,  2.24616408e+00,  1.77700615e+00,\n",
      "        3.25123519e-01,  2.12637424e-01,  1.66008249e-01,  8.56941640e-02,\n",
      "        6.60465211e-02,  5.01776896e-02,  3.88599522e-02,  3.22906077e-02,\n",
      "        2.45536976e-02,  1.96886845e-02,  1.42024336e-02,  1.24458279e-02,\n",
      "        1.09746605e-02,  7.62801524e-03,  6.40797382e-03,  5.43792360e-03,\n",
      "        4.74336650e-03,  3.60945729e-03,  3.34099820e-03,  2.54011853e-03,\n",
      "        2.10912968e-03,  1.93536584e-03,  1.88021350e-03,  1.42931822e-03,\n",
      "        1.22898642e-03,  9.74374416e-04,  7.46579317e-04,  6.62200560e-04,\n",
      "        6.05648209e-04,  5.59860724e-04,  4.51811327e-04,  3.51682276e-04,\n",
      "        3.24813096e-04,  2.73132406e-04,  2.27315250e-04,  1.72333457e-04,\n",
      "        1.60165422e-04,  1.50436492e-04,  9.76250158e-05,  9.13560580e-05,\n",
      "        7.15812566e-05,  5.74085752e-05,  4.24263126e-05,  4.36669470e-05,\n",
      "        3.10215437e-05,  2.37204440e-05,  9.88644570e-06, -9.26778557e-06,\n",
      "       -7.60968851e-06,  5.86243141e-06,  4.96439861e-06, -5.54441658e-06,\n",
      "        4.32132219e-06, -4.77762433e-06, -3.51534527e-06, -3.28910505e-06,\n",
      "       -3.09498091e-06,  2.92706113e-06, -2.51981010e-06,  2.33801234e-06,\n",
      "        2.20317293e-06,  1.97345480e-06, -1.76860419e-06, -1.69402824e-06,\n",
      "        1.72229124e-06,  1.61599553e-06, -1.60981665e-06,  1.24407154e-06,\n",
      "       -1.21886717e-06, -1.02244087e-06,  1.10282781e-06,  1.00778004e-06,\n",
      "       -8.11116308e-07,  8.49976232e-07,  7.80846506e-07, -6.50816958e-07,\n",
      "       -6.14425346e-07,  5.14795147e-07, -5.55876682e-07, -4.96182281e-07,\n",
      "        4.91958531e-07,  4.44547624e-07, -4.33911765e-07, -4.08748178e-07,\n",
      "        3.87191648e-07,  3.32474769e-07,  2.63635030e-07, -2.98843020e-07,\n",
      "       -2.56559730e-07, -2.33559760e-07,  2.33353987e-07, -1.91977108e-07,\n",
      "        1.88700682e-07, -1.70300666e-07,  1.44164304e-07, -9.13433098e-08,\n",
      "       -7.57637011e-08,  9.63970805e-08,  8.43498213e-08,  7.57025589e-08,\n",
      "        5.74669592e-08, -5.02858377e-08,  5.03333339e-08, -3.35655201e-08,\n",
      "        3.65656661e-08, -2.16139817e-08, -1.48874486e-08,  1.66243659e-08,\n",
      "       -2.49500309e-10,  2.06327355e-09,  4.06204892e-09,  5.36040279e-09,\n",
      "        2.89370465e-08, -2.37107134e-08, -4.73553019e-09, -6.90581059e-09],\n",
      "      dtype=float32), array([[-0.06631477, -0.12298723, -0.14357875, ..., -0.00291939,\n",
      "        -0.00364592, -0.00161559],\n",
      "       [-0.04873394, -0.01448398,  0.1292615 , ..., -0.09980863,\n",
      "        -0.0519508 ,  0.05458564],\n",
      "       [-0.01275353,  0.03057876, -0.05484244, ...,  0.18139037,\n",
      "         0.04381365,  0.02572218],\n",
      "       ...,\n",
      "       [ 0.04048718, -0.02808284, -0.06898768, ..., -0.03722822,\n",
      "         0.04119031, -0.00288356],\n",
      "       [-0.18223763, -0.00072267, -0.17935461, ...,  0.01665782,\n",
      "        -0.00979581, -0.00504959],\n",
      "       [-0.0636754 ,  0.02725043, -0.06506373, ...,  0.01715853,\n",
      "         0.01949404,  0.02583347]], dtype=float32))\n",
      "(array([ 6.8061414e+02,  3.5828066e+00,  1.7354512e+00,  5.7150984e-01,\n",
      "        2.2082059e-01,  5.1724311e-02,  4.6573367e-02,  3.1886671e-02,\n",
      "        2.2881219e-02,  1.4675717e-02,  1.2714423e-02,  8.0566844e-03,\n",
      "        6.8050907e-03,  5.3916425e-03,  4.8120054e-03,  3.9077802e-03,\n",
      "        3.3095623e-03,  2.4832990e-03,  1.5960329e-03,  1.4146960e-03,\n",
      "        1.0430588e-03,  8.3524070e-04,  6.6738430e-04,  6.1799865e-04,\n",
      "        5.6356337e-04,  4.6139988e-04,  3.3976205e-04,  2.8393805e-04,\n",
      "        2.2642373e-04,  2.0254277e-04,  1.7525427e-04,  1.5926419e-04,\n",
      "        1.4628796e-04,  1.2448267e-04,  9.6739095e-05,  7.9860758e-05,\n",
      "        7.2604424e-05,  6.7553345e-05,  5.3527852e-05,  5.1133975e-05,\n",
      "        4.0401101e-05,  3.5236208e-05,  3.0770483e-05,  2.9559986e-05,\n",
      "        2.3927421e-05,  1.7593429e-05,  1.6629643e-05,  1.5875548e-05,\n",
      "       -1.2727066e-05, -1.1813100e-05,  1.2837325e-05, -9.3515273e-06,\n",
      "        1.0222432e-05, -8.5041802e-06,  8.7259523e-06, -7.1003838e-06,\n",
      "        6.8306199e-06,  6.3133302e-06, -5.2489390e-06, -4.8655816e-06,\n",
      "        4.9905370e-06, -4.0467280e-06,  4.3972959e-06,  3.9585511e-06,\n",
      "        3.6451979e-06, -3.4252432e-06, -3.1347977e-06, -2.4617909e-06,\n",
      "        2.9091916e-06,  2.4529502e-06,  2.5784157e-06, -1.9388344e-06,\n",
      "        2.1095027e-06, -1.8194601e-06,  1.9147401e-06,  1.4405254e-06,\n",
      "       -1.3308357e-06, -1.2114923e-06, -1.1049900e-06,  1.1455714e-06,\n",
      "        9.9471072e-07,  9.1514005e-07,  7.5362288e-07, -8.2851761e-07,\n",
      "       -7.4694884e-07, -7.1472681e-07, -5.4209522e-07,  6.7491032e-07,\n",
      "        5.6155898e-07,  5.0802794e-07, -4.0692225e-07, -3.5932683e-07,\n",
      "        3.5049712e-07, -3.1702652e-07,  2.3532826e-07, -2.3967002e-07,\n",
      "       -1.8674879e-07,  1.9326455e-07, -1.4254266e-07,  1.5476685e-07,\n",
      "        1.4223284e-07, -1.1663865e-07, -8.9172865e-08,  9.8027108e-08,\n",
      "        8.8039293e-08, -7.3024580e-08,  5.6355862e-08, -4.1721432e-08,\n",
      "        4.1565368e-08, -2.6937672e-08,  3.4589061e-08, -1.5600857e-08,\n",
      "        2.1770687e-08,  1.7519868e-08,  1.3271003e-08, -1.0540530e-08,\n",
      "       -7.8766826e-11,  4.6446753e-09, -7.8360269e-09, -5.9694836e-09],\n",
      "      dtype=float32), array([[ 0.07831949,  0.18918426,  0.05223808, ...,  0.00067261,\n",
      "        -0.01616733, -0.00635138],\n",
      "       [ 0.05087724,  0.04870275, -0.14565532, ...,  0.00799332,\n",
      "         0.01894837, -0.05097054],\n",
      "       [ 0.01046503, -0.03315005,  0.04440186, ..., -0.06040223,\n",
      "        -0.02110825,  0.11317161],\n",
      "       ...,\n",
      "       [-0.0401245 ,  0.03066666,  0.09901865, ..., -0.02928218,\n",
      "        -0.01731979, -0.02044586],\n",
      "       [ 0.18405585, -0.00058202,  0.09432194, ...,  0.00480166,\n",
      "        -0.0023575 ,  0.00183063],\n",
      "       [ 0.06230105, -0.02079463,  0.02518882, ...,  0.00888382,\n",
      "         0.00179508, -0.02571895]], dtype=float32))\n",
      "(array([ 4.28771759e+02,  1.36684346e+00,  4.93959963e-01,  3.98920923e-01,\n",
      "        1.56481355e-01,  1.14091493e-01,  6.81834966e-02,  4.12786007e-02,\n",
      "        3.77871096e-02,  2.94530112e-02,  1.25012435e-02,  9.83286090e-03,\n",
      "        8.20542127e-03,  6.46762783e-03,  5.07618859e-03,  4.25012037e-03,\n",
      "        3.05447564e-03,  2.21168553e-03,  2.18367181e-03,  1.55685423e-03,\n",
      "        1.28006691e-03,  1.15120562e-03,  8.95693665e-04,  8.47909250e-04,\n",
      "        7.61729665e-04,  5.95581252e-04,  5.41500282e-04,  4.45472891e-04,\n",
      "        3.33821634e-04,  2.99998326e-04,  2.81334505e-04,  2.55896739e-04,\n",
      "        2.15003514e-04,  1.89635452e-04,  1.55915855e-04,  1.24899030e-04,\n",
      "        1.15901545e-04,  9.92843852e-05,  8.96114143e-05,  8.56617116e-05,\n",
      "        5.67253592e-05,  5.48424287e-05,  4.64076475e-05,  4.03561608e-05,\n",
      "        3.18525999e-05,  2.79783908e-05,  2.36030228e-05,  2.21391929e-05,\n",
      "        1.53501642e-05,  1.37305015e-05, -1.03135344e-05, -6.32150204e-06,\n",
      "        6.35774177e-06,  5.55874840e-06, -4.48429910e-06,  4.80263952e-06,\n",
      "       -3.54891722e-06,  3.93329856e-06, -2.96667781e-06,  3.21425887e-06,\n",
      "       -2.58170235e-06,  2.44914122e-06,  2.29654620e-06,  1.81723988e-06,\n",
      "       -1.86691921e-06, -1.75012315e-06, -1.47006335e-06,  1.37697305e-06,\n",
      "       -1.28512045e-06,  1.20486175e-06,  1.16067190e-06,  8.81656774e-07,\n",
      "        8.41046642e-07, -1.04077935e-06, -8.34350999e-07, -8.12086057e-07,\n",
      "       -9.60165039e-07,  6.87851241e-07,  5.83166241e-07,  4.83445547e-07,\n",
      "       -5.97543135e-07, -5.54805524e-07, -5.27909094e-07, -4.02071805e-07,\n",
      "        4.26677900e-07,  3.59438474e-07, -2.95395409e-07, -2.56124025e-07,\n",
      "        2.73911070e-07,  2.50292999e-07,  1.97171360e-07,  1.78631737e-07,\n",
      "       -2.20984376e-07, -1.72518185e-07, -1.46285274e-07,  1.34903189e-07,\n",
      "       -1.06083071e-07,  1.02540163e-07, -9.21711845e-08, -7.48344391e-08,\n",
      "        7.90025041e-08,  6.27462242e-08,  5.82194062e-08, -5.68649448e-08,\n",
      "       -5.09769329e-08,  4.25153424e-08,  3.54723930e-08, -3.98634157e-08,\n",
      "       -2.62273332e-08,  2.24840626e-08, -2.22788437e-08, -1.36573171e-08,\n",
      "        1.08551959e-08, -1.02771800e-08, -8.54321502e-09,  7.23758742e-09,\n",
      "        3.89730248e-09,  3.49785645e-09,  3.63817337e-10, -1.20324428e-09],\n",
      "      dtype=float32), array([[ 4.17752415e-02,  7.70547241e-02,  1.28712863e-01, ...,\n",
      "         3.18954401e-02,  1.68471392e-02, -1.18063409e-02],\n",
      "       [ 4.91311997e-02, -8.03008676e-02, -1.62017539e-01, ...,\n",
      "        -4.55837435e-04, -1.39103096e-03, -3.64704914e-02],\n",
      "       [ 1.50673979e-04,  1.63884200e-02,  3.06671653e-02, ...,\n",
      "         1.59599986e-02, -8.53268057e-02,  1.51555777e-01],\n",
      "       ...,\n",
      "       [-1.68455280e-02,  8.48696288e-03,  1.17468648e-01, ...,\n",
      "         5.30642346e-02,  7.47781694e-02, -1.06693506e-01],\n",
      "       [ 1.57839462e-01,  9.29918140e-02,  4.20879163e-02, ...,\n",
      "        -4.76708636e-03,  4.55044629e-03, -3.35650891e-03],\n",
      "       [ 3.51303630e-02,  3.57572436e-02,  6.00963607e-02, ...,\n",
      "         1.04430407e-01,  4.50499468e-02,  1.14862241e-01]], dtype=float32))\n",
      "(array([ 3.75956665e+02,  8.87966931e-01,  1.10493138e-01,  5.65680601e-02,\n",
      "        3.86856496e-02,  3.19294445e-02,  2.17894055e-02,  1.24999080e-02,\n",
      "        1.00055877e-02,  5.95099479e-03,  4.13260516e-03,  3.68786254e-03,\n",
      "        2.29393877e-03,  1.95530872e-03,  1.27319014e-03,  1.14921213e-03,\n",
      "        7.99204048e-04,  6.27809553e-04,  5.10896207e-04,  3.99755896e-04,\n",
      "        3.41811858e-04,  3.11306532e-04,  2.50755635e-04,  2.18877103e-04,\n",
      "        1.68818107e-04,  1.42125806e-04,  1.32320842e-04,  1.15335206e-04,\n",
      "        1.13033835e-04,  9.16499775e-05,  7.31745095e-05,  5.92010401e-05,\n",
      "        5.11755970e-05,  4.41642915e-05,  3.77147589e-05,  3.49747170e-05,\n",
      "        2.45709653e-05,  2.40933095e-05, -1.21825369e-05,  1.58275034e-05,\n",
      "        1.44340574e-05,  1.39737840e-05,  1.33266021e-05,  1.18168100e-05,\n",
      "        1.09848561e-05,  1.01552941e-05, -7.52862297e-06,  7.61722958e-06,\n",
      "        6.40080452e-06,  6.25726761e-06,  5.81208405e-06, -5.19058040e-06,\n",
      "       -4.73339014e-06,  5.03203000e-06, -3.43599322e-06,  3.74971160e-06,\n",
      "        3.33575804e-06, -2.99642988e-06,  2.68082476e-06, -2.33486207e-06,\n",
      "        2.09515974e-06, -1.93092978e-06,  2.03213244e-06, -1.65578297e-06,\n",
      "        1.67794144e-06, -1.37274981e-06,  1.36781057e-06,  1.05012828e-06,\n",
      "       -1.15751209e-06, -1.02068964e-06, -7.47694855e-07,  8.95708695e-07,\n",
      "        8.35179605e-07,  7.85685927e-07, -6.31835235e-07,  6.25161363e-07,\n",
      "       -5.40833128e-07,  5.88357352e-07,  5.29047725e-07, -4.65202902e-07,\n",
      "       -3.97996757e-07,  4.30686669e-07,  3.74285065e-07,  2.95781319e-07,\n",
      "        2.87495823e-07, -3.30272513e-07, -2.81830012e-07, -2.56655142e-07,\n",
      "        2.38014664e-07,  2.14590116e-07,  1.88731860e-07,  1.63014391e-07,\n",
      "       -1.80699814e-07, -1.59687346e-07,  1.23112571e-07,  1.08343947e-07,\n",
      "       -1.07982657e-07,  8.15154380e-08, -1.03040676e-07,  5.49065149e-08,\n",
      "        5.07377358e-08, -8.05151998e-08, -7.35982297e-08, -6.84926107e-08,\n",
      "       -5.66418343e-08,  4.06085654e-08,  3.17163185e-08, -2.95051841e-08,\n",
      "        1.77294091e-08,  1.42066936e-08, -1.94787759e-08, -1.85964115e-08,\n",
      "       -1.73979693e-08, -1.39847574e-08,  5.25534416e-09, -8.20858403e-09,\n",
      "       -5.24970600e-09, -1.56808511e-09,  2.68938050e-09,  2.43656473e-09],\n",
      "      dtype=float32), array([[ 0.03590919, -0.14952654,  0.15266299, ..., -0.02581996,\n",
      "        -0.03017329,  0.0924283 ],\n",
      "       [ 0.05041123,  0.18545471,  0.02122653, ..., -0.0084039 ,\n",
      "        -0.01798318, -0.03330509],\n",
      "       [ 0.00510049, -0.05885055, -0.05708093, ..., -0.04359929,\n",
      "         0.16388574,  0.15245475],\n",
      "       ...,\n",
      "       [-0.02938856, -0.05286767,  0.02465883, ...,  0.10416842,\n",
      "        -0.02309239, -0.02470105],\n",
      "       [ 0.15986721, -0.10218126,  0.06369326, ..., -0.00309894,\n",
      "        -0.00070629, -0.00571471],\n",
      "       [ 0.04059396, -0.07020497, -0.05112768, ...,  0.02767621,\n",
      "        -0.00455845, -0.14466575]], dtype=float32))\n",
      "(array([ 3.93154053e+02,  8.48573267e-01,  2.18472466e-01,  6.53217807e-02,\n",
      "        2.68481374e-02,  2.17376463e-02,  1.77897718e-02,  1.75435282e-02,\n",
      "        1.47023117e-02,  4.01857914e-03,  3.37540009e-03,  3.05816648e-03,\n",
      "        1.64717855e-03,  1.52995263e-03,  1.26353593e-03,  9.97056952e-04,\n",
      "        8.63640918e-04,  5.81403961e-04,  4.96670546e-04,  3.62876890e-04,\n",
      "        3.55452765e-04,  3.24963359e-04,  2.76531064e-04,  2.29914163e-04,\n",
      "        1.74221321e-04,  1.57300223e-04,  1.38482792e-04,  1.30308777e-04,\n",
      "        8.94254481e-05,  7.68454920e-05,  6.61880986e-05,  6.09337003e-05,\n",
      "        4.76032910e-05,  4.80988238e-05,  4.26392362e-05,  3.44762811e-05,\n",
      "        3.04676105e-05,  2.68236818e-05,  2.16906883e-05,  1.94193999e-05,\n",
      "       -1.08499662e-05,  1.50208070e-05,  1.42059735e-05,  1.35991022e-05,\n",
      "        1.18102898e-05, -8.52913399e-06,  1.01742398e-05, -5.99429495e-06,\n",
      "        6.63206902e-06,  5.94521771e-06,  5.62681043e-06, -4.08939377e-06,\n",
      "        4.63981587e-06,  4.36033724e-06,  3.76171829e-06,  3.24711368e-06,\n",
      "       -3.09603797e-06, -2.82601900e-06, -2.69150701e-06,  2.63425454e-06,\n",
      "        2.24900123e-06,  1.75339687e-06, -1.56409783e-06, -1.37089398e-06,\n",
      "        1.61137234e-06, -1.18628589e-06,  1.35742050e-06,  1.31188960e-06,\n",
      "        9.98738074e-07,  9.74187174e-07, -9.18266210e-07, -8.32660419e-07,\n",
      "        8.09914923e-07, -6.79506854e-07,  7.16626232e-07, -6.01514330e-07,\n",
      "       -5.83462338e-07,  6.00761382e-07,  5.24867005e-07,  4.79801997e-07,\n",
      "        4.07517661e-07, -4.60288533e-07, -3.88959052e-07,  3.65721576e-07,\n",
      "        3.29182996e-07, -2.98613827e-07, -2.57354458e-07, -2.43505497e-07,\n",
      "       -2.24653476e-07,  2.64112401e-07,  2.32358687e-07,  2.14410036e-07,\n",
      "        1.64214597e-07, -1.75622660e-07, -1.47685483e-07, -1.40864117e-07,\n",
      "        1.21891205e-07, -1.11579403e-07, -8.36433003e-08,  9.53126076e-08,\n",
      "       -5.12049141e-08,  8.46866683e-08,  6.67264217e-08,  5.01051751e-08,\n",
      "       -4.06216145e-08,  4.43915056e-08,  3.60170809e-08, -3.12481880e-08,\n",
      "        3.07238857e-08, -2.38438034e-08,  2.42878837e-08, -1.81040907e-08,\n",
      "        1.15171961e-08, -9.70087655e-09, -6.18777785e-09, -4.56636284e-09,\n",
      "        5.62199265e-09,  4.02387856e-09, -4.93303176e-11, -5.18941612e-10],\n",
      "      dtype=float32), array([[ 0.03901331, -0.09221696,  0.06712265, ...,  0.02397368,\n",
      "         0.0296898 ,  0.00137805],\n",
      "       [ 0.04942362,  0.18154356,  0.04515174, ..., -0.01737057,\n",
      "        -0.02445038, -0.06328019],\n",
      "       [ 0.00437367, -0.05860408, -0.00501305, ...,  0.00533892,\n",
      "        -0.29954618,  0.30079103],\n",
      "       ...,\n",
      "       [-0.02842782, -0.04518285, -0.01461068, ...,  0.0162552 ,\n",
      "         0.03671124, -0.03429666],\n",
      "       [ 0.16067225, -0.07995825,  0.08342976, ..., -0.00407291,\n",
      "        -0.0051035 , -0.01513111],\n",
      "       [ 0.04012858, -0.05152519,  0.00681802, ..., -0.00081352,\n",
      "         0.0220173 , -0.01186368]], dtype=float32))\n",
      "(array([ 4.00445465e+02,  9.16940272e-01,  5.15913546e-01,  6.05261363e-02,\n",
      "        5.01822606e-02,  3.30588967e-02,  2.16750186e-02,  1.36476588e-02,\n",
      "        7.93328881e-03,  7.42283650e-03,  4.89498209e-03,  3.90098034e-03,\n",
      "        3.38313379e-03,  2.35174270e-03,  1.69579405e-03,  1.22110220e-03,\n",
      "        9.17105295e-04,  7.60899682e-04,  7.22808531e-04,  5.07843739e-04,\n",
      "        4.34520101e-04,  3.21683678e-04,  2.83635571e-04,  2.76615523e-04,\n",
      "        2.38822991e-04,  1.48000530e-04,  1.28377316e-04,  1.15348790e-04,\n",
      "        1.00818084e-04,  8.24144809e-05,  6.41904917e-05,  6.10370043e-05,\n",
      "        5.18690213e-05,  4.79469527e-05,  4.12262561e-05,  3.14451172e-05,\n",
      "        2.59775134e-05,  2.38945740e-05,  2.11847964e-05,  1.57715021e-05,\n",
      "        1.48971030e-05, -1.01352498e-05,  1.17459158e-05, -7.05146431e-06,\n",
      "        1.07487822e-05,  1.00730413e-05,  8.31016587e-06,  7.56636655e-06,\n",
      "       -4.96215489e-06,  6.17573278e-06, -4.10659140e-06,  5.45722469e-06,\n",
      "        4.84317343e-06,  4.53058965e-06, -3.13120563e-06,  3.37954634e-06,\n",
      "        2.89936793e-06, -2.59729700e-06,  2.64461528e-06, -2.08701317e-06,\n",
      "       -1.80182326e-06,  2.19544791e-06,  1.84342343e-06, -1.52172004e-06,\n",
      "        1.63143488e-06,  1.47562992e-06,  1.38994358e-06,  1.29003354e-06,\n",
      "       -1.12307077e-06, -9.88722263e-07, -8.73901740e-07,  9.66639163e-07,\n",
      "        9.17227965e-07, -7.23758262e-07,  7.41348856e-07,  7.02694820e-07,\n",
      "       -6.55475105e-07, -5.88488490e-07,  5.81841789e-07,  5.08893265e-07,\n",
      "        4.57026346e-07, -4.69936737e-07,  3.75233071e-07, -3.88045549e-07,\n",
      "       -3.50595286e-07,  3.43070582e-07,  2.96079662e-07, -2.37077046e-07,\n",
      "       -2.27390260e-07,  2.24815011e-07, -1.91246357e-07, -1.77787584e-07,\n",
      "        1.83421449e-07,  1.67968494e-07,  1.42287931e-07,  1.31880753e-07,\n",
      "       -1.35912231e-07, -1.10555227e-07,  1.04330901e-07,  9.90609905e-08,\n",
      "        6.86785384e-08, -8.09941483e-08, -6.60720971e-08, -5.97515140e-08,\n",
      "        5.06385867e-08,  3.34914851e-08, -3.81081051e-08, -3.59627137e-08,\n",
      "        2.57913708e-08, -2.39274147e-08,  1.45970720e-08,  1.08209610e-08,\n",
      "        9.26723409e-09, -1.75792323e-08, -1.38774015e-08, -1.19377681e-08,\n",
      "       -7.26769578e-09, -3.51181240e-09, -2.30137617e-10,  2.22303442e-09],\n",
      "      dtype=float32), array([[ 4.1397091e-02,  1.7251618e-01,  1.7586976e-01, ...,\n",
      "        -1.8026473e-02, -3.4770392e-02, -8.6632036e-03],\n",
      "       [ 4.9534656e-02, -1.4289197e-01,  9.3946420e-02, ...,\n",
      "        -1.6646950e-04, -2.0463955e-02, -1.6571381e-03],\n",
      "       [ 3.3178218e-03,  5.6562610e-02, -5.7334483e-02, ...,\n",
      "         1.9207010e-01, -1.0351212e-01,  1.2185822e-01],\n",
      "       ...,\n",
      "       [-2.6436625e-02,  4.6409272e-02,  3.0108616e-02, ...,\n",
      "        -4.3047834e-02,  5.4489806e-02,  7.8971259e-02],\n",
      "       [ 1.5952812e-01,  1.0251298e-01,  2.9935054e-03, ...,\n",
      "         3.0953113e-03,  8.0333743e-04,  8.5232491e-03],\n",
      "       [ 3.8695589e-02,  4.9312904e-02, -5.5860102e-02, ...,\n",
      "         2.5928803e-02,  2.2697777e-03,  1.2947404e-03]], dtype=float32))\n",
      "(array([ 4.35072571e+02,  2.09430599e+00,  1.05266964e+00,  2.47858137e-01,\n",
      "        1.38813198e-01,  1.02748610e-01,  5.65387495e-02,  3.90407853e-02,\n",
      "        3.04863509e-02,  2.34109722e-02,  1.47874560e-02,  1.15544563e-02,\n",
      "        5.58159733e-03,  4.92819725e-03,  4.53833677e-03,  3.00368434e-03,\n",
      "        2.69857328e-03,  2.18359032e-03,  1.86896243e-03,  1.19363843e-03,\n",
      "        1.10883883e-03,  9.42693849e-04,  8.47695919e-04,  6.44274114e-04,\n",
      "        4.73562191e-04,  4.10707376e-04,  3.06000788e-04,  2.30763675e-04,\n",
      "        1.54192909e-04,  1.46872102e-04,  1.22830912e-04,  7.46850783e-05,\n",
      "        6.51847076e-05,  5.59134787e-05,  4.73282998e-05,  3.56765013e-05,\n",
      "        3.12023476e-05,  2.58455111e-05,  2.24017604e-05, -1.52713965e-05,\n",
      "        2.04440894e-05,  1.47478804e-05,  1.38320038e-05, -8.20418791e-06,\n",
      "       -7.00165992e-06,  8.15299245e-06, -4.86247973e-06,  6.83026838e-06,\n",
      "        5.73608168e-06,  5.58891270e-06,  4.97684459e-06, -4.41825978e-06,\n",
      "        4.30787668e-06, -3.13999954e-06,  3.20974664e-06, -2.46144577e-06,\n",
      "        2.76337482e-06,  2.57318857e-06, -1.90847072e-06,  1.96630890e-06,\n",
      "        1.92393941e-06,  1.56572810e-06,  1.38400355e-06, -1.46875720e-06,\n",
      "       -1.33586070e-06, -1.22611118e-06,  1.16691251e-06,  1.06708751e-06,\n",
      "       -9.96915560e-07, -9.13936560e-07,  8.72317571e-07,  8.55953374e-07,\n",
      "       -7.50037032e-07, -6.09192739e-07, -4.50354833e-07,  7.10151255e-07,\n",
      "        6.78337415e-07,  5.70459122e-07,  5.06592301e-07,  4.29985590e-07,\n",
      "       -3.68834606e-07,  3.54468625e-07, -3.14311194e-07, -2.88830336e-07,\n",
      "       -2.17646800e-07,  2.60779871e-07,  2.80478531e-07,  2.34547514e-07,\n",
      "       -1.27280188e-07, -1.62048948e-07, -1.48896532e-07,  1.89509223e-07,\n",
      "        1.24082831e-07,  1.61637374e-07, -9.05180997e-08,  9.73513181e-08,\n",
      "        8.17870571e-08,  7.09414891e-08, -7.00764247e-08, -6.79221941e-08,\n",
      "       -5.77063410e-08,  5.31551230e-08,  4.72213806e-08, -3.54950629e-08,\n",
      "        3.24943308e-08, -2.80989152e-08,  2.59751314e-08,  3.74978946e-08,\n",
      "       -2.17271179e-08,  1.80053892e-08,  1.49496682e-08,  1.34661189e-08,\n",
      "       -1.39502063e-08, -1.28714905e-08, -9.99854421e-09,  7.61696306e-09,\n",
      "        3.87502297e-09,  2.90758750e-09, -3.49482798e-09, -1.51101409e-09],\n",
      "      dtype=float32), array([[ 0.05928909, -0.04088214, -0.00149637, ...,  0.00176609,\n",
      "        -0.00709042,  0.00181765],\n",
      "       [ 0.03413489,  0.02814905, -0.20839378, ...,  0.02983614,\n",
      "        -0.01597179,  0.06464867],\n",
      "       [-0.00635658, -0.04388798, -0.00352337, ..., -0.11271729,\n",
      "         0.1016356 , -0.01940547],\n",
      "       ...,\n",
      "       [ 0.00330991,  0.06201126,  0.05881098, ..., -0.02032084,\n",
      "         0.04493771, -0.07837608],\n",
      "       [ 0.15109429, -0.19816011,  0.0057014 , ..., -0.00208592,\n",
      "        -0.00291366,  0.02645651],\n",
      "       [ 0.01967122, -0.14479114, -0.00533459, ...,  0.00400603,\n",
      "         0.01257059,  0.09273273]], dtype=float32))\n",
      "(array([ 4.01201080e+02,  1.11879325e+00,  3.55716556e-01,  1.45652071e-01,\n",
      "        3.75829153e-02,  2.84465291e-02,  2.18451004e-02,  1.39448512e-02,\n",
      "        7.30984937e-03,  4.95314877e-03,  2.60736351e-03,  2.20607570e-03,\n",
      "        1.99537678e-03,  1.60086376e-03,  1.15726539e-03,  9.35553282e-04,\n",
      "        6.26473455e-04,  3.97739117e-04,  3.32304277e-04,  2.85088841e-04,\n",
      "        2.43497998e-04,  1.83735319e-04,  1.44860969e-04,  1.19424403e-04,\n",
      "        1.03465522e-04,  6.98338772e-05,  6.48193090e-05,  4.75383240e-05,\n",
      "        4.17651936e-05,  3.59969781e-05,  2.73574733e-05,  2.42531587e-05,\n",
      "        2.07093290e-05,  1.53359888e-05,  1.28282054e-05, -1.10476240e-05,\n",
      "       -7.53847735e-06, -7.00299552e-06,  9.06755668e-06,  8.65060429e-06,\n",
      "        6.84860561e-06,  6.68049051e-06,  5.31745491e-06,  4.51234746e-06,\n",
      "        4.06077379e-06, -4.01397483e-06, -3.81582231e-06,  3.38573045e-06,\n",
      "       -2.67507357e-06, -2.23350321e-06,  2.62492745e-06,  2.38024813e-06,\n",
      "        2.23659868e-06,  1.90967535e-06,  1.70210023e-06,  1.55370014e-06,\n",
      "       -1.62534411e-06, -1.46032426e-06, -1.39029282e-06,  1.41343401e-06,\n",
      "        1.27421697e-06, -1.03710408e-06,  1.20430923e-06, -8.41471547e-07,\n",
      "        8.51154482e-07, -6.36509014e-07,  7.14468001e-07,  6.85040447e-07,\n",
      "        5.82264249e-07, -5.47499781e-07,  5.74389617e-07, -4.45013427e-07,\n",
      "        3.96211249e-07, -3.94798462e-07, -3.66841675e-07,  3.87329777e-07,\n",
      "       -3.17229592e-07, -2.74353653e-07,  3.41043830e-07,  3.06699690e-07,\n",
      "        2.60843535e-07, -1.99868381e-07,  2.21754874e-07, -1.75499252e-07,\n",
      "        2.06107217e-07,  1.88660408e-07, -1.13178920e-07, -1.22914344e-07,\n",
      "        1.68269054e-07,  1.53556627e-07,  1.30408637e-07, -9.03135344e-08,\n",
      "       -7.87371164e-08,  1.09396545e-07,  9.12066582e-08, -6.44496936e-08,\n",
      "        5.68822394e-08, -5.06984179e-08, -4.08077234e-08,  5.14706180e-08,\n",
      "        4.67140460e-08,  3.64255754e-08,  3.94650357e-08, -2.94960163e-08,\n",
      "       -2.71095004e-08,  3.18541318e-08,  1.82389890e-08, -1.77158856e-08,\n",
      "        1.49906683e-08,  1.23901831e-08, -1.13283019e-08, -1.05559668e-08,\n",
      "       -7.19098070e-09, -8.42267411e-09,  8.07833356e-09,  6.89968704e-09,\n",
      "       -3.33806494e-09,  1.85180271e-09,  9.92166571e-10,  5.31420519e-10],\n",
      "      dtype=float32), array([[-0.05531058,  0.0023739 , -0.11322378, ..., -0.02037313,\n",
      "         0.01916867, -0.00142723],\n",
      "       [-0.03233535,  0.10336436,  0.11692628, ..., -0.0685108 ,\n",
      "         0.00203365,  0.01041938],\n",
      "       [ 0.00598686,  0.0794434 , -0.04815956, ..., -0.20575117,\n",
      "        -0.07059666,  0.01202718],\n",
      "       ...,\n",
      "       [ 0.00232094, -0.29041252, -0.02990665, ..., -0.08844409,\n",
      "         0.01026616,  0.06543482],\n",
      "       [-0.14226899, -0.01921016, -0.14966452, ...,  0.0134175 ,\n",
      "         0.00840838, -0.00808857],\n",
      "       [-0.01440188,  0.0851925 , -0.12827267, ..., -0.08163275,\n",
      "        -0.09671855, -0.03419326]], dtype=float32))\n",
      "(array([ 3.8805652e+02,  1.9917388e+00,  3.0281344e-01,  2.7638307e-01,\n",
      "        1.5216595e-01,  4.2372249e-02,  3.9232675e-02,  3.4366492e-02,\n",
      "        2.3152055e-02,  1.6647989e-02,  1.0273828e-02,  6.3750702e-03,\n",
      "        5.8218362e-03,  4.0809228e-03,  2.6042699e-03,  2.0768896e-03,\n",
      "        1.3700915e-03,  1.2767155e-03,  9.6687017e-04,  8.7506091e-04,\n",
      "        6.9298164e-04,  5.8019714e-04,  5.5759633e-04,  4.2147265e-04,\n",
      "        3.6632377e-04,  2.6051444e-04,  2.1644917e-04,  1.9106118e-04,\n",
      "        1.4555197e-04,  1.2577219e-04,  9.4076320e-05,  8.2484730e-05,\n",
      "        6.8912450e-05,  5.8439760e-05,  4.3084667e-05,  3.6096641e-05,\n",
      "        3.1167692e-05,  2.7085143e-05,  2.2405900e-05,  1.6532545e-05,\n",
      "        1.4658676e-05,  1.2462960e-05, -9.2616829e-06, -8.1739618e-06,\n",
      "        8.9422947e-06,  7.9784049e-06,  6.7750361e-06,  6.4753235e-06,\n",
      "       -5.0696663e-06,  5.1267866e-06, -3.9081956e-06,  4.5341271e-06,\n",
      "        4.0526302e-06,  3.5461537e-06,  2.9667829e-06, -2.5627576e-06,\n",
      "        2.6162418e-06,  2.4010769e-06,  2.1558546e-06, -1.9582544e-06,\n",
      "       -1.7936161e-06,  1.6252096e-06, -1.5097046e-06, -1.2811730e-06,\n",
      "        1.2337966e-06, -1.0297836e-06,  1.1696438e-06, -8.4443042e-07,\n",
      "        1.0294518e-06,  9.4642587e-07,  8.5819238e-07, -6.8905706e-07,\n",
      "        7.5251791e-07,  6.4500989e-07,  5.4108136e-07,  4.9692966e-07,\n",
      "       -5.5022196e-07, -5.1304420e-07, -4.2818328e-07, -3.9063664e-07,\n",
      "        3.6766090e-07, -3.5192775e-07,  3.1432464e-07,  2.7963003e-07,\n",
      "       -2.4372864e-07,  2.2602327e-07, -2.1945684e-07,  2.0172324e-07,\n",
      "        1.8473523e-07,  1.5797200e-07, -1.7797289e-07, -1.6121794e-07,\n",
      "       -1.4093881e-07,  1.1789407e-07,  9.4296098e-08, -9.6943985e-08,\n",
      "        8.5631257e-08, -6.8253321e-08, -7.2039192e-08, -6.0633468e-08,\n",
      "       -4.9641631e-08,  5.9297932e-08,  5.4216983e-08,  4.6897743e-08,\n",
      "       -3.2724632e-08, -2.5264335e-08,  2.8780802e-08,  2.4253010e-08,\n",
      "       -1.9691303e-08,  1.7386919e-08,  8.7346486e-09, -9.2756132e-09,\n",
      "       -6.9489987e-09, -8.2155394e-09, -4.0014196e-09,  5.3273475e-09,\n",
      "        3.6310575e-09,  2.8069302e-09,  9.3593566e-10, -1.7619176e-09],\n",
      "      dtype=float32), array([[ 0.04706799,  0.26307884, -0.16116   , ..., -0.03934695,\n",
      "        -0.04080132,  0.0163433 ],\n",
      "       [ 0.03485001, -0.0332923 ,  0.15124616, ..., -0.05892938,\n",
      "         0.0457625 , -0.02445433],\n",
      "       [-0.00325558, -0.00885104, -0.00262688, ...,  0.19133218,\n",
      "         0.01988527,  0.12658694],\n",
      "       ...,\n",
      "       [-0.01668269,  0.12011347, -0.08928305, ..., -0.00816786,\n",
      "         0.02022386,  0.0244243 ],\n",
      "       [ 0.14334868, -0.23137264, -0.146955  , ..., -0.00087775,\n",
      "        -0.0121411 ,  0.01277468],\n",
      "       [ 0.01318855, -0.06264329, -0.06188511, ..., -0.00760617,\n",
      "         0.06393053,  0.06594437]], dtype=float32))\n",
      "(array([ 4.89809204e+02,  9.97029483e-01,  3.01873565e-01,  2.51768142e-01,\n",
      "        1.08902633e-01,  3.13038155e-02,  2.47319490e-02,  1.91343576e-02,\n",
      "        9.79369786e-03,  6.17928198e-03,  3.32047301e-03,  2.59812968e-03,\n",
      "        1.44222681e-03,  1.10315939e-03,  1.05109299e-03,  6.98710792e-04,\n",
      "        6.05738664e-04,  4.37723502e-04,  3.89480090e-04,  2.85544287e-04,\n",
      "        2.28911318e-04,  2.16091415e-04,  1.79733775e-04,  1.45586833e-04,\n",
      "        1.42540695e-04,  1.01623657e-04,  9.30384122e-05,  7.40587930e-05,\n",
      "        6.63915926e-05,  5.75997692e-05,  4.47431557e-05,  3.41067571e-05,\n",
      "        2.71807548e-05, -1.68385523e-05,  2.30830537e-05,  2.20641814e-05,\n",
      "        1.65709644e-05,  1.62286851e-05, -1.32111472e-05,  1.38697969e-05,\n",
      "        1.12706875e-05,  1.09309049e-05,  1.04479795e-05,  1.02315644e-05,\n",
      "       -7.36623133e-06,  8.34428738e-06,  7.36500488e-06,  6.82293103e-06,\n",
      "        5.89898309e-06,  5.53614700e-06, -5.00570241e-06, -4.60994443e-06,\n",
      "       -3.83993483e-06,  4.70993564e-06,  3.91120602e-06,  3.51577796e-06,\n",
      "       -2.87493231e-06,  3.33784351e-06, -2.28597378e-06,  2.63695961e-06,\n",
      "       -1.99112719e-06,  2.18435503e-06,  1.94528275e-06,  1.86188322e-06,\n",
      "       -1.64142205e-06,  1.53356484e-06, -1.42023589e-06,  1.40779503e-06,\n",
      "        1.22416543e-06,  1.17513684e-06,  9.26574444e-07,  8.52538165e-07,\n",
      "       -1.06310881e-06, -9.52968776e-07, -8.74131217e-07, -7.88470913e-07,\n",
      "       -5.62549474e-07,  5.98040117e-07,  5.49532160e-07,  5.23837741e-07,\n",
      "       -4.60732480e-07,  4.74619043e-07, -3.75390925e-07,  3.80291112e-07,\n",
      "       -2.89463287e-07,  2.83102281e-07,  2.55699348e-07, -2.22657491e-07,\n",
      "       -1.87900071e-07,  2.11391139e-07,  1.96647960e-07, -1.57104580e-07,\n",
      "       -1.42609821e-07,  1.46923014e-07,  1.35484072e-07, -1.15564099e-07,\n",
      "        9.45747658e-08,  8.45127843e-08, -7.93990864e-08, -6.04750525e-08,\n",
      "        6.61795099e-08, -5.01921598e-08, -3.96814315e-08, -3.76144236e-08,\n",
      "        3.70353561e-08, -2.55249031e-08,  3.22392566e-08, -1.35696334e-08,\n",
      "       -1.20065149e-08,  2.21193250e-08, -9.17904774e-09,  1.68738481e-08,\n",
      "       -3.45148310e-09,  1.36170115e-08,  1.33035307e-08,  9.64345759e-09,\n",
      "        6.84698742e-10, -1.16844659e-10,  6.19178042e-09,  5.37754996e-09],\n",
      "      dtype=float32), array([[ 0.05349597, -0.2724638 , -0.07407331, ...,  0.00480756,\n",
      "        -0.00365765, -0.00185717],\n",
      "       [ 0.03724771,  0.03800857,  0.14480479, ...,  0.01858091,\n",
      "        -0.01012562, -0.04628932],\n",
      "       [-0.00518567,  0.01300407,  0.03944123, ..., -0.08364704,\n",
      "         0.10023373,  0.10553947],\n",
      "       ...,\n",
      "       [-0.00251972, -0.15412585, -0.14320084, ..., -0.02066819,\n",
      "         0.04392897, -0.02810602],\n",
      "       [ 0.15957257,  0.18731673, -0.17670329, ..., -0.00773957,\n",
      "        -0.01031716,  0.00343696],\n",
      "       [ 0.01968904,  0.0389556 , -0.02878336, ...,  0.07666934,\n",
      "        -0.0317051 , -0.03399414]], dtype=float32))\n",
      "(array([ 4.0367917e+02,  1.0613762e+00,  4.4629186e-01,  2.6200059e-01,\n",
      "        7.2111279e-02,  4.7423411e-02,  4.0781315e-02,  1.6649252e-02,\n",
      "        1.3159130e-02,  8.4619084e-03,  7.0799533e-03,  4.3254639e-03,\n",
      "        3.4814347e-03,  2.7430600e-03,  1.9627439e-03,  1.3571151e-03,\n",
      "        1.0473483e-03,  9.6914597e-04,  8.1885117e-04,  6.4772216e-04,\n",
      "        5.6396419e-04,  4.1822743e-04,  3.3066847e-04,  3.1130551e-04,\n",
      "        2.7220373e-04,  1.9060787e-04,  1.6249508e-04,  1.5980798e-04,\n",
      "        1.1354878e-04,  9.6181255e-05,  8.2700069e-05,  6.3098989e-05,\n",
      "        5.0988885e-05,  4.2626369e-05,  3.7874033e-05,  3.0092015e-05,\n",
      "        2.7892471e-05,  2.1241021e-05,  1.9803552e-05,  1.4884884e-05,\n",
      "       -1.1393011e-05,  1.1738528e-05,  1.0062089e-05, -7.3423048e-06,\n",
      "        8.1535172e-06,  7.1801028e-06, -5.5432511e-06, -4.4627745e-06,\n",
      "       -4.4002177e-06,  5.6919375e-06,  4.9215778e-06,  4.6326140e-06,\n",
      "        3.9545957e-06, -2.5547690e-06,  3.5428022e-06,  2.9835676e-06,\n",
      "        2.8163208e-06, -2.1535695e-06,  2.2434103e-06,  2.0050443e-06,\n",
      "       -1.9176377e-06, -1.7023789e-06,  1.6863481e-06,  1.4053015e-06,\n",
      "       -1.2335015e-06, -1.1135845e-06,  1.2516082e-06,  1.1069178e-06,\n",
      "        9.0398521e-07,  8.5419526e-07, -8.0904090e-07, -7.5919343e-07,\n",
      "        7.4036717e-07, -6.9919207e-07,  7.2473705e-07, -5.6222831e-07,\n",
      "        5.9729075e-07, -4.8828832e-07, -4.2757975e-07,  4.8734461e-07,\n",
      "        4.5354338e-07,  3.8806087e-07, -3.0094742e-07,  3.0695091e-07,\n",
      "       -2.5835141e-07, -2.4307056e-07,  2.9686112e-07,  2.5064526e-07,\n",
      "        2.2583549e-07, -1.7110182e-07, -1.5352110e-07,  1.9007054e-07,\n",
      "        1.7283280e-07,  1.4509018e-07, -1.2021854e-07, -9.0636362e-08,\n",
      "        1.0044089e-07,  9.0531465e-08,  6.8037068e-08,  6.3633159e-08,\n",
      "       -5.0693323e-08, -6.8252362e-08, -6.1274022e-08,  4.4064887e-08,\n",
      "       -4.0047436e-08,  4.0721645e-08, -2.2802674e-08,  2.6855991e-08,\n",
      "       -1.8985805e-08,  2.4668216e-08,  2.0105288e-08, -1.1929562e-08,\n",
      "       -9.0996508e-09, -6.5054033e-09,  7.4705673e-09,  6.6725852e-09,\n",
      "        4.3583090e-10,  4.5054485e-09,  2.0969524e-09, -2.4307421e-09],\n",
      "      dtype=float32), array([[ 0.05535151,  0.25561053,  0.00412367, ..., -0.00948786,\n",
      "        -0.01175839,  0.01190973],\n",
      "       [ 0.03578509, -0.0598914 , -0.02201495, ..., -0.01306247,\n",
      "        -0.00641636,  0.03294668],\n",
      "       [-0.0022208 ,  0.00096996,  0.00563369, ..., -0.0016755 ,\n",
      "         0.11738811,  0.13849796],\n",
      "       ...,\n",
      "       [-0.01539524,  0.21762894,  0.0170394 , ...,  0.05909264,\n",
      "         0.02944545,  0.04857827],\n",
      "       [ 0.14197513, -0.05438814,  0.25195563, ..., -0.00265409,\n",
      "         0.01964065,  0.00057028],\n",
      "       [ 0.01556968,  0.03128067,  0.13548408, ...,  0.0702621 ,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.10509089, -0.02554143]], dtype=float32))\n",
      "(array([ 4.70261078e+02,  4.54348236e-01,  2.52009690e-01,  1.29068270e-01,\n",
      "        5.19426540e-02,  2.97917686e-02,  1.54014975e-02,  8.43558088e-03,\n",
      "        4.55450406e-03,  3.07232118e-03,  2.55755428e-03,  2.07804772e-03,\n",
      "        1.14293257e-03,  9.64077655e-04,  9.23640502e-04,  8.71128344e-04,\n",
      "        5.16817265e-04,  4.58106224e-04,  3.98699252e-04,  2.93506047e-04,\n",
      "        2.26259799e-04,  1.70304804e-04,  1.40548902e-04,  1.16800089e-04,\n",
      "        1.00084209e-04,  8.34927705e-05,  7.21465476e-05,  5.93116129e-05,\n",
      "        5.27366756e-05,  4.48243845e-05,  3.61500279e-05,  2.85407750e-05,\n",
      "        2.65638864e-05,  1.96001911e-05, -1.29968048e-05, -1.13343394e-05,\n",
      "        1.65160909e-05,  1.43801335e-05,  1.40353814e-05,  1.21519379e-05,\n",
      "       -7.33786601e-06,  1.04795863e-05,  9.48250181e-06,  9.04949866e-06,\n",
      "        7.99070040e-06, -6.21026447e-06, -4.88645583e-06,  6.38604661e-06,\n",
      "        5.95795700e-06,  5.13603254e-06, -4.09358427e-06, -3.34094898e-06,\n",
      "       -2.92626373e-06,  4.78537549e-06,  4.30528007e-06,  4.44868601e-06,\n",
      "        3.29665954e-06,  3.10444193e-06,  2.72014790e-06, -2.18956166e-06,\n",
      "        2.15124305e-06,  2.10786766e-06, -1.60017521e-06,  1.78584730e-06,\n",
      "        1.71464023e-06, -1.39790632e-06,  1.56927047e-06, -1.12501232e-06,\n",
      "        1.16828892e-06,  9.70359338e-07, -8.14006910e-07, -7.91823766e-07,\n",
      "        7.81517372e-07,  7.09350161e-07, -6.59451530e-07, -5.32541605e-07,\n",
      "        5.80458163e-07,  5.73348643e-07, -4.18861049e-07,  4.88252567e-07,\n",
      "        4.94461460e-07,  4.11727939e-07,  3.25055140e-07, -3.24545908e-07,\n",
      "       -2.77460714e-07, -2.42058064e-07, -1.97562755e-07,  3.08104546e-07,\n",
      "        2.60585097e-07,  2.33797934e-07, -1.74762761e-07,  1.63114521e-07,\n",
      "        1.79106351e-07, -1.30785764e-07,  1.52821912e-07, -1.04946317e-07,\n",
      "        1.01027808e-07,  9.96045912e-08, -6.98470330e-08,  7.01585705e-08,\n",
      "       -5.26748423e-08,  5.77319028e-08, -4.70939909e-08,  4.81118505e-08,\n",
      "       -3.64583919e-08,  3.54520786e-08,  2.95461273e-08, -2.59592792e-08,\n",
      "        2.40527918e-08,  1.72392483e-08, -1.89589606e-08, -1.38093892e-08,\n",
      "        8.16731927e-09,  6.21207752e-09,  2.36035902e-09, -7.47819318e-09,\n",
      "       -5.56271118e-09, -6.05081230e-09,  2.76946882e-10, -1.67796954e-09],\n",
      "      dtype=float32), array([[-0.06065522, -0.02325486,  0.06821572, ..., -0.02782668,\n",
      "         0.00721826, -0.01269747],\n",
      "       [-0.03654904,  0.12283005, -0.09431005, ..., -0.05396403,\n",
      "        -0.01354887, -0.03761803],\n",
      "       [ 0.00261654, -0.01848575,  0.03163866, ...,  0.09749824,\n",
      "        -0.02248668, -0.12065271],\n",
      "       ...,\n",
      "       [ 0.01056157,  0.04176119, -0.01715583, ..., -0.00757697,\n",
      "        -0.00459302, -0.04857858],\n",
      "       [-0.15209161, -0.1813245 , -0.17022358, ...,  0.02037157,\n",
      "         0.00135937,  0.01474499],\n",
      "       [-0.01856854, -0.08367924, -0.02897632, ..., -0.01315152,\n",
      "         0.03425181,  0.04263688]], dtype=float32))\n",
      "(array([ 4.49236298e+02,  1.26714110e-01,  6.76719323e-02,  3.28556597e-02,\n",
      "        9.30603780e-03,  7.36951176e-03,  4.29932540e-03,  2.84925685e-03,\n",
      "        1.53154565e-03,  1.07573008e-03,  5.18662506e-04,  4.14578040e-04,\n",
      "        3.34304146e-04,  2.34558684e-04,  1.88796766e-04,  1.24910439e-04,\n",
      "        8.17459004e-05,  7.43918135e-05,  6.01161191e-05,  4.87802390e-05,\n",
      "        3.58483157e-05,  2.84375037e-05,  2.19549711e-05,  2.12294763e-05,\n",
      "       -1.51659660e-05,  1.73204771e-05, -1.27326939e-05,  1.48341815e-05,\n",
      "        1.41427254e-05,  1.37527932e-05,  1.15993762e-05, -9.82061010e-06,\n",
      "       -8.15650674e-06, -7.84863096e-06,  8.73956014e-06,  7.72683143e-06,\n",
      "        7.08666585e-06, -5.19620517e-06,  6.39296195e-06,  6.15017325e-06,\n",
      "        5.33716820e-06,  5.10884047e-06,  4.22921539e-06, -3.17294553e-06,\n",
      "        3.72331397e-06,  3.32417289e-06, -2.42723058e-06,  2.80545032e-06,\n",
      "        2.60053412e-06, -1.97802206e-06,  2.19280969e-06, -1.45558181e-06,\n",
      "        1.96659198e-06,  1.89004493e-06,  1.70883584e-06, -1.31571699e-06,\n",
      "        1.54772545e-06, -1.11800102e-06, -1.05043887e-06,  1.41927842e-06,\n",
      "        1.28615113e-06,  1.18546780e-06,  1.04019966e-06,  8.93707465e-07,\n",
      "       -7.28185512e-07, -6.45376986e-07,  8.14510429e-07,  7.27579277e-07,\n",
      "        6.26873600e-07,  6.10641450e-07, -4.69599513e-07, -4.52014405e-07,\n",
      "        5.28792668e-07,  4.81524125e-07, -3.46845269e-07, -3.08837457e-07,\n",
      "        4.16425110e-07,  3.47517044e-07, -2.57199503e-07,  2.74900401e-07,\n",
      "        2.73956033e-07, -2.18663487e-07,  2.45321871e-07, -1.77585562e-07,\n",
      "        1.88582717e-07,  1.93917643e-07, -1.12947383e-07, -1.43950857e-07,\n",
      "       -1.35661793e-07,  1.66405570e-07,  1.49707375e-07,  1.07596314e-07,\n",
      "        1.18501255e-07, -8.82010838e-08, -7.62100214e-08,  9.64245430e-08,\n",
      "        7.87884389e-08,  7.24983593e-08,  5.76879415e-08, -5.11091969e-08,\n",
      "       -4.30819647e-08,  4.75753161e-08,  4.24001563e-08, -2.48941276e-08,\n",
      "        3.55563543e-08, -1.98409058e-08,  2.63829243e-08,  2.20612524e-08,\n",
      "        1.85109315e-08,  1.60104054e-08, -1.09518297e-08,  1.08008544e-08,\n",
      "       -9.74919434e-09,  6.99124669e-09,  3.58976893e-09,  1.05357811e-09,\n",
      "       -3.64032204e-09, -3.46486573e-09, -2.37947689e-10, -2.22215135e-09],\n",
      "      dtype=float32), array([[-0.05978795,  0.00962272,  0.1386017 , ...,  0.00044218,\n",
      "         0.03811685, -0.00302604],\n",
      "       [-0.03462334, -0.07285099, -0.12758648, ...,  0.0053663 ,\n",
      "         0.04858457, -0.01268236],\n",
      "       [ 0.00304331,  0.03019874,  0.0066466 , ...,  0.01200959,\n",
      "         0.00515114,  0.0879689 ],\n",
      "       ...,\n",
      "       [ 0.00932424, -0.02122247,  0.15979864, ..., -0.08865184,\n",
      "         0.07040414,  0.03120182],\n",
      "       [-0.1500071 ,  0.19162562, -0.07568948, ..., -0.00847648,\n",
      "        -0.00472303,  0.01671087],\n",
      "       [-0.01615465,  0.13253379, -0.00848663, ..., -0.11686673,\n",
      "        -0.03269451,  0.10499559]], dtype=float32))\n",
      "(array([ 4.85370392e+02,  7.11083055e-01,  2.86120713e-01,  1.66113347e-01,\n",
      "        8.84478986e-02,  6.44394383e-02,  5.74755967e-02,  2.98570581e-02,\n",
      "        1.34910410e-02,  7.87239708e-03,  4.82125580e-03,  4.05001920e-03,\n",
      "        3.40245641e-03,  3.04562645e-03,  1.26645400e-03,  9.51348222e-04,\n",
      "        7.04584992e-04,  5.63307607e-04,  4.55406873e-04,  3.81998630e-04,\n",
      "        3.31151008e-04,  2.69313168e-04,  2.33698782e-04,  2.21863054e-04,\n",
      "        1.77066308e-04,  1.38205971e-04,  1.12632486e-04,  9.25200875e-05,\n",
      "        7.38807212e-05,  5.71773307e-05,  5.44413269e-05,  3.85519124e-05,\n",
      "        3.44584550e-05,  3.34726356e-05,  2.31460381e-05,  1.83220982e-05,\n",
      "        1.53676228e-05, -1.11105346e-05,  1.33887143e-05, -8.91698983e-06,\n",
      "        1.18892449e-05,  1.08283812e-05,  8.84377096e-06,  7.70714450e-06,\n",
      "       -6.40364533e-06,  6.58848012e-06, -5.75487047e-06,  5.41243526e-06,\n",
      "       -4.67619748e-06, -3.87331738e-06,  4.73852242e-06,  4.47530692e-06,\n",
      "        4.14557280e-06, -3.21726702e-06,  3.15272678e-06,  2.82555266e-06,\n",
      "       -1.98691555e-06,  2.32848083e-06,  2.23297229e-06,  2.04651178e-06,\n",
      "       -1.54341535e-06,  1.76495962e-06, -1.40256475e-06,  1.58160583e-06,\n",
      "        1.41645364e-06,  1.26105851e-06,  1.11023814e-06, -1.07690664e-06,\n",
      "       -9.29637565e-07, -8.78689320e-07, -7.90694344e-07,  9.29431735e-07,\n",
      "        7.73283148e-07,  5.85992723e-07, -5.65518008e-07, -5.19991886e-07,\n",
      "       -4.42313166e-07,  5.21508866e-07,  4.54423173e-07, -3.75535194e-07,\n",
      "        3.97023314e-07,  3.61511582e-07,  3.81751903e-07, -2.81952225e-07,\n",
      "       -2.73861559e-07,  3.06092630e-07,  2.58648384e-07, -2.09069299e-07,\n",
      "       -1.63756511e-07,  2.12661575e-07,  1.66149590e-07, -1.30542574e-07,\n",
      "        1.48200030e-07, -8.94113370e-08,  1.20385408e-07,  1.07570976e-07,\n",
      "        8.60068923e-08, -8.21007404e-08, -7.38685628e-08, -6.80505963e-08,\n",
      "        7.00464824e-08, -4.23036184e-08,  6.31854817e-08,  6.62505784e-08,\n",
      "       -3.59993706e-08,  3.83023284e-08, -3.10765671e-08,  3.03406544e-08,\n",
      "       -1.59225824e-08,  2.12401030e-08,  1.79485440e-08,  1.57286735e-08,\n",
      "       -1.14726548e-08, -9.07409259e-09, -2.75386580e-09, -5.52907553e-10,\n",
      "        3.93920407e-09,  4.13988532e-09,  7.22876559e-09,  1.00429745e-08],\n",
      "      dtype=float32), array([[-5.8063027e-02, -9.2153072e-02,  4.1475549e-02, ...,\n",
      "         6.5928358e-03, -4.7399227e-02, -2.0166810e-03],\n",
      "       [-3.5062041e-02,  4.5113653e-02, -1.0032641e-02, ...,\n",
      "        -3.8098384e-02,  2.2201471e-02,  8.0697089e-02],\n",
      "       [ 3.9648213e-03,  4.1798748e-02, -1.2712858e-02, ...,\n",
      "        -9.2103370e-02, -1.0416237e-01, -2.0013860e-01],\n",
      "       ...,\n",
      "       [ 3.8479867e-03, -3.1168351e-01,  2.7149204e-02, ...,\n",
      "         7.1722187e-02, -1.8715210e-02, -1.4624368e-02],\n",
      "       [-1.5639298e-01, -4.9539827e-02,  1.9151513e-01, ...,\n",
      "         2.5463072e-04, -8.1779780e-03, -9.5553575e-03],\n",
      "       [-1.8899469e-02, -2.7805012e-02,  1.1099736e-01, ...,\n",
      "        -5.8880895e-02,  2.9230552e-02, -6.0586307e-02]], dtype=float32))\n",
      "(array([ 4.8959262e+02,  8.4547257e-01,  5.7735592e-01,  3.2160863e-01,\n",
      "        7.8286618e-02,  5.0505895e-02,  4.2431612e-02,  2.9187834e-02,\n",
      "        1.5820581e-02,  9.5412787e-03,  6.4382995e-03,  5.6108455e-03,\n",
      "        3.8140782e-03,  2.8874278e-03,  2.1589659e-03,  1.9980490e-03,\n",
      "        1.3840870e-03,  1.1519903e-03,  9.4553019e-04,  6.7230413e-04,\n",
      "        5.1267038e-04,  4.0908108e-04,  3.0493925e-04,  2.5984138e-04,\n",
      "        2.0410355e-04,  1.4749162e-04,  1.4460446e-04,  1.0817347e-04,\n",
      "        9.3494142e-05,  6.7813700e-05,  5.9238275e-05,  4.6819034e-05,\n",
      "        3.9640552e-05,  3.3614622e-05,  2.9226985e-05,  2.3797467e-05,\n",
      "        2.0733560e-05, -1.3490898e-05,  1.6936168e-05,  1.4110465e-05,\n",
      "        1.2084386e-05,  1.0895102e-05, -8.4529092e-06,  9.2879973e-06,\n",
      "        8.2637116e-06, -6.6259281e-06,  6.5928521e-06,  6.8890527e-06,\n",
      "       -5.4844481e-06,  5.5538726e-06,  5.0466310e-06,  4.2059155e-06,\n",
      "        3.6875706e-06, -3.5233836e-06, -3.4574873e-06, -2.6672215e-06,\n",
      "       -2.4245455e-06,  3.0728736e-06,  2.9444129e-06,  2.6804130e-06,\n",
      "        2.4086282e-06, -2.0351704e-06,  2.0222535e-06,  1.9686495e-06,\n",
      "        1.7483247e-06, -1.5747122e-06, -1.2363855e-06,  1.4352462e-06,\n",
      "        1.2110952e-06, -9.5897190e-07,  1.0252650e-06,  9.4892641e-07,\n",
      "        9.1991194e-07, -7.0267885e-07,  7.5499185e-07,  5.8787913e-07,\n",
      "       -7.5307594e-07, -6.3699008e-07, -5.6415087e-07,  5.3256883e-07,\n",
      "       -4.2352318e-07, -3.7986183e-07,  3.9674848e-07,  3.5129986e-07,\n",
      "       -2.6930852e-07,  3.3246494e-07,  2.7593569e-07, -2.1975640e-07,\n",
      "       -2.1505652e-07,  2.1951828e-07,  1.8194210e-07, -1.5270281e-07,\n",
      "       -1.3318672e-07,  1.5537937e-07,  1.3821000e-07,  1.2401422e-07,\n",
      "       -1.0155421e-07, -8.8199371e-08,  9.0667214e-08,  7.6425145e-08,\n",
      "        7.2927129e-08, -5.6675727e-08, -6.8035042e-08, -6.3218231e-08,\n",
      "        5.3365479e-08, -4.5834749e-08,  4.1912717e-08,  3.1391931e-08,\n",
      "       -2.3514703e-08,  2.3459743e-08, -1.4534197e-08, -1.2823007e-08,\n",
      "       -7.0158461e-09,  1.5131249e-08, -2.3800215e-09,  2.1904256e-09,\n",
      "        1.9722934e-09,  5.8248566e-09,  9.8185176e-09,  7.7616020e-09],\n",
      "      dtype=float32), array([[-0.06329653,  0.17599067, -0.00908838, ...,  0.03217437,\n",
      "        -0.02368568, -0.02590338],\n",
      "       [-0.03825893, -0.04512642,  0.1554339 , ..., -0.02608044,\n",
      "        -0.0075758 ,  0.01590543],\n",
      "       [ 0.0020026 ,  0.00653607, -0.01886107, ..., -0.2547482 ,\n",
      "         0.06145805,  0.00779798],\n",
      "       ...,\n",
      "       [ 0.00750993,  0.1694472 , -0.00063939, ..., -0.0885206 ,\n",
      "         0.07620962,  0.07200287],\n",
      "       [-0.15378341, -0.13972877, -0.0437994 , ..., -0.00974023,\n",
      "         0.01959393,  0.00492401],\n",
      "       [-0.02019338,  0.00347104, -0.04755901, ...,  0.05913585,\n",
      "        -0.04922625, -0.03095736]], dtype=float32))\n",
      "(array([ 4.85462677e+02,  4.88061428e-01,  4.05866593e-01,  1.36841208e-01,\n",
      "        4.46699448e-02,  2.28725877e-02,  9.10202321e-03,  8.77251104e-03,\n",
      "        4.46172571e-03,  3.66451731e-03,  2.66152155e-03,  2.21871096e-03,\n",
      "        1.59823068e-03,  6.64249412e-04,  5.04728639e-04,  4.48494800e-04,\n",
      "        3.61169921e-04,  3.75097239e-04,  2.93394871e-04,  1.93860411e-04,\n",
      "        1.38708681e-04,  1.19926714e-04,  1.04896848e-04,  7.83364885e-05,\n",
      "        6.45020191e-05,  5.74433107e-05,  4.89599879e-05,  4.12737463e-05,\n",
      "        3.45809931e-05,  2.84889938e-05,  2.39183701e-05,  2.19598896e-05,\n",
      "        1.75091736e-05,  1.72747405e-05, -1.32431205e-05,  1.49386069e-05,\n",
      "        1.18835469e-05, -9.82163419e-06, -9.30581609e-06,  1.01778496e-05,\n",
      "        8.80166590e-06, -6.90192337e-06,  7.84901658e-06,  7.18043293e-06,\n",
      "        5.64738366e-06, -4.59477542e-06, -4.13318276e-06,  5.09870461e-06,\n",
      "        4.62693015e-06,  4.25953931e-06, -3.13671148e-06, -2.71130034e-06,\n",
      "        3.80954111e-06,  3.34890842e-06,  3.27156135e-06, -2.64869095e-06,\n",
      "        2.58945533e-06,  2.33292280e-06, -1.89889886e-06,  2.06336517e-06,\n",
      "       -1.29884097e-06,  1.75393154e-06,  1.50643859e-06,  1.40469706e-06,\n",
      "        1.35754567e-06, -1.19952483e-06, -1.08561358e-06, -9.84037115e-07,\n",
      "        1.15299781e-06,  1.07222559e-06,  8.63417995e-07, -6.80361609e-07,\n",
      "       -5.92933645e-07,  7.96542849e-07, -5.24461257e-07, -4.81917255e-07,\n",
      "        5.25549751e-07,  5.69184806e-07,  6.02874309e-07,  3.97751791e-07,\n",
      "        3.86822649e-07,  3.33373578e-07, -2.97831207e-07, -2.61728331e-07,\n",
      "        2.88050302e-07,  2.46547046e-07, -1.97466704e-07,  2.14816595e-07,\n",
      "       -1.83980987e-07,  1.99183276e-07,  1.78366847e-07,  1.56223166e-07,\n",
      "       -1.31207997e-07, -1.08302764e-07,  1.05005185e-07, -8.79703848e-08,\n",
      "        9.50648413e-08, -7.76041773e-08,  8.21529085e-08, -6.33580157e-08,\n",
      "        7.65371624e-08,  7.01900476e-08, -4.78251465e-08, -4.31792344e-08,\n",
      "        4.45606858e-08,  3.78005680e-08, -2.49668872e-08, -2.99045411e-08,\n",
      "        3.42088988e-08, -1.45587684e-08,  2.43183162e-08, -9.53337587e-09,\n",
      "       -7.20784810e-09, -4.39630599e-09,  1.82806943e-08, -1.66336098e-10,\n",
      "        4.49401849e-09,  8.69217764e-09,  1.13091483e-08,  1.29092692e-08],\n",
      "      dtype=float32), array([[-0.0657558 ,  0.02648581,  0.04097755, ..., -0.00504344,\n",
      "         0.01235445, -0.0014815 ],\n",
      "       [-0.03327548,  0.12591079,  0.05871738, ...,  0.03495795,\n",
      "        -0.0713819 , -0.03678329],\n",
      "       [ 0.00607267, -0.00543605, -0.07192919, ..., -0.18332358,\n",
      "        -0.0547714 ,  0.05565751],\n",
      "       ...,\n",
      "       [-0.01390886, -0.07127558,  0.28232017, ...,  0.03671738,\n",
      "         0.03790988,  0.09929095],\n",
      "       [-0.15713373, -0.19269629,  0.12009645, ..., -0.01060155,\n",
      "        -0.01590934, -0.01833039],\n",
      "       [-0.01951355, -0.1224127 ,  0.0176385 , ...,  0.01506385,\n",
      "         0.03318924,  0.07209689]], dtype=float32))\n",
      "(array([ 4.1202402e+02,  5.2660108e-01,  4.8602754e-01,  1.3525474e-01,\n",
      "        5.4569155e-02,  2.4406264e-02,  1.3956796e-02,  8.9367228e-03,\n",
      "        6.6446504e-03,  3.5956332e-03,  2.0604839e-03,  1.9646869e-03,\n",
      "        1.4346211e-03,  9.4050134e-04,  8.5294503e-04,  5.5393355e-04,\n",
      "        4.5526982e-04,  3.5100384e-04,  3.0596400e-04,  2.3852887e-04,\n",
      "        1.9886879e-04,  1.5904980e-04,  1.2049040e-04,  9.8244600e-05,\n",
      "        6.9777343e-05,  5.6152774e-05,  5.1738403e-05,  4.5633733e-05,\n",
      "        4.2402793e-05,  3.0126414e-05,  2.0604150e-05, -1.3533740e-05,\n",
      "        1.6807331e-05,  1.4259535e-05,  1.3634736e-05,  1.2856712e-05,\n",
      "        1.0631971e-05, -8.4891808e-06,  9.4056577e-06, -6.0479119e-06,\n",
      "        8.1167072e-06,  7.7100876e-06,  6.7000938e-06, -4.4675280e-06,\n",
      "        5.2522937e-06,  5.3911440e-06,  4.5463885e-06, -3.8804592e-06,\n",
      "       -3.2806777e-06, -3.1491525e-06,  3.6645013e-06,  3.3292322e-06,\n",
      "        2.8571992e-06, -2.3050227e-06,  2.7051351e-06,  2.2533600e-06,\n",
      "        2.0840632e-06, -1.7612201e-06,  1.8286388e-06,  1.6488658e-06,\n",
      "       -1.5562176e-06, -1.4175304e-06, -1.2621887e-06, -1.0251671e-06,\n",
      "        1.3786786e-06,  1.2651727e-06,  1.1496600e-06,  1.0500449e-06,\n",
      "        9.0932059e-07, -8.1262351e-07, -7.4052184e-07,  7.4174483e-07,\n",
      "       -6.0870366e-07,  6.5858796e-07,  6.0641651e-07, -5.6956600e-07,\n",
      "       -4.0338989e-07, -3.0262851e-07,  4.9602340e-07,  4.4296249e-07,\n",
      "        3.9753377e-07,  3.4038339e-07,  3.3337193e-07,  2.8949066e-07,\n",
      "       -2.4138311e-07, -2.3073555e-07,  2.2695950e-07,  1.8165457e-07,\n",
      "       -1.6937832e-07, -1.3557721e-07,  1.6185456e-07,  1.5066557e-07,\n",
      "       -1.1216684e-07, -9.6229577e-08,  1.2810519e-07,  1.0134615e-07,\n",
      "        9.0102262e-08, -6.1944881e-08, -5.4045692e-08, -4.7560125e-08,\n",
      "        6.5886574e-08,  6.0529501e-08,  5.2866096e-08,  4.9017963e-08,\n",
      "        3.8581820e-08,  3.0484433e-08,  2.7695533e-08, -2.6583564e-08,\n",
      "        2.2742602e-08, -2.3741963e-08, -2.0188105e-08, -1.4643025e-08,\n",
      "        7.6231510e-09,  6.2506000e-09, -5.3738125e-09,  3.0765424e-09,\n",
      "        4.9511961e-10, -8.2024648e-10, -1.3062615e-09, -1.8711552e-09],\n",
      "      dtype=float32), array([[-0.0598686 , -0.0745537 ,  0.10008477, ..., -0.04514927,\n",
      "         0.01674552,  0.00150096],\n",
      "       [-0.03245807, -0.05376072, -0.15232782, ...,  0.01822489,\n",
      "        -0.00820993,  0.01335835],\n",
      "       [ 0.00448833, -0.01595246,  0.02518662, ..., -0.11201032,\n",
      "        -0.15061498,  0.02317795],\n",
      "       ...,\n",
      "       [-0.00607334, -0.08583676,  0.09042656, ..., -0.12667346,\n",
      "         0.00060132,  0.11255299],\n",
      "       [-0.147266  ,  0.25999993, -0.01291533, ...,  0.01101696,\n",
      "        -0.02545685, -0.01319099],\n",
      "       [-0.01552041,  0.02963759,  0.0776007 , ..., -0.10258073,\n",
      "        -0.04251024, -0.08299541]], dtype=float32))\n",
      "(array([ 4.7473700e+02,  8.2445884e-01,  6.1670703e-01,  2.1425204e-01,\n",
      "        8.3379291e-02,  3.1811900e-02,  2.0581005e-02,  1.3753365e-02,\n",
      "        1.2383427e-02,  9.6693188e-03,  5.4998761e-03,  4.7789249e-03,\n",
      "        4.0859408e-03,  2.8174741e-03,  1.4415695e-03,  1.1721867e-03,\n",
      "        1.0321235e-03,  9.7364612e-04,  6.4522499e-04,  3.8509280e-04,\n",
      "        3.8086876e-04,  2.7679323e-04,  2.5152764e-04,  2.1041883e-04,\n",
      "        1.6931862e-04,  1.4933258e-04,  8.2230348e-05,  6.4496198e-05,\n",
      "        5.9580001e-05,  4.9709259e-05,  3.1473923e-05,  2.5699632e-05,\n",
      "        2.3232969e-05,  2.0466601e-05,  2.0094820e-05,  1.4971643e-05,\n",
      "       -1.1093932e-05, -9.7026059e-06,  1.2619389e-05,  1.1324780e-05,\n",
      "        9.5310534e-06,  8.5179372e-06,  7.3063115e-06, -6.1446653e-06,\n",
      "       -5.9630665e-06,  6.5554373e-06, -4.4620351e-06,  5.2777013e-06,\n",
      "        4.6901596e-06, -3.3991560e-06,  4.5108013e-06,  4.2891779e-06,\n",
      "        3.6559852e-06, -2.9000892e-06,  3.0448382e-06,  2.8140896e-06,\n",
      "       -2.2768163e-06,  2.1479814e-06, -1.7956251e-06, -1.6022740e-06,\n",
      "        1.9468982e-06,  1.7448016e-06,  1.6179142e-06, -1.3720775e-06,\n",
      "        1.3766272e-06, -1.2280684e-06, -9.0506677e-07,  1.1224636e-06,\n",
      "        1.0285301e-06, -8.2894519e-07, -6.9162962e-07,  7.3086801e-07,\n",
      "        7.3961849e-07, -5.7008288e-07,  6.4054700e-07,  5.6375580e-07,\n",
      "       -4.9023271e-07, -4.4347303e-07,  4.5776309e-07,  4.1941590e-07,\n",
      "        4.0522440e-07,  3.3788899e-07,  3.0394958e-07, -3.6868775e-07,\n",
      "       -3.1983035e-07, -2.5450194e-07, -2.4177345e-07,  2.3829911e-07,\n",
      "        1.9279270e-07, -1.7737824e-07, -1.6545914e-07, -1.3770043e-07,\n",
      "        1.5657626e-07,  1.2960264e-07,  1.1775221e-07, -1.0195853e-07,\n",
      "       -7.8703970e-08,  1.0091047e-07, -6.5302700e-08, -5.5835734e-08,\n",
      "        8.1336836e-08,  7.2956269e-08,  5.9138952e-08,  5.5712775e-08,\n",
      "        3.5406359e-08, -3.3236418e-08,  2.9258809e-08, -2.4675305e-08,\n",
      "        1.8733553e-08, -1.7208832e-08, -1.3502770e-08, -7.4327886e-09,\n",
      "       -5.3645772e-09, -2.6499378e-09, -3.7927115e-09,  1.4141015e-08,\n",
      "        4.8884718e-09,  4.0795731e-09,  8.1945339e-09,  1.0665637e-08],\n",
      "      dtype=float32), array([[-0.05614532,  0.06628899,  0.07873579, ..., -0.00805965,\n",
      "         0.00246005,  0.02895777],\n",
      "       [-0.03441093, -0.04124098,  0.12922524, ..., -0.02596447,\n",
      "        -0.03538002, -0.06623793],\n",
      "       [ 0.00420062,  0.02727488, -0.04137672, ..., -0.11098343,\n",
      "        -0.03433866, -0.11363897],\n",
      "       ...,\n",
      "       [-0.0058344 ,  0.03814124,  0.1916253 , ..., -0.00191372,\n",
      "        -0.12158962, -0.11028952],\n",
      "       [-0.15659381,  0.20565781,  0.01797459, ...,  0.00459714,\n",
      "         0.01480081,  0.02115177],\n",
      "       [-0.02209234,  0.11084364,  0.00515352, ..., -0.02246537,\n",
      "        -0.0705096 , -0.02666362]], dtype=float32))\n",
      "(array([ 4.16778748e+02,  1.02137935e+00,  4.96509880e-01,  6.63612485e-02,\n",
      "        5.34902066e-02,  4.86112237e-02,  2.47818325e-02,  1.54509684e-02,\n",
      "        9.09535028e-03,  5.53387217e-03,  4.64227889e-03,  3.81553848e-03,\n",
      "        3.15748085e-03,  2.14705081e-03,  1.53182819e-03,  1.23068201e-03,\n",
      "        1.04776490e-03,  8.40002962e-04,  6.39797945e-04,  5.26352960e-04,\n",
      "        4.43924160e-04,  3.44662258e-04,  2.41382309e-04,  2.34609703e-04,\n",
      "        2.03856252e-04,  1.60317068e-04,  1.29524458e-04,  1.19644690e-04,\n",
      "        1.13765775e-04,  9.83098143e-05,  6.07773291e-05,  6.01954816e-05,\n",
      "        5.59443870e-05,  4.47452621e-05,  3.42912972e-05,  2.61888054e-05,\n",
      "        2.49881432e-05,  2.21904102e-05,  1.87108708e-05,  1.43542293e-05,\n",
      "        1.29631453e-05,  1.11271365e-05, -9.16308272e-06, -8.15714611e-06,\n",
      "       -7.07241225e-06,  8.27888198e-06,  7.25736891e-06,  7.08508605e-06,\n",
      "        6.84630368e-06, -4.90867478e-06,  5.13848136e-06,  4.46868171e-06,\n",
      "        4.33161313e-06, -3.91404728e-06, -3.02144417e-06,  3.79441713e-06,\n",
      "        3.24984399e-06, -2.68716849e-06, -2.50609628e-06,  2.98502005e-06,\n",
      "        2.67012547e-06,  2.39333963e-06,  2.03549848e-06, -1.67539577e-06,\n",
      "       -1.50395556e-06,  1.87556520e-06,  1.61130924e-06,  1.44433352e-06,\n",
      "        1.33254082e-06, -1.25957399e-06, -1.24387657e-06, -1.19147853e-06,\n",
      "       -8.04735464e-07,  1.03316734e-06,  9.28443740e-07,  8.66845085e-07,\n",
      "       -6.79624918e-07,  6.84907889e-07,  5.84949476e-07, -5.63671335e-07,\n",
      "       -5.15078170e-07,  5.14481201e-07, -4.39719230e-07,  4.35509833e-07,\n",
      "       -3.81902908e-07, -3.15979719e-07,  3.88711754e-07,  3.17543567e-07,\n",
      "       -2.82745560e-07, -2.31057612e-07, -2.06883328e-07,  3.26284663e-07,\n",
      "        2.57767198e-07, -1.65028808e-07,  2.04807833e-07,  1.85695399e-07,\n",
      "       -1.39597716e-07,  1.55346825e-07,  1.22112951e-07, -8.42787671e-08,\n",
      "       -7.73406370e-08,  9.99078438e-08,  7.21311793e-08, -5.18095966e-08,\n",
      "        4.84752789e-08, -3.80474923e-08,  3.64680730e-08,  2.58989363e-08,\n",
      "       -2.63897473e-08, -1.62027156e-08,  1.55396780e-08,  1.18269190e-08,\n",
      "       -1.36204727e-08, -1.20799948e-08,  1.00099555e-08,  5.50582913e-09,\n",
      "       -5.85742388e-09, -4.28551150e-09,  9.74556616e-11, -1.63885627e-09],\n",
      "      dtype=float32), array([[ 0.04374636,  0.09201654, -0.05897322, ..., -0.03286371,\n",
      "         0.0106768 ,  0.05582963],\n",
      "       [ 0.0481712 , -0.10278588,  0.16801226, ..., -0.00943127,\n",
      "        -0.03420012, -0.0051529 ],\n",
      "       [ 0.00287667,  0.00948968, -0.06588814, ...,  0.17558685,\n",
      "        -0.07221299, -0.09361456],\n",
      "       ...,\n",
      "       [-0.01240155,  0.04644471, -0.00210554, ...,  0.12802017,\n",
      "        -0.00336094, -0.12667242],\n",
      "       [ 0.16785732,  0.07097659, -0.10066657, ..., -0.01107537,\n",
      "         0.00527967, -0.00104673],\n",
      "       [ 0.04230111,  0.0031717 , -0.0699436 , ..., -0.02599974,\n",
      "        -0.00748027,  0.0104183 ]], dtype=float32))\n",
      "(array([ 3.97268066e+02,  6.36521220e-01,  2.33587965e-01,  9.49135646e-02,\n",
      "        6.37697354e-02,  3.36748473e-02,  1.79593768e-02,  1.12600764e-02,\n",
      "        8.47608689e-03,  5.49704023e-03,  5.07132430e-03,  3.64666665e-03,\n",
      "        3.41243763e-03,  2.45417794e-03,  1.71915779e-03,  1.35906017e-03,\n",
      "        9.44657426e-04,  7.86178804e-04,  7.34623696e-04,  4.42765682e-04,\n",
      "        3.09470430e-04,  2.77808169e-04,  2.21385693e-04,  2.01930627e-04,\n",
      "        1.72025844e-04,  1.52897919e-04,  1.24574479e-04,  1.00703546e-04,\n",
      "        8.80292791e-05,  7.23097837e-05,  6.26227920e-05,  5.66767521e-05,\n",
      "        4.97338333e-05,  3.54702206e-05,  3.03992165e-05,  2.85638453e-05,\n",
      "        2.35632415e-05,  1.91241907e-05, -1.17733425e-05,  1.53336932e-05,\n",
      "        1.44127807e-05,  1.20861769e-05,  1.02949662e-05,  9.57915290e-06,\n",
      "       -8.03130570e-06, -6.27377494e-06,  8.01614442e-06,  6.95763583e-06,\n",
      "        6.70647387e-06,  5.78549134e-06, -4.62181106e-06, -4.03924923e-06,\n",
      "        4.73155251e-06,  4.01002808e-06,  3.99010696e-06, -2.70964620e-06,\n",
      "       -2.57979946e-06,  3.18906473e-06,  3.09015718e-06,  2.54289967e-06,\n",
      "        2.18362493e-06, -1.90178207e-06,  1.92737616e-06, -1.70955491e-06,\n",
      "        1.67210192e-06, -1.60821548e-06, -1.30376486e-06, -1.20091249e-06,\n",
      "        1.37617917e-06, -9.54651455e-07,  1.22828544e-06,  1.11008330e-06,\n",
      "        1.00454383e-06,  8.55621465e-07, -8.21041397e-07, -7.28801524e-07,\n",
      "       -5.90511547e-07,  6.36004984e-07,  5.64063782e-07,  5.42773648e-07,\n",
      "        4.87721309e-07, -4.35434316e-07,  4.28568001e-07, -3.91374329e-07,\n",
      "        3.81287009e-07, -3.05305036e-07, -2.83055243e-07,  2.94621515e-07,\n",
      "        2.66681354e-07, -2.41630232e-07, -1.86360865e-07,  2.01905010e-07,\n",
      "        1.75070710e-07, -1.51478417e-07, -1.68449787e-07,  1.60901664e-07,\n",
      "        1.33909950e-07, -1.35699821e-07, -1.37398644e-07,  1.03983602e-07,\n",
      "       -1.01758964e-07,  8.41687537e-08, -8.06653304e-08,  6.18821403e-08,\n",
      "       -6.04900947e-08,  4.22629434e-08, -4.40186163e-08, -3.43983189e-08,\n",
      "        3.12776685e-08,  2.14348503e-08, -1.83867286e-08,  1.49145372e-08,\n",
      "       -1.46652255e-08,  1.26284840e-08, -1.19318635e-08, -5.29217781e-09,\n",
      "       -2.10643258e-09,  6.30101260e-09,  1.53826663e-09,  3.62074548e-09],\n",
      "      dtype=float32), array([[-4.2477425e-02,  6.1449248e-02, -1.3609044e-01, ...,\n",
      "        -1.8942295e-02,  2.9129185e-02,  3.9848808e-02],\n",
      "       [-4.7333889e-02, -1.9471925e-01, -7.2983927e-03, ...,\n",
      "         4.4831014e-03, -1.6081108e-02, -7.6607510e-02],\n",
      "       [-2.1363196e-03,  6.3090630e-02,  2.1095585e-02, ...,\n",
      "        -2.5401703e-01,  4.8185598e-02,  1.7106976e-02],\n",
      "       ...,\n",
      "       [ 6.4272769e-03,  2.0072257e-02, -3.6673907e-02, ...,\n",
      "         1.8107504e-02,  2.2612283e-02, -1.5066290e-01],\n",
      "       [-1.6508417e-01,  9.4946995e-02, -6.3697055e-02, ...,\n",
      "        -7.1859523e-04, -1.8983439e-04, -1.6554064e-04],\n",
      "       [-3.9847776e-02,  6.6062629e-02,  3.8816713e-02, ...,\n",
      "        -9.5475949e-03, -2.0429146e-02, -3.3929076e-02]], dtype=float32))\n",
      "(array([ 4.15256073e+02,  1.44129956e+00,  4.22619849e-01,  1.22703679e-01,\n",
      "        4.62140478e-02,  3.61834243e-02,  2.20207870e-02,  1.17569817e-02,\n",
      "        1.12804919e-02,  7.24941120e-03,  4.57257032e-03,  4.46500257e-03,\n",
      "        3.64059932e-03,  2.80297082e-03,  1.93441706e-03,  1.54956104e-03,\n",
      "        1.00729393e-03,  8.96441750e-04,  6.08643692e-04,  5.38538268e-04,\n",
      "        4.30652406e-04,  3.94799426e-04,  3.78861616e-04,  2.88562413e-04,\n",
      "        2.67137075e-04,  2.38842651e-04,  2.05484786e-04,  1.58778726e-04,\n",
      "        1.34075221e-04,  1.08518259e-04,  9.73690621e-05,  8.47375122e-05,\n",
      "        6.30827199e-05,  5.91601893e-05,  5.21190595e-05,  4.46087506e-05,\n",
      "        3.92427246e-05,  3.60777813e-05,  2.85489568e-05,  2.49086279e-05,\n",
      "        2.20251186e-05,  2.12499126e-05,  1.72369564e-05,  1.51255963e-05,\n",
      "       -9.89197088e-06,  1.29205127e-05,  1.07676378e-05,  1.03014136e-05,\n",
      "       -7.94877724e-06, -6.71303314e-06,  7.71795385e-06,  7.07942172e-06,\n",
      "        6.79012919e-06,  5.75789909e-06,  5.60182252e-06, -4.15489058e-06,\n",
      "        4.29187321e-06, -3.58530815e-06, -2.91080755e-06,  3.04258219e-06,\n",
      "       -2.30247906e-06, -2.01539410e-06, -1.90141020e-06,  2.29762281e-06,\n",
      "        2.24039309e-06,  1.92885773e-06,  1.71127988e-06, -1.51524000e-06,\n",
      "        1.24358905e-06, -1.24486860e-06, -1.11541613e-06,  9.46461171e-07,\n",
      "        8.69399344e-07, -9.08285074e-07, -8.17934790e-07,  7.97258167e-07,\n",
      "       -7.01814997e-07,  7.10621180e-07,  6.49540709e-07,  5.81049392e-07,\n",
      "       -5.80539506e-07,  4.40994995e-07, -4.33315478e-07, -3.94773508e-07,\n",
      "        3.23453094e-07, -3.35904190e-07,  2.84840070e-07, -2.82216547e-07,\n",
      "        2.43706097e-07,  2.00359779e-07,  1.75966363e-07, -2.65729881e-07,\n",
      "       -2.49689720e-07, -2.20278750e-07, -1.71090576e-07, -1.41631233e-07,\n",
      "        1.39563568e-07,  1.26783092e-07, -1.12772675e-07, -7.60752314e-08,\n",
      "        9.76093943e-08,  8.97559289e-08, -7.18099500e-08,  7.45583577e-08,\n",
      "        6.23669294e-08, -4.17524006e-08, -3.45850744e-08,  3.72648152e-08,\n",
      "        3.41807080e-08,  2.99265679e-08, -2.56649741e-08,  1.67700538e-08,\n",
      "        1.12748255e-08, -2.01693560e-08, -1.24333130e-08,  5.86622839e-09,\n",
      "        2.50689292e-09, -1.64304161e-11, -5.98453687e-09, -5.02000885e-09],\n",
      "      dtype=float32), array([[ 0.04602161,  0.09862822,  0.02283963, ...,  0.00201676,\n",
      "        -0.01598091,  0.01073567],\n",
      "       [ 0.04312524, -0.01531556, -0.19168095, ...,  0.0255646 ,\n",
      "        -0.04765225, -0.00626962],\n",
      "       [-0.00233895, -0.05544014,  0.06597919, ..., -0.10822616,\n",
      "         0.07831464,  0.16196741],\n",
      "       ...,\n",
      "       [ 0.00864859,  0.15166117, -0.013311  , ..., -0.04427056,\n",
      "        -0.10040311,  0.04222865],\n",
      "       [ 0.16423135, -0.00333699,  0.08728568, ...,  0.00343568,\n",
      "        -0.00182619, -0.0092854 ],\n",
      "       [ 0.03351021, -0.07830884,  0.07997809, ..., -0.0347346 ,\n",
      "        -0.02763739,  0.0034983 ]], dtype=float32))\n",
      "(array([ 4.2715143e+02,  8.5003006e-01,  3.0895510e-01,  8.1225991e-02,\n",
      "        4.0416408e-02,  3.4789298e-02,  1.7074682e-02,  9.2902072e-03,\n",
      "        8.1276819e-03,  6.2168827e-03,  3.3025441e-03,  2.8365750e-03,\n",
      "        2.5132827e-03,  1.7487841e-03,  1.1748342e-03,  9.5611211e-04,\n",
      "        8.4972550e-04,  6.6152611e-04,  4.3624282e-04,  4.0686229e-04,\n",
      "        3.1950112e-04,  2.9076877e-04,  2.5811675e-04,  2.2479167e-04,\n",
      "        1.5140262e-04,  1.3236262e-04,  1.1936253e-04,  1.0261788e-04,\n",
      "        9.5387688e-05,  7.1363960e-05,  6.4328306e-05,  4.9769566e-05,\n",
      "        4.3587330e-05,  3.8656352e-05,  3.5091234e-05,  3.0692601e-05,\n",
      "        2.7190803e-05,  1.9874466e-05,  1.8017854e-05, -1.3294969e-05,\n",
      "        1.6052985e-05,  1.5110753e-05,  1.2939928e-05,  1.1344694e-05,\n",
      "        8.7235512e-06,  7.9851798e-06, -6.5136178e-06, -6.2349636e-06,\n",
      "       -5.2606938e-06,  6.7474589e-06,  6.3031935e-06,  5.2949522e-06,\n",
      "        4.8320635e-06, -4.0746872e-06, -3.5545270e-06,  4.3443974e-06,\n",
      "        4.2435558e-06,  3.4950456e-06, -2.4753986e-06,  3.1481625e-06,\n",
      "        2.9842765e-06,  2.6973466e-06, -1.9486570e-06,  1.9403840e-06,\n",
      "        1.6727106e-06, -1.5580769e-06, -1.4065560e-06, -1.2602652e-06,\n",
      "       -1.0680285e-06,  1.4644099e-06,  1.3670439e-06,  1.2484110e-06,\n",
      "        1.1391478e-06, -8.7266062e-07,  9.0687138e-07, -7.3513780e-07,\n",
      "        7.3336872e-07,  6.3680966e-07,  5.2008011e-07, -6.2222290e-07,\n",
      "       -6.0518158e-07, -5.4211046e-07, -4.9698122e-07, -4.3212333e-07,\n",
      "        4.3725549e-07,  3.9595844e-07, -3.5849905e-07,  2.9950053e-07,\n",
      "        3.2256091e-07, -2.5509931e-07, -2.3310882e-07, -2.0355800e-07,\n",
      "        2.5535115e-07,  2.0779123e-07,  1.8732629e-07,  1.5819413e-07,\n",
      "       -1.4589536e-07, -1.2098209e-07, -7.3193689e-08,  1.1861939e-07,\n",
      "        1.0382674e-07,  8.1798653e-08,  7.0254060e-08, -5.9328482e-08,\n",
      "       -4.7558810e-08,  3.8840160e-08,  3.6819198e-08, -3.3216899e-08,\n",
      "       -2.5417670e-08,  2.3426786e-08,  2.1949115e-08,  1.8994246e-08,\n",
      "       -1.5420225e-08, -1.3211839e-08, -6.4214185e-09, -2.7837241e-09,\n",
      "       -4.2768905e-10,  4.7366031e-09,  7.9423570e-09,  1.0857097e-08],\n",
      "      dtype=float32), array([[-4.3297324e-02, -1.0570914e-01, -8.0983773e-02, ...,\n",
      "         2.5800103e-03, -2.2412689e-02, -1.4693818e-02],\n",
      "       [-4.7150813e-02,  1.9628529e-01, -6.6918939e-02, ...,\n",
      "        -4.0392915e-05, -8.2416954e-03, -3.8657501e-02],\n",
      "       [-2.3205522e-03, -5.7274405e-02,  1.3434188e-05, ...,\n",
      "         1.2766045e-01, -2.7276149e-01, -1.4100502e-01],\n",
      "       ...,\n",
      "       [ 7.2980169e-03, -2.3484370e-02,  4.4258129e-02, ...,\n",
      "         1.0323796e-02,  1.1557621e-01, -9.7027786e-02],\n",
      "       [-1.6792092e-01, -9.2929564e-02, -1.0837073e-01, ...,\n",
      "         1.1982387e-03,  4.5637083e-03,  5.3427387e-03],\n",
      "       [-4.0049028e-02, -6.4641766e-02, -2.2489488e-02, ...,\n",
      "         2.4473522e-02,  6.5090165e-02,  1.4394870e-02]], dtype=float32))\n",
      "(array([ 4.17581024e+02,  9.51386571e-01,  3.06788146e-01,  2.16974318e-01,\n",
      "        1.26263455e-01,  7.44640008e-02,  4.02950943e-02,  2.01149136e-02,\n",
      "        1.27636390e-02,  9.82593000e-03,  6.37932168e-03,  5.12487488e-03,\n",
      "        4.98621166e-03,  3.17561394e-03,  2.68018921e-03,  2.25626095e-03,\n",
      "        1.17107050e-03,  9.97644849e-04,  8.45316506e-04,  5.89850242e-04,\n",
      "        4.96651512e-04,  4.53621353e-04,  3.77326069e-04,  3.36214114e-04,\n",
      "        2.54092069e-04,  2.19132256e-04,  1.91045838e-04,  1.67574137e-04,\n",
      "        1.27874344e-04,  1.04315433e-04,  9.02384127e-05,  8.58931453e-05,\n",
      "        7.41432523e-05,  6.23967135e-05,  4.76911009e-05,  3.73033181e-05,\n",
      "        2.83912486e-05,  2.65364142e-05,  2.52373356e-05,  2.27108685e-05,\n",
      "        2.14673310e-05, -1.18724765e-05, -1.06014595e-05,  1.31550350e-05,\n",
      "        1.21054463e-05,  1.04982810e-05, -6.98459962e-06,  7.82703410e-06,\n",
      "        7.21938022e-06, -4.77457115e-06,  6.07108632e-06,  5.60927856e-06,\n",
      "        4.67608561e-06,  4.17607043e-06,  3.60849413e-06, -3.18624734e-06,\n",
      "       -2.77555455e-06,  3.17510171e-06, -2.27661167e-06, -2.01272974e-06,\n",
      "        2.87517150e-06,  2.45100068e-06,  2.36246547e-06,  2.05968217e-06,\n",
      "        1.52886616e-06,  1.60495824e-06, -1.46408149e-06, -1.28207625e-06,\n",
      "        1.21585799e-06,  1.10937083e-06, -1.05735205e-06, -9.47689500e-07,\n",
      "       -8.63576474e-07, -6.94739526e-07, -5.23582173e-07,  8.52133951e-07,\n",
      "        7.46751709e-07,  6.70068175e-07,  6.07913762e-07,  5.07141863e-07,\n",
      "        4.94785127e-07, -4.29939234e-07,  3.92310369e-07, -3.66742285e-07,\n",
      "        2.87324013e-07, -2.63223939e-07, -2.12157119e-07,  2.28949020e-07,\n",
      "        2.14391903e-07, -1.82924310e-07, -1.76308532e-07,  1.65928583e-07,\n",
      "        1.59115444e-07,  1.31503555e-07, -1.15736363e-07, -9.96754821e-08,\n",
      "        9.27676354e-08,  8.11452949e-08,  7.07930994e-08, -8.06632414e-08,\n",
      "       -7.57444951e-08,  6.37295443e-08, -6.71892479e-08,  3.67325974e-08,\n",
      "        3.91186141e-08,  4.14329335e-08, -5.30038164e-08, -4.86041500e-08,\n",
      "       -3.92199020e-08,  2.01404475e-08,  1.27451942e-08, -2.29078765e-08,\n",
      "        6.88266200e-09,  5.10804332e-09,  1.99358641e-09, -1.91911802e-08,\n",
      "       -3.93552924e-09, -7.86970755e-09, -1.42512286e-08, -1.36402472e-08],\n",
      "      dtype=float32), array([[-0.05442495, -0.03063644,  0.18144338, ..., -0.00834077,\n",
      "         0.04317236, -0.01014454],\n",
      "       [-0.04028059, -0.04193355,  0.02873899, ..., -0.03278565,\n",
      "        -0.05094452,  0.0445005 ],\n",
      "       [ 0.00891922,  0.00962604, -0.11527129, ...,  0.21571518,\n",
      "        -0.00391542,  0.02323727],\n",
      "       ...,\n",
      "       [-0.02505673, -0.03087356,  0.28922275, ...,  0.04772918,\n",
      "         0.02306263,  0.08236302],\n",
      "       [-0.1590329 ,  0.03874419, -0.10752337, ...,  0.00646065,\n",
      "         0.00602557,  0.00907904],\n",
      "       [-0.02631928, -0.02605485, -0.14108315, ..., -0.11751529,\n",
      "        -0.00716799,  0.05522919]], dtype=float32))\n",
      "(array([ 3.7706003e+02,  9.4243050e-01,  2.6604867e-01,  1.7811438e-01,\n",
      "        7.3913097e-02,  2.3361368e-02,  1.4560905e-02,  1.0818656e-02,\n",
      "        9.0508834e-03,  5.1979795e-03,  4.3220809e-03,  2.7401277e-03,\n",
      "        2.5546420e-03,  1.7054009e-03,  1.1672875e-03,  9.3179528e-04,\n",
      "        8.2380226e-04,  5.8024755e-04,  4.7037215e-04,  3.3595515e-04,\n",
      "        2.4632140e-04,  2.0959106e-04,  1.6896143e-04,  1.6303203e-04,\n",
      "        1.1984079e-04,  1.0624540e-04,  8.8063229e-05,  7.9297315e-05,\n",
      "        6.9858281e-05,  5.7913403e-05,  4.5771703e-05,  3.8051356e-05,\n",
      "        3.4077719e-05,  2.9337127e-05,  2.2992414e-05,  1.9035526e-05,\n",
      "       -1.1641858e-05,  1.5200944e-05,  1.3184587e-05,  1.2253178e-05,\n",
      "        1.0034649e-05,  8.9166397e-06, -6.7387441e-06,  6.9640564e-06,\n",
      "       -6.0295592e-06,  7.5746930e-06, -4.0288842e-06,  5.7211196e-06,\n",
      "        5.5849910e-06,  4.6877835e-06,  4.2750635e-06,  3.6894255e-06,\n",
      "        3.1648929e-06, -2.8254835e-06, -2.6946443e-06, -2.1898281e-06,\n",
      "        2.6410848e-06,  2.3224425e-06, -1.7360071e-06,  2.0607022e-06,\n",
      "        1.8453544e-06,  1.6995840e-06, -1.4375669e-06,  1.6109951e-06,\n",
      "        1.3364495e-06, -1.2072096e-06,  1.2844031e-06, -1.0561355e-06,\n",
      "        1.1040149e-06,  9.8009605e-07, -8.4859971e-07,  8.6479247e-07,\n",
      "       -7.2483687e-07,  7.1281323e-07, -7.0715788e-07,  6.2870589e-07,\n",
      "       -5.3220333e-07,  5.5742095e-07, -4.7312562e-07, -4.3264717e-07,\n",
      "        4.6679830e-07,  3.7764659e-07, -3.2899152e-07,  3.1066745e-07,\n",
      "       -2.6749777e-07,  2.7133444e-07,  2.2603555e-07, -2.2193242e-07,\n",
      "        1.9645101e-07, -1.9490339e-07, -1.7796293e-07, -1.4159878e-07,\n",
      "       -1.2740186e-07,  1.6674173e-07,  1.5833203e-07,  1.3477840e-07,\n",
      "       -9.6129774e-08, -8.0256967e-08,  9.6367124e-08,  9.2046449e-08,\n",
      "        7.6216068e-08, -6.2264476e-08,  5.2726129e-08,  4.4962825e-08,\n",
      "       -4.1247691e-08, -4.7759297e-08, -3.1540097e-08,  3.5275704e-08,\n",
      "        2.4484171e-08, -2.0792308e-08, -1.6643677e-08,  1.5343472e-08,\n",
      "        1.4658531e-08,  1.2066616e-08,  5.9810419e-09,  2.9427021e-09,\n",
      "       -2.4545226e-09, -5.0297357e-09, -1.1247813e-08, -1.2800851e-08],\n",
      "      dtype=float32), array([[ 0.04533991,  0.08524264, -0.07354354, ...,  0.01078281,\n",
      "         0.03708473, -0.00898632],\n",
      "       [ 0.0407292 ,  0.0534153 ,  0.16239853, ...,  0.02083281,\n",
      "        -0.01188422, -0.01369234],\n",
      "       [-0.00849815, -0.06245533, -0.03593104, ...,  0.15730934,\n",
      "        -0.01074125, -0.10367238],\n",
      "       ...,\n",
      "       [ 0.02392121,  0.15798075, -0.00673933, ..., -0.01958568,\n",
      "        -0.05735421, -0.00787687],\n",
      "       [ 0.15462962, -0.07416672, -0.07348889, ...,  0.01000977,\n",
      "        -0.01466645, -0.00969884],\n",
      "       [ 0.026969  , -0.01772844, -0.08683243, ...,  0.02274386,\n",
      "        -0.0204639 , -0.0326494 ]], dtype=float32))\n",
      "(array([ 3.82548004e+02,  3.06269705e-01,  1.08954743e-01,  1.69177055e-02,\n",
      "        1.35798166e-02,  1.10085998e-02,  4.66953078e-03,  3.09818122e-03,\n",
      "        1.92574353e-03,  1.51024479e-03,  9.97896655e-04,  7.65994133e-04,\n",
      "        5.02998533e-04,  3.59780912e-04,  3.20289255e-04,  2.26173259e-04,\n",
      "        1.81332274e-04,  1.43723460e-04,  1.13687194e-04,  7.74664586e-05,\n",
      "        6.19801067e-05,  5.53698665e-05,  4.53876601e-05,  3.87807959e-05,\n",
      "        3.15896905e-05,  2.77862546e-05,  2.39154779e-05,  2.08876208e-05,\n",
      "        1.94077747e-05,  1.71191277e-05, -1.23824057e-05, -9.48525849e-06,\n",
      "        1.17132386e-05,  1.14509967e-05,  9.98988071e-06,  9.18282785e-06,\n",
      "        8.88353316e-06,  7.54205121e-06, -5.76950151e-06, -4.62393245e-06,\n",
      "        5.96224936e-06,  5.54350936e-06,  5.30783336e-06, -4.09936501e-06,\n",
      "        4.38804091e-06, -3.15214925e-06,  3.87961745e-06,  3.22016649e-06,\n",
      "        3.13066039e-06, -2.54193060e-06,  2.88000956e-06,  2.49673349e-06,\n",
      "        2.47001776e-06, -1.71340753e-06,  2.17971228e-06,  2.12250438e-06,\n",
      "       -1.50095173e-06,  1.85914041e-06, -1.23027746e-06, -1.03339448e-06,\n",
      "        1.54940426e-06,  1.26975806e-06,  1.35284836e-06,  1.41174633e-06,\n",
      "        1.10371786e-06, -8.01847079e-07,  9.55322093e-07,  8.30571764e-07,\n",
      "        7.61574483e-07, -6.55099598e-07, -6.21759909e-07,  6.05884281e-07,\n",
      "       -5.02392027e-07,  5.46556009e-07,  5.26396661e-07, -4.24398110e-07,\n",
      "       -3.99151190e-07, -3.70798574e-07, -3.00010669e-07,  4.49983645e-07,\n",
      "        4.20355718e-07,  3.38561193e-07,  2.92705408e-07,  2.40166258e-07,\n",
      "        2.32788977e-07, -1.92203814e-07, -1.67433157e-07,  1.70113907e-07,\n",
      "        1.60724625e-07, -1.39698912e-07, -1.16156961e-07,  1.39664650e-07,\n",
      "       -9.94518459e-08, -9.12650862e-08,  1.24724039e-07,  1.05471322e-07,\n",
      "        9.60846407e-08,  8.46235224e-08,  7.33709200e-08, -5.85421134e-08,\n",
      "        5.55446853e-08,  4.85255640e-08, -4.74152841e-08, -4.27744240e-08,\n",
      "       -3.16554498e-08,  3.58906220e-08, -2.57249280e-08,  2.66623665e-08,\n",
      "        2.47158933e-08, -1.46078012e-08, -2.16433058e-08,  1.90149301e-08,\n",
      "        1.03829194e-08,  7.63187558e-09,  5.33355005e-09,  1.88329774e-09,\n",
      "       -7.39289652e-09, -1.50977197e-09, -5.07532194e-09, -3.47160745e-09],\n",
      "      dtype=float32), array([[-0.05119516,  0.03544095,  0.11736576, ..., -0.05189476,\n",
      "         0.01403001,  0.01659202],\n",
      "       [-0.03451932, -0.16039224, -0.10150581, ...,  0.04239582,\n",
      "         0.04118613,  0.00706189],\n",
      "       [ 0.01257111,  0.07193745, -0.08417924, ...,  0.00096119,\n",
      "        -0.00036858, -0.0449086 ],\n",
      "       ...,\n",
      "       [-0.0328416 , -0.09553751,  0.26438937, ..., -0.04173619,\n",
      "         0.06723821,  0.00345187],\n",
      "       [-0.15224439,  0.10906623, -0.1294523 , ...,  0.01257889,\n",
      "         0.01633566, -0.01823172],\n",
      "       [-0.02094941,  0.09772129, -0.05774561, ...,  0.01393139,\n",
      "         0.05750001, -0.06778306]], dtype=float32))\n",
      "(array([ 2.9917667e+02,  4.1596377e-01,  5.3903557e-02,  3.0777523e-02,\n",
      "        1.8414594e-02,  7.4499068e-03,  4.1090632e-03,  2.9044196e-03,\n",
      "        1.7401158e-03,  7.3888514e-04,  5.2039867e-04,  3.1295311e-04,\n",
      "        1.5422843e-04,  1.4672628e-04,  1.0739382e-04,  8.2292187e-05,\n",
      "        7.6219039e-05,  6.2419524e-05,  4.1848969e-05,  3.5191435e-05,\n",
      "        3.1800893e-05,  1.8620914e-05,  1.6384098e-05,  1.3614904e-05,\n",
      "        1.2377777e-05,  1.1192689e-05,  1.0345364e-05,  9.6658760e-06,\n",
      "       -7.7033465e-06, -7.0991564e-06,  7.2346716e-06,  6.3680322e-06,\n",
      "       -4.8908755e-06,  5.4936495e-06,  5.2254145e-06,  4.8497668e-06,\n",
      "        4.2473966e-06,  3.8879725e-06, -3.3749586e-06, -3.0250121e-06,\n",
      "       -2.7258734e-06,  3.2266457e-06,  3.2588960e-06, -2.3813743e-06,\n",
      "        2.6532673e-06,  2.3563289e-06, -1.6982375e-06,  2.2185425e-06,\n",
      "        2.0886885e-06,  1.8079070e-06, -1.1803407e-06,  1.5266312e-06,\n",
      "        1.3774436e-06,  1.2687539e-06,  1.2311069e-06,  1.0661345e-06,\n",
      "       -8.8784293e-07, -8.9988788e-07,  9.5975258e-07, -7.7623633e-07,\n",
      "        8.2400788e-07,  7.7179709e-07, -6.4851173e-07, -5.9951435e-07,\n",
      "        6.2724251e-07, -5.0187703e-07,  5.6829703e-07, -4.7468396e-07,\n",
      "        4.9289645e-07,  4.2793795e-07,  4.0043673e-07,  3.6746260e-07,\n",
      "       -2.8892416e-07, -2.6047991e-07,  3.2353239e-07,  2.8597242e-07,\n",
      "       -2.0738430e-07,  2.6210586e-07,  2.3212607e-07, -1.8669091e-07,\n",
      "       -1.4276783e-07, -1.1804286e-07,  1.9663284e-07,  1.6949095e-07,\n",
      "        1.6847930e-07,  1.3507258e-07,  1.3078810e-07, -9.5253242e-08,\n",
      "        1.1036301e-07,  1.0342984e-07, -8.3664631e-08, -7.1343912e-08,\n",
      "       -6.9822029e-08, -4.5736929e-08,  8.5860144e-08,  7.4418658e-08,\n",
      "        6.4264512e-08,  5.5799259e-08,  5.0242047e-08, -2.9655398e-08,\n",
      "       -2.7405623e-08,  3.7823099e-08,  3.1763754e-08, -9.3301020e-09,\n",
      "       -1.5037992e-08, -1.6403414e-08, -1.7777143e-08, -5.1434110e-09,\n",
      "        2.7647820e-08,  2.6067317e-08,  9.1702193e-09, -2.2549753e-09,\n",
      "       -2.5144791e-09,  3.9263122e-09,  3.5123959e-10,  5.4488982e-09,\n",
      "        2.1062789e-08,  1.2529484e-08,  1.9153035e-08,  1.6094258e-08],\n",
      "      dtype=float32), array([[-0.04643384, -0.07524252, -0.14367932, ..., -0.04277823,\n",
      "         0.06241777,  0.01244658],\n",
      "       [-0.03394751,  0.18828972, -0.03832703, ..., -0.04583897,\n",
      "         0.12406393,  0.05506258],\n",
      "       [ 0.01265159, -0.02012317, -0.1151855 , ..., -0.0110353 ,\n",
      "         0.03015176, -0.06860947],\n",
      "       ...,\n",
      "       [-0.03135232,  0.04308731,  0.09156275, ..., -0.06031442,\n",
      "         0.02082262,  0.02811669],\n",
      "       [-0.13432093, -0.17043549,  0.04171211, ..., -0.021978  ,\n",
      "        -0.01032803,  0.02003483],\n",
      "       [-0.01851781, -0.0735682 , -0.06854053, ..., -0.04261811,\n",
      "         0.11010183,  0.00027346]], dtype=float32))\n",
      "(array([ 2.9834033e+02,  4.8814955e-01,  2.5809306e-01,  6.2553823e-02,\n",
      "        3.1881239e-02,  2.3777053e-02,  1.6736103e-02,  9.3684923e-03,\n",
      "        3.3846211e-03,  2.5612756e-03,  2.1119025e-03,  1.2156473e-03,\n",
      "        1.0413545e-03,  6.0239475e-04,  5.2178488e-04,  3.5862773e-04,\n",
      "        2.8261959e-04,  2.2625287e-04,  1.8311951e-04,  1.4817617e-04,\n",
      "        1.2881405e-04,  8.7345914e-05,  8.1524267e-05,  6.5030275e-05,\n",
      "        3.3465116e-05,  3.0332616e-05,  2.7331807e-05,  1.9544977e-05,\n",
      "        1.7341994e-05,  1.4077414e-05, -9.6192070e-06,  1.0627747e-05,\n",
      "        9.9840308e-06,  7.8077373e-06,  7.4461773e-06, -5.9129202e-06,\n",
      "        6.6503085e-06, -4.5523084e-06,  5.6023837e-06, -3.6897395e-06,\n",
      "        4.7886392e-06,  4.5111765e-06,  4.0193363e-06,  3.4521586e-06,\n",
      "        3.2379075e-06,  2.9804271e-06, -2.5119250e-06, -2.3801376e-06,\n",
      "        2.4507212e-06, -2.2650152e-06,  2.1181872e-06, -1.7190778e-06,\n",
      "        1.7209341e-06,  1.6329584e-06,  1.3719950e-06, -1.2295969e-06,\n",
      "       -1.0092533e-06, -9.3653819e-07,  1.0601652e-06,  1.0474973e-06,\n",
      "        9.2474909e-07,  8.6864122e-07, -7.2776373e-07, -5.7350712e-07,\n",
      "       -5.2088831e-07,  7.9393726e-07,  7.3434086e-07,  6.4562101e-07,\n",
      "        5.8768154e-07,  5.0718677e-07, -4.3388320e-07,  4.4629860e-07,\n",
      "       -3.6073936e-07,  3.8633146e-07, -3.1660437e-07,  3.6737831e-07,\n",
      "        3.2564145e-07, -2.3054398e-07, -1.9112350e-07, -1.7606168e-07,\n",
      "        2.5583091e-07,  2.3080680e-07,  1.9627203e-07,  1.8820596e-07,\n",
      "       -1.5698592e-07, -1.2429581e-07,  1.4726810e-07,  1.3273697e-07,\n",
      "       -1.0910893e-07,  1.1472169e-07, -9.0143622e-08, -7.2602816e-08,\n",
      "       -6.5393934e-08,  9.0090339e-08,  9.7145481e-08,  7.9372825e-08,\n",
      "        7.7941351e-08,  6.6355291e-08, -5.2974301e-08, -4.4362203e-08,\n",
      "        4.7154444e-08,  3.6932459e-08,  4.1681439e-08, -3.3750961e-08,\n",
      "       -3.1286930e-08,  3.2470858e-08,  2.6363150e-08, -2.2790532e-08,\n",
      "        1.9745404e-08,  1.8955758e-08, -1.2742300e-08, -6.4884431e-09,\n",
      "       -4.0364454e-09, -7.5437594e-09, -7.1198203e-10, -6.6761907e-10,\n",
      "        9.8252251e-09,  2.8962974e-09,  4.7836251e-09,  8.0325773e-09],\n",
      "      dtype=float32), array([[-0.04767352, -0.07991356, -0.18002789, ...,  0.01272012,\n",
      "         0.01707499, -0.06320348],\n",
      "       [-0.03559419,  0.21012041, -0.01103521, ...,  0.0004372 ,\n",
      "         0.07313728, -0.11534607],\n",
      "       [ 0.01100184, -0.01393563,  0.01907629, ..., -0.06346744,\n",
      "         0.06259918,  0.02399345],\n",
      "       ...,\n",
      "       [-0.02762232,  0.01028949,  0.05649286, ..., -0.05169573,\n",
      "        -0.07496671,  0.08968396],\n",
      "       [-0.1346285 , -0.1806432 ,  0.04579327, ..., -0.00316535,\n",
      "        -0.01189528,  0.02714246],\n",
      "       [-0.0207127 , -0.07989797,  0.02051542, ..., -0.1004671 ,\n",
      "        -0.06404323, -0.04039845]], dtype=float32))\n",
      "(array([ 3.0710754e+02,  4.0157685e-01,  9.8168120e-02,  1.8800234e-02,\n",
      "        1.6753910e-02,  7.7096741e-03,  2.1499821e-03,  1.6745140e-03,\n",
      "        1.2422978e-03,  7.9111964e-04,  5.9051416e-04,  3.1592816e-04,\n",
      "        2.4390373e-04,  1.3688953e-04,  1.0655087e-04,  7.7353121e-05,\n",
      "        7.1114366e-05,  6.2850893e-05,  3.8405258e-05,  3.5542900e-05,\n",
      "        2.9233412e-05,  2.6363967e-05,  2.0178561e-05,  1.4483032e-05,\n",
      "       -1.0809373e-05,  1.2380506e-05,  1.1219813e-05,  9.2939572e-06,\n",
      "       -6.7907204e-06,  7.9608290e-06,  7.3004076e-06, -5.2106598e-06,\n",
      "        6.3912480e-06,  4.7761705e-06,  4.9155851e-06, -4.1159269e-06,\n",
      "        3.9865695e-06, -2.6904629e-06,  3.5377182e-06,  3.3045899e-06,\n",
      "        3.0797196e-06,  3.1680115e-06, -2.3721752e-06,  2.5289364e-06,\n",
      "        2.1136652e-06, -1.6561283e-06, -1.3954765e-06, -1.1769949e-06,\n",
      "        1.5893454e-06,  1.4790629e-06,  1.3422862e-06,  1.2653908e-06,\n",
      "       -1.0003670e-06, -7.9187532e-07,  1.0864405e-06,  1.0419717e-06,\n",
      "        9.9441343e-07, -7.6760665e-07,  8.3349352e-07,  8.2053640e-07,\n",
      "       -6.1856980e-07,  6.8618328e-07, -5.5664680e-07,  6.4852105e-07,\n",
      "        5.4588645e-07, -4.3470175e-07, -4.1151074e-07, -3.3564481e-07,\n",
      "       -2.9745399e-07,  5.1882836e-07,  4.6976072e-07,  4.6148079e-07,\n",
      "        4.0729344e-07,  3.9548456e-07,  3.3272497e-07, -2.2680634e-07,\n",
      "        3.0274580e-07,  2.7752924e-07, -2.3714725e-07, -1.6860143e-07,\n",
      "        2.4710528e-07,  2.3733406e-07, -1.4421674e-07,  2.1624886e-07,\n",
      "        2.0434135e-07,  1.9178772e-07,  1.6945251e-07, -1.1000220e-07,\n",
      "        1.2911163e-07,  1.2262338e-07, -9.2644619e-08, -8.1068762e-08,\n",
      "       -7.0527605e-08,  1.1091214e-07,  9.2888556e-08,  8.4821686e-08,\n",
      "       -4.3596955e-08,  6.8172177e-08,  6.7364887e-08,  4.6429964e-08,\n",
      "       -3.5366504e-08, -2.5307013e-08,  4.0095259e-08,  3.2584250e-08,\n",
      "        3.4313658e-08,  2.7281663e-08,  1.8181405e-08, -1.9348718e-08,\n",
      "        1.5314608e-08, -1.3906985e-08,  1.1564156e-08,  9.0677288e-09,\n",
      "       -1.3222632e-08,  3.9555235e-09, -9.0648005e-09, -8.6816483e-09,\n",
      "        1.1675200e-09, -5.3591962e-09, -7.1486506e-10, -2.2813855e-09],\n",
      "      dtype=float32), array([[-0.0467481 , -0.06415905,  0.14044397, ...,  0.04827457,\n",
      "        -0.01557779, -0.01243281],\n",
      "       [-0.03317074,  0.18704112, -0.00702937, ..., -0.00422672,\n",
      "        -0.02680118, -0.02200744],\n",
      "       [ 0.01316788, -0.02613266,  0.06202848, ...,  0.01163366,\n",
      "        -0.05394309, -0.00663974],\n",
      "       ...,\n",
      "       [-0.03372011,  0.06323589, -0.02363617, ..., -0.02622565,\n",
      "        -0.04956942, -0.0142304 ],\n",
      "       [-0.13523762, -0.16526169, -0.0142335 , ..., -0.00623969,\n",
      "        -0.02092827, -0.01213382],\n",
      "       [-0.0195894 , -0.07769136,  0.01111823, ..., -0.01906774,\n",
      "         0.13586189, -0.04859142]], dtype=float32))\n",
      "(array([ 2.86976776e+02,  4.06360984e-01,  3.00417393e-01,  3.98025475e-02,\n",
      "        2.21295785e-02,  2.02961247e-02,  5.87202283e-03,  3.82315321e-03,\n",
      "        2.63839425e-03,  1.48552784e-03,  1.42992986e-03,  8.98628845e-04,\n",
      "        6.26570894e-04,  4.62542375e-04,  3.32253578e-04,  3.12294404e-04,\n",
      "        2.50622543e-04,  1.39775642e-04,  1.10495945e-04,  8.33618105e-05,\n",
      "        6.91882888e-05,  6.06059002e-05,  5.18359157e-05,  4.01773723e-05,\n",
      "        2.49773675e-05,  1.95251814e-05,  1.63788955e-05, -9.01225303e-06,\n",
      "        1.15574385e-05,  9.99771964e-06,  8.98052076e-06, -5.56935220e-06,\n",
      "        6.83538656e-06,  6.09731524e-06,  6.56013935e-06,  5.06198194e-06,\n",
      "        4.66558004e-06,  4.62184335e-06, -3.40154133e-06, -2.82207316e-06,\n",
      "        3.46289221e-06,  3.11602275e-06, -2.15527666e-06, -1.89291916e-06,\n",
      "        2.69740167e-06,  2.30640694e-06,  2.18198215e-06,  1.97133272e-06,\n",
      "       -1.54060751e-06,  1.79606411e-06,  1.66583322e-06, -1.35019366e-06,\n",
      "        1.47522258e-06,  1.35691960e-06, -1.05688434e-06, -8.83195810e-07,\n",
      "        1.15105195e-06,  8.91481363e-07,  8.51397886e-07, -6.73793920e-07,\n",
      "       -5.74980959e-07, -5.62565617e-07, -4.81492179e-07,  7.13043562e-07,\n",
      "        6.77330263e-07,  6.16355067e-07,  5.48236414e-07,  5.15911722e-07,\n",
      "       -3.89628894e-07,  4.18034801e-07, -3.30844927e-07,  3.35060946e-07,\n",
      "        3.24892682e-07, -2.37962979e-07, -2.21609653e-07,  2.76979677e-07,\n",
      "        2.62006637e-07, -1.96973389e-07, -1.52434623e-07, -1.44126872e-07,\n",
      "       -1.13779301e-07,  2.04587707e-07,  1.90985673e-07,  1.77517620e-07,\n",
      "        1.71722178e-07,  1.55434222e-07, -1.00116580e-07,  1.40672938e-07,\n",
      "        1.12912005e-07, -7.11172063e-08, -8.46037977e-08, -6.18073770e-08,\n",
      "       -5.24932808e-08,  1.00835102e-07,  9.29990236e-08,  8.01475224e-08,\n",
      "       -4.57798635e-08, -2.78537904e-08,  6.42670273e-08,  6.05184951e-08,\n",
      "        5.27514281e-08, -2.25768257e-08,  4.82612066e-08, -9.25730781e-09,\n",
      "       -1.25328272e-08, -1.70113807e-08,  3.98404190e-08,  3.62520467e-08,\n",
      "        3.81003069e-08, -4.72896788e-09, -3.47190388e-10, -1.49929213e-09,\n",
      "        3.33655414e-09,  2.59746944e-08,  2.44985561e-08,  8.83278606e-09,\n",
      "        5.33666267e-09,  1.29410322e-08,  1.91726404e-08,  1.72885883e-08],\n",
      "      dtype=float32), array([[-0.04414851,  0.10381947,  0.23170711, ...,  0.03257306,\n",
      "        -0.01207183,  0.06938779],\n",
      "       [-0.03430733,  0.12383753, -0.135665  , ...,  0.00656268,\n",
      "         0.09916081,  0.0210705 ],\n",
      "       [ 0.01439133, -0.0934796 , -0.07255562, ..., -0.09644017,\n",
      "        -0.24823894,  0.10489827],\n",
      "       ...,\n",
      "       [-0.03096798,  0.15738674,  0.08627354, ...,  0.0030353 ,\n",
      "         0.03621348,  0.01989796],\n",
      "       [-0.13378409, -0.13886939,  0.07966901, ..., -0.00952991,\n",
      "         0.03153874,  0.00399196],\n",
      "       [-0.01841322, -0.08178595,  0.01661729, ..., -0.13332088,\n",
      "        -0.02081289,  0.02331634]], dtype=float32))\n",
      "(array([ 2.98695862e+02,  4.75737333e-01,  2.25092903e-01,  1.26222759e-01,\n",
      "        3.84613760e-02,  2.79510487e-02,  1.89972539e-02,  8.56904965e-03,\n",
      "        6.06330344e-03,  3.06703430e-03,  2.12853635e-03,  1.15419854e-03,\n",
      "        9.38046025e-04,  6.66806241e-04,  5.99582912e-04,  4.56495793e-04,\n",
      "        3.72685667e-04,  3.02385917e-04,  2.52236146e-04,  1.88402104e-04,\n",
      "        1.02784128e-04,  8.69151409e-05,  6.57503770e-05,  5.84285153e-05,\n",
      "        4.22472403e-05,  3.70542730e-05,  2.59253065e-05,  2.30991536e-05,\n",
      "        2.17233719e-05,  2.07583216e-05,  1.63274017e-05,  1.42408589e-05,\n",
      "       -1.05475265e-05,  1.20868071e-05,  1.06065254e-05,  8.10505389e-06,\n",
      "       -6.65621246e-06,  7.16882960e-06, -4.72869397e-06,  6.33467107e-06,\n",
      "       -3.55993939e-06,  4.91947503e-06,  4.63520337e-06,  4.39968471e-06,\n",
      "        4.19305161e-06,  3.87554383e-06,  3.36032599e-06, -2.31263016e-06,\n",
      "        2.73066598e-06, -1.90820947e-06, -1.76400056e-06,  2.23777579e-06,\n",
      "        1.99252327e-06,  1.76882918e-06,  1.74113279e-06, -1.27053818e-06,\n",
      "        1.53596363e-06, -1.00069076e-06,  1.39307997e-06,  1.29417424e-06,\n",
      "        1.15848331e-06,  1.01827914e-06, -8.72764474e-07,  8.42830389e-07,\n",
      "       -7.94646041e-07, -6.98330723e-07,  7.09415929e-07,  6.41773966e-07,\n",
      "        5.71433077e-07, -4.77001834e-07, -4.19595295e-07, -3.87636675e-07,\n",
      "        4.69644306e-07,  4.18137802e-07,  3.92293771e-07,  3.54629577e-07,\n",
      "       -3.05005443e-07,  2.97372509e-07,  2.74428885e-07, -2.60489003e-07,\n",
      "       -2.29539793e-07, -1.95761004e-07, -1.58655510e-07, -1.47627347e-07,\n",
      "        2.17347988e-07,  1.76993922e-07,  1.98081096e-07,  1.63674045e-07,\n",
      "       -1.34283624e-07,  1.45427691e-07, -1.13971261e-07,  1.29204565e-07,\n",
      "        1.03504846e-07, -9.21834271e-08, -7.53675593e-08, -6.99355525e-08,\n",
      "        7.67626318e-08, -4.67822794e-08,  7.83754714e-08, -3.63315635e-08,\n",
      "        5.85094142e-08,  5.16102681e-08,  4.53979609e-08, -2.57923070e-08,\n",
      "       -2.12893170e-08,  3.67156652e-08,  3.15317266e-08, -1.55632840e-08,\n",
      "        2.15481712e-08,  1.68920220e-08, -7.56983276e-09, -4.85609686e-09,\n",
      "       -2.56266341e-09, -7.60204788e-10,  2.29441866e-09,  1.16657137e-08,\n",
      "        1.00159028e-08,  8.89688678e-09,  4.71359440e-09,  6.88316337e-09],\n",
      "      dtype=float32), array([[-0.04838779, -0.09773853,  0.18634781, ..., -0.06277361,\n",
      "        -0.02255596, -0.05678794],\n",
      "       [-0.03336731,  0.18965739,  0.01644615, ..., -0.05035529,\n",
      "         0.02180213, -0.00851087],\n",
      "       [ 0.01257276, -0.02488484,  0.03258346, ..., -0.18437302,\n",
      "        -0.07343788, -0.14076562],\n",
      "       ...,\n",
      "       [-0.03073994,  0.04021015,  0.02112816, ...,  0.06657871,\n",
      "        -0.0455624 ,  0.00552231],\n",
      "       [-0.13240789, -0.17333204,  0.03665384, ..., -0.00619239,\n",
      "        -0.01390227,  0.00896433],\n",
      "       [-0.01930366, -0.08885323, -0.00261186, ..., -0.05460592,\n",
      "        -0.05751001,  0.17263299]], dtype=float32))\n",
      "(array([ 3.1910025e+02,  5.1735842e-01,  1.2517381e-01,  7.5061932e-02,\n",
      "        2.0835025e-02,  1.4821214e-02,  7.3573147e-03,  4.8671407e-03,\n",
      "        2.3838829e-03,  1.3238428e-03,  1.1384090e-03,  8.5986091e-04,\n",
      "        5.5731979e-04,  4.9915869e-04,  3.4783999e-04,  2.8000018e-04,\n",
      "        2.1584413e-04,  1.4984739e-04,  1.3148092e-04,  1.1618550e-04,\n",
      "        7.4080090e-05,  6.1400729e-05,  5.8056699e-05,  3.9551094e-05,\n",
      "        3.1601110e-05,  2.6142316e-05,  2.3974999e-05,  1.7854074e-05,\n",
      "        1.3598632e-05,  1.1788796e-05, -9.0854001e-06,  1.0337162e-05,\n",
      "        9.4868110e-06,  7.5023918e-06, -6.1203755e-06,  6.7222109e-06,\n",
      "        6.2928966e-06,  5.9692143e-06,  5.3369449e-06,  5.1802203e-06,\n",
      "        4.7166059e-06, -3.7155282e-06,  3.9754536e-06, -2.7153874e-06,\n",
      "        3.2760629e-06,  3.0069234e-06, -2.2260722e-06,  2.5916559e-06,\n",
      "        2.4734584e-06, -1.9797860e-06,  2.1202834e-06, -1.6775368e-06,\n",
      "        1.8437712e-06,  1.7046840e-06, -1.4028091e-06,  1.5760834e-06,\n",
      "        1.3551708e-06, -1.1510338e-06, -1.0659714e-06, -8.9655214e-07,\n",
      "        1.1626945e-06,  1.0725593e-06,  8.5708660e-07,  7.9661930e-07,\n",
      "        7.3168223e-07, -6.4107309e-07,  6.8101338e-07, -5.3403926e-07,\n",
      "        5.7077375e-07, -4.4222017e-07,  4.9828628e-07,  4.3762014e-07,\n",
      "       -3.8478919e-07,  4.0139705e-07, -3.1603145e-07, -2.7525883e-07,\n",
      "        3.3897882e-07,  3.0893008e-07, -2.2982877e-07,  2.7908658e-07,\n",
      "        2.2999714e-07,  2.1131051e-07,  2.0505576e-07, -1.6684763e-07,\n",
      "       -1.5671512e-07,  1.6383278e-07, -1.4279630e-07, -1.3093191e-07,\n",
      "        1.4462721e-07,  1.4006970e-07, -1.1707458e-07,  1.1537150e-07,\n",
      "        9.6075823e-08,  9.4801230e-08, -8.0901174e-08, -7.7463952e-08,\n",
      "       -6.1121852e-08,  7.6418331e-08, -5.2181079e-08,  5.8384593e-08,\n",
      "        5.1524768e-08, -4.0530775e-08, -2.9587712e-08,  4.2527645e-08,\n",
      "       -2.4388058e-08,  3.2696150e-08, -1.7678991e-08,  2.4754099e-08,\n",
      "       -1.4397444e-08,  2.3297916e-08,  2.0390500e-08, -8.1628446e-09,\n",
      "        1.2725280e-08,  1.0671250e-08, -4.1685579e-09, -1.4276355e-09,\n",
      "       -2.5315718e-09,  5.8879994e-09,  3.4492416e-09,  3.7272989e-09],\n",
      "      dtype=float32), array([[-0.04902848, -0.08943778,  0.12072524, ...,  0.01280395,\n",
      "         0.01086513,  0.01183428],\n",
      "       [-0.03574685,  0.20777082,  0.01828079, ..., -0.01290962,\n",
      "        -0.04789127,  0.00326237],\n",
      "       [ 0.00895155, -0.00784441,  0.06338086, ...,  0.16145837,\n",
      "         0.01926097,  0.09943447],\n",
      "       ...,\n",
      "       [-0.02427367,  0.02970349, -0.02412634, ...,  0.12928416,\n",
      "        -0.06501158, -0.05778739],\n",
      "       [-0.1369337 , -0.17819194,  0.12925309, ..., -0.01215075,\n",
      "        -0.00034999, -0.00557316],\n",
      "       [-0.0250224 , -0.08016589,  0.08973724, ..., -0.07428167,\n",
      "         0.00459232,  0.00600493]], dtype=float32))\n",
      "(array([ 2.97636810e+02,  3.73338044e-01,  1.62711009e-01,  2.49628425e-02,\n",
      "        1.35440202e-02,  1.12769306e-02,  4.42511775e-03,  3.32255871e-03,\n",
      "        1.81791291e-03,  1.00631197e-03,  8.76212027e-04,  5.45932504e-04,\n",
      "        5.16084372e-04,  3.36496218e-04,  2.21859475e-04,  1.79086375e-04,\n",
      "        1.16300653e-04,  9.74052236e-05,  6.00418207e-05,  5.00629249e-05,\n",
      "        3.80876409e-05,  3.62683713e-05,  2.58423788e-05,  2.40257395e-05,\n",
      "        1.79878298e-05,  1.61549451e-05,  1.39994045e-05,  1.24519083e-05,\n",
      "       -9.63897037e-06,  9.76655610e-06,  8.43759972e-06, -6.13935254e-06,\n",
      "        5.75074864e-06,  5.13410805e-06, -4.03427021e-06,  4.42433520e-06,\n",
      "        4.11787323e-06, -3.36628955e-06,  3.68172050e-06,  3.26690542e-06,\n",
      "        2.95486439e-06, -2.65124322e-06, -2.41743328e-06,  2.54305655e-06,\n",
      "        2.11246038e-06,  2.04367439e-06,  1.92800144e-06, -1.72761963e-06,\n",
      "       -1.60542527e-06,  1.62727827e-06, -1.24037922e-06,  1.40233601e-06,\n",
      "       -1.08907409e-06,  1.18626849e-06,  1.01721184e-06,  9.00976659e-07,\n",
      "       -7.33456773e-07, -7.15339525e-07,  8.91868467e-07,  8.24815231e-07,\n",
      "       -6.55810140e-07,  7.57658370e-07,  7.19768764e-07,  6.52976382e-07,\n",
      "       -5.53721407e-07,  5.62600462e-07, -4.65187185e-07,  5.08754511e-07,\n",
      "        4.32502105e-07,  4.09947006e-07, -3.73092377e-07, -3.36523414e-07,\n",
      "       -3.00812758e-07,  3.41907480e-07, -2.37505532e-07, -2.11486920e-07,\n",
      "        2.92079136e-07,  2.86343607e-07,  2.43897063e-07,  2.31786998e-07,\n",
      "       -1.81485376e-07,  2.05190631e-07, -1.73829136e-07, -1.42258486e-07,\n",
      "       -1.18928007e-07,  1.63808608e-07,  1.46971360e-07,  1.33063239e-07,\n",
      "        1.16207374e-07, -8.53995843e-08,  1.04616348e-07, -7.56055556e-08,\n",
      "        8.55362501e-08,  8.27044744e-08, -5.74515653e-08, -4.66438017e-08,\n",
      "        7.55982867e-08,  5.65872540e-08,  5.36457776e-08, -3.58117411e-08,\n",
      "       -3.09565813e-08, -2.62528186e-08,  4.19058814e-08,  3.57686041e-08,\n",
      "       -1.70093877e-08, -1.61769957e-08,  3.26813989e-08,  2.68129305e-08,\n",
      "        2.36031532e-08,  1.70119705e-08, -8.96156926e-09,  1.42152290e-08,\n",
      "        1.22675372e-08, -6.52826770e-09, -1.72860837e-09, -3.68304637e-10,\n",
      "        9.85338922e-10,  7.06457337e-09,  6.36879349e-09,  3.52243434e-09],\n",
      "      dtype=float32), array([[-4.9449023e-02,  1.0319658e-01, -1.7484432e-01, ...,\n",
      "        -9.8305410e-03,  2.3156175e-02, -6.8094775e-02],\n",
      "       [-3.2549731e-02, -1.9983847e-01,  1.7623063e-02, ...,\n",
      "         1.0756734e-01,  1.4602105e-02,  2.1042850e-02],\n",
      "       [ 1.1644954e-02,  2.2788268e-02, -5.7500433e-02, ...,\n",
      "        -8.2442045e-02,  5.6466434e-02,  1.8286885e-01],\n",
      "       ...,\n",
      "       [-3.1270046e-02, -3.9564651e-02, -2.3952434e-02, ...,\n",
      "        -8.3694877e-03,  1.4331748e-02,  6.0197987e-02],\n",
      "       [-1.3109751e-01,  1.5393066e-01,  7.8352988e-02, ...,\n",
      "        -3.7325427e-02, -1.6889691e-02,  1.6266771e-02],\n",
      "       [-2.2069693e-02,  7.9789296e-02, -2.8593991e-02, ...,\n",
      "        -3.8446188e-02, -9.4155032e-05,  1.1895845e-03]], dtype=float32))\n",
      "(array([ 3.00050537e+02,  2.74117142e-01,  5.73390462e-02,  1.57869775e-02,\n",
      "        1.21116247e-02,  8.33810586e-03,  3.14774201e-03,  2.77363067e-03,\n",
      "        6.96815434e-04,  6.23535539e-04,  4.25570790e-04,  3.49700043e-04,\n",
      "        3.16348334e-04,  1.32143643e-04,  8.40271459e-05,  7.12649271e-05,\n",
      "        5.18857996e-05,  3.61578568e-05,  2.38486173e-05,  2.19462418e-05,\n",
      "        1.83320662e-05, -1.20605018e-05,  1.53513138e-05,  1.35988084e-05,\n",
      "        9.79761262e-06, -7.77060814e-06,  8.78282117e-06,  8.23465780e-06,\n",
      "       -5.26026633e-06,  6.99286056e-06,  6.79443610e-06,  6.03903891e-06,\n",
      "        5.69447093e-06, -3.67850794e-06,  5.08721632e-06,  4.01763873e-06,\n",
      "        3.92490847e-06, -2.88806200e-06,  3.62750575e-06,  3.23389554e-06,\n",
      "       -2.22053859e-06,  2.46439504e-06,  2.32372076e-06,  2.28858289e-06,\n",
      "       -1.72027967e-06,  2.05633819e-06,  1.90645233e-06, -1.28885972e-06,\n",
      "        1.57396175e-06,  1.36302822e-06, -1.16623994e-06,  1.23443033e-06,\n",
      "        1.09675977e-06, -9.31675231e-07, -8.87370902e-07,  1.02064394e-06,\n",
      "        9.99719759e-07,  8.84139183e-07, -6.43470969e-07,  6.93380230e-07,\n",
      "       -5.68654627e-07, -5.32208730e-07,  6.01801446e-07,  5.57317435e-07,\n",
      "       -4.41344127e-07,  4.47578003e-07,  4.06585997e-07, -3.43905526e-07,\n",
      "        3.74793558e-07, -3.21767175e-07,  3.48062940e-07, -2.89456295e-07,\n",
      "       -2.39552691e-07,  3.22113863e-07,  2.88925605e-07,  2.67565071e-07,\n",
      "        2.31882908e-07,  2.01449893e-07, -1.63499536e-07,  1.86317649e-07,\n",
      "       -1.53095883e-07, -1.49699119e-07,  1.54570813e-07, -1.16922280e-07,\n",
      "       -7.74447884e-08,  1.42193343e-07,  1.32885859e-07,  1.15550925e-07,\n",
      "        9.52549257e-08,  9.37531226e-08,  8.68112764e-08, -6.50456684e-08,\n",
      "        7.68307729e-08, -5.63060709e-08, -5.34575761e-08,  6.17770226e-08,\n",
      "        5.98826588e-08, -4.26823590e-08, -3.83202305e-08,  5.10351619e-08,\n",
      "       -3.35882326e-08,  4.10261372e-08, -2.38788047e-08,  3.50180009e-08,\n",
      "        3.19012550e-08,  2.35664519e-08, -1.71735426e-08, -1.25864998e-08,\n",
      "       -1.14751924e-08,  1.64176370e-08, -6.64599442e-09,  1.25388668e-08,\n",
      "        1.37682870e-08,  1.06191349e-08, -2.33223796e-09,  6.68184175e-09,\n",
      "        4.75789053e-09, -1.17861043e-09,  5.95568386e-11,  2.37143261e-09],\n",
      "      dtype=float32), array([[-0.05120042, -0.10775386,  0.00317782, ..., -0.01704207,\n",
      "         0.00585462, -0.03656023],\n",
      "       [-0.03416542,  0.19271852, -0.07670042, ...,  0.00801131,\n",
      "        -0.07807488,  0.0356589 ],\n",
      "       [ 0.00808935, -0.02513642, -0.03413776, ...,  0.08947691,\n",
      "        -0.01933449, -0.10270721],\n",
      "       ...,\n",
      "       [-0.02468421,  0.03698716,  0.00980991, ...,  0.05163379,\n",
      "        -0.08614112,  0.00274941],\n",
      "       [-0.12918992, -0.20687525, -0.12046243, ...,  0.01022799,\n",
      "         0.00185702, -0.00890852],\n",
      "       [-0.02326225, -0.06963371, -0.02799325, ..., -0.07234409,\n",
      "         0.01410496,  0.03217272]], dtype=float32))\n",
      "(array([ 3.43123474e+02,  4.61609781e-01,  2.04966858e-01,  6.68076053e-02,\n",
      "        2.61243898e-02,  1.76056772e-02,  1.45008191e-02,  1.03477985e-02,\n",
      "        5.33867627e-03,  3.01452191e-03,  2.46817735e-03,  1.31543039e-03,\n",
      "        8.85193818e-04,  6.51209673e-04,  4.14372247e-04,  3.77280463e-04,\n",
      "        2.51696823e-04,  2.11133622e-04,  1.88420876e-04,  1.37436306e-04,\n",
      "        1.07671636e-04,  8.13659863e-05,  6.90444285e-05,  5.13603190e-05,\n",
      "        4.73251202e-05,  4.23498968e-05,  3.69389418e-05,  2.67188461e-05,\n",
      "        2.12499763e-05,  1.70554868e-05,  1.44448604e-05,  1.34168758e-05,\n",
      "        1.25422912e-05,  9.51686252e-06,  9.02675401e-06, -7.73931879e-06,\n",
      "        6.57948158e-06, -6.33777790e-06, -5.60067838e-06,  5.50292771e-06,\n",
      "        5.27476186e-06,  4.71883914e-06, -3.68629890e-06, -3.45204489e-06,\n",
      "        4.06881009e-06,  3.56484998e-06,  3.12145698e-06,  2.83504596e-06,\n",
      "        2.56521116e-06,  2.29120883e-06, -2.11768361e-06,  2.35968423e-06,\n",
      "       -1.69357440e-06,  1.89551452e-06,  1.67223868e-06,  1.55582131e-06,\n",
      "       -1.25872850e-06, -1.17207253e-06,  1.22492884e-06, -1.02950469e-06,\n",
      "        1.09263647e-06,  1.06446498e-06, -8.91790080e-07,  7.80460880e-07,\n",
      "       -7.06895491e-07, -6.28540590e-07,  6.24179620e-07,  5.92941092e-07,\n",
      "       -5.37765516e-07, -4.75071033e-07,  5.23754920e-07,  4.91481899e-07,\n",
      "       -3.92433435e-07, -3.51374212e-07,  3.92584496e-07,  3.59047078e-07,\n",
      "        3.39564821e-07, -2.45879733e-07,  2.75776841e-07,  2.50121275e-07,\n",
      "        2.44072908e-07, -1.87761628e-07, -1.59666357e-07, -1.70322366e-07,\n",
      "        1.88196921e-07,  1.77941317e-07, -1.17133006e-07,  1.52965967e-07,\n",
      "        1.30343693e-07,  1.38884900e-07,  1.13806230e-07,  1.03391905e-07,\n",
      "       -8.55777600e-08, -9.69297389e-08, -7.33482750e-08,  8.35266860e-08,\n",
      "        9.72340857e-08,  6.50368293e-08, -5.44851702e-08,  4.94002563e-08,\n",
      "        4.17307291e-08, -4.31066951e-08, -3.82221543e-08, -3.40145334e-08,\n",
      "        3.49080764e-08,  2.39892159e-08,  2.70820166e-08, -2.10951878e-08,\n",
      "       -1.84501747e-08,  1.68706773e-08,  1.31659768e-08, -9.18866405e-09,\n",
      "       -6.73558320e-09,  8.79461037e-09,  7.24131732e-09, -3.87106613e-09,\n",
      "        3.98712263e-09,  1.24466915e-09, -2.07804796e-09, -1.15914234e-09],\n",
      "      dtype=float32), array([[-0.05744306,  0.09672703,  0.05656361, ...,  0.02214964,\n",
      "        -0.00628293,  0.04644454],\n",
      "       [-0.03772665, -0.20143594,  0.05525823, ..., -0.03729604,\n",
      "         0.04208688,  0.02048392],\n",
      "       [ 0.00474646,  0.005656  , -0.03502953, ...,  0.22421464,\n",
      "        -0.03207419,  0.03665694],\n",
      "       ...,\n",
      "       [-0.0189501 , -0.00386667,  0.102587  , ..., -0.07217801,\n",
      "         0.00760546,  0.06797038],\n",
      "       [-0.13494615,  0.21680893,  0.15930535, ..., -0.01437668,\n",
      "        -0.0266437 , -0.00168166],\n",
      "       [-0.02607142,  0.08402327,  0.00146138, ...,  0.01920993,\n",
      "        -0.06909105,  0.07781194]], dtype=float32))\n",
      "(array([ 3.70270508e+02,  3.37259173e-01,  1.44228995e-01,  5.55222966e-02,\n",
      "        3.32391262e-02,  1.94326770e-02,  6.44033123e-03,  5.72125008e-03,\n",
      "        4.69044503e-03,  2.49532098e-03,  1.47887517e-03,  1.06581580e-03,\n",
      "        6.94514019e-04,  5.40654699e-04,  3.02928936e-04,  2.60058820e-04,\n",
      "        2.21636030e-04,  1.77121517e-04,  1.08438944e-04,  8.14180457e-05,\n",
      "        6.36961486e-05,  5.30409015e-05,  5.03412630e-05,  3.51281560e-05,\n",
      "        3.06864240e-05,  2.44613257e-05,  2.07494777e-05,  1.91374183e-05,\n",
      "        1.54341415e-05, -9.64419178e-06,  1.33949225e-05,  1.23604923e-05,\n",
      "        1.00786347e-05,  9.13032818e-06, -7.20492972e-06, -6.04918978e-06,\n",
      "        7.60023022e-06,  7.44775298e-06,  6.43728936e-06,  5.85360112e-06,\n",
      "        5.30941952e-06,  4.58682734e-06, -4.27576106e-06, -4.19195067e-06,\n",
      "       -2.94092933e-06,  3.78986124e-06,  3.55604971e-06,  3.19017477e-06,\n",
      "        2.86876798e-06, -2.31436798e-06,  2.06920231e-06,  1.92572429e-06,\n",
      "       -1.69825910e-06, -1.57606326e-06,  1.62892889e-06, -1.30113892e-06,\n",
      "        1.38147402e-06,  1.25613951e-06,  1.18425055e-06,  1.21090943e-06,\n",
      "       -9.77432705e-07, -9.22811012e-07,  1.04887897e-06, -8.26185385e-07,\n",
      "        9.27529868e-07,  8.56285681e-07, -6.42092516e-07,  7.10875611e-07,\n",
      "        6.95742187e-07, -5.26806559e-07, -4.70326313e-07, -4.05963618e-07,\n",
      "       -3.97559575e-07,  5.52070446e-07,  5.40050621e-07,  4.60698573e-07,\n",
      "        3.94808922e-07, -2.87190289e-07, -2.28221637e-07,  3.53756434e-07,\n",
      "        3.36421692e-07,  3.08743267e-07,  2.34382625e-07,  2.31347400e-07,\n",
      "       -1.88747649e-07, -1.64730039e-07,  1.97417890e-07,  1.76672614e-07,\n",
      "        1.65283836e-07, -1.44206467e-07,  1.41491185e-07, -1.19682738e-07,\n",
      "       -1.01308245e-07, -8.68496173e-08,  1.18159626e-07,  1.05838112e-07,\n",
      "        9.26099233e-08, -6.81724543e-08,  8.00282152e-08, -4.46499548e-08,\n",
      "        5.71958338e-08, -3.61956403e-08,  4.94135470e-08,  4.29323741e-08,\n",
      "        3.79027227e-08, -2.50130441e-08,  2.52440575e-08,  2.24992522e-08,\n",
      "       -1.80297661e-08, -1.67828151e-08, -1.50643551e-08,  1.52290269e-08,\n",
      "       -6.91814384e-09, -4.99738606e-09,  1.01760209e-08,  8.27410407e-09,\n",
      "        1.28006117e-09, -1.21713040e-09,  3.31110694e-09,  4.20061275e-09],\n",
      "      dtype=float32), array([[-0.05722781,  0.05136998,  0.01321697, ...,  0.02143034,\n",
      "        -0.01328053,  0.01548545],\n",
      "       [-0.03822567, -0.1875434 ,  0.09937739, ...,  0.02099019,\n",
      "         0.02335442, -0.01244674],\n",
      "       [ 0.00401563,  0.00730584,  0.01306865, ..., -0.12518755,\n",
      "         0.16618997,  0.12001401],\n",
      "       ...,\n",
      "       [-0.01665878, -0.0097566 , -0.03554974, ...,  0.00813694,\n",
      "         0.00181233,  0.05879902],\n",
      "       [-0.14054151,  0.24385929,  0.12535289, ...,  0.01003269,\n",
      "         0.02270904, -0.03283162],\n",
      "       [-0.0273238 ,  0.07576284,  0.03854933, ...,  0.02180744,\n",
      "         0.00642059,  0.01896337]], dtype=float32))\n",
      "(array([ 3.92694580e+02,  5.02568364e-01,  2.16641411e-01,  1.66491792e-01,\n",
      "        7.70660490e-02,  5.08640744e-02,  2.97488216e-02,  1.58353411e-02,\n",
      "        8.31644610e-03,  7.77958799e-03,  4.95887501e-03,  3.02267028e-03,\n",
      "        1.82688993e-03,  1.34016760e-03,  1.08870806e-03,  9.16602788e-04,\n",
      "        5.96842670e-04,  4.09319415e-04,  3.87154054e-04,  3.31158575e-04,\n",
      "        2.55898252e-04,  2.03114090e-04,  1.51737448e-04,  1.42375720e-04,\n",
      "        1.17625365e-04,  9.04221160e-05,  7.26712969e-05,  6.90759553e-05,\n",
      "        6.48660498e-05,  4.74280787e-05,  4.23968559e-05,  3.31651936e-05,\n",
      "        2.73173264e-05,  2.23947500e-05,  2.07530138e-05,  1.58292605e-05,\n",
      "       -9.29331600e-06,  1.37886118e-05,  1.24064291e-05,  1.08619297e-05,\n",
      "        1.00771313e-05,  8.72189685e-06,  8.08310415e-06, -6.61769536e-06,\n",
      "       -5.58279453e-06,  7.48581806e-06,  6.31224793e-06,  5.95438587e-06,\n",
      "       -3.81794644e-06,  5.08887479e-06,  4.48309129e-06,  4.23789425e-06,\n",
      "       -3.43293709e-06,  3.66221025e-06,  3.27170414e-06,  2.97332645e-06,\n",
      "        2.67601945e-06, -2.09100108e-06, -1.91630261e-06,  1.87862179e-06,\n",
      "       -1.42298222e-06, -1.40080181e-06, -1.27575242e-06,  1.64326821e-06,\n",
      "        1.48896538e-06,  1.39332019e-06, -1.07713993e-06,  1.18895639e-06,\n",
      "        9.98056294e-07, -8.40222526e-07,  8.70017004e-07, -7.37726680e-07,\n",
      "       -6.95678864e-07,  7.20483854e-07, -5.48271601e-07, -5.15678039e-07,\n",
      "        6.96600182e-07,  5.54720771e-07,  5.23339054e-07,  4.80066831e-07,\n",
      "       -4.05846293e-07,  3.67456408e-07,  3.28655460e-07, -2.89549462e-07,\n",
      "       -2.72047288e-07, -1.89654045e-07, -1.82275997e-07,  2.66959205e-07,\n",
      "        2.15141597e-07,  1.98979436e-07,  2.03904790e-07,  1.69486611e-07,\n",
      "       -1.23560397e-07, -1.02298600e-07,  1.19742737e-07,  7.99416142e-08,\n",
      "       -7.61027437e-08,  6.60991333e-08,  6.41016271e-08, -6.18047835e-08,\n",
      "       -5.70698084e-08,  4.59008476e-08,  3.99886027e-08, -3.63340895e-08,\n",
      "        3.42074884e-08,  2.77676531e-08, -2.64845283e-08, -2.39224658e-08,\n",
      "        2.14780549e-08, -2.06017887e-08, -1.16095240e-08, -1.03729025e-08,\n",
      "       -8.35521696e-09,  1.37673002e-08,  1.31258497e-08,  1.01373496e-08,\n",
      "       -4.92394792e-09, -1.38271161e-09,  5.13971798e-09,  2.80888246e-09],\n",
      "      dtype=float32), array([[-6.3952461e-02,  1.0421280e-01,  2.3285413e-02, ...,\n",
      "        -1.2416473e-02, -7.0370580e-03, -1.2315055e-02],\n",
      "       [-4.5210201e-02,  2.1908176e-01, -5.7828374e-02, ...,\n",
      "         1.4385129e-02, -1.0889691e-02, -4.5779318e-02],\n",
      "       [ 2.7453648e-03,  1.2656562e-04, -7.0367411e-02, ...,\n",
      "        -4.1328538e-02,  1.0019058e-01, -1.5423359e-01],\n",
      "       ...,\n",
      "       [-9.2303269e-03, -5.9790634e-02,  2.9069814e-01, ...,\n",
      "         3.7564702e-02,  1.1773051e-01, -5.8893815e-02],\n",
      "       [-1.4527538e-01, -1.5124269e-01, -4.6437994e-02, ...,\n",
      "         9.0856431e-03, -1.7538026e-02,  4.4455142e-03],\n",
      "       [-2.8863151e-02, -6.5507472e-02, -1.5890947e-02, ...,\n",
      "        -4.2967442e-02,  3.8611852e-02,  1.3920810e-02]], dtype=float32))\n",
      "(array([ 4.4542429e+02,  4.4620749e-01,  6.4875387e-02,  3.2262363e-02,\n",
      "        2.7502220e-02,  1.0729941e-02,  6.6614193e-03,  4.0431721e-03,\n",
      "        1.7772770e-03,  1.1378912e-03,  9.0868014e-04,  8.4218831e-04,\n",
      "        3.3137112e-04,  2.3529989e-04,  1.9870220e-04,  1.2375030e-04,\n",
      "        9.9679753e-05,  7.9392099e-05,  7.0529146e-05,  4.9086313e-05,\n",
      "        4.2404521e-05,  3.4090452e-05,  2.6180627e-05,  2.2088114e-05,\n",
      "        1.6274744e-05,  1.3771795e-05, -9.9480221e-06, -9.5027626e-06,\n",
      "        1.1616864e-05,  1.0756025e-05, -7.6724709e-06,  9.1194588e-06,\n",
      "        7.9080828e-06,  7.5463299e-06, -6.4469345e-06, -5.0880153e-06,\n",
      "        6.4755573e-06,  6.1460714e-06,  5.4464213e-06,  4.8445636e-06,\n",
      "       -3.8779081e-06, -3.2677469e-06,  3.8317803e-06,  3.5741486e-06,\n",
      "        3.2871224e-06, -2.5654581e-06, -2.2756969e-06,  2.7770550e-06,\n",
      "        2.5121619e-06,  2.2239906e-06,  2.1099399e-06,  1.8240087e-06,\n",
      "       -1.9296085e-06, -1.7008331e-06, -1.4639468e-06,  1.4968706e-06,\n",
      "        1.3064081e-06, -1.0946617e-06, -1.0316083e-06,  1.0903796e-06,\n",
      "        9.7707425e-07, -8.0054252e-07, -6.5659367e-07,  8.9392705e-07,\n",
      "        7.7079403e-07,  7.5542397e-07, -5.3592350e-07, -4.1903837e-07,\n",
      "       -4.0300705e-07,  5.9155855e-07,  5.5555029e-07,  4.8921555e-07,\n",
      "        4.7413542e-07,  5.3219219e-07,  4.1094992e-07,  3.6598126e-07,\n",
      "       -3.2231569e-07, -3.0770175e-07,  3.4396950e-07, -2.7364547e-07,\n",
      "        2.8179178e-07,  2.7263988e-07,  2.3443538e-07, -1.9282737e-07,\n",
      "       -1.8700035e-07,  1.9382357e-07, -1.3897194e-07,  1.8268116e-07,\n",
      "        1.4884431e-07,  1.3778512e-07, -1.0193503e-07, -6.8878975e-08,\n",
      "        1.1588668e-07,  9.7363980e-08,  8.4827469e-08,  7.8599001e-08,\n",
      "       -6.2366297e-08,  6.3675827e-08, -5.6687625e-08, -3.5808412e-08,\n",
      "       -2.3018082e-08,  4.6907743e-08,  4.3100890e-08,  3.2628293e-08,\n",
      "        2.5602457e-08,  2.8829525e-08, -1.6666238e-08, -1.4192790e-08,\n",
      "       -1.3601310e-08,  1.7072271e-08, -7.8048874e-09,  1.2178378e-08,\n",
      "        1.1315331e-08,  9.8960964e-09,  7.3839352e-09,  5.6803495e-09,\n",
      "        2.0962583e-09, -2.9287124e-09, -2.0273128e-09, -5.6050375e-10],\n",
      "      dtype=float32), array([[-0.04826819,  0.1461598 ,  0.14777575, ...,  0.0092327 ,\n",
      "        -0.03575286,  0.00148578],\n",
      "       [-0.04583181, -0.23569292,  0.03465007, ..., -0.05592683,\n",
      "        -0.00845529,  0.01388523],\n",
      "       [ 0.00124972,  0.00487395,  0.01513151, ...,  0.22289762,\n",
      "         0.4205934 ,  0.03534678],\n",
      "       ...,\n",
      "       [-0.00530442,  0.01340439, -0.01540423, ...,  0.02288879,\n",
      "         0.16169506,  0.05568328],\n",
      "       [-0.1529962 ,  0.17026936,  0.06433699, ...,  0.01577792,\n",
      "         0.01110777, -0.00088795],\n",
      "       [-0.03313961,  0.0772578 ,  0.03600977, ...,  0.0067678 ,\n",
      "        -0.05736807,  0.06393746]], dtype=float32))\n",
      "(array([ 3.76797455e+02,  5.87272942e-01,  3.56069148e-01,  1.33695289e-01,\n",
      "        7.18279779e-02,  5.24270050e-02,  2.97132712e-02,  2.30083484e-02,\n",
      "        8.24054796e-03,  4.66994802e-03,  4.09084884e-03,  2.58102315e-03,\n",
      "        1.69622398e-03,  1.29363663e-03,  6.71413494e-04,  5.44277485e-04,\n",
      "        4.48889798e-04,  3.76375741e-04,  3.27052869e-04,  2.40871756e-04,\n",
      "        1.88844861e-04,  1.65785110e-04,  1.56908078e-04,  1.08734930e-04,\n",
      "        9.68074019e-05,  7.70984334e-05,  6.74802141e-05,  5.46192314e-05,\n",
      "        4.85768323e-05,  4.06322906e-05,  3.87279797e-05,  2.84882717e-05,\n",
      "        2.46626860e-05,  2.28991939e-05,  1.80387142e-05, -1.08681352e-05,\n",
      "        1.20131635e-05,  1.04572346e-05, -8.33170816e-06,  9.02575266e-06,\n",
      "        7.85895190e-06,  7.19108584e-06, -6.16506713e-06, -4.93546531e-06,\n",
      "        5.19491550e-06,  5.08368885e-06,  4.50116568e-06,  4.15520799e-06,\n",
      "       -3.45263334e-06, -2.95489372e-06, -2.26320708e-06,  3.20449408e-06,\n",
      "        3.04222976e-06,  2.57037209e-06,  2.62013350e-06,  2.35466041e-06,\n",
      "       -1.76890637e-06,  2.01256034e-06, -1.66208213e-06,  1.87050887e-06,\n",
      "       -1.43952866e-06, -1.02568390e-06,  1.52638211e-06,  1.38333780e-06,\n",
      "        1.25121483e-06,  1.17975060e-06, -9.20527668e-07, -7.74143871e-07,\n",
      "        8.83620601e-07,  8.38208791e-07, -6.42995929e-07,  7.57256203e-07,\n",
      "        6.55655185e-07,  5.89286856e-07, -5.47426055e-07, -4.44934358e-07,\n",
      "       -3.71106324e-07,  5.12277779e-07,  4.47053736e-07,  4.01782870e-07,\n",
      "        3.57787741e-07,  3.15932198e-07, -2.75617822e-07, -2.36376721e-07,\n",
      "        2.47349760e-07,  2.26469027e-07, -2.01288358e-07,  1.82869883e-07,\n",
      "        1.64189146e-07, -1.63711107e-07, -1.70441183e-07,  1.35897267e-07,\n",
      "        1.17218136e-07, -1.23750084e-07, -1.13693730e-07, -1.02283032e-07,\n",
      "        1.02737474e-07, -9.95167468e-08, -6.01052577e-08,  7.95845452e-08,\n",
      "        5.76518637e-08,  6.17446716e-08,  4.68765506e-08, -4.45602453e-08,\n",
      "       -3.45346187e-08,  3.60635894e-08,  3.08525969e-08, -2.30543229e-08,\n",
      "       -1.65489578e-08,  1.98955714e-08, -1.26629223e-08, -8.57559357e-09,\n",
      "       -3.33947958e-09, -4.18603952e-09,  1.23367178e-10,  3.98475608e-09,\n",
      "        1.44654200e-08,  1.27202879e-08,  8.54565307e-09,  4.95123587e-09],\n",
      "      dtype=float32), array([[-0.04878827,  0.0575909 ,  0.0720168 , ..., -0.00643823,\n",
      "         0.03525281, -0.02639935],\n",
      "       [-0.04106216, -0.2118271 ,  0.03299782, ..., -0.07815722,\n",
      "         0.04080972,  0.00235645],\n",
      "       [ 0.00556831, -0.00507162,  0.07869723, ...,  0.22193485,\n",
      "         0.03689614, -0.08294273],\n",
      "       ...,\n",
      "       [-0.01665857, -0.01048549, -0.15427458, ...,  0.03121195,\n",
      "         0.11352357, -0.07300523],\n",
      "       [-0.14830479,  0.14853095,  0.11104166, ...,  0.00232243,\n",
      "         0.0308351 , -0.00623638],\n",
      "       [-0.029206  ,  0.06197776,  0.07611179, ..., -0.02376513,\n",
      "        -0.08270177, -0.01783768]], dtype=float32))\n",
      "(array([ 3.9617615e+02,  1.1976064e+00,  7.2588795e-01,  4.5799160e-01,\n",
      "        8.2854554e-02,  5.0736945e-02,  3.2422375e-02,  1.9671408e-02,\n",
      "        1.4987349e-02,  7.0971269e-03,  5.3732535e-03,  4.7585098e-03,\n",
      "        2.8814890e-03,  2.3323777e-03,  1.9360721e-03,  1.5656550e-03,\n",
      "        8.1109506e-04,  7.4332720e-04,  5.8585184e-04,  4.6850546e-04,\n",
      "        3.3108398e-04,  3.2659163e-04,  2.0902243e-04,  1.8923488e-04,\n",
      "        1.3613715e-04,  1.0145157e-04,  8.7030654e-05,  6.9802845e-05,\n",
      "        5.2070991e-05,  4.7515554e-05,  2.7479491e-05,  2.5083615e-05,\n",
      "        2.0546688e-05, -1.1529600e-05,  1.6437582e-05,  1.5595740e-05,\n",
      "        1.4104949e-05,  1.1518295e-05,  1.0878174e-05,  1.0094877e-05,\n",
      "       -6.9229409e-06,  8.6433356e-06,  7.7849700e-06,  7.1062400e-06,\n",
      "       -5.4865832e-06, -4.4803228e-06,  5.1442112e-06,  4.7721155e-06,\n",
      "       -3.5165810e-06,  3.9510364e-06,  3.9172028e-06,  3.3038689e-06,\n",
      "        3.1350123e-06, -2.6338930e-06, -2.3575917e-06,  2.3156449e-06,\n",
      "        2.1211217e-06, -1.6362553e-06,  1.8337302e-06, -1.3478935e-06,\n",
      "       -1.2512979e-06, -1.1470788e-06,  1.5852744e-06,  1.4226624e-06,\n",
      "        1.2613439e-06,  1.0393391e-06, -9.3867317e-07,  8.8864164e-07,\n",
      "        8.5210132e-07, -6.8373839e-07,  7.5653645e-07,  6.3789372e-07,\n",
      "       -5.6779072e-07, -5.4181720e-07, -4.5326161e-07,  5.0245268e-07,\n",
      "        4.6993208e-07,  4.1774388e-07, -3.6847362e-07,  3.7805179e-07,\n",
      "        3.4083902e-07,  3.0919071e-07, -3.0824708e-07, -2.8727146e-07,\n",
      "        2.5643953e-07, -2.3824586e-07,  2.3812538e-07,  1.9360185e-07,\n",
      "        1.7969117e-07, -1.9333700e-07, -1.6907563e-07, -1.5100879e-07,\n",
      "        1.1178998e-07, -9.7065197e-08, -1.1023163e-07, -1.2564000e-07,\n",
      "        9.3044235e-08,  8.8021245e-08,  7.1154510e-08, -7.2012895e-08,\n",
      "       -6.7966020e-08,  6.1252869e-08, -4.0160337e-08,  4.0219458e-08,\n",
      "        3.4966487e-08, -2.9571757e-08, -2.5429049e-08,  2.6280766e-08,\n",
      "        2.5236385e-08, -1.9318444e-08, -1.7707430e-08,  1.6026263e-08,\n",
      "       -9.8986206e-09,  1.2349924e-08, -4.6938693e-09,  9.8114867e-09,\n",
      "       -1.9149238e-10,  2.6083291e-09,  4.4365089e-09,  5.7176632e-09],\n",
      "      dtype=float32), array([[ 0.04768638,  0.03030267, -0.02436631, ...,  0.005069  ,\n",
      "        -0.01575614, -0.02940578],\n",
      "       [ 0.03924666,  0.02896943,  0.08372734, ..., -0.01063612,\n",
      "         0.05960411, -0.01244953],\n",
      "       [-0.00605791,  0.05723187, -0.06406419, ..., -0.09152297,\n",
      "         0.10677506,  0.05404238],\n",
      "       ...,\n",
      "       [ 0.0180766 , -0.1426892 ,  0.09097938, ...,  0.09065736,\n",
      "         0.03651292,  0.10743667],\n",
      "       [ 0.15502484,  0.1583116 , -0.07464696, ..., -0.00450943,\n",
      "        -0.00215391, -0.00361228],\n",
      "       [ 0.0282221 ,  0.04629652, -0.12009212, ...,  0.00168575,\n",
      "        -0.00855367, -0.01272826]], dtype=float32))\n",
      "(array([ 3.77803558e+02,  6.04746997e-01,  3.91437918e-01,  2.67954469e-01,\n",
      "        1.24464452e-01,  6.57469630e-02,  4.84937206e-02,  3.29143368e-02,\n",
      "        1.25807989e-02,  7.88889453e-03,  6.58212788e-03,  4.88813035e-03,\n",
      "        3.83997126e-03,  3.24165681e-03,  2.41594180e-03,  1.60500500e-03,\n",
      "        1.43888313e-03,  1.02760526e-03,  7.84914300e-04,  6.43782201e-04,\n",
      "        5.02183044e-04,  3.78913828e-04,  3.68362176e-04,  3.16929392e-04,\n",
      "        2.68240139e-04,  2.45906645e-04,  1.91439918e-04,  1.57164075e-04,\n",
      "        1.28365253e-04,  1.21033627e-04,  1.08348206e-04,  8.85165427e-05,\n",
      "        8.19589259e-05,  7.24408455e-05,  6.27115878e-05,  5.19734131e-05,\n",
      "        4.37038507e-05,  3.66996283e-05,  3.47777495e-05,  2.95716854e-05,\n",
      "        2.52339705e-05,  2.16482476e-05,  1.81539344e-05,  1.67686831e-05,\n",
      "        1.46939710e-05,  1.25009128e-05, -9.20078037e-06, -7.94195785e-06,\n",
      "        8.82199129e-06,  6.52909057e-06,  5.41931195e-06,  5.36097286e-06,\n",
      "       -4.31424860e-06, -3.97448002e-06,  4.63807601e-06,  4.01562556e-06,\n",
      "        3.76189928e-06, -2.40066788e-06,  2.85660462e-06,  2.36839219e-06,\n",
      "       -1.96962674e-06,  2.15329783e-06,  1.93648134e-06,  1.52916016e-06,\n",
      "       -1.59926333e-06, -1.65124300e-06, -1.27145177e-06, -1.14000136e-06,\n",
      "        1.15822922e-06,  1.08294546e-06, -9.24740959e-07, -8.70525014e-07,\n",
      "        8.31225861e-07,  8.00488579e-07, -6.38655024e-07,  6.51404889e-07,\n",
      "       -5.42833106e-07,  5.74235571e-07,  5.56948180e-07,  4.90341392e-07,\n",
      "        4.29697764e-07, -4.31895359e-07, -3.95207621e-07,  3.30447904e-07,\n",
      "        3.00047873e-07, -3.62903023e-07, -3.10524740e-07, -2.83273152e-07,\n",
      "       -2.22539128e-07,  2.21001187e-07,  1.92160442e-07, -1.88205121e-07,\n",
      "       -1.42609764e-07,  1.62727119e-07,  1.27407887e-07, -1.19823426e-07,\n",
      "       -1.08909191e-07,  9.54911243e-08,  1.00211018e-07, -9.33685200e-08,\n",
      "        6.96291877e-08,  4.59564262e-08, -6.76112251e-08,  5.97459220e-08,\n",
      "       -6.17912903e-08, -4.65070826e-08,  2.69380802e-08, -3.19776419e-08,\n",
      "       -2.85771620e-08,  1.93928020e-08, -2.02469330e-08,  1.48573802e-08,\n",
      "        1.10811600e-08,  8.69529870e-09, -1.34632412e-08, -1.21971624e-08,\n",
      "        2.13162377e-09, -5.11505993e-09, -2.38097253e-09, -1.11120368e-09],\n",
      "      dtype=float32), array([[-4.75113876e-02,  9.46086179e-03,  6.16929792e-02, ...,\n",
      "         9.30554979e-03,  3.37639302e-02,  8.64046719e-03],\n",
      "       [-4.02123630e-02, -1.10945806e-01,  7.50357509e-02, ...,\n",
      "         9.86309815e-03,  1.33817121e-05,  6.21861918e-03],\n",
      "       [ 7.02591380e-03,  2.84445211e-02, -1.07439041e-01, ...,\n",
      "         3.02350968e-02, -1.99488252e-01,  6.69203326e-02],\n",
      "       ...,\n",
      "       [-1.80085637e-02, -5.36469780e-02,  1.89733431e-01, ...,\n",
      "        -2.05057897e-02,  6.80164397e-02, -7.20992386e-02],\n",
      "       [-1.55329093e-01, -1.84015092e-02, -5.94815053e-02, ...,\n",
      "         8.73588119e-03, -2.49773860e-02,  9.73272510e-03],\n",
      "       [-2.76237167e-02, -1.27463499e-02, -1.20133780e-01, ...,\n",
      "        -4.84765656e-02, -3.69904079e-02,  4.03001979e-02]], dtype=float32))\n",
      "(array([ 3.75543060e+02,  4.22033161e-01,  1.38966426e-01,  3.92182991e-02,\n",
      "        2.59748064e-02,  1.83748435e-02,  7.73355551e-03,  6.74102595e-03,\n",
      "        5.34409378e-03,  3.09970626e-03,  2.24069995e-03,  1.76160783e-03,\n",
      "        1.16615242e-03,  8.68945324e-04,  7.05062877e-04,  5.78147883e-04,\n",
      "        4.91373125e-04,  4.39491618e-04,  3.15651414e-04,  2.02181662e-04,\n",
      "        1.78836854e-04,  1.32355708e-04,  1.27984895e-04,  1.00661193e-04,\n",
      "        8.00031121e-05,  5.84044501e-05,  5.18453016e-05,  4.58682043e-05,\n",
      "        3.57925855e-05,  3.40984661e-05,  2.64499540e-05,  2.28289118e-05,\n",
      "        2.15631899e-05,  1.92154675e-05,  1.70665589e-05,  1.46333532e-05,\n",
      "       -1.00897423e-05, -8.94177265e-06,  1.24468033e-05,  1.10703531e-05,\n",
      "        1.06182242e-05,  8.05656509e-06,  6.81510892e-06,  6.40258941e-06,\n",
      "        6.10567531e-06, -4.66522488e-06,  5.46307865e-06, -3.69992313e-06,\n",
      "        4.49332219e-06,  4.10667553e-06, -3.11137364e-06,  3.45903254e-06,\n",
      "       -2.72314628e-06,  3.01472141e-06,  2.82222663e-06, -2.30413639e-06,\n",
      "        2.35340212e-06,  2.45374076e-06, -2.01502689e-06,  1.94112818e-06,\n",
      "       -1.71128409e-06,  1.62001811e-06, -1.27751900e-06,  1.41871408e-06,\n",
      "        1.24440078e-06, -1.11770930e-06, -1.02145111e-06, -9.61062597e-07,\n",
      "       -8.09852565e-07,  1.04538742e-06,  9.00240423e-07,  9.05134186e-07,\n",
      "        8.13922156e-07, -6.65382800e-07,  7.21390279e-07, -5.57118767e-07,\n",
      "        6.47065292e-07,  5.56355189e-07, -4.29054836e-07, -3.79234507e-07,\n",
      "       -3.46154252e-07,  4.76358110e-07,  4.30629029e-07,  4.10666559e-07,\n",
      "        3.55194771e-07,  2.91714969e-07, -2.45801175e-07, -2.28446893e-07,\n",
      "        2.57284114e-07, -1.98269277e-07, -1.67206423e-07, -1.59009176e-07,\n",
      "        2.07491979e-07,  2.24961568e-07,  1.77482946e-07,  1.34535455e-07,\n",
      "       -1.12865862e-07,  1.08459624e-07, -8.53497895e-08, -7.59920482e-08,\n",
      "       -5.21126644e-08,  9.01243666e-08,  8.14416055e-08,  6.13403159e-08,\n",
      "        5.38800400e-08,  4.29316920e-08, -3.78031189e-08, -2.39996520e-08,\n",
      "        2.90960251e-08,  2.46329162e-08,  2.75969807e-08, -1.95363903e-08,\n",
      "        1.25236435e-08, -1.13875958e-08, -9.64094848e-09, -4.77738915e-09,\n",
      "       -3.24728466e-09,  6.69519684e-09,  6.47886012e-09,  4.41156667e-09],\n",
      "      dtype=float32), array([[-0.0413458 , -0.11469361, -0.05665268, ...,  0.04899253,\n",
      "         0.02465557, -0.03498869],\n",
      "       [-0.04555037,  0.16570412, -0.07218584, ..., -0.05412172,\n",
      "        -0.0056083 ,  0.02229838],\n",
      "       [-0.00160228, -0.06146209,  0.02856846, ...,  0.2249898 ,\n",
      "         0.10632867, -0.31204826],\n",
      "       ...,\n",
      "       [ 0.00761818, -0.01211431,  0.02910712, ..., -0.05569795,\n",
      "         0.10292437,  0.10399386],\n",
      "       [-0.16300121, -0.12059156, -0.08347111, ...,  0.00497449,\n",
      "         0.00265508, -0.01555092],\n",
      "       [-0.03874708, -0.05457602,  0.00834281, ...,  0.02314922,\n",
      "        -0.06293564,  0.05300523]], dtype=float32))\n",
      "(array([ 4.70534393e+02,  1.11137354e+00,  7.15690374e-01,  2.29863599e-01,\n",
      "        4.13227677e-02,  3.04906052e-02,  2.41209120e-02,  1.59139875e-02,\n",
      "        1.34451957e-02,  9.11229104e-03,  7.32393982e-03,  6.89490186e-03,\n",
      "        2.71749147e-03,  2.25881673e-03,  1.61437073e-03,  1.31682516e-03,\n",
      "        1.12723804e-03,  9.73722199e-04,  7.15640606e-04,  6.06426387e-04,\n",
      "        5.78023784e-04,  4.52351844e-04,  3.85248510e-04,  3.38122307e-04,\n",
      "        3.24834313e-04,  2.30170146e-04,  1.85382509e-04,  1.60247815e-04,\n",
      "        1.33218258e-04,  1.22073805e-04,  1.05803680e-04,  8.46783951e-05,\n",
      "        7.77372261e-05,  6.22788939e-05,  5.89275405e-05,  5.11730541e-05,\n",
      "        4.19347525e-05,  4.02523619e-05,  3.34707001e-05,  2.80834556e-05,\n",
      "        2.34686195e-05,  2.08082620e-05,  1.88592257e-05, -1.31035331e-05,\n",
      "        1.32150708e-05,  1.14236345e-05,  1.04968076e-05,  9.59177578e-06,\n",
      "        8.11881091e-06, -7.60398734e-06, -5.80465394e-06,  6.84511770e-06,\n",
      "        6.14507326e-06,  5.21915854e-06, -4.67882683e-06, -4.59539069e-06,\n",
      "       -4.05069568e-06, -3.66998961e-06,  4.20042079e-06,  3.07637288e-06,\n",
      "        2.87809667e-06, -2.37023050e-06,  2.46277659e-06, -1.98562407e-06,\n",
      "       -1.79502922e-06, -1.62688082e-06,  2.06440086e-06,  1.87362173e-06,\n",
      "        1.72952423e-06,  1.51908182e-06, -1.21584378e-06,  1.21557878e-06,\n",
      "        1.12781993e-06, -9.32316539e-07, -7.52920982e-07, -6.57222927e-07,\n",
      "        7.55190854e-07,  7.15038141e-07, -6.36275729e-07,  6.20805167e-07,\n",
      "       -5.48402795e-07,  5.26192423e-07, -3.58490382e-07, -3.82423082e-07,\n",
      "        4.22443492e-07,  4.03805160e-07,  3.40313193e-07, -3.06495707e-07,\n",
      "       -2.45786339e-07,  2.53449485e-07, -1.86449213e-07, -1.56257116e-07,\n",
      "        1.89308579e-07,  1.62391487e-07,  1.46795728e-07, -1.29061860e-07,\n",
      "       -1.03720694e-07,  1.09062469e-07, -9.72566596e-08,  9.96963010e-08,\n",
      "        8.95742289e-08, -5.40890639e-08, -6.54574777e-08,  6.79482071e-08,\n",
      "        5.81895563e-08,  4.95126109e-08,  4.03625222e-08, -3.15001998e-08,\n",
      "        2.71278644e-08, -2.38535680e-08,  2.00644745e-08, -1.73360810e-08,\n",
      "        1.40266216e-08, -9.96071847e-09,  8.06615841e-09,  3.51934948e-09,\n",
      "        1.73228365e-09, -4.07596001e-09, -2.63192645e-09, -1.44979739e-09],\n",
      "      dtype=float32), array([[ 0.05219596,  0.09254872,  0.01695267, ..., -0.01390275,\n",
      "         0.03522413, -0.00080055],\n",
      "       [ 0.04269547, -0.09452635,  0.16667691, ..., -0.0104185 ,\n",
      "         0.0230772 , -0.025081  ],\n",
      "       [-0.00231404, -0.02754212, -0.08577371, ..., -0.25628218,\n",
      "        -0.08163983, -0.05566055],\n",
      "       ...,\n",
      "       [ 0.00512817,  0.13560869,  0.08956926, ...,  0.02701022,\n",
      "        -0.04917559,  0.06087581],\n",
      "       [ 0.16638023, -0.00700661, -0.10347795, ..., -0.00440067,\n",
      "        -0.00169943, -0.00399558],\n",
      "       [ 0.03329251, -0.05497881, -0.11834572, ...,  0.05098125,\n",
      "        -0.01023993, -0.06372394]], dtype=float32))\n",
      "(array([ 5.96072815e+02,  6.03720248e-01,  3.00043225e-01,  4.58899252e-02,\n",
      "        3.70615609e-02,  2.41900329e-02,  1.86533444e-02,  1.48364836e-02,\n",
      "        1.36182215e-02,  1.17170140e-02,  5.47354436e-03,  3.51656554e-03,\n",
      "        2.95015401e-03,  1.79504370e-03,  1.33344845e-03,  1.04661495e-03,\n",
      "        9.60634206e-04,  9.08122864e-04,  5.42468857e-04,  4.77309048e-04,\n",
      "        3.71341041e-04,  3.51907394e-04,  2.82826950e-04,  2.39891277e-04,\n",
      "        2.11548206e-04,  1.63668345e-04,  1.41957818e-04,  1.20265198e-04,\n",
      "        9.89976834e-05,  8.60259461e-05,  7.83853611e-05,  6.86243075e-05,\n",
      "        5.42792586e-05,  4.25687831e-05,  3.56129749e-05,  3.13639721e-05,\n",
      "        2.74012309e-05,  2.21883838e-05,  2.06492787e-05,  1.81095565e-05,\n",
      "       -1.29971695e-05, -1.09557595e-05,  1.67394483e-05,  1.50754004e-05,\n",
      "        1.09814810e-05,  1.13325214e-05, -8.66043956e-06,  9.45302872e-06,\n",
      "        8.82795393e-06, -7.70485804e-06,  7.94064454e-06,  6.61733748e-06,\n",
      "       -5.90772743e-06,  5.80149617e-06,  5.51456378e-06,  5.07657887e-06,\n",
      "       -4.50337302e-06,  4.37849258e-06,  3.91613366e-06, -3.44076102e-06,\n",
      "       -3.08508470e-06,  3.30168223e-06,  3.09467487e-06, -2.63815127e-06,\n",
      "        2.83257918e-06, -2.16080343e-06,  2.27176270e-06, -1.72867453e-06,\n",
      "        1.83300529e-06,  1.69066243e-06,  1.38428379e-06,  1.31820798e-06,\n",
      "        1.20018137e-06, -1.29943930e-06, -9.72846578e-07, -1.12689577e-06,\n",
      "       -1.14509442e-06,  1.01176795e-06, -7.39381278e-07,  7.48808077e-07,\n",
      "        7.01835688e-07, -6.29981741e-07,  6.44210559e-07, -5.02763157e-07,\n",
      "       -4.20227366e-07, -2.90698807e-07,  4.67215870e-07,  4.17738391e-07,\n",
      "        3.30423376e-07,  2.36931584e-07,  2.38771236e-07, -2.24745619e-07,\n",
      "        2.03100214e-07,  1.89746444e-07, -1.63417923e-07, -1.52100824e-07,\n",
      "        1.36667211e-07,  1.02842833e-07, -1.28675737e-07, -1.08228242e-07,\n",
      "        7.52941247e-08, -9.31392776e-08, -5.98739902e-08, -5.50847012e-08,\n",
      "        6.05053927e-08,  4.60941507e-08, -4.52745397e-08,  3.88527823e-08,\n",
      "        3.49636267e-08, -2.75041945e-08, -2.07344844e-08,  2.05686543e-08,\n",
      "        1.26832278e-08,  1.38524197e-08,  4.33687353e-09,  1.61716784e-09,\n",
      "       -1.19042998e-09, -5.11486942e-09, -7.16510407e-09, -8.23806801e-09],\n",
      "      dtype=float32), array([[-0.06154797, -0.09514005, -0.00044878, ...,  0.02898677,\n",
      "         0.00416547,  0.01839224],\n",
      "       [-0.04581215, -0.10376304,  0.17627986, ...,  0.01836051,\n",
      "         0.01369435,  0.03283362],\n",
      "       [ 0.00207629,  0.0478559 , -0.03128102, ...,  0.17490633,\n",
      "         0.03375143, -0.05877875],\n",
      "       ...,\n",
      "       [-0.00323765, -0.08014879, -0.02767354, ..., -0.00403989,\n",
      "         0.08376314, -0.02964454],\n",
      "       [-0.17075256,  0.06938373, -0.06833882, ...,  0.00447744,\n",
      "         0.00631017, -0.00516716],\n",
      "       [-0.03331079,  0.04380705, -0.05868363, ...,  0.03177034,\n",
      "        -0.0016238 ,  0.07643363]], dtype=float32))\n",
      "(array([ 5.77210266e+02,  8.39764178e-01,  3.82012188e-01,  1.21494584e-01,\n",
      "        4.10922654e-02,  2.53601316e-02,  1.50544196e-02,  1.29129561e-02,\n",
      "        8.85961577e-03,  8.44302401e-03,  4.29151021e-03,  3.01117986e-03,\n",
      "        2.52628094e-03,  1.85560947e-03,  1.35449669e-03,  1.15362217e-03,\n",
      "        9.34711599e-04,  8.08525481e-04,  6.07702415e-04,  4.77716938e-04,\n",
      "        4.14465641e-04,  3.94096918e-04,  2.91114004e-04,  2.01923045e-04,\n",
      "        1.70054482e-04,  1.38663207e-04,  1.30285203e-04,  1.22937548e-04,\n",
      "        1.07458196e-04,  8.63962196e-05,  7.98428518e-05,  6.40408907e-05,\n",
      "        5.23647723e-05,  4.96756948e-05,  4.24691680e-05,  3.56486598e-05,\n",
      "        3.07452574e-05, -2.03005093e-05,  2.63139373e-05,  2.22386479e-05,\n",
      "        1.97812460e-05, -1.48072668e-05,  1.70401563e-05, -1.13477654e-05,\n",
      "        1.39499116e-05,  1.24865273e-05,  1.17843474e-05,  1.06047719e-05,\n",
      "        9.40977043e-06, -7.87213412e-06, -7.40531732e-06,  8.78233095e-06,\n",
      "        7.57272619e-06,  7.24874826e-06,  6.43056819e-06,  5.86167334e-06,\n",
      "       -4.72989495e-06, -4.00929730e-06, -3.79250946e-06,  4.55796862e-06,\n",
      "        4.22171024e-06,  3.85850717e-06,  3.39267103e-06,  3.07603682e-06,\n",
      "       -2.45997740e-06,  2.44021612e-06, -2.07779567e-06, -1.99461761e-06,\n",
      "        2.02341221e-06,  1.71546276e-06, -1.65671588e-06, -1.34667221e-06,\n",
      "        1.39085660e-06, -1.11147256e-06,  1.02683327e-06, -9.63350658e-07,\n",
      "        8.84028907e-07,  8.01322244e-07, -6.08705932e-07,  6.56631130e-07,\n",
      "       -5.67607344e-07,  6.26057329e-07,  5.31710612e-07,  4.26803723e-07,\n",
      "       -4.54372213e-07, -4.20900506e-07,  3.84080408e-07, -3.41300961e-07,\n",
      "        2.83324169e-07, -2.61312579e-07, -2.20716160e-07,  2.25679145e-07,\n",
      "       -1.82790174e-07,  1.78427371e-07,  1.49888521e-07, -1.50195788e-07,\n",
      "       -1.34859533e-07,  1.24078923e-07,  1.13351838e-07, -9.43922913e-08,\n",
      "       -6.99453508e-08, -5.41691278e-08,  8.08430016e-08,  6.83765862e-08,\n",
      "        5.43558230e-08, -4.73106425e-08,  3.98767952e-08, -3.46857334e-08,\n",
      "        3.01841503e-08, -2.49096441e-08,  2.22510224e-08, -1.75484001e-08,\n",
      "       -1.93200016e-08,  1.59253126e-08,  9.34747746e-09,  5.75407855e-09,\n",
      "       -4.78320006e-09, -3.56017038e-09, -4.54358579e-10,  1.76133885e-09],\n",
      "      dtype=float32), array([[-0.06250812,  0.01057499,  0.08014845, ...,  0.00507378,\n",
      "        -0.01235914, -0.02107234],\n",
      "       [-0.04537649,  0.06284015,  0.20379288, ...,  0.04054383,\n",
      "         0.01405217,  0.02331128],\n",
      "       [ 0.00278548, -0.04171178, -0.02743802, ..., -0.15371422,\n",
      "         0.02707693, -0.12595293],\n",
      "       ...,\n",
      "       [-0.00562567,  0.08699441, -0.05481153, ..., -0.09882256,\n",
      "        -0.03689083,  0.0169549 ],\n",
      "       [-0.16954252, -0.0395011 , -0.0153223 , ...,  0.02334722,\n",
      "        -0.0019618 ,  0.00312027],\n",
      "       [-0.0320966 , -0.03389993, -0.04847155, ...,  0.00942951,\n",
      "         0.00315922,  0.00738987]], dtype=float32))\n",
      "(array([ 4.28320709e+02,  4.27517533e-01,  2.07233593e-01,  1.10180378e-01,\n",
      "        3.81889343e-02,  1.64902173e-02,  1.15817273e-02,  7.84514751e-03,\n",
      "        6.52679754e-03,  4.95577371e-03,  3.38668097e-03,  3.08490521e-03,\n",
      "        1.74562726e-03,  1.18756015e-03,  1.05607160e-03,  6.23663189e-04,\n",
      "        5.43348433e-04,  4.36019036e-04,  3.97455820e-04,  2.44408380e-04,\n",
      "        2.02781725e-04,  1.56187220e-04,  1.31161869e-04,  1.04541352e-04,\n",
      "        8.55846811e-05,  7.82108546e-05,  6.44256288e-05,  5.55614315e-05,\n",
      "        4.33085188e-05,  3.51836607e-05,  2.91688302e-05,  2.43682389e-05,\n",
      "        1.99025344e-05, -1.23343953e-05,  1.53132605e-05,  1.48007211e-05,\n",
      "        1.27954663e-05, -8.41649307e-06,  1.03230877e-05,  9.87921612e-06,\n",
      "        9.20472485e-06, -5.90436548e-06,  7.23378525e-06, -5.26921349e-06,\n",
      "        6.27332838e-06,  5.70520751e-06,  5.55454744e-06,  4.68485177e-06,\n",
      "       -3.90901232e-06,  4.15712339e-06, -3.41048917e-06, -2.45843762e-06,\n",
      "        3.49072411e-06,  3.28979945e-06,  3.12367320e-06,  2.85113083e-06,\n",
      "        2.48445826e-06,  2.33948435e-06,  2.10278745e-06, -1.75853006e-06,\n",
      "        1.96816222e-06,  1.91256299e-06, -1.53133487e-06, -1.38832354e-06,\n",
      "       -1.25067004e-06,  1.59378214e-06,  1.41141538e-06, -1.03514481e-06,\n",
      "        1.10382405e-06,  1.06935795e-06, -8.91030425e-07,  1.01783371e-06,\n",
      "       -7.10641928e-07,  7.97907376e-07,  7.52322080e-07, -6.21913216e-07,\n",
      "        6.60773537e-07, -5.39538519e-07, -4.94629887e-07, -4.47299215e-07,\n",
      "        5.49461959e-07,  5.09711242e-07,  4.20129993e-07, -3.62215616e-07,\n",
      "        3.80858808e-07,  2.98421611e-07, -3.25013275e-07, -3.19042073e-07,\n",
      "       -2.11139479e-07,  2.74596374e-07,  2.26765721e-07,  2.06381628e-07,\n",
      "       -1.60359093e-07,  1.52670253e-07,  1.18357548e-07, -1.24909647e-07,\n",
      "       -1.17352243e-07, -1.05838204e-07, -9.08933870e-08,  1.30331969e-07,\n",
      "        9.80953203e-08,  8.82469209e-08,  7.88366847e-08, -5.93040141e-08,\n",
      "        3.82822272e-08,  4.68928434e-08,  3.18602318e-08, -3.53232572e-08,\n",
      "       -3.87712475e-08, -2.69903691e-08, -1.89686293e-08,  1.71500290e-08,\n",
      "        1.33511611e-08, -1.14835030e-08, -7.71254349e-09,  9.31001765e-09,\n",
      "        2.93856917e-09,  5.19720356e-09, -9.57386614e-10, -2.16602625e-09],\n",
      "      dtype=float32), array([[-4.63054553e-02, -2.04759687e-01,  1.21295592e-02, ...,\n",
      "        -7.74473228e-05, -4.18693163e-02,  9.77909379e-03],\n",
      "       [-4.54450548e-02,  2.66999342e-02,  1.44482508e-01, ...,\n",
      "        -3.47393900e-02,  2.78873742e-02, -2.25608833e-02],\n",
      "       [-2.88197451e-04,  8.29666033e-02, -7.32849464e-02, ...,\n",
      "         4.66080615e-03, -7.33335763e-02,  3.60939533e-01],\n",
      "       ...,\n",
      "       [ 6.76407851e-03, -2.54808813e-01,  6.57009557e-02, ...,\n",
      "         1.26624465e-01,  1.65695194e-02, -4.97864299e-02],\n",
      "       [-1.65617242e-01, -6.81126025e-03, -1.03973165e-01, ...,\n",
      "         1.17254397e-02,  9.17619653e-03,  1.20871188e-02],\n",
      "       [-3.76011506e-02,  1.06036901e-01, -6.16675988e-02, ...,\n",
      "         2.32321918e-02, -3.83283943e-02, -1.88466404e-02]], dtype=float32))\n",
      "(array([ 4.6372687e+02,  3.0918804e-01,  1.9526392e-01,  6.5144703e-02,\n",
      "        2.9125158e-02,  2.4095362e-02,  1.4543492e-02,  8.2159527e-03,\n",
      "        6.0006478e-03,  4.3510227e-03,  3.7079446e-03,  1.7921306e-03,\n",
      "        1.3967039e-03,  1.2768784e-03,  1.0208680e-03,  8.0496370e-04,\n",
      "        5.5883155e-04,  5.2846660e-04,  3.3167913e-04,  2.4403087e-04,\n",
      "        1.8156394e-04,  1.3880254e-04,  1.1463213e-04,  8.2315841e-05,\n",
      "        6.5329754e-05,  5.8532492e-05,  4.3982971e-05,  3.6756512e-05,\n",
      "        3.3617976e-05,  2.6376851e-05,  2.6672991e-05,  2.3324859e-05,\n",
      "        2.0406864e-05,  1.7618810e-05, -1.1357702e-05,  1.4570080e-05,\n",
      "        1.2458495e-05,  1.1856119e-05, -9.1953652e-06, -7.9265701e-06,\n",
      "        9.7350003e-06,  9.2549772e-06,  8.2151755e-06,  7.3709380e-06,\n",
      "       -6.4883452e-06, -5.5331816e-06,  6.4729879e-06,  5.5677542e-06,\n",
      "       -4.3618238e-06,  4.8480906e-06,  4.4788094e-06,  3.9843680e-06,\n",
      "        3.5373073e-06, -3.0089664e-06, -2.8086824e-06,  3.3086967e-06,\n",
      "        3.0638173e-06,  2.5269403e-06, -2.2206655e-06, -1.9761728e-06,\n",
      "        2.3324735e-06,  1.9267698e-06, -1.4941977e-06,  1.7574835e-06,\n",
      "        1.5819621e-06, -1.0919098e-06,  1.3012333e-06,  1.2605223e-06,\n",
      "       -9.9834244e-07,  1.0807447e-06,  9.7042050e-07,  9.1194187e-07,\n",
      "        8.1345394e-07, -6.9195880e-07, -6.3493138e-07, -6.0297020e-07,\n",
      "       -4.8361051e-07, -3.9017777e-07,  6.2124616e-07,  6.4386347e-07,\n",
      "        5.5916206e-07,  4.6443503e-07,  4.3000321e-07, -3.2343044e-07,\n",
      "       -2.9969985e-07,  3.4021258e-07,  3.3283393e-07,  3.1312950e-07,\n",
      "        2.4885321e-07, -2.1138757e-07, -1.8786969e-07,  2.0008727e-07,\n",
      "        1.5757117e-07, -1.9502097e-07, -1.4395550e-07, -1.3467593e-07,\n",
      "        1.3468819e-07,  1.2846137e-07,  9.7830011e-08, -9.0650182e-08,\n",
      "       -8.7799748e-08, -6.9363047e-08,  7.3253666e-08,  6.5557501e-08,\n",
      "       -4.4376893e-08,  4.2295596e-08,  4.1365862e-08, -3.3217063e-08,\n",
      "        2.9892028e-08,  2.7093943e-08,  2.1302556e-08, -1.5224195e-08,\n",
      "        1.3737502e-08, -8.8862269e-09,  5.7113367e-09, -5.8490128e-09,\n",
      "        2.5744085e-09, -3.7360985e-09,  1.1945861e-09, -1.1782585e-09],\n",
      "      dtype=float32), array([[-4.7324378e-02,  2.2962181e-01,  6.7588113e-02, ...,\n",
      "        -2.9920254e-02, -1.2432587e-02, -3.6688056e-02],\n",
      "       [-4.6727791e-02, -6.9800034e-02, -1.7798896e-01, ...,\n",
      "        -6.8204133e-03,  2.6197081e-02,  1.7739296e-02],\n",
      "       [-1.4565848e-03,  1.6033892e-02,  6.1689831e-02, ...,\n",
      "        -1.8110646e-01,  1.9166712e-02, -2.0561105e-01],\n",
      "       ...,\n",
      "       [ 1.1521692e-02,  3.7636805e-02,  2.2040447e-05, ...,\n",
      "         8.9945890e-02, -7.5781591e-02,  3.3667292e-02],\n",
      "       [-1.6703291e-01,  3.3488896e-02,  9.9233761e-02, ...,\n",
      "         1.1203608e-02,  9.3459813e-03, -6.8925433e-03],\n",
      "       [-3.9187949e-02, -1.2974490e-02,  9.2908844e-02, ...,\n",
      "        -2.4735432e-02,  1.0573446e-03,  5.1779132e-02]], dtype=float32))\n",
      "(array([ 4.7266650e+02,  8.8236642e-01,  4.5086312e-01,  2.6301187e-01,\n",
      "        1.3356566e-01,  6.6962123e-02,  3.7620574e-02,  2.0447666e-02,\n",
      "        1.6331390e-02,  8.9165680e-03,  7.1854014e-03,  4.7522574e-03,\n",
      "        3.3629055e-03,  3.0195587e-03,  2.5820322e-03,  1.9742202e-03,\n",
      "        1.4840971e-03,  1.2199606e-03,  1.1074499e-03,  8.8808039e-04,\n",
      "        5.2607246e-04,  5.0992327e-04,  4.6609700e-04,  3.7442127e-04,\n",
      "        3.6181090e-04,  2.4529101e-04,  2.2415066e-04,  1.9364874e-04,\n",
      "        1.6398767e-04,  1.5987654e-04,  1.2335840e-04,  1.0621511e-04,\n",
      "        8.4177940e-05,  7.3820956e-05,  5.8383255e-05,  5.0741928e-05,\n",
      "        4.0511255e-05,  3.6233792e-05,  3.2271138e-05,  2.9061755e-05,\n",
      "        2.4666859e-05,  2.3642944e-05,  2.2929704e-05, -1.4151137e-05,\n",
      "        1.6126816e-05,  1.5493239e-05,  1.4430729e-05,  1.2598690e-05,\n",
      "       -9.6638514e-06, -7.5052185e-06,  9.4220686e-06,  8.3553768e-06,\n",
      "        7.2729235e-06,  6.3323077e-06, -4.3944065e-06,  4.7400417e-06,\n",
      "       -3.2577564e-06,  3.9193546e-06,  3.6188912e-06,  2.8999059e-06,\n",
      "       -2.6197520e-06,  2.4285441e-06,  2.1639337e-06, -2.2954164e-06,\n",
      "       -2.1168530e-06, -1.7410979e-06, -1.6413076e-06,  1.8993300e-06,\n",
      "        1.6342636e-06, -1.2779357e-06,  1.2252203e-06, -1.1413309e-06,\n",
      "        1.1025678e-06, -9.2845107e-07, -8.2851602e-07, -7.4547376e-07,\n",
      "        9.2222115e-07,  8.2108545e-07,  7.7202196e-07, -6.4811178e-07,\n",
      "        5.9765620e-07, -5.5574390e-07,  5.0391986e-07, -4.0301987e-07,\n",
      "       -4.4704362e-07, -2.9682136e-07,  4.2667133e-07,  3.5559574e-07,\n",
      "        3.5016930e-07,  2.9769865e-07, -2.2681203e-07,  1.9713774e-07,\n",
      "        1.7651041e-07, -1.6083311e-07,  1.5455088e-07,  1.2834919e-07,\n",
      "       -1.4528042e-07, -1.2726144e-07, -9.1711371e-08,  9.0101103e-08,\n",
      "        7.0388985e-08, -7.2565037e-08, -5.9156040e-08,  5.5794469e-08,\n",
      "        4.7007749e-08, -3.8129972e-08, -3.4789768e-08,  3.7476575e-08,\n",
      "       -2.7466621e-08,  2.9784490e-08,  2.3812168e-08, -1.5183373e-08,\n",
      "        1.6677875e-08, -9.2464401e-09, -5.2547580e-09,  1.1737551e-09,\n",
      "        2.5256524e-09, -2.7286442e-09,  8.5359719e-09,  1.1021104e-08],\n",
      "      dtype=float32), array([[-5.81167080e-02, -6.91700056e-02,  1.18273430e-01, ...,\n",
      "         4.79445010e-02, -4.10693660e-02,  1.01980269e-02],\n",
      "       [-4.12695184e-02,  6.99446648e-02,  1.24215245e-01, ...,\n",
      "         2.80858632e-02,  3.61169726e-02,  1.58309825e-02],\n",
      "       [ 4.40385891e-03,  1.36020323e-02, -1.04164712e-01, ...,\n",
      "         7.57847652e-02,  2.25955293e-01,  1.25570506e-01],\n",
      "       ...,\n",
      "       [-8.97394214e-03, -6.26517981e-02,  2.17685729e-01, ...,\n",
      "        -6.19754754e-03, -6.89654564e-03, -8.76364112e-02],\n",
      "       [-1.65106773e-01,  1.88699065e-04, -1.02995798e-01, ...,\n",
      "        -7.49169849e-03, -1.13156512e-02, -2.20016763e-03],\n",
      "       [-3.04212719e-02,  5.19613288e-02, -1.25603586e-01, ...,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2.34304015e-02, -3.56497057e-02,  1.51383439e-02]], dtype=float32))\n",
      "(array([ 4.16500824e+02,  9.72141683e-01,  2.86063969e-01,  1.23016179e-01,\n",
      "        4.61575612e-02,  2.21607182e-02,  1.42832361e-02,  1.05337780e-02,\n",
      "        3.73634580e-03,  2.98710796e-03,  2.34518875e-03,  1.94406905e-03,\n",
      "        1.32499437e-03,  1.23051892e-03,  8.17562686e-04,  7.22275639e-04,\n",
      "        6.54072850e-04,  5.40343870e-04,  4.82375792e-04,  3.43287131e-04,\n",
      "        2.86115392e-04,  2.63579830e-04,  1.92957814e-04,  1.68126149e-04,\n",
      "        1.37938230e-04,  1.15232855e-04,  8.83387911e-05,  8.00751295e-05,\n",
      "        6.97696232e-05,  5.74779951e-05,  5.20085450e-05,  3.95625066e-05,\n",
      "        3.46967863e-05,  3.08752169e-05,  2.60351298e-05,  2.23328425e-05,\n",
      "        1.83555094e-05, -9.09529808e-06,  1.38820060e-05,  1.31366814e-05,\n",
      "        1.18868657e-05,  1.08621552e-05,  1.04561441e-05,  7.51464040e-06,\n",
      "       -6.17494015e-06,  6.83030066e-06,  6.22380730e-06, -5.49106016e-06,\n",
      "       -5.01156865e-06,  5.36874404e-06, -3.86168131e-06, -3.16645583e-06,\n",
      "        4.53652228e-06,  3.80222514e-06,  3.64308721e-06,  3.73844887e-06,\n",
      "       -2.43058412e-06, -2.31509171e-06,  3.14746535e-06,  2.56632029e-06,\n",
      "        2.34780464e-06,  2.04268827e-06,  2.09349651e-06, -1.78101095e-06,\n",
      "       -1.60689251e-06, -1.52461143e-06,  1.66870393e-06,  1.40082102e-06,\n",
      "       -1.13837552e-06,  1.18304797e-06, -9.49148102e-07,  9.59607632e-07,\n",
      "       -8.62938748e-07,  9.01237058e-07, -7.86066380e-07,  8.08673235e-07,\n",
      "       -6.10613085e-07, -6.46739920e-07,  7.24335735e-07,  5.56621956e-07,\n",
      "        5.93299490e-07,  6.11986763e-07, -4.33082391e-07, -3.88546368e-07,\n",
      "        4.50870175e-07,  3.89430568e-07,  3.46312447e-07, -2.95820030e-07,\n",
      "       -2.70581154e-07,  2.52365226e-07,  2.28772095e-07, -1.89759334e-07,\n",
      "        1.84267307e-07, -1.41247966e-07,  1.50598368e-07, -1.25472724e-07,\n",
      "        1.21541689e-07,  1.09217424e-07, -9.64639568e-08, -8.25748643e-08,\n",
      "        7.69500446e-08,  6.76170941e-08, -6.16736386e-08, -5.17562917e-08,\n",
      "        5.29417790e-08,  4.10424157e-08, -4.42645920e-08, -3.70227404e-08,\n",
      "        3.45924569e-08, -2.27605117e-08, -1.69254353e-08,  1.86561522e-08,\n",
      "        1.79194615e-08,  1.55187951e-08,  1.08856559e-08,  6.80184886e-09,\n",
      "       -6.50092291e-09, -7.64908803e-10, -3.24702065e-09, -3.46408857e-09],\n",
      "      dtype=float32), array([[ 0.04743856,  0.16422348, -0.04333458, ..., -0.00386749,\n",
      "         0.01728898,  0.01251913],\n",
      "       [ 0.0452514 , -0.02956587, -0.05169427, ..., -0.01982919,\n",
      "         0.04305693, -0.024513  ],\n",
      "       [-0.00071466, -0.076691  ,  0.07611909, ...,  0.10584561,\n",
      "         0.12768848,  0.07794373],\n",
      "       ...,\n",
      "       [-0.00395634,  0.23967777, -0.16456872, ...,  0.05348672,\n",
      "        -0.00950042, -0.03171045],\n",
      "       [ 0.16639642,  0.00924017,  0.11359542, ...,  0.01080334,\n",
      "        -0.00376846, -0.00740724],\n",
      "       [ 0.03682451, -0.09515704,  0.06879303, ..., -0.07667761,\n",
      "         0.09924578, -0.00780481]], dtype=float32))\n",
      "(array([ 4.58791718e+02,  1.09334624e+00,  3.74173939e-01,  2.01984659e-01,\n",
      "        1.51446030e-01,  3.71896960e-02,  2.85925902e-02,  1.56406611e-02,\n",
      "        1.15825450e-02,  9.64615773e-03,  8.59334413e-03,  6.48206333e-03,\n",
      "        5.83385583e-03,  4.37070569e-03,  2.92270491e-03,  2.21512420e-03,\n",
      "        1.25707733e-03,  1.20807835e-03,  1.01895619e-03,  8.19652865e-04,\n",
      "        7.65561184e-04,  5.20069909e-04,  4.21137956e-04,  3.33163363e-04,\n",
      "        3.20020801e-04,  2.55435763e-04,  2.35068670e-04,  1.66567872e-04,\n",
      "        1.41884491e-04,  1.33718393e-04,  1.17376025e-04,  9.83122445e-05,\n",
      "        8.13278457e-05,  6.05183159e-05,  5.23320887e-05,  5.04401505e-05,\n",
      "        3.92066722e-05,  3.42879539e-05,  3.33523058e-05,  2.99050807e-05,\n",
      "        2.85077404e-05,  2.26185512e-05,  2.06602363e-05,  1.56109381e-05,\n",
      "       -1.03552211e-05,  1.18382304e-05,  1.10349602e-05,  9.33963565e-06,\n",
      "       -7.16131945e-06, -6.01686588e-06,  8.24259223e-06,  6.54188443e-06,\n",
      "        6.36187997e-06,  5.81504855e-06,  5.53541440e-06, -4.63109518e-06,\n",
      "       -4.42932742e-06,  4.66015626e-06,  3.95602547e-06,  3.06705601e-06,\n",
      "        2.89988657e-06, -2.73662613e-06, -2.15088244e-06, -2.03160516e-06,\n",
      "       -1.74163858e-06,  1.89714547e-06,  1.76504795e-06, -1.47119215e-06,\n",
      "        1.46577611e-06, -1.20772438e-06,  1.31047727e-06, -1.01516571e-06,\n",
      "        1.04579999e-06,  1.07329174e-06,  8.67595531e-07,  7.18787078e-07,\n",
      "       -8.05056118e-07, -9.34103809e-07, -9.09749872e-07, -5.91937692e-07,\n",
      "        5.20809749e-07,  4.85733267e-07, -3.92961397e-07,  4.14202333e-07,\n",
      "       -3.50375984e-07, -3.38248185e-07,  3.44762725e-07,  3.08741988e-07,\n",
      "        2.64876235e-07, -2.57578733e-07, -2.06742499e-07, -2.10918884e-07,\n",
      "        2.07858420e-07,  1.95683185e-07, -1.56600052e-07, -1.35671172e-07,\n",
      "       -1.13591497e-07,  1.46974656e-07,  1.28013511e-07,  1.10501993e-07,\n",
      "        7.52052500e-08, -8.07709313e-08, -7.06197056e-08, -5.33376117e-08,\n",
      "        4.73060489e-08, -4.42175683e-08,  3.62649040e-08, -3.68566866e-08,\n",
      "        2.59911932e-08, -2.62080615e-08, -1.92912584e-08,  1.75272099e-08,\n",
      "        1.72552141e-08,  9.90936044e-09, -9.80208448e-09,  6.06614980e-09,\n",
      "        2.52934451e-09, -3.96626776e-09, -2.08301332e-09, -5.47160450e-09],\n",
      "      dtype=float32), array([[-0.04648717,  0.04809645, -0.04317759, ...,  0.02168178,\n",
      "         0.00570343,  0.0040594 ],\n",
      "       [-0.04692892, -0.07466337, -0.15702769, ..., -0.04140458,\n",
      "         0.02445447,  0.01018595],\n",
      "       [-0.00081284, -0.01745026,  0.07138938, ...,  0.27890524,\n",
      "         0.05680249, -0.12450198],\n",
      "       ...,\n",
      "       [ 0.00610531,  0.09991621, -0.06938346, ...,  0.07638945,\n",
      "         0.04808971, -0.11754505],\n",
      "       [-0.16702083,  0.01648837,  0.07657602, ...,  0.00444138,\n",
      "        -0.01306453, -0.0043911 ],\n",
      "       [-0.03879759, -0.04925535,  0.09631549, ...,  0.05572341,\n",
      "         0.00122867, -0.00878445]], dtype=float32))\n",
      "(array([ 5.26908020e+02,  9.11304832e-01,  5.87062478e-01,  3.10773730e-01,\n",
      "        1.20721579e-01,  1.14168964e-01,  6.25042692e-02,  3.27270143e-02,\n",
      "        3.04156430e-02,  2.12445166e-02,  1.70573499e-02,  1.08279707e-02,\n",
      "        6.87391311e-03,  5.20982081e-03,  3.71346530e-03,  3.30161373e-03,\n",
      "        2.07336014e-03,  1.70945085e-03,  1.51392899e-03,  1.27397338e-03,\n",
      "        1.08008145e-03,  9.70292371e-04,  7.02631078e-04,  5.52864687e-04,\n",
      "        4.65093472e-04,  4.36299189e-04,  3.85197432e-04,  3.15339945e-04,\n",
      "        2.59889930e-04,  2.15759210e-04,  1.89786864e-04,  1.80351955e-04,\n",
      "        1.34066140e-04,  1.14943919e-04,  9.75385265e-05,  8.54495156e-05,\n",
      "        8.27343829e-05,  5.56324703e-05,  4.94304586e-05,  3.94564086e-05,\n",
      "        3.48682042e-05,  2.98466020e-05, -1.64930570e-05,  2.10021863e-05,\n",
      "        1.66433965e-05,  1.49688431e-05,  1.35480714e-05,  1.10655556e-05,\n",
      "       -9.72486032e-06,  9.50360482e-06,  7.52910000e-06, -7.45708030e-06,\n",
      "       -7.09702226e-06, -6.27233294e-06,  6.20369974e-06, -4.96505254e-06,\n",
      "        5.07063942e-06,  4.76368041e-06,  3.98662542e-06,  3.57727936e-06,\n",
      "        2.81862071e-06, -2.71550493e-06, -2.36167784e-06,  2.21912160e-06,\n",
      "       -2.01626699e-06, -1.77730465e-06,  1.89254945e-06,  1.70891326e-06,\n",
      "        1.43795046e-06, -1.32437526e-06,  1.26537702e-06,  1.19334993e-06,\n",
      "        1.05700667e-06, -1.08578377e-06,  8.40894529e-07, -9.37106563e-07,\n",
      "       -8.34710136e-07,  7.18074091e-07, -6.19251807e-07,  5.87688703e-07,\n",
      "        5.03203751e-07, -5.73424416e-07, -4.18773681e-07, -3.89990845e-07,\n",
      "        3.55880985e-07,  3.36940985e-07,  2.60190632e-07, -3.40613354e-07,\n",
      "       -2.64210001e-07, -2.52671271e-07,  2.25415604e-07,  1.83980006e-07,\n",
      "       -1.63911025e-07,  1.58597672e-07,  1.41830697e-07, -1.32174662e-07,\n",
      "       -1.22934068e-07, -1.08055772e-07,  1.03130489e-07,  8.19093628e-08,\n",
      "       -8.40629966e-08,  6.66375897e-08, -5.89706097e-08, -6.29488923e-08,\n",
      "        4.81849689e-08, -4.17138466e-08,  4.21076685e-08,  3.11252180e-08,\n",
      "       -2.84471149e-08, -1.98264676e-08, -1.88954772e-08,  1.89000335e-08,\n",
      "        1.77906987e-08,  1.29945672e-08, -7.84685472e-09,  8.00934519e-09,\n",
      "        5.60864644e-09,  4.40347925e-10, -2.10508833e-09, -1.64696345e-09],\n",
      "      dtype=float32), array([[-0.05387765, -0.12555052,  0.06119079, ..., -0.00243763,\n",
      "         0.00554256,  0.00167544],\n",
      "       [-0.04633359,  0.16356973, -0.1432057 , ..., -0.01278021,\n",
      "         0.00730372,  0.02389462],\n",
      "       [ 0.00183825, -0.03597953,  0.00668904, ..., -0.10079531,\n",
      "         0.05460268,  0.17860785],\n",
      "       ...,\n",
      "       [-0.00215857,  0.00879386,  0.08445209, ...,  0.06773396,\n",
      "        -0.0039093 , -0.13710953],\n",
      "       [-0.16407102, -0.06144891,  0.09088158, ..., -0.01024237,\n",
      "         0.00173609,  0.00200584],\n",
      "       [-0.0321691 , -0.03285469,  0.11816499, ...,  0.0616799 ,\n",
      "        -0.01445224, -0.08687767]], dtype=float32))\n",
      "(array([ 4.55037354e+02,  7.30498731e-01,  5.23832440e-01,  4.10409003e-01,\n",
      "        1.56164244e-01,  1.33285686e-01,  3.16356607e-02,  2.45215856e-02,\n",
      "        1.70091297e-02,  1.36473840e-02,  1.22890333e-02,  5.86238969e-03,\n",
      "        4.61220834e-03,  3.30949458e-03,  2.28827936e-03,  2.14907760e-03,\n",
      "        1.46895228e-03,  1.17999420e-03,  9.77162737e-04,  8.19823821e-04,\n",
      "        6.83834602e-04,  6.26441382e-04,  5.43429458e-04,  4.26130020e-04,\n",
      "        2.68799544e-04,  2.45263916e-04,  2.34222083e-04,  1.90262726e-04,\n",
      "        1.45214130e-04,  1.48721214e-04,  1.15791147e-04,  1.01521655e-04,\n",
      "        9.43435080e-05,  8.06626122e-05,  6.37219855e-05,  5.85484413e-05,\n",
      "        4.86449680e-05,  4.47600432e-05,  3.94803355e-05,  2.79860051e-05,\n",
      "        2.35432090e-05, -1.50673513e-05,  1.99799051e-05,  1.78861774e-05,\n",
      "        1.67380695e-05,  1.32208907e-05, -8.31217585e-06,  1.05395275e-05,\n",
      "        9.98525866e-06, -6.93932134e-06,  8.16380179e-06,  7.72468047e-06,\n",
      "       -5.68781888e-06,  5.62879677e-06,  5.16211139e-06,  4.55539748e-06,\n",
      "        4.16748617e-06, -3.47261812e-06,  3.45504100e-06,  3.31096317e-06,\n",
      "       -2.75025286e-06, -2.40391023e-06,  2.68837675e-06,  2.34070035e-06,\n",
      "       -2.14432703e-06, -1.80602626e-06, -1.31038769e-06,  1.55492330e-06,\n",
      "        1.48779020e-06, -1.06899040e-06,  1.22346626e-06,  1.11722159e-06,\n",
      "       -9.22981371e-07,  1.00303760e-06,  9.02006150e-07, -7.09880624e-07,\n",
      "        6.89334115e-07,  5.99386965e-07, -6.09336325e-07, -5.20279059e-07,\n",
      "        4.92039646e-07,  4.74947853e-07, -3.81003417e-07,  3.56099008e-07,\n",
      "       -3.20964801e-07,  3.05648314e-07,  2.73108185e-07, -2.60681787e-07,\n",
      "        2.34944451e-07,  2.07848473e-07, -2.33453122e-07, -1.98831643e-07,\n",
      "       -2.20808190e-07,  1.32721524e-07,  1.14027280e-07, -1.68352045e-07,\n",
      "       -1.26955214e-07, -1.15755924e-07,  1.02085544e-07, -7.53396421e-08,\n",
      "        7.15496142e-08,  7.97581308e-08, -6.89963997e-08,  5.14209688e-08,\n",
      "        4.55120848e-08, -4.83623630e-08, -4.18167510e-08,  3.40713768e-08,\n",
      "        2.39291591e-08, -2.79879817e-08,  1.22338530e-08,  1.50661599e-08,\n",
      "        5.49678481e-09,  3.85658705e-09, -1.91061744e-08, -6.01098615e-10,\n",
      "       -2.99715230e-09, -8.05350719e-09, -1.30678508e-08, -1.13206280e-08],\n",
      "      dtype=float32), array([[-0.04902123,  0.17930207,  0.22967301, ...,  0.014883  ,\n",
      "         0.00514965, -0.01029482],\n",
      "       [-0.04088271, -0.12539257, -0.0013349 , ..., -0.02252386,\n",
      "        -0.04436896,  0.0128305 ],\n",
      "       [ 0.00400726, -0.03861607, -0.02442938, ..., -0.14287442,\n",
      "        -0.02013386, -0.13583404],\n",
      "       ...,\n",
      "       [-0.00886018,  0.14959718,  0.18300311, ..., -0.05113522,\n",
      "         0.10431134, -0.08945149],\n",
      "       [-0.16076243, -0.00197306, -0.03210389, ..., -0.00532072,\n",
      "         0.00720898,  0.00033887],\n",
      "       [-0.02902823, -0.07983522,  0.01628423, ...,  0.08780733,\n",
      "        -0.0476708 , -0.00872061]], dtype=float32))\n",
      "(array([ 3.03476349e+02,  4.31684875e+00,  1.37978435e-01,  3.47101949e-02,\n",
      "        3.09418403e-02,  8.66221730e-03,  8.24514218e-03,  4.16486524e-03,\n",
      "        3.07628792e-03,  1.48369838e-03,  8.02913855e-04,  6.11401687e-04,\n",
      "        4.51049564e-04,  3.46592336e-04,  2.17253633e-04,  1.91686006e-04,\n",
      "        1.30065164e-04,  9.99133918e-05,  9.00778250e-05,  7.37874943e-05,\n",
      "        4.58306204e-05,  3.57437930e-05,  3.13726123e-05,  1.83165193e-05,\n",
      "        1.67007220e-05,  1.34653355e-05, -8.44423721e-06,  1.02938202e-05,\n",
      "        9.39709935e-06,  8.56849965e-06,  8.45395789e-06,  7.07498521e-06,\n",
      "        6.33633590e-06, -5.36842708e-06, -4.02483738e-06,  5.54211829e-06,\n",
      "        5.12666020e-06,  4.62106618e-06,  3.88838453e-06,  3.21928474e-06,\n",
      "        2.86254067e-06, -2.96104986e-06, -2.64587447e-06, -2.52283576e-06,\n",
      "       -2.00577529e-06,  2.67163728e-06,  2.35257812e-06,  2.27095734e-06,\n",
      "        2.04187972e-06, -1.57668751e-06,  1.75447838e-06, -1.38691166e-06,\n",
      "        1.51609731e-06,  1.44329920e-06,  1.33830770e-06, -1.02232707e-06,\n",
      "       -9.15898113e-07,  1.14204272e-06,  9.52309506e-07, -7.54837231e-07,\n",
      "        9.15212240e-07, -6.64010599e-07,  8.31434136e-07,  7.68029736e-07,\n",
      "       -6.40243286e-07,  7.14972543e-07, -5.72102238e-07, -4.98828456e-07,\n",
      "        5.95124447e-07,  5.29962847e-07,  5.02383102e-07, -3.60432637e-07,\n",
      "       -3.10939669e-07,  4.02637880e-07,  3.57467513e-07,  3.13376461e-07,\n",
      "       -2.49342406e-07, -2.24454226e-07,  2.55494172e-07, -1.97563494e-07,\n",
      "        2.20462880e-07,  2.08502456e-07, -1.75774886e-07, -1.41587307e-07,\n",
      "        1.84226323e-07,  1.73298403e-07,  1.61337439e-07,  1.43828316e-07,\n",
      "        1.30311221e-07, -1.10450252e-07, -1.13583262e-07,  1.10385841e-07,\n",
      "       -8.90893261e-08,  9.57533217e-08, -6.68017961e-08, -6.18480485e-08,\n",
      "        7.67842963e-08,  6.41276259e-08,  5.96211720e-08,  4.94156573e-08,\n",
      "       -4.15033199e-08,  4.37441088e-08, -3.49671510e-08, -2.30655992e-08,\n",
      "       -1.95095193e-08,  3.20840066e-08,  3.01893976e-08,  2.64987179e-08,\n",
      "       -1.13381127e-08,  1.92610621e-08,  1.38312757e-08,  1.14396732e-08,\n",
      "        9.04688413e-09,  6.65190791e-09, -6.68007027e-09,  4.19982848e-09,\n",
      "       -4.50203119e-09, -9.76600259e-11, -1.86337457e-09, -3.30439320e-09],\n",
      "      dtype=float32), array([[-6.48251474e-02,  1.25245869e-01, -5.97725175e-02, ...,\n",
      "        -5.37813315e-03,  4.67465185e-02,  1.53124376e-04],\n",
      "       [-3.65937799e-02,  2.83586904e-02,  1.75889552e-01, ...,\n",
      "         5.34409545e-02, -7.94041157e-03, -1.03170564e-02],\n",
      "       [ 9.23175178e-03, -6.39016414e-03, -4.21137214e-02, ...,\n",
      "         1.20915413e-01,  1.09490156e-02, -4.12383527e-02],\n",
      "       ...,\n",
      "       [-3.06668654e-02,  6.09115437e-02,  3.69089171e-02, ...,\n",
      "         3.48626114e-02,  2.73253787e-02,  1.70198046e-02],\n",
      "       [-1.37339532e-01, -1.55459106e-01, -1.11028954e-01, ...,\n",
      "         2.32309010e-03, -2.32112315e-02,  1.33084301e-02],\n",
      "       [-2.02663988e-02, -3.36497426e-02, -7.27566481e-02, ...,\n",
      "         3.75149921e-02,  3.63518931e-02, -2.01829728e-02]], dtype=float32))\n",
      "(array([ 3.48753326e+02,  1.01902974e+00,  8.66101608e-02,  2.24124957e-02,\n",
      "        1.38433687e-02,  7.57949520e-03,  5.61945746e-03,  1.43168622e-03,\n",
      "        1.29335967e-03,  6.83850201e-04,  6.33919844e-04,  1.99097456e-04,\n",
      "        1.65325488e-04,  1.30556786e-04,  6.39011778e-05,  4.61498385e-05,\n",
      "        3.62869177e-05,  2.22142971e-05,  1.92563548e-05, -1.54347108e-05,\n",
      "        1.44359065e-05,  1.23801947e-05,  1.13810520e-05, -8.23404935e-06,\n",
      "        9.11518146e-06,  8.42248937e-06, -5.50200411e-06,  6.11562518e-06,\n",
      "        5.88776356e-06, -4.23285019e-06,  4.44089665e-06,  4.07127527e-06,\n",
      "       -3.50510390e-06, -2.73242722e-06,  3.50322512e-06, -2.43786099e-06,\n",
      "        3.02902276e-06,  2.81569214e-06,  2.34748768e-06,  2.26684347e-06,\n",
      "       -1.94183554e-06,  1.97382019e-06, -1.67559097e-06, -1.59327192e-06,\n",
      "        1.67769258e-06,  1.59569481e-06,  1.42782665e-06,  1.26967223e-06,\n",
      "       -1.10954886e-06, -9.47358785e-07, -8.83867472e-07,  1.04821345e-06,\n",
      "        9.45763588e-07,  9.00807322e-07, -6.95668007e-07,  8.14433406e-07,\n",
      "        7.64830531e-07,  6.54582379e-07, -6.19289779e-07, -5.64960033e-07,\n",
      "        5.94063295e-07, -4.97631959e-07,  5.37225731e-07,  5.23266692e-07,\n",
      "       -4.03065798e-07,  3.98643749e-07, -3.54784447e-07, -3.48463686e-07,\n",
      "        3.74533414e-07, -2.77098707e-07, -2.34746111e-07,  3.32008511e-07,\n",
      "        3.16625403e-07,  2.67736596e-07,  2.54405251e-07, -1.82478857e-07,\n",
      "        1.92328358e-07, -1.58967680e-07, -1.42081163e-07,  1.65866012e-07,\n",
      "        1.58966827e-07,  1.46299939e-07, -1.08285150e-07, -9.22286318e-08,\n",
      "        1.35204630e-07,  1.23022886e-07,  1.17876695e-07, -7.42615853e-08,\n",
      "        9.43310923e-08, -6.60883259e-08,  7.32673513e-08, -5.23398249e-08,\n",
      "        6.31751718e-08, -3.91245081e-08, -2.97198870e-08,  4.94460544e-08,\n",
      "        4.82375171e-08,  3.71089826e-08,  3.59529153e-08, -2.63513869e-08,\n",
      "        2.91794731e-08, -2.09725748e-08, -1.63443605e-08,  2.39579432e-08,\n",
      "        2.48668517e-08,  2.01536281e-08,  1.73238881e-08,  1.33509275e-08,\n",
      "       -1.30041125e-08, -8.88461216e-09, -1.14560814e-08, -4.96008301e-09,\n",
      "        9.99029304e-09,  6.85084167e-09, -1.84395754e-09,  5.70173686e-09,\n",
      "        4.00186329e-09,  2.34151498e-09,  2.57878829e-10,  3.47086179e-11],\n",
      "      dtype=float32), array([[ 0.0578029 ,  0.1208231 , -0.04518821, ...,  0.01792155,\n",
      "        -0.02433868,  0.00775272],\n",
      "       [ 0.03035141,  0.03575771,  0.15781128, ...,  0.0662007 ,\n",
      "        -0.05161054, -0.10120235],\n",
      "       [-0.01195339, -0.00324123, -0.04638104, ..., -0.08505376,\n",
      "        -0.00032086,  0.06188754],\n",
      "       ...,\n",
      "       [ 0.03409488,  0.0639512 ,  0.04904487, ..., -0.02775349,\n",
      "         0.03942575, -0.01192771],\n",
      "       [ 0.14222936, -0.15790562, -0.08160671, ...,  0.01152661,\n",
      "        -0.01876232, -0.00538414],\n",
      "       [ 0.0179308 , -0.02885089, -0.06964023, ...,  0.00884371,\n",
      "         0.01626856,  0.13882726]], dtype=float32))\n",
      "(array([ 2.3825894e+02,  2.3185353e+00,  1.1215228e-01,  9.7686782e-02,\n",
      "        4.6205550e-02,  3.0051317e-02,  1.4623456e-02,  8.7393057e-03,\n",
      "        6.7019965e-03,  3.3887567e-03,  2.1828357e-03,  1.6204715e-03,\n",
      "        8.9528167e-04,  6.3763373e-04,  4.9116311e-04,  3.3089303e-04,\n",
      "        3.1292081e-04,  2.1818922e-04,  1.3968695e-04,  1.2303318e-04,\n",
      "        8.9422691e-05,  6.7431472e-05,  6.4281907e-05,  4.6146542e-05,\n",
      "        3.4516834e-05,  2.9472329e-05,  2.2546552e-05,  1.9988136e-05,\n",
      "        1.7817774e-05,  1.5124636e-05,  1.0441772e-05,  7.8787371e-06,\n",
      "        7.3698247e-06, -5.5863247e-06,  5.7311536e-06, -3.9120641e-06,\n",
      "        4.8853135e-06,  4.0090436e-06,  3.8002788e-06, -3.2103528e-06,\n",
      "        3.3959111e-06,  3.0309250e-06, -2.2358070e-06,  2.5749168e-06,\n",
      "       -1.9566075e-06,  1.9853508e-06,  1.7783544e-06, -1.4290922e-06,\n",
      "       -1.3590379e-06,  1.5276879e-06,  1.3827267e-06,  1.3606133e-06,\n",
      "       -1.0943859e-06,  1.1380985e-06,  1.0429716e-06,  9.9152896e-07,\n",
      "        9.0994547e-07, -8.4999363e-07, -7.2562915e-07, -5.4048121e-07,\n",
      "        6.2709188e-07,  5.6636208e-07, -4.9902087e-07,  5.2190859e-07,\n",
      "        4.9763293e-07, -3.9956848e-07,  4.1026041e-07, -3.3473668e-07,\n",
      "       -2.8545341e-07, -2.7541518e-07,  4.0492327e-07,  3.3642738e-07,\n",
      "        3.3154652e-07,  2.9041348e-07,  2.6428086e-07, -1.9991531e-07,\n",
      "        2.1639286e-07,  2.0003955e-07, -1.7253323e-07, -1.5000865e-07,\n",
      "        1.8144033e-07,  1.7311443e-07, -1.2092788e-07, -1.2701628e-07,\n",
      "       -9.9610467e-08,  1.5468784e-07,  1.3849041e-07,  1.3023089e-07,\n",
      "        1.0753934e-07, -8.3304052e-08,  9.5011103e-08,  8.2210178e-08,\n",
      "       -6.5217982e-08, -5.5251871e-08, -5.0730293e-08,  7.0821343e-08,\n",
      "        5.1882861e-08,  5.5845355e-08, -3.8782382e-08,  3.7061728e-08,\n",
      "        4.0622105e-08, -2.8440509e-08,  3.0405779e-08, -2.6419395e-08,\n",
      "       -2.0029722e-08,  2.2910299e-08,  2.1485006e-08, -1.7426975e-08,\n",
      "       -1.4930192e-08,  2.0256390e-08,  1.7328412e-08, -1.2530448e-08,\n",
      "        1.0545961e-08,  8.2011571e-09,  6.3460059e-09,  4.8649063e-09,\n",
      "       -8.8930907e-09, -1.9545494e-09, -3.6885803e-09, -6.2067254e-09],\n",
      "      dtype=float32), array([[ 0.0729519 ,  0.11454191,  0.13355021, ...,  0.0067613 ,\n",
      "        -0.0182914 ,  0.00317955],\n",
      "       [ 0.03423845,  0.02852428, -0.11016345, ..., -0.05899246,\n",
      "        -0.0152065 , -0.04287438],\n",
      "       [-0.01268912, -0.00077552,  0.06874894, ..., -0.22861685,\n",
      "         0.05770088, -0.09994107],\n",
      "       ...,\n",
      "       [ 0.03924713,  0.04797116, -0.04726674, ..., -0.04555628,\n",
      "         0.02438382,  0.03066202],\n",
      "       [ 0.12089047, -0.1537347 ,  0.09500074, ...,  0.00290207,\n",
      "         0.00707304,  0.00465286],\n",
      "       [ 0.0129196 , -0.04081231,  0.09011447, ...,  0.12519777,\n",
      "         0.07118068, -0.04286839]], dtype=float32))\n",
      "(array([ 3.53765503e+02,  2.67017066e-01,  1.88602749e-02,  1.25973327e-02,\n",
      "        2.15736288e-03,  1.22630387e-03,  7.50550302e-04,  4.17643256e-04,\n",
      "        1.02714585e-04,  6.52074668e-05,  4.45071964e-05,  2.80256900e-05,\n",
      "        2.06535715e-05,  1.29087675e-05,  1.09830598e-05,  1.06111902e-05,\n",
      "       -9.61839669e-06, -8.58157910e-06,  9.42209226e-06,  8.33319700e-06,\n",
      "        7.70651059e-06, -6.74991225e-06, -4.72079410e-06,  6.26534711e-06,\n",
      "        5.69061513e-06,  5.46935553e-06, -4.32194884e-06,  4.47593993e-06,\n",
      "       -3.57355498e-06,  3.93054688e-06,  3.54389294e-06, -2.66549227e-06,\n",
      "       -2.44825310e-06,  2.76202854e-06,  2.56208114e-06, -2.06895834e-06,\n",
      "        2.22170524e-06, -1.77407117e-06,  1.92579773e-06,  1.69589975e-06,\n",
      "       -1.41635917e-06, -1.15405658e-06,  1.48914194e-06,  1.30403112e-06,\n",
      "        1.14406146e-06, -9.28204145e-07, -8.42641668e-07,  9.60700390e-07,\n",
      "        9.75216835e-07,  7.81673350e-07,  6.73339002e-07, -6.56120619e-07,\n",
      "       -6.25667326e-07,  6.17116143e-07,  5.63525020e-07, -5.03263891e-07,\n",
      "       -4.57462477e-07,  5.04449702e-07,  4.96626967e-07, -3.89980784e-07,\n",
      "        3.91658546e-07,  3.68109937e-07, -3.12468558e-07, -2.98440028e-07,\n",
      "        3.18354779e-07,  2.86065955e-07, -2.36297154e-07,  2.65598487e-07,\n",
      "        2.56589544e-07,  2.22285763e-07, -1.78016748e-07,  1.91630818e-07,\n",
      "       -1.69478426e-07,  1.77747808e-07,  1.50552466e-07, -1.48945404e-07,\n",
      "       -1.40072373e-07,  1.27937298e-07, -1.14304200e-07,  1.14232733e-07,\n",
      "        1.04935751e-07, -8.61953424e-08, -7.33142258e-08, -6.33823021e-08,\n",
      "        9.47099537e-08,  8.40984953e-08,  6.70291556e-08,  7.00548881e-08,\n",
      "        5.77969637e-08,  5.12112486e-08, -4.01230125e-08,  4.61696601e-08,\n",
      "       -3.68961715e-08, -3.34606511e-08,  4.06242791e-08,  3.28325136e-08,\n",
      "        2.96036777e-08,  2.69093299e-08, -2.18018137e-08, -1.96353547e-08,\n",
      "       -1.84251743e-08,  2.16363798e-08, -1.47560399e-08,  1.87508977e-08,\n",
      "       -1.00649107e-08,  1.71818737e-08,  1.52032289e-08, -6.30290931e-09,\n",
      "        1.21109460e-08,  1.08372182e-08, -6.46997789e-09, -3.27525584e-09,\n",
      "       -1.12284781e-09, -1.36470135e-09,  6.32726538e-10,  5.12263210e-09,\n",
      "        5.02719510e-09,  2.73484502e-09,  3.53394314e-09,  6.05936901e-09],\n",
      "      dtype=float32), array([[-0.05803656, -0.11253418,  0.2959617 , ..., -0.0023369 ,\n",
      "         0.03060297, -0.01089762],\n",
      "       [-0.02969369,  0.18471567, -0.07032327, ...,  0.02029849,\n",
      "        -0.06994406, -0.03977959],\n",
      "       [ 0.01667867, -0.00640721, -0.11450777, ..., -0.01543327,\n",
      "        -0.09391282,  0.0723033 ],\n",
      "       ...,\n",
      "       [-0.0405306 , -0.01883834,  0.20778175, ..., -0.00048522,\n",
      "        -0.01957428,  0.05160726],\n",
      "       [-0.14312573, -0.08877459, -0.06801014, ...,  0.00120165,\n",
      "        -0.01271496,  0.00052134],\n",
      "       [-0.01459431, -0.09937561,  0.06087796, ..., -0.03180616,\n",
      "        -0.08040799, -0.01937542]], dtype=float32))\n",
      "(array([ 2.95173248e+02,  1.66555715e+00,  1.16438039e-01,  6.86735362e-02,\n",
      "        2.00335458e-02,  1.23625314e-02,  7.48839928e-03,  4.14736848e-03,\n",
      "        1.82764407e-03,  1.44307734e-03,  7.75590190e-04,  4.24904370e-04,\n",
      "        3.60372302e-04,  2.62491609e-04,  1.87582671e-04,  1.43690399e-04,\n",
      "        8.67784838e-05,  8.32166625e-05,  6.11312353e-05,  4.90061830e-05,\n",
      "        2.97579227e-05,  2.51870715e-05,  2.11804909e-05,  1.84826622e-05,\n",
      "        1.50645783e-05, -1.06021398e-05,  1.04664141e-05, -7.52523738e-06,\n",
      "        9.26679695e-06,  8.12451890e-06,  7.68773134e-06,  7.24042957e-06,\n",
      "        6.16214720e-06, -4.57203851e-06, -3.70176167e-06,  4.98745840e-06,\n",
      "        4.76550440e-06,  4.27364739e-06,  3.97251597e-06,  3.47409537e-06,\n",
      "        3.33013304e-06, -2.62319531e-06, -2.71407930e-06,  2.58764294e-06,\n",
      "        2.39165365e-06,  2.14813986e-06, -1.86666182e-06, -1.69594352e-06,\n",
      "        1.82656106e-06,  1.61445689e-06,  1.45907825e-06, -1.22232780e-06,\n",
      "        1.19605090e-06,  1.29389571e-06,  1.26356269e-06, -1.08870677e-06,\n",
      "       -9.82194820e-07, -7.70134761e-07,  9.06920150e-07,  8.92356070e-07,\n",
      "        7.49617811e-07, -5.57111491e-07,  6.72631131e-07,  6.29219471e-07,\n",
      "        5.78201025e-07, -4.46680389e-07, -4.06064913e-07,  5.15478348e-07,\n",
      "        4.60202472e-07,  4.71358987e-07, -3.45369358e-07, -3.22377929e-07,\n",
      "       -2.53250533e-07,  3.85447976e-07,  3.36818147e-07,  3.29181916e-07,\n",
      "        2.79087999e-07, -1.96212326e-07,  2.30003025e-07,  2.39379574e-07,\n",
      "       -1.74211763e-07, -1.29543253e-07, -1.14885914e-07,  1.87920321e-07,\n",
      "        1.39408883e-07,  1.64706051e-07,  1.54667333e-07, -1.02516196e-07,\n",
      "       -8.87194105e-08,  1.00958921e-07,  9.15883192e-08, -7.15707458e-08,\n",
      "       -5.40587592e-08, -4.43082051e-08,  8.04535674e-08,  7.36060102e-08,\n",
      "        6.27670431e-08,  5.25104049e-08,  4.90616507e-08,  4.38051302e-08,\n",
      "       -3.33729027e-08,  4.02828491e-08, -2.99961727e-08, -2.25212684e-08,\n",
      "        3.36255432e-08,  2.82880794e-08, -1.57880446e-08,  2.33815012e-08,\n",
      "        2.04817585e-08, -1.26125492e-08, -1.33589078e-08, -9.28479071e-09,\n",
      "       -5.80654946e-09,  1.43252219e-08,  1.29683100e-08,  1.04256106e-08,\n",
      "       -1.10778475e-09,  3.94529920e-09,  7.94086463e-10,  2.60820321e-09],\n",
      "      dtype=float32), array([[ 0.05858381, -0.15522143, -0.07431263, ...,  0.00959161,\n",
      "         0.00036061, -0.00460422],\n",
      "       [ 0.03044885, -0.02180156,  0.16767907, ..., -0.08153907,\n",
      "        -0.03646433, -0.01080445],\n",
      "       [-0.01305024, -0.00336473, -0.03231904, ..., -0.12506175,\n",
      "        -0.05570395,  0.14384636],\n",
      "       ...,\n",
      "       [ 0.03445569, -0.06183014,  0.01408672, ...,  0.02794247,\n",
      "        -0.03180727, -0.00059374],\n",
      "       [ 0.13171   ,  0.17015351, -0.13968553, ..., -0.00689437,\n",
      "         0.02082917, -0.00451215],\n",
      "       [ 0.01491701,  0.03302932, -0.06975779, ...,  0.10639198,\n",
      "        -0.20098172, -0.02179482]], dtype=float32))\n",
      "(array([ 3.2926962e+02,  4.2357549e-02,  2.3278173e-02,  1.2913774e-02,\n",
      "        3.8710849e-03,  3.7697169e-03,  1.7481144e-03,  7.0072513e-04,\n",
      "        4.4349904e-04,  3.0000400e-04,  7.4751428e-05,  7.2680472e-05,\n",
      "        5.0530813e-05,  3.7742484e-05,  3.0233574e-05,  1.8391971e-05,\n",
      "        1.5914078e-05,  1.4371993e-05,  1.2531748e-05,  1.0909075e-05,\n",
      "        9.9591734e-06, -8.5534693e-06,  8.3145187e-06, -6.2915360e-06,\n",
      "       -5.3793847e-06,  6.2810964e-06,  5.9237736e-06,  5.5063801e-06,\n",
      "       -4.9246250e-06,  4.8233605e-06, -3.1962995e-06,  4.0571063e-06,\n",
      "        3.7168563e-06,  3.3073991e-06, -2.7001049e-06, -2.6522364e-06,\n",
      "       -2.1106241e-06,  2.7960659e-06,  2.5784407e-06,  2.4204248e-06,\n",
      "        2.0358902e-06, -1.7051805e-06,  1.9184279e-06,  1.8066548e-06,\n",
      "        1.6205597e-06, -1.2617775e-06,  1.3817155e-06, -1.0576082e-06,\n",
      "        1.2016707e-06, -9.6673728e-07,  9.6596909e-07,  9.2937938e-07,\n",
      "        9.1667442e-07,  8.5365855e-07, -7.4514929e-07,  7.5940255e-07,\n",
      "       -6.7614997e-07,  6.6528037e-07,  6.2081170e-07,  5.1204091e-07,\n",
      "       -5.3926692e-07, -5.1487126e-07, -4.6743750e-07, -4.1119745e-07,\n",
      "       -3.6771465e-07,  4.3558072e-07,  4.0140219e-07,  3.8319885e-07,\n",
      "        3.6915040e-07,  3.4769616e-07, -2.9038557e-07, -2.4318433e-07,\n",
      "       -2.1031512e-07,  2.9813324e-07,  2.4873987e-07,  2.3339462e-07,\n",
      "        2.1192079e-07, -1.6877208e-07,  1.9567585e-07, -1.4689164e-07,\n",
      "       -1.0694929e-07,  1.6939796e-07, -8.8346589e-08,  1.5856664e-07,\n",
      "        1.4209795e-07,  1.2108451e-07,  1.0873313e-07, -7.7828183e-08,\n",
      "       -6.3981609e-08,  8.0201403e-08,  8.1735656e-08,  7.2527470e-08,\n",
      "        6.9326134e-08, -4.7715250e-08, -4.1371706e-08, -3.7070524e-08,\n",
      "        5.8901993e-08,  5.0186927e-08,  4.0170210e-08, -2.8928630e-08,\n",
      "       -2.3773287e-08, -1.6861316e-08,  3.5912166e-08,  3.0270705e-08,\n",
      "        2.9402129e-08,  2.3116748e-08, -9.8362278e-09,  1.8651233e-08,\n",
      "       -5.3893490e-09,  1.6006446e-08,  1.3830317e-08,  1.0596026e-08,\n",
      "        9.1343617e-09, -1.3921118e-09, -3.9221326e-10,  1.0023317e-10,\n",
      "        3.5583569e-09,  4.7036686e-09,  4.3817483e-09,  4.2662061e-09],\n",
      "      dtype=float32), array([[-0.05185343,  0.04181853,  0.11623747, ..., -0.02082176,\n",
      "         0.01698501, -0.01454776],\n",
      "       [-0.02863196, -0.1536024 , -0.05758962, ..., -0.02322312,\n",
      "        -0.01915924, -0.10765544],\n",
      "       [ 0.01325323,  0.06361167, -0.10932893, ..., -0.02179244,\n",
      "         0.12330671, -0.10758045],\n",
      "       ...,\n",
      "       [-0.03225483, -0.10682627,  0.2689372 , ...,  0.02056159,\n",
      "        -0.03847256, -0.01288557],\n",
      "       [-0.13636576,  0.12846726,  0.15838999, ..., -0.01717443,\n",
      "         0.00873006, -0.0142721 ],\n",
      "       [-0.01566753,  0.06776474, -0.01885161, ...,  0.09648416,\n",
      "        -0.09534078,  0.03657322]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "a_list = []\n",
    "for i in range(len(activations)):\n",
    "    a = np.linalg.eig(np.dot(activations[ i,:].T, activations[i,:]))\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  3., 21., 18., 22., 29., 14., 12.,  9., 17., 24., 16.,\n",
       "        10., 10., 10.,  2.,  5.,  5.,  5.,  3.,  0.,  1.,  2.,  2.,  1.,\n",
       "         0.,  3.,  1.,  6.,  2.,  9.,  6.,  0.,  3.,  4.,  2.,  4.,  2.,\n",
       "         1.]),\n",
       " array([ 161.07484,  182.38326,  203.69167,  225.00008,  246.30849,\n",
       "         267.61688,  288.9253 ,  310.2337 ,  331.5421 ,  352.85052,\n",
       "         374.15894,  395.46735,  416.77576,  438.08417,  459.39258,\n",
       "         480.701  ,  502.0094 ,  523.3178 ,  544.6262 ,  565.93463,\n",
       "         587.24304,  608.55145,  629.85986,  651.1683 ,  672.4767 ,\n",
       "         693.7851 ,  715.0935 ,  736.4019 ,  757.7103 ,  779.01874,\n",
       "         800.32715,  821.63556,  842.944  ,  864.2524 ,  885.5608 ,\n",
       "         906.8692 ,  928.1776 ,  949.486  ,  970.79443,  992.10284,\n",
       "        1013.41125], dtype=float32),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(a_list, bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.6252017e+00, -7.0994723e-08,  5.4083674e-08,  4.0907953e-08,\n",
       "        -3.8566370e-08,  2.9606486e-08,  2.8139612e-08,  2.2056648e-08,\n",
       "        -2.4415739e-08, -2.2970017e-08, -2.1439469e-08,  1.9300945e-08,\n",
       "         1.8010997e-08, -1.7426018e-08, -1.4991572e-08,  1.2980103e-08,\n",
       "        -1.3421663e-08,  1.0464358e-08, -1.1469672e-08,  9.2682351e-09,\n",
       "        -9.7955732e-09, -8.7888967e-09,  6.9577966e-09, -7.1053150e-09,\n",
       "        -5.7462310e-09, -5.6636997e-09,  5.9220784e-09,  5.6234546e-09,\n",
       "         5.5546359e-09,  4.3976311e-09,  3.9706514e-09, -4.2436747e-09,\n",
       "        -4.3176391e-09, -3.4624463e-09, -2.8841358e-09, -2.6164158e-09,\n",
       "         2.6396410e-09,  2.4596190e-09, -2.3317865e-09, -2.1457545e-09,\n",
       "         2.1399031e-09,  2.0038751e-09, -1.9678896e-09,  1.8507910e-09,\n",
       "         1.7357562e-09, -1.5936288e-09, -1.5125163e-09,  1.4574953e-09,\n",
       "        -1.4186180e-09,  1.3057007e-09, -1.2680751e-09,  1.1780564e-09,\n",
       "         1.0587603e-09, -1.0182752e-09, -9.2577140e-10,  8.8999041e-10,\n",
       "         8.6250651e-10, -8.1054391e-10, -7.8644952e-10, -6.5799077e-10,\n",
       "         7.1668554e-10,  6.4358469e-10,  5.9390171e-10,  5.5564980e-10,\n",
       "        -4.9242876e-10,  4.8654764e-10,  4.4445786e-10,  3.6348116e-10,\n",
       "        -4.0788586e-10, -4.1824952e-10,  2.8607780e-10, -3.5916692e-10,\n",
       "        -3.1090572e-10, -2.6273397e-10,  2.6756528e-10, -2.0974562e-10,\n",
       "         2.1025542e-10,  2.0532492e-10, -1.7583250e-10, -1.6574135e-10,\n",
       "        -1.4780449e-10, -1.3124764e-10, -1.1878000e-10,  1.5053173e-10,\n",
       "         1.2574285e-10,  1.3119854e-10,  9.9229687e-11, -8.6244373e-11,\n",
       "         8.1809573e-11, -7.6384822e-11,  7.5954881e-11,  7.1701582e-11,\n",
       "        -5.9016736e-11, -5.3540606e-11,  5.4529395e-11,  4.7190401e-11,\n",
       "         3.9734896e-11, -4.4355367e-11, -3.9073637e-11, -3.5251121e-11,\n",
       "         3.3248085e-11, -2.8185608e-11, -2.0089755e-11,  2.5304489e-11,\n",
       "         2.2418074e-11, -1.7789974e-11, -1.3603746e-11, -1.2689458e-11,\n",
       "         1.5039317e-11,  1.2901417e-11,  2.1057802e-12, -1.8784683e-12,\n",
       "        -1.3687472e-13, -6.4513360e-12,  1.0296410e-11, -2.8082007e-12,\n",
       "        -1.1636378e-12,  7.9521303e-12,  5.3500373e-12,  3.3972421e-12],\n",
       "       dtype=float32),\n",
       " array([[-2.98693664e-02, -4.20373725e-03,  4.69613355e-03, ...,\n",
       "         -1.00600850e-02, -5.88780455e-03, -8.61639716e-03],\n",
       "        [-2.96351165e-02,  1.02737732e-02, -3.36382426e-02, ...,\n",
       "         -3.83751071e-03,  2.07291488e-02,  1.71235446e-02],\n",
       "        [ 1.44351795e-02,  3.46840220e-03,  8.78269505e-03, ...,\n",
       "         -2.93181390e-02,  3.06359809e-02,  4.47828397e-02],\n",
       "        ...,\n",
       "        [-1.11652408e-02, -4.11770539e-03,  5.52476663e-03, ...,\n",
       "         -4.43737544e-02, -3.47717665e-02, -1.00039668e-01],\n",
       "        [-1.52363166e-01, -1.12937376e-01, -8.87315050e-02, ...,\n",
       "         -5.13265934e-03,  6.62501622e-03, -4.05827072e-03],\n",
       "        [-2.16387156e-02, -7.16184222e-05, -1.07229166e-02, ...,\n",
       "         -5.77763072e-04,  2.40041073e-02, -2.56964993e-02]], dtype=float32))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(np.dot(activations[np.newaxis, 10,:].T, activations[np.newaxis,10,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00805962,  0.00600163, -0.00716474, ...,  0.01081743,\n",
       "         0.02783012,  0.00172846],\n",
       "       [ 0.00600163,  0.00446915, -0.00533526, ...,  0.00805525,\n",
       "         0.02072384,  0.00128711],\n",
       "       [-0.00716474, -0.00533526,  0.00636922, ..., -0.00961634,\n",
       "        -0.02474007, -0.00153655],\n",
       "       ...,\n",
       "       [ 0.01081743,  0.00805525, -0.00961634, ...,  0.0145189 ,\n",
       "         0.03735293,  0.0023199 ],\n",
       "       [ 0.02783012,  0.02072384, -0.02474007, ...,  0.03735293,\n",
       "         0.09609832,  0.00596844],\n",
       "       [ 0.00172846,  0.00128711, -0.00153655, ...,  0.0023199 ,\n",
       "         0.00596844,  0.00037069]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(activations[np.newaxis, 3,:].T, activations[np.newaxis,3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14300, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(activations)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1440f519588>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_embedded[:,0], X_embedded[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(parameters_list)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x25480135448>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1])\n",
    "plt.scatter(X_embedded[0,0], X_embedded[0,1], c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maml.load_state_dict(torch.load(save_model_file_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.55525592e-02,  3.77668254e-02, -4.42602821e-02, -3.41717713e-02,\n",
       "        3.96080092e-02,  8.17221329e-02,  9.96415503e-03, -7.70228058e-02,\n",
       "        6.84627667e-02, -5.72013445e-02, -5.99408485e-02,  5.80710731e-02,\n",
       "        5.58182932e-02, -3.88639122e-02,  2.62596756e-02, -7.05522224e-02,\n",
       "        4.40023318e-02, -7.71313719e-03,  1.23815527e-02, -6.63354155e-03,\n",
       "        4.29893956e-02, -2.78736632e-02, -4.57188226e-02,  5.84799051e-02,\n",
       "        4.90391068e-02, -1.54506946e-02, -3.97548378e-02,  2.87726112e-02,\n",
       "        9.13246349e-02,  6.74578026e-02, -2.59573609e-02,  9.55008939e-02,\n",
       "        4.73733060e-02, -4.56347317e-02, -7.06606284e-02, -9.33174342e-02,\n",
       "        8.73021127e-05, -5.30967563e-02,  2.32417062e-02, -1.20859025e-02,\n",
       "        2.76789255e-02, -8.43265504e-02, -3.86885903e-03, -1.67625789e-02,\n",
       "       -5.00808395e-02, -8.60744901e-03,  2.36390680e-02, -7.72519335e-02,\n",
       "        1.52680231e-03, -6.06458671e-02,  2.26588491e-02, -1.60999224e-02,\n",
       "        4.75947335e-02,  2.12435406e-02, -2.27395743e-02,  4.10613082e-02,\n",
       "        3.45672034e-02,  2.62674149e-02,  5.05305938e-02, -5.82242310e-02,\n",
       "        2.10711248e-02, -1.61289629e-02,  5.82388882e-03, -8.08294956e-03,\n",
       "        8.17401707e-03, -3.81839741e-03,  4.12785076e-03, -9.07627717e-02,\n",
       "        4.96825576e-02, -8.82048905e-02, -2.68044285e-02,  5.52326329e-02,\n",
       "       -7.13069960e-02, -2.22913604e-02,  4.39422242e-02,  6.11381344e-02,\n",
       "        5.96349649e-02, -7.85258710e-02, -2.29225643e-02, -4.43125777e-02,\n",
       "        4.14369516e-02,  2.56852750e-02,  8.65609199e-02,  3.88454422e-02,\n",
       "       -9.84702036e-02, -3.40344086e-02,  1.72325037e-02, -7.12124407e-02,\n",
       "       -5.51301353e-02,  1.75300855e-02,  1.03965551e-02,  9.42891240e-02,\n",
       "        6.56968041e-04,  6.47855997e-02, -2.11470318e-03,  5.57731465e-02,\n",
       "        4.67040129e-02,  6.95051346e-03, -7.03481808e-02,  9.72941797e-03,\n",
       "       -8.40470940e-02, -1.59913190e-02,  6.22804686e-02,  8.37188065e-02,\n",
       "        5.65349385e-02, -1.97221600e-02,  3.41523588e-02, -6.20947257e-02,\n",
       "        3.29205915e-02,  1.14289690e-02, -3.48295458e-02, -1.16013561e-03,\n",
       "       -4.70751561e-02, -6.16802201e-02,  2.86546592e-02, -1.26899518e-02,\n",
       "       -8.62388462e-02, -3.53678800e-02, -9.40995216e-02, -3.69543035e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x241077482c8>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04197604\n",
      "0.041967083\n",
      "0.041958276\n",
      "0.041949566\n",
      "0.04194093\n",
      "0.041932367\n",
      "0.04192387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-84d22a036b8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_maml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_ML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Data Analytics Master\\Semester4-Thesis\\repo\\time-series-meta-learning\\master-thesis\\Code\\meta-learning\\run_MAML_04.py\u001b[0m in \u001b[0;36mtest2\u001b[1;34m(maml, model, model_name, dataset_name, test_data_ML, adaptation_steps, learning_rate, noise_level, noise_type, is_test, horizon)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m#error.backward()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m             \u001b[1;31m#opt2.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\learn2learn\\algorithms\\maml.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, loss, first_order, allow_unused, allow_nograd)\u001b[0m\n\u001b[0;32m    184\u001b[0m                                  \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecond_order\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                                  \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecond_order\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                                  allow_unused=allow_unused)\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trial = 2\n",
    "output_directory = \"../../Models/\"+dataset_name+\"_\"+model_name+\"_MAML/\"+str(trial)+\"/\"\n",
    "\n",
    "save_model_file_ = output_directory + \"encoder_\"+save_model_file\n",
    "save_model_file_2 = output_directory + save_model_file\n",
    "load_model_file_ = output_directory + load_model_file\n",
    "\n",
    "model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n",
    "model2 = nn.Linear(120, 1)\n",
    "\n",
    "model.cuda()\n",
    "model2.cuda()\n",
    "\n",
    "maml = l2l.algorithms.MAML(model2, lr=learning_rate, first_order=False)\n",
    "model.load_state_dict(torch.load(save_model_file_))\n",
    "maml.load_state_dict(torch.load(save_model_file_2))\n",
    "\n",
    "for i in range(10):\n",
    "    loss = test_maml(maml, model, model_name, dataset_name, test_data_ML, i, learning_rate,0, noise_type)\n",
    "    print(loss.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_nomaml = \"../../Models/\"+dataset_name+\"_\"+model_name+\"/\"+str(trial)+\"/\"\n",
    "save_model_file_nomaml = output_directory_nomaml + \"temp_model.pt\"\n",
    "load_model_file_nomaml = output_directory_nomaml + \"model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tasks, task_size, dim, channels = test_data_ML.x.shape if is_test else validation_data_ML.x.shape\n",
    "horizon = 10\n",
    "freeze_model_flag = True\n",
    "test_loss_list1 = []\n",
    "test_loss_list2 = []\n",
    "initial_test_loss_list1 = []\n",
    "initial_test_loss_list2 = []\n",
    "regularization_penalty = 0.0\n",
    "\n",
    "def test_nomaml(epochs):\n",
    "\n",
    "    verbose = 0\n",
    "    if n_tasks == 50:\n",
    "        step = n_tasks//100\n",
    "    else:\n",
    "        step = 1\n",
    "\n",
    "    for task_id in range(0, (n_tasks-horizon-1), step):\n",
    "\n",
    "\n",
    "        #check that all files blong to the same domain\n",
    "        temp_file_idx = test_data_ML.file_idx[task_id:task_id+horizon+1] if is_test else validation_data_ML.file_idx[task_id:task_id+horizon+1]\n",
    "        if(len(np.unique(temp_file_idx))>1):\n",
    "            continue\n",
    "\n",
    "        if is_test: \n",
    "            temp_x_train = test_data_ML.x[task_id]\n",
    "            temp_y_train = test_data_ML.y[task_id]\n",
    "\n",
    "            temp_x_test1 = test_data_ML.x[(task_id+1):(task_id+horizon+1)].reshape(-1, dim, channels)\n",
    "            temp_y_test1 = test_data_ML.y[(task_id+1):(task_id+horizon+1)].reshape(-1, 1)\n",
    "\n",
    "            temp_x_test2 = test_data_ML.x[(task_id+1)].reshape(-1, dim, channels)\n",
    "            temp_y_test2 = test_data_ML.y[(task_id+1)].reshape(-1, 1)\n",
    "\n",
    "        else:\n",
    "            temp_x_train = validation_data_ML.x[task_id]\n",
    "            temp_y_train = validation_data_ML.y[task_id]\n",
    "\n",
    "            temp_x_test1 = validation_data_ML.x[(task_id+1):(task_id+horizon+1)].reshape(-1, dim, channels)\n",
    "            temp_y_test1 = validation_data_ML.y[(task_id+1):(task_id+horizon+1)].reshape(-1, 1)\n",
    "\n",
    "            temp_x_test2 = validation_data_ML.x[(task_id+1)].reshape(-1, dim, channels)\n",
    "            temp_y_test2 = validation_data_ML.y[(task_id+1)].reshape(-1, 1)\n",
    "\n",
    "\n",
    "        if model_name == \"FCN\":\n",
    "\n",
    "            kernels = [8,5,3] if dataset_name!= \"POLLUTION\" else [4,2,1]\n",
    "            temp_x_train = np.transpose(temp_x_train, [0,2,1])\n",
    "            temp_x_test1 = np.transpose(temp_x_test1, [0,2,1])\n",
    "            temp_x_test2 = np.transpose(temp_x_test2, [0,2,1])\n",
    "            #temp_x_val = np.transpose(temp_x_val, [0,2,1])\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=patience_stopping, model_file=save_model_file_nomaml, verbose=verbose)\n",
    "\n",
    "\n",
    "        if model_name == \"LSTM\":\n",
    "            model = LSTMModel( batch_size=batch_size, seq_len = window_size, input_dim = input_dim, n_layers = 2, hidden_dim = 120, output_dim =1)\n",
    "        elif model_name == \"FCN\":\n",
    "            model = FCN(time_steps = window_size, channels=[input_dim, 128, 128, 128], kernels=kernels )\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(load_model_file_nomaml))\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(SimpleDataset(x=temp_x_train, y=temp_y_train), **params)\n",
    "        test_loader1 = DataLoader(SimpleDataset(x=temp_x_test1, y=temp_y_test1), **params)\n",
    "        test_loader2 = DataLoader(SimpleDataset(x=temp_x_test2, y=temp_y_test2), **params)\n",
    "\n",
    "        verbose = False\n",
    "\n",
    "        model.cuda()\n",
    "        initial_loss1 = test(model, test_loader1, output_directory, load_model_file_nomaml, verbose)\n",
    "        initial_loss2 = test(model, test_loader2, output_directory, load_model_file_nomaml, verbose)\n",
    "\n",
    "        if freeze_model_flag:\n",
    "            freeze_model(model)\n",
    "\n",
    "\n",
    "        #early_stopping(initial_loss, model)\n",
    "        train(model, train_loader, test_loader1, early_stopping, learning_rate, epochs, regularization_penalty) \n",
    "        early_stopping(0.0, model)\n",
    "        loss1 = test(model, test_loader1, output_directory, save_model_file_, verbose)\n",
    "        loss2 = test(model, test_loader2, output_directory, save_model_file_, verbose)\n",
    "        print(loss1)\n",
    "\n",
    "        test_loss_list1.append(loss1)\n",
    "        initial_test_loss_list1.append(initial_loss1)\n",
    "        test_loss_list2.append(loss2)\n",
    "        initial_test_loss_list2.append(initial_loss2)\n",
    "\n",
    "    return test_loss_list1, test_loss_list2, initial_test_loss_list1, initial_test_loss_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.144789\n",
      "Regression error on test: 0.204599\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.093888\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.124488\n",
      "done\n",
      "Regression error on test: 0.131772\n",
      "Regression error on test: 0.042639\n",
      "0.13177210092544556\n",
      "Regression error on test: 0.145688\n",
      "Regression error on test: 0.150315\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.193621\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.122633\n",
      "done\n",
      "Regression error on test: 0.184600\n",
      "Regression error on test: 0.093331\n",
      "0.18459990620613098\n",
      "Regression error on test: 0.136736\n",
      "Regression error on test: 0.169615\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139395\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118164\n",
      "done\n",
      "Regression error on test: 0.207958\n",
      "Regression error on test: 0.063799\n",
      "0.207957923412323\n",
      "Regression error on test: 0.127920\n",
      "Regression error on test: 0.141182\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158886\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117124\n",
      "done\n",
      "Regression error on test: 0.242952\n",
      "Regression error on test: 0.084222\n",
      "0.24295160174369812\n",
      "Regression error on test: 0.143248\n",
      "Regression error on test: 0.136221\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130575\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140803\n",
      "done\n",
      "Regression error on test: 0.299013\n",
      "Regression error on test: 0.084511\n",
      "0.29901322722435\n",
      "Regression error on test: 0.144645\n",
      "Regression error on test: 0.150047\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125672\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.150348\n",
      "done\n",
      "Regression error on test: 0.337131\n",
      "Regression error on test: 0.068855\n",
      "0.33713093400001526\n",
      "Regression error on test: 0.136637\n",
      "Regression error on test: 0.135629\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139513\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.143222\n",
      "done\n",
      "Regression error on test: 0.354753\n",
      "Regression error on test: 0.083461\n",
      "0.3547532856464386\n",
      "Regression error on test: 0.134216\n",
      "Regression error on test: 0.088064\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125083\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140582\n",
      "done\n",
      "Regression error on test: 0.363729\n",
      "Regression error on test: 0.182394\n",
      "0.36372917890548706\n",
      "Regression error on test: 0.131674\n",
      "Regression error on test: 0.170302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.080276\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.137062\n",
      "done\n",
      "Regression error on test: 0.368891\n",
      "Regression error on test: 0.177624\n",
      "0.3688913583755493\n",
      "Regression error on test: 0.127905\n",
      "Regression error on test: 0.101916\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.156385\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.137267\n",
      "done\n",
      "Regression error on test: 0.367890\n",
      "Regression error on test: 0.436884\n",
      "0.36788955330848694\n",
      "Regression error on test: 0.129125\n",
      "Regression error on test: 0.213587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091581\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.135380\n",
      "done\n",
      "Regression error on test: 0.343494\n",
      "Regression error on test: 0.570917\n",
      "0.3434940576553345\n",
      "Regression error on test: 0.121165\n",
      "Regression error on test: 0.060791\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.198937\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.141131\n",
      "done\n",
      "Regression error on test: 0.306705\n",
      "Regression error on test: 0.326911\n",
      "0.3067047595977783\n",
      "Regression error on test: 0.121355\n",
      "Regression error on test: 0.081464\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061040\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.121048\n",
      "done\n",
      "Regression error on test: 0.301218\n",
      "Regression error on test: 0.413736\n",
      "0.3012184500694275\n",
      "Regression error on test: 0.117664\n",
      "Regression error on test: 0.294457\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079566\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127334\n",
      "done\n",
      "Regression error on test: 0.290323\n",
      "Regression error on test: 0.644838\n",
      "0.29032278060913086\n",
      "Regression error on test: 0.096449\n",
      "Regression error on test: 0.150195\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.279416\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132545\n",
      "done\n",
      "Regression error on test: 0.253652\n",
      "Regression error on test: 0.465688\n",
      "0.25365179777145386\n",
      "Regression error on test: 0.085740\n",
      "Regression error on test: 0.069959\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.136808\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.128634\n",
      "done\n",
      "Regression error on test: 0.234044\n",
      "Regression error on test: 0.245079\n",
      "0.23404449224472046\n",
      "Regression error on test: 0.091803\n",
      "Regression error on test: 0.111423\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061379\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065419\n",
      "done\n",
      "Regression error on test: 0.237400\n",
      "Regression error on test: 0.173220\n",
      "0.2374003529548645\n",
      "Regression error on test: 0.088243\n",
      "Regression error on test: 0.062646\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097891\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056230\n",
      "done\n",
      "Regression error on test: 0.258664\n",
      "Regression error on test: 0.234015\n",
      "0.25866439938545227\n",
      "Regression error on test: 0.090106\n",
      "Regression error on test: 0.132611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050852\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068850\n",
      "done\n",
      "Regression error on test: 0.287353\n",
      "Regression error on test: 0.167606\n",
      "0.2873528301715851\n",
      "Regression error on test: 0.078688\n",
      "Regression error on test: 0.114119\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.118822\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065725\n",
      "done\n",
      "Regression error on test: 0.317365\n",
      "Regression error on test: 0.192931\n",
      "0.3173651099205017\n",
      "Regression error on test: 0.084808\n",
      "Regression error on test: 0.133988\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.103695\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080582\n",
      "done\n",
      "Regression error on test: 0.358520\n",
      "Regression error on test: 0.203024\n",
      "0.35852015018463135\n",
      "Regression error on test: 0.093019\n",
      "Regression error on test: 0.062687\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.119147\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101937\n",
      "done\n",
      "Regression error on test: 0.403658\n",
      "Regression error on test: 0.272048\n",
      "0.40365785360336304\n",
      "Regression error on test: 0.096435\n",
      "Regression error on test: 0.044552\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062064\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100017\n",
      "done\n",
      "Regression error on test: 0.426108\n",
      "Regression error on test: 0.304779\n",
      "0.42610761523246765\n",
      "Regression error on test: 0.097979\n",
      "Regression error on test: 0.082305\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043589\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101136\n",
      "done\n",
      "Regression error on test: 0.432311\n",
      "Regression error on test: 0.278129\n",
      "0.4323112368583679\n",
      "Regression error on test: 0.097754\n",
      "Regression error on test: 0.043110\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079270\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104744\n",
      "done\n",
      "Regression error on test: 0.445569\n",
      "Regression error on test: 0.269615\n",
      "0.44556865096092224\n",
      "Regression error on test: 0.102056\n",
      "Regression error on test: 0.130587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041225\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.110663\n",
      "done\n",
      "Regression error on test: 0.463153\n",
      "Regression error on test: 0.278637\n",
      "0.4631534814834595\n",
      "Regression error on test: 0.092418\n",
      "Regression error on test: 0.075820\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.113457\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.129054\n",
      "done\n",
      "Regression error on test: 0.467757\n",
      "Regression error on test: 0.385860\n",
      "0.4677569270133972\n",
      "Regression error on test: 0.092611\n",
      "Regression error on test: 0.081279\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055546\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.144611\n",
      "done\n",
      "Regression error on test: 0.471576\n",
      "Regression error on test: 0.520900\n",
      "0.4715755879878998\n",
      "Regression error on test: 0.088182\n",
      "Regression error on test: 0.018431\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066868\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076754\n",
      "done\n",
      "Regression error on test: 0.457961\n",
      "Regression error on test: 0.467728\n",
      "0.4579613208770752\n",
      "Regression error on test: 0.093110\n",
      "Regression error on test: 0.175317\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017773\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091445\n",
      "done\n",
      "Regression error on test: 0.438789\n",
      "Regression error on test: 0.604480\n",
      "0.43878883123397827\n",
      "Regression error on test: 0.092913\n",
      "Regression error on test: 0.216100\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159573\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093421\n",
      "done\n",
      "Regression error on test: 0.394260\n",
      "Regression error on test: 0.654401\n",
      "0.3942600190639496\n",
      "Regression error on test: 0.082954\n",
      "Regression error on test: 0.096846\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.196823\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096586\n",
      "done\n",
      "Regression error on test: 0.346207\n",
      "Regression error on test: 0.496546\n",
      "0.3462067246437073\n",
      "Regression error on test: 0.087096\n",
      "Regression error on test: 0.059991\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.093257\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092926\n",
      "done\n",
      "Regression error on test: 0.313760\n",
      "Regression error on test: 0.366816\n",
      "0.31375986337661743\n",
      "Regression error on test: 0.090531\n",
      "Regression error on test: 0.080061\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060128\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.090071\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.300012\n",
      "Regression error on test: 0.410703\n",
      "0.30001190304756165\n",
      "Regression error on test: 0.091859\n",
      "Regression error on test: 0.086125\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.075749\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104908\n",
      "done\n",
      "Regression error on test: 0.280656\n",
      "Regression error on test: 0.445463\n",
      "0.28065648674964905\n",
      "Regression error on test: 0.087546\n",
      "Regression error on test: 0.034208\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078217\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.108398\n",
      "done\n",
      "Regression error on test: 0.260831\n",
      "Regression error on test: 0.324671\n",
      "0.2608312964439392\n",
      "Regression error on test: 0.087788\n",
      "Regression error on test: 0.077753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031500\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081773\n",
      "done\n",
      "Regression error on test: 0.252245\n",
      "Regression error on test: 0.424047\n",
      "0.2522452473640442\n",
      "Regression error on test: 0.083151\n",
      "Regression error on test: 0.036989\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063323\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114078\n",
      "done\n",
      "Regression error on test: 0.236627\n",
      "Regression error on test: 0.384756\n",
      "0.23662713170051575\n",
      "Regression error on test: 0.082381\n",
      "Regression error on test: 0.067713\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035136\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092239\n",
      "done\n",
      "Regression error on test: 0.221755\n",
      "Regression error on test: 0.276004\n",
      "0.22175531089305878\n",
      "Regression error on test: 0.078362\n",
      "Regression error on test: 0.173346\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059659\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061955\n",
      "done\n",
      "Regression error on test: 0.219546\n",
      "Regression error on test: 0.159192\n",
      "0.21954606473445892\n",
      "Regression error on test: 0.063331\n",
      "Regression error on test: 0.116513\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158214\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052292\n",
      "done\n",
      "Regression error on test: 0.227339\n",
      "Regression error on test: 0.173868\n",
      "0.2273394614458084\n",
      "Regression error on test: 0.053866\n",
      "Regression error on test: 0.138260\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109896\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045805\n",
      "done\n",
      "Regression error on test: 0.237295\n",
      "Regression error on test: 0.172077\n",
      "0.23729471862316132\n",
      "Regression error on test: 0.043768\n",
      "Regression error on test: 0.094345\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.126540\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040038\n",
      "done\n",
      "Regression error on test: 0.249263\n",
      "Regression error on test: 0.229336\n",
      "0.24926303327083588\n",
      "Regression error on test: 0.039895\n",
      "Regression error on test: 0.093344\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088265\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039000\n",
      "done\n",
      "Regression error on test: 0.264217\n",
      "Regression error on test: 0.217149\n",
      "0.26421669125556946\n",
      "Regression error on test: 0.034079\n",
      "Regression error on test: 0.042992\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.086828\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034705\n",
      "done\n",
      "Regression error on test: 0.273780\n",
      "Regression error on test: 0.247212\n",
      "0.2737800180912018\n",
      "Regression error on test: 0.033061\n",
      "Regression error on test: 0.036623\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039338\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032734\n",
      "done\n",
      "Regression error on test: 0.282815\n",
      "Regression error on test: 0.238811\n",
      "0.28281542658805847\n",
      "Regression error on test: 0.034858\n",
      "Regression error on test: 0.031388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031942\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037944\n",
      "done\n",
      "Regression error on test: 0.295435\n",
      "Regression error on test: 0.267866\n",
      "0.2954351603984833\n",
      "Regression error on test: 0.038224\n",
      "Regression error on test: 0.029289\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030787\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037246\n",
      "done\n",
      "Regression error on test: 0.300331\n",
      "Regression error on test: 0.236039\n",
      "0.3003307580947876\n",
      "Regression error on test: 0.039884\n",
      "Regression error on test: 0.027518\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023816\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041598\n",
      "done\n",
      "Regression error on test: 0.305171\n",
      "Regression error on test: 0.253911\n",
      "0.3051706552505493\n",
      "Regression error on test: 0.042521\n",
      "Regression error on test: 0.023040\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027518\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042276\n",
      "done\n",
      "Regression error on test: 0.312676\n",
      "Regression error on test: 0.237126\n",
      "0.312676340341568\n",
      "Regression error on test: 0.048384\n",
      "Regression error on test: 0.021857\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023146\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048286\n",
      "done\n",
      "Regression error on test: 0.322763\n",
      "Regression error on test: 0.273421\n",
      "0.3227630853652954\n",
      "Regression error on test: 0.050033\n",
      "Regression error on test: 0.037282\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022294\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050775\n",
      "done\n",
      "Regression error on test: 0.324831\n",
      "Regression error on test: 0.291761\n",
      "0.3248308002948761\n",
      "Regression error on test: 0.048662\n",
      "Regression error on test: 0.055613\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034365\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051033\n",
      "done\n",
      "Regression error on test: 0.322712\n",
      "Regression error on test: 0.378872\n",
      "0.32271242141723633\n",
      "Regression error on test: 0.052130\n",
      "Regression error on test: 0.035185\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054853\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055848\n",
      "done\n",
      "Regression error on test: 0.305217\n",
      "Regression error on test: 0.312782\n",
      "0.30521705746650696\n",
      "Regression error on test: 0.054811\n",
      "Regression error on test: 0.032811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030616\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053927\n",
      "done\n",
      "Regression error on test: 0.296234\n",
      "Regression error on test: 0.337566\n",
      "0.2962341010570526\n",
      "Regression error on test: 0.055043\n",
      "Regression error on test: 0.054600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032448\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053868\n",
      "done\n",
      "Regression error on test: 0.288075\n",
      "Regression error on test: 0.365008\n",
      "0.2880747616291046\n",
      "Regression error on test: 0.054415\n",
      "Regression error on test: 0.065039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054708\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055379\n",
      "done\n",
      "Regression error on test: 0.273418\n",
      "Regression error on test: 0.316822\n",
      "0.2734184265136719\n",
      "Regression error on test: 0.051053\n",
      "Regression error on test: 0.045894\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062947\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048059\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.284438\n",
      "0.2647024095058441\n",
      "Regression error on test: 0.051035\n",
      "Regression error on test: 0.053886\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043458\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046400\n",
      "done\n",
      "Regression error on test: 0.257963\n",
      "Regression error on test: 0.328967\n",
      "0.2579631805419922\n",
      "Regression error on test: 0.048933\n",
      "Regression error on test: 0.081669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048352\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066146\n",
      "done\n",
      "Regression error on test: 0.248783\n",
      "Regression error on test: 0.337994\n",
      "0.24878303706645966\n",
      "Regression error on test: 0.044736\n",
      "Regression error on test: 0.038354\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.071549\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075964\n",
      "done\n",
      "Regression error on test: 0.238841\n",
      "Regression error on test: 0.294098\n",
      "0.23884065449237823\n",
      "Regression error on test: 0.045454\n",
      "Regression error on test: 0.023573\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037897\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039263\n",
      "done\n",
      "Regression error on test: 0.231860\n",
      "Regression error on test: 0.270577\n",
      "0.23185983300209045\n",
      "Regression error on test: 0.046971\n",
      "Regression error on test: 0.090293\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021155\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035862\n",
      "done\n",
      "Regression error on test: 0.228843\n",
      "Regression error on test: 0.203918\n",
      "0.22884348034858704\n",
      "Regression error on test: 0.043821\n",
      "Regression error on test: 0.061994\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078163\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027340\n",
      "done\n",
      "Regression error on test: 0.230210\n",
      "Regression error on test: 0.222953\n",
      "0.23021039366722107\n",
      "Regression error on test: 0.042227\n",
      "Regression error on test: 0.035126\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051908\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027112\n",
      "done\n",
      "Regression error on test: 0.232743\n",
      "Regression error on test: 0.255972\n",
      "0.23274259269237518\n",
      "Regression error on test: 0.047610\n",
      "Regression error on test: 0.048322\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034726\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041883\n",
      "done\n",
      "Regression error on test: 0.228450\n",
      "Regression error on test: 0.218445\n",
      "0.22844964265823364\n",
      "Regression error on test: 0.053526\n",
      "Regression error on test: 0.031418\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038365\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033525\n",
      "done\n",
      "Regression error on test: 0.226086\n",
      "Regression error on test: 0.229661\n",
      "0.2260863333940506\n",
      "Regression error on test: 0.056575\n",
      "Regression error on test: 0.045715\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029245\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045202\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.225170\n",
      "Regression error on test: 0.217046\n",
      "0.22517023980617523\n",
      "Regression error on test: 0.058599\n",
      "Regression error on test: 0.032868\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037153\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038903\n",
      "done\n",
      "Regression error on test: 0.226957\n",
      "Regression error on test: 0.237166\n",
      "0.22695666551589966\n",
      "Regression error on test: 0.063042\n",
      "Regression error on test: 0.039700\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030360\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051527\n",
      "done\n",
      "Regression error on test: 0.226117\n",
      "Regression error on test: 0.238570\n",
      "0.22611671686172485\n",
      "Regression error on test: 0.066996\n",
      "Regression error on test: 0.045533\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036640\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055528\n",
      "done\n",
      "Regression error on test: 0.236251\n",
      "Regression error on test: 0.224290\n",
      "0.23625054955482483\n",
      "Regression error on test: 0.069430\n",
      "Regression error on test: 0.038743\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035793\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050562\n",
      "done\n",
      "Regression error on test: 0.240930\n",
      "Regression error on test: 0.240413\n",
      "0.24093003571033478\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.058793\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033029\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059367\n",
      "done\n",
      "Regression error on test: 0.253729\n",
      "Regression error on test: 0.217587\n",
      "0.2537294924259186\n",
      "Regression error on test: 0.066588\n",
      "Regression error on test: 0.046056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052682\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054114\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.248275\n",
      "0.26470187306404114\n",
      "Regression error on test: 0.068380\n",
      "Regression error on test: 0.088950\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042813\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060710\n",
      "done\n",
      "Regression error on test: 0.278891\n",
      "Regression error on test: 0.213043\n",
      "0.27889102697372437\n",
      "Regression error on test: 0.063563\n",
      "Regression error on test: 0.107488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076645\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062554\n",
      "done\n",
      "Regression error on test: 0.296243\n",
      "Regression error on test: 0.194812\n",
      "0.29624268412590027\n",
      "Regression error on test: 0.059090\n",
      "Regression error on test: 0.061899\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.095164\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067441\n",
      "done\n",
      "Regression error on test: 0.317561\n",
      "Regression error on test: 0.220500\n",
      "0.31756100058555603\n",
      "Regression error on test: 0.057614\n",
      "Regression error on test: 0.065955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054570\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066591\n",
      "done\n",
      "Regression error on test: 0.334063\n",
      "Regression error on test: 0.234910\n",
      "0.33406320214271545\n",
      "Regression error on test: 0.062140\n",
      "Regression error on test: 0.077302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055330\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083091\n",
      "done\n",
      "Regression error on test: 0.353975\n",
      "Regression error on test: 0.228766\n",
      "0.3539747893810272\n",
      "Regression error on test: 0.062371\n",
      "Regression error on test: 0.079238\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069971\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085952\n",
      "done\n",
      "Regression error on test: 0.372552\n",
      "Regression error on test: 0.339908\n",
      "0.37255221605300903\n",
      "Regression error on test: 0.064429\n",
      "Regression error on test: 0.069872\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.074789\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052351\n",
      "done\n",
      "Regression error on test: 0.383426\n",
      "Regression error on test: 0.271085\n",
      "0.38342559337615967\n",
      "Regression error on test: 0.063655\n",
      "Regression error on test: 0.038643\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057766\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102751\n",
      "done\n",
      "Regression error on test: 0.390243\n",
      "Regression error on test: 0.368408\n",
      "0.39024290442466736\n",
      "Regression error on test: 0.070119\n",
      "Regression error on test: 0.030479\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034154\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063423\n",
      "done\n",
      "Regression error on test: 0.377002\n",
      "Regression error on test: 0.327311\n",
      "0.37700167298316956\n",
      "Regression error on test: 0.070296\n",
      "Regression error on test: 0.063970\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027227\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079260\n",
      "done\n",
      "Regression error on test: 0.374148\n",
      "Regression error on test: 0.390166\n",
      "0.3741475045681\n",
      "Regression error on test: 0.068259\n",
      "Regression error on test: 0.040783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062561\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063570\n",
      "done\n",
      "Regression error on test: 0.365729\n",
      "Regression error on test: 0.386559\n",
      "0.36572885513305664\n",
      "Regression error on test: 0.068756\n",
      "Regression error on test: 0.062762\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032267\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063689\n",
      "done\n",
      "Regression error on test: 0.350445\n",
      "Regression error on test: 0.407995\n",
      "0.35044506192207336\n",
      "Regression error on test: 0.068803\n",
      "Regression error on test: 0.047133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048542\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073303\n",
      "done\n",
      "Regression error on test: 0.328281\n",
      "Regression error on test: 0.385522\n",
      "0.32828134298324585\n",
      "Regression error on test: 0.066642\n",
      "Regression error on test: 0.111214\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041977\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068917\n",
      "done\n",
      "Regression error on test: 0.314229\n",
      "Regression error on test: 0.434026\n",
      "0.31422916054725647\n",
      "Regression error on test: 0.058989\n",
      "Regression error on test: 0.079619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.099042\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073593\n",
      "done\n",
      "Regression error on test: 0.290493\n",
      "Regression error on test: 0.414540\n",
      "0.2904933989048004\n",
      "Regression error on test: 0.057036\n",
      "Regression error on test: 0.099811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065628\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083580\n",
      "done\n",
      "Regression error on test: 0.272946\n",
      "Regression error on test: 0.448642\n",
      "0.27294573187828064\n",
      "Regression error on test: 0.060403\n",
      "Regression error on test: 0.062137\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.084788\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096718\n",
      "done\n",
      "Regression error on test: 0.245828\n",
      "Regression error on test: 0.339258\n",
      "0.24582824110984802\n",
      "Regression error on test: 0.059411\n",
      "Regression error on test: 0.103280\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061997\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055379\n",
      "done\n",
      "Regression error on test: 0.228155\n",
      "Regression error on test: 0.235996\n",
      "0.22815541923046112\n",
      "Regression error on test: 0.053799\n",
      "Regression error on test: 0.032249\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.092526\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037990\n",
      "done\n",
      "Regression error on test: 0.220271\n",
      "Regression error on test: 0.298770\n",
      "0.22027131915092468\n",
      "Regression error on test: 0.055079\n",
      "Regression error on test: 0.043600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025641\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041699\n",
      "done\n",
      "Regression error on test: 0.206626\n",
      "Regression error on test: 0.305979\n",
      "0.2066257745027542\n",
      "Regression error on test: 0.055720\n",
      "Regression error on test: 0.045751\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043353\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062994\n",
      "done\n",
      "Regression error on test: 0.191440\n",
      "Regression error on test: 0.233722\n",
      "0.19144028425216675\n",
      "Regression error on test: 0.057435\n",
      "Regression error on test: 0.063239\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043916\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046342\n",
      "done\n",
      "Regression error on test: 0.187230\n",
      "Regression error on test: 0.186358\n",
      "0.18722981214523315\n",
      "Regression error on test: 0.057448\n",
      "Regression error on test: 0.025517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052098\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032603\n",
      "done\n",
      "Regression error on test: 0.184849\n",
      "Regression error on test: 0.245000\n",
      "0.1848488450050354\n",
      "Regression error on test: 0.060472\n",
      "Regression error on test: 0.034682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025356\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057910\n",
      "done\n",
      "Regression error on test: 0.176822\n",
      "Regression error on test: 0.196668\n",
      "0.1768217384815216\n",
      "Regression error on test: 0.061501\n",
      "Regression error on test: 0.060097\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026792\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036481\n",
      "done\n",
      "Regression error on test: 0.173460\n",
      "Regression error on test: 0.239064\n",
      "0.1734597235918045\n",
      "Regression error on test: 0.062084\n",
      "Regression error on test: 0.133477\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059157\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055270\n",
      "done\n",
      "Regression error on test: 0.173670\n",
      "Regression error on test: 0.177467\n",
      "0.17366991937160492\n",
      "Regression error on test: 0.059289\n",
      "Regression error on test: 0.052222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.121750\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028533\n",
      "done\n",
      "Regression error on test: 0.168952\n",
      "Regression error on test: 0.162530\n",
      "0.168951615691185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.057997\n",
      "Regression error on test: 0.057566\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058244\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044980\n",
      "done\n",
      "Regression error on test: 0.216129\n",
      "Regression error on test: 0.165961\n",
      "0.21612942218780518\n",
      "Regression error on test: 0.073794\n",
      "Regression error on test: 0.059231\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046751\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058128\n",
      "done\n",
      "Regression error on test: 0.254908\n",
      "Regression error on test: 0.158954\n",
      "0.2549077868461609\n",
      "Regression error on test: 0.071745\n",
      "Regression error on test: 0.057058\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048492\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059070\n",
      "done\n",
      "Regression error on test: 0.270274\n",
      "Regression error on test: 0.161945\n",
      "0.2702735364437103\n",
      "Regression error on test: 0.082382\n",
      "Regression error on test: 0.054173\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046962\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077616\n",
      "done\n",
      "Regression error on test: 0.305084\n",
      "Regression error on test: 0.160258\n",
      "0.3050840198993683\n",
      "Regression error on test: 0.097677\n",
      "Regression error on test: 0.047381\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043482\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101351\n",
      "done\n",
      "Regression error on test: 0.344543\n",
      "Regression error on test: 0.163280\n",
      "0.34454345703125\n",
      "Regression error on test: 0.099663\n",
      "Regression error on test: 0.048677\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036744\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104920\n",
      "done\n",
      "Regression error on test: 0.355526\n",
      "Regression error on test: 0.162178\n",
      "0.35552555322647095\n",
      "Regression error on test: 0.112753\n",
      "Regression error on test: 0.051180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037997\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.116824\n",
      "done\n",
      "Regression error on test: 0.355586\n",
      "Regression error on test: 0.162218\n",
      "0.3555864691734314\n",
      "Regression error on test: 0.123142\n",
      "Regression error on test: 0.047216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040494\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127790\n",
      "done\n",
      "Regression error on test: 0.353504\n",
      "Regression error on test: 0.263413\n",
      "0.35350385308265686\n",
      "Regression error on test: 0.135291\n",
      "Regression error on test: 0.033591\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045392\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.134422\n",
      "done\n",
      "Regression error on test: 0.342894\n",
      "Regression error on test: 0.298133\n",
      "0.3428936302661896\n",
      "Regression error on test: 0.151426\n",
      "Regression error on test: 0.123897\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029492\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.149329\n",
      "done\n",
      "Regression error on test: 0.330533\n",
      "Regression error on test: 0.464954\n",
      "0.33053284883499146\n",
      "Regression error on test: 0.159658\n",
      "Regression error on test: 0.215538\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109921\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.178245\n",
      "done\n",
      "Regression error on test: 0.298201\n",
      "Regression error on test: 0.553744\n",
      "0.2982012629508972\n",
      "Regression error on test: 0.155887\n",
      "Regression error on test: 0.038740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.201052\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.186644\n",
      "done\n",
      "Regression error on test: 0.260420\n",
      "Regression error on test: 0.312611\n",
      "0.2604202926158905\n",
      "Regression error on test: 0.161906\n",
      "Regression error on test: 0.163422\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034191\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.146712\n",
      "done\n",
      "Regression error on test: 0.251510\n",
      "Regression error on test: 0.510050\n",
      "0.2515101730823517\n",
      "Regression error on test: 0.153620\n",
      "Regression error on test: 0.207127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.148132\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.198324\n",
      "done\n",
      "Regression error on test: 0.227162\n",
      "Regression error on test: 0.554852\n",
      "0.22716204822063446\n",
      "Regression error on test: 0.135698\n",
      "Regression error on test: 0.067245\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.190486\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.196017\n",
      "done\n",
      "Regression error on test: 0.203941\n",
      "Regression error on test: 0.273101\n",
      "0.2039414346218109\n",
      "Regression error on test: 0.149311\n",
      "Regression error on test: 0.179569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059614\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109028\n",
      "done\n",
      "Regression error on test: 0.201581\n",
      "Regression error on test: 0.162787\n",
      "0.20158079266548157\n",
      "Regression error on test: 0.134318\n",
      "Regression error on test: 0.155073\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160953\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.084275\n",
      "done\n",
      "Regression error on test: 0.210833\n",
      "Regression error on test: 0.141392\n",
      "0.21083325147628784\n",
      "Regression error on test: 0.125349\n",
      "Regression error on test: 0.168702\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.138883\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082694\n",
      "done\n",
      "Regression error on test: 0.231026\n",
      "Regression error on test: 0.157312\n",
      "0.23102593421936035\n",
      "Regression error on test: 0.117055\n",
      "Regression error on test: 0.194945\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.151670\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085070\n",
      "done\n",
      "Regression error on test: 0.261571\n",
      "Regression error on test: 0.174525\n",
      "0.2615712881088257\n",
      "Regression error on test: 0.116121\n",
      "Regression error on test: 0.206218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.175901\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096193\n",
      "done\n",
      "Regression error on test: 0.301176\n",
      "Regression error on test: 0.141638\n",
      "0.30117589235305786\n",
      "Regression error on test: 0.107900\n",
      "Regression error on test: 0.177830\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.188488\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100972\n",
      "done\n",
      "Regression error on test: 0.337312\n",
      "Regression error on test: 0.175934\n",
      "0.3373115062713623\n",
      "Regression error on test: 0.117214\n",
      "Regression error on test: 0.098930\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160069\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.123469\n",
      "done\n",
      "Regression error on test: 0.387430\n",
      "Regression error on test: 0.223510\n",
      "0.3874301314353943\n",
      "Regression error on test: 0.137951\n",
      "Regression error on test: 0.080555\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.082882\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.155414\n",
      "done\n",
      "Regression error on test: 0.436770\n",
      "Regression error on test: 0.266569\n",
      "0.43676960468292236\n",
      "Regression error on test: 0.138017\n",
      "Regression error on test: 0.027908\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063971\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.167579\n",
      "done\n",
      "Regression error on test: 0.454916\n",
      "Regression error on test: 0.322645\n",
      "0.4549157917499542\n",
      "Regression error on test: 0.153624\n",
      "Regression error on test: 0.203377\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022711\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.161533\n",
      "done\n",
      "Regression error on test: 0.446340\n",
      "Regression error on test: 0.249495\n",
      "0.446340411901474\n",
      "Regression error on test: 0.145058\n",
      "Regression error on test: 0.029640\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.181282\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.167154\n",
      "done\n",
      "Regression error on test: 0.449763\n",
      "Regression error on test: 0.255312\n",
      "0.4497632682323456\n",
      "Regression error on test: 0.153258\n",
      "Regression error on test: 0.065388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026959\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.156805\n",
      "done\n",
      "Regression error on test: 0.453222\n",
      "Regression error on test: 0.343319\n",
      "0.45322248339653015\n",
      "Regression error on test: 0.157865\n",
      "Regression error on test: 0.085754\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062831\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.161268\n",
      "done\n",
      "Regression error on test: 0.446306\n",
      "Regression error on test: 0.462765\n",
      "0.4463064670562744\n",
      "Regression error on test: 0.158946\n",
      "Regression error on test: 0.185604\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076884\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.162547\n",
      "done\n",
      "Regression error on test: 0.429696\n",
      "Regression error on test: 0.570571\n",
      "0.42969605326652527\n",
      "Regression error on test: 0.155166\n",
      "Regression error on test: 0.124012\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169291\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.173398\n",
      "done\n",
      "Regression error on test: 0.388589\n",
      "Regression error on test: 0.502994\n",
      "0.3885892629623413\n",
      "Regression error on test: 0.159176\n",
      "Regression error on test: 0.270967\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107907\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189254\n",
      "done\n",
      "Regression error on test: 0.358044\n",
      "Regression error on test: 0.677121\n",
      "0.3580436408519745\n",
      "Regression error on test: 0.143990\n",
      "Regression error on test: 0.306304\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.252829\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189358\n",
      "done\n",
      "Regression error on test: 0.314204\n",
      "Regression error on test: 0.716904\n",
      "0.3142043650150299\n",
      "Regression error on test: 0.132494\n",
      "Regression error on test: 0.081218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.287625\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.192077\n",
      "done\n",
      "Regression error on test: 0.260108\n",
      "Regression error on test: 0.448032\n",
      "0.2601081132888794\n",
      "Regression error on test: 0.144000\n",
      "Regression error on test: 0.183971\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077995\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.171963\n",
      "done\n",
      "Regression error on test: 0.231583\n",
      "Regression error on test: 0.236892\n",
      "0.23158305883407593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.146084\n",
      "Regression error on test: 0.117721\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161846\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073045\n",
      "done\n",
      "Regression error on test: 0.224565\n",
      "Regression error on test: 0.283723\n",
      "0.2245648056268692\n",
      "Regression error on test: 0.156430\n",
      "Regression error on test: 0.111636\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.096858\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085897\n",
      "done\n",
      "Regression error on test: 0.213813\n",
      "Regression error on test: 0.289904\n",
      "0.21381281316280365\n",
      "Regression error on test: 0.164548\n",
      "Regression error on test: 0.111461\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091097\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094433\n",
      "done\n",
      "Regression error on test: 0.202130\n",
      "Regression error on test: 0.274158\n",
      "0.2021297663450241\n",
      "Regression error on test: 0.168545\n",
      "Regression error on test: 0.096564\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091856\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100633\n",
      "done\n",
      "Regression error on test: 0.195746\n",
      "Regression error on test: 0.296661\n",
      "0.1957460641860962\n",
      "Regression error on test: 0.175893\n",
      "Regression error on test: 0.147802\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077721\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.112952\n",
      "done\n",
      "Regression error on test: 0.186836\n",
      "Regression error on test: 0.159503\n",
      "0.18683631718158722\n",
      "Regression error on test: 0.178832\n",
      "Regression error on test: 0.164113\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130871\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114164\n",
      "done\n",
      "Regression error on test: 0.189518\n",
      "Regression error on test: 0.197538\n",
      "0.18951837718486786\n",
      "Regression error on test: 0.175644\n",
      "Regression error on test: 0.119106\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.144433\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.105781\n",
      "done\n",
      "Regression error on test: 0.193231\n",
      "Regression error on test: 0.238728\n",
      "0.19323137402534485\n",
      "Regression error on test: 0.182646\n",
      "Regression error on test: 0.191342\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.103690\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118783\n",
      "done\n",
      "Regression error on test: 0.190529\n",
      "Regression error on test: 0.175942\n",
      "0.19052943587303162\n",
      "Regression error on test: 0.181285\n",
      "Regression error on test: 0.196284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.171362\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109670\n",
      "done\n",
      "Regression error on test: 0.196141\n",
      "Regression error on test: 0.162781\n",
      "0.19614122807979584\n",
      "Regression error on test: 0.175006\n",
      "Regression error on test: 0.204814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177062\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.107049\n",
      "done\n",
      "Regression error on test: 0.206939\n",
      "Regression error on test: 0.166709\n",
      "0.20693938434123993\n",
      "Regression error on test: 0.167447\n",
      "Regression error on test: 0.221176\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.185029\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.111009\n",
      "done\n",
      "Regression error on test: 0.233683\n",
      "Regression error on test: 0.176204\n",
      "0.23368339240550995\n",
      "Regression error on test: 0.148788\n",
      "Regression error on test: 0.192814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.200361\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.103248\n",
      "done\n",
      "Regression error on test: 0.251618\n",
      "Regression error on test: 0.173074\n",
      "0.25161781907081604\n",
      "Regression error on test: 0.133013\n",
      "Regression error on test: 0.151440\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.173889\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102236\n",
      "done\n",
      "Regression error on test: 0.270645\n",
      "Regression error on test: 0.210321\n",
      "0.2706454396247864\n",
      "Regression error on test: 0.122893\n",
      "Regression error on test: 0.170039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132814\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104852\n",
      "done\n",
      "Regression error on test: 0.288149\n",
      "Regression error on test: 0.207563\n",
      "0.2881491482257843\n",
      "Regression error on test: 0.111307\n",
      "Regression error on test: 0.177196\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.154619\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097403\n",
      "done\n",
      "Regression error on test: 0.295909\n",
      "Regression error on test: 0.186323\n",
      "0.29590868949890137\n",
      "Regression error on test: 0.099754\n",
      "Regression error on test: 0.132225\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159055\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096053\n",
      "done\n",
      "Regression error on test: 0.312279\n",
      "Regression error on test: 0.234668\n",
      "0.31227928400039673\n",
      "Regression error on test: 0.090488\n",
      "Regression error on test: 0.189127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.114065\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097978\n",
      "done\n",
      "Regression error on test: 0.323445\n",
      "Regression error on test: 0.211709\n",
      "0.32344505190849304\n",
      "Regression error on test: 0.079390\n",
      "Regression error on test: 0.177733\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169787\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.099538\n",
      "done\n",
      "Regression error on test: 0.341050\n",
      "Regression error on test: 0.232059\n",
      "0.3410504460334778\n",
      "Regression error on test: 0.069359\n",
      "Regression error on test: 0.133500\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158091\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102334\n",
      "done\n",
      "Regression error on test: 0.352893\n",
      "Regression error on test: 0.270763\n",
      "0.3528931736946106\n",
      "Regression error on test: 0.060285\n",
      "Regression error on test: 0.129222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.119999\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.095777\n",
      "done\n",
      "Regression error on test: 0.357090\n",
      "Regression error on test: 0.434149\n",
      "0.35708969831466675\n",
      "Regression error on test: 0.052655\n",
      "Regression error on test: 0.034584\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.116659\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039411\n",
      "done\n",
      "Regression error on test: 0.345406\n",
      "Regression error on test: 0.355548\n",
      "0.3454063832759857\n",
      "Regression error on test: 0.055666\n",
      "Regression error on test: 0.035065\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031706\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047993\n",
      "done\n",
      "Regression error on test: 0.341046\n",
      "Regression error on test: 0.363350\n",
      "0.3410455286502838\n",
      "Regression error on test: 0.060072\n",
      "Regression error on test: 0.050242\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028085\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046314\n",
      "done\n",
      "Regression error on test: 0.337358\n",
      "Regression error on test: 0.385359\n",
      "0.33735790848731995\n",
      "Regression error on test: 0.062548\n",
      "Regression error on test: 0.054178\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037639\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046413\n",
      "done\n",
      "Regression error on test: 0.329977\n",
      "Regression error on test: 0.285158\n",
      "0.32997745275497437\n",
      "Regression error on test: 0.063296\n",
      "Regression error on test: 0.061669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043993\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094030\n",
      "done\n",
      "Regression error on test: 0.331519\n",
      "Regression error on test: 0.350030\n",
      "0.3315185010433197\n",
      "Regression error on test: 0.064783\n",
      "Regression error on test: 0.039561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057740\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044297\n",
      "done\n",
      "Regression error on test: 0.327391\n",
      "Regression error on test: 0.346326\n",
      "0.3273911774158478\n",
      "Regression error on test: 0.068522\n",
      "Regression error on test: 0.078151\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035810\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051807\n",
      "done\n",
      "Regression error on test: 0.323734\n",
      "Regression error on test: 0.387763\n",
      "0.32373401522636414\n",
      "Regression error on test: 0.068630\n",
      "Regression error on test: 0.077424\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070252\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041282\n",
      "done\n",
      "Regression error on test: 0.316336\n",
      "Regression error on test: 0.350486\n",
      "0.3163362145423889\n",
      "Regression error on test: 0.070834\n",
      "Regression error on test: 0.042758\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067748\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044188\n",
      "done\n",
      "Regression error on test: 0.313635\n",
      "Regression error on test: 0.312728\n",
      "0.3136351704597473\n",
      "Regression error on test: 0.073850\n",
      "Regression error on test: 0.052918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034027\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049225\n",
      "done\n",
      "Regression error on test: 0.312144\n",
      "Regression error on test: 0.317315\n",
      "0.31214433908462524\n",
      "Regression error on test: 0.075093\n",
      "Regression error on test: 0.064695\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.047519\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052756\n",
      "done\n",
      "Regression error on test: 0.310107\n",
      "Regression error on test: 0.311938\n",
      "0.3101068139076233\n",
      "Regression error on test: 0.077521\n",
      "Regression error on test: 0.079127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062902\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059215\n",
      "done\n",
      "Regression error on test: 0.307643\n",
      "Regression error on test: 0.326474\n",
      "0.3076429069042206\n",
      "Regression error on test: 0.079261\n",
      "Regression error on test: 0.075003\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069369\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046494\n",
      "done\n",
      "Regression error on test: 0.304451\n",
      "Regression error on test: 0.311555\n",
      "0.3044512867927551\n",
      "Regression error on test: 0.079136\n",
      "Regression error on test: 0.061660\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064945\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044376\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.301342\n",
      "Regression error on test: 0.300569\n",
      "0.30134153366088867\n",
      "Regression error on test: 0.080070\n",
      "Regression error on test: 0.076535\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052868\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050650\n",
      "done\n",
      "Regression error on test: 0.307600\n",
      "Regression error on test: 0.308756\n",
      "0.3075996935367584\n",
      "Regression error on test: 0.077504\n",
      "Regression error on test: 0.076955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065484\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042787\n",
      "done\n",
      "Regression error on test: 0.315123\n",
      "Regression error on test: 0.309754\n",
      "0.31512340903282166\n",
      "Regression error on test: 0.077705\n",
      "Regression error on test: 0.079229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065908\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047445\n",
      "done\n",
      "Regression error on test: 0.314961\n",
      "Regression error on test: 0.313785\n",
      "0.3149605095386505\n",
      "Regression error on test: 0.077502\n",
      "Regression error on test: 0.099462\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069845\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055856\n",
      "done\n",
      "Regression error on test: 0.309780\n",
      "Regression error on test: 0.323476\n",
      "0.3097796142101288\n",
      "Regression error on test: 0.071562\n",
      "Regression error on test: 0.072918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088567\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052844\n",
      "done\n",
      "Regression error on test: 0.312271\n",
      "Regression error on test: 0.297820\n",
      "0.31227076053619385\n",
      "Regression error on test: 0.068030\n",
      "Regression error on test: 0.065350\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062091\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052906\n",
      "done\n",
      "Regression error on test: 0.318478\n",
      "Regression error on test: 0.296940\n",
      "0.3184778690338135\n",
      "Regression error on test: 0.068847\n",
      "Regression error on test: 0.088975\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054148\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055746\n",
      "done\n",
      "Regression error on test: 0.326959\n",
      "Regression error on test: 0.287299\n",
      "0.3269594609737396\n",
      "Regression error on test: 0.064155\n",
      "Regression error on test: 0.096529\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078425\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056947\n",
      "done\n",
      "Regression error on test: 0.329997\n",
      "Regression error on test: 0.294558\n",
      "0.329996794462204\n",
      "Regression error on test: 0.059285\n",
      "Regression error on test: 0.073748\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085962\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054263\n",
      "done\n",
      "Regression error on test: 0.337613\n",
      "Regression error on test: 0.280458\n",
      "0.3376132547855377\n",
      "Regression error on test: 0.055278\n",
      "Regression error on test: 0.071000\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064744\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054716\n",
      "done\n",
      "Regression error on test: 0.339779\n",
      "Regression error on test: 0.363149\n",
      "0.33977919816970825\n",
      "Regression error on test: 0.053268\n",
      "Regression error on test: 0.050878\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066871\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052513\n",
      "done\n",
      "Regression error on test: 0.333962\n",
      "Regression error on test: 0.383994\n",
      "0.3339623212814331\n",
      "Regression error on test: 0.053194\n",
      "Regression error on test: 0.078958\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037938\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060686\n",
      "done\n",
      "Regression error on test: 0.320876\n",
      "Regression error on test: 0.308126\n",
      "0.3208759129047394\n",
      "Regression error on test: 0.048368\n",
      "Regression error on test: 0.077206\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079455\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048373\n",
      "done\n",
      "Regression error on test: 0.314376\n",
      "Regression error on test: 0.261976\n",
      "0.314375638961792\n",
      "Regression error on test: 0.048787\n",
      "Regression error on test: 0.040056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069439\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064264\n",
      "done\n",
      "Regression error on test: 0.318877\n",
      "Regression error on test: 0.348387\n",
      "0.31887656450271606\n",
      "Regression error on test: 0.050438\n",
      "Regression error on test: 0.037605\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039221\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046150\n",
      "done\n",
      "Regression error on test: 0.312372\n",
      "Regression error on test: 0.359891\n",
      "0.31237223744392395\n",
      "Regression error on test: 0.048699\n",
      "Regression error on test: 0.073517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034804\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044884\n",
      "done\n",
      "Regression error on test: 0.299888\n",
      "Regression error on test: 0.381756\n",
      "0.29988816380500793\n",
      "Regression error on test: 0.045367\n",
      "Regression error on test: 0.042051\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.071250\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043163\n",
      "done\n",
      "Regression error on test: 0.286350\n",
      "Regression error on test: 0.317673\n",
      "0.2863500416278839\n",
      "Regression error on test: 0.043471\n",
      "Regression error on test: 0.047826\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042838\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045008\n",
      "done\n",
      "Regression error on test: 0.279744\n",
      "Regression error on test: 0.370723\n",
      "0.27974408864974976\n",
      "Regression error on test: 0.043033\n",
      "Regression error on test: 0.033682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042762\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044418\n",
      "done\n",
      "Regression error on test: 0.265693\n",
      "Regression error on test: 0.302118\n",
      "0.2656926214694977\n",
      "Regression error on test: 0.044369\n",
      "Regression error on test: 0.050902\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032402\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048432\n",
      "done\n",
      "Regression error on test: 0.259182\n",
      "Regression error on test: 0.304980\n",
      "0.259181946516037\n",
      "Regression error on test: 0.043689\n",
      "Regression error on test: 0.050133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050286\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040351\n",
      "done\n",
      "Regression error on test: 0.251869\n",
      "Regression error on test: 0.253130\n",
      "0.25186887383461\n",
      "Regression error on test: 0.045896\n",
      "Regression error on test: 0.030703\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050362\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041939\n",
      "done\n",
      "Regression error on test: 0.252464\n",
      "Regression error on test: 0.243123\n",
      "0.25246402621269226\n",
      "Regression error on test: 0.046135\n",
      "Regression error on test: 0.081399\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022533\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037733\n",
      "done\n",
      "Regression error on test: 0.251519\n",
      "Regression error on test: 0.306985\n",
      "0.2515185475349426\n",
      "Regression error on test: 0.042942\n",
      "Regression error on test: 0.056561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.072876\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033978\n",
      "done\n",
      "Regression error on test: 0.244537\n",
      "Regression error on test: 0.283344\n",
      "0.24453668296337128\n",
      "Regression error on test: 0.041054\n",
      "Regression error on test: 0.020216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052100\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033174\n",
      "done\n",
      "Regression error on test: 0.252111\n",
      "Regression error on test: 0.235050\n",
      "0.2521113455295563\n",
      "Regression error on test: 0.044212\n",
      "Regression error on test: 0.040201\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.019209\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055107\n",
      "done\n",
      "Regression error on test: 0.266514\n",
      "Regression error on test: 0.246375\n",
      "0.26651427149772644\n",
      "Regression error on test: 0.046182\n",
      "Regression error on test: 0.023085\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040256\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047768\n",
      "done\n",
      "Regression error on test: 0.277301\n",
      "Regression error on test: 0.251613\n",
      "0.27730056643486023\n",
      "Regression error on test: 0.048412\n",
      "Regression error on test: 0.043449\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017914\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063570\n",
      "done\n",
      "Regression error on test: 0.281129\n",
      "Regression error on test: 0.230208\n",
      "0.28112930059432983\n",
      "Regression error on test: 0.048590\n",
      "Regression error on test: 0.047044\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043172\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042567\n",
      "done\n",
      "Regression error on test: 0.294545\n",
      "Regression error on test: 0.237011\n",
      "0.29454508423805237\n",
      "Regression error on test: 0.048329\n",
      "Regression error on test: 0.044101\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036346\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035044\n",
      "done\n",
      "Regression error on test: 0.298135\n",
      "Regression error on test: 0.231849\n",
      "0.29813525080680847\n",
      "Regression error on test: 0.045603\n",
      "Regression error on test: 0.072201\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034246\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038331\n",
      "done\n",
      "Regression error on test: 0.295648\n",
      "Regression error on test: 0.259081\n",
      "0.2956481873989105\n",
      "Regression error on test: 0.107702\n",
      "Regression error on test: 0.139534\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065795\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088885\n",
      "done\n",
      "Regression error on test: 0.150728\n",
      "Regression error on test: 0.039339\n",
      "0.15072837471961975\n",
      "Regression error on test: 0.098447\n",
      "Regression error on test: 0.137116\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.129368\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081506\n",
      "done\n",
      "Regression error on test: 0.181189\n",
      "Regression error on test: 0.042918\n",
      "0.18118897080421448\n",
      "Regression error on test: 0.110597\n",
      "Regression error on test: 0.117420\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.126938\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101370\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.229031\n",
      "Regression error on test: 0.070183\n",
      "0.22903060913085938\n",
      "Regression error on test: 0.117865\n",
      "Regression error on test: 0.118753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107160\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.116506\n",
      "done\n",
      "Regression error on test: 0.269985\n",
      "Regression error on test: 0.080901\n",
      "0.2699846029281616\n",
      "Regression error on test: 0.125451\n",
      "Regression error on test: 0.114937\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108321\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132008\n",
      "done\n",
      "Regression error on test: 0.301020\n",
      "Regression error on test: 0.084510\n",
      "0.30101990699768066\n",
      "Regression error on test: 0.116219\n",
      "Regression error on test: 0.108688\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.104469\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126925\n",
      "done\n",
      "Regression error on test: 0.318761\n",
      "Regression error on test: 0.090517\n",
      "0.3187609910964966\n",
      "Regression error on test: 0.109202\n",
      "Regression error on test: 0.078587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.098210\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126011\n",
      "done\n",
      "Regression error on test: 0.340227\n",
      "Regression error on test: 0.105296\n",
      "0.34022653102874756\n",
      "Regression error on test: 0.105053\n",
      "Regression error on test: 0.041248\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067987\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.125108\n",
      "done\n",
      "Regression error on test: 0.355546\n",
      "Regression error on test: 0.221746\n",
      "0.35554584860801697\n",
      "Regression error on test: 0.103646\n",
      "Regression error on test: 0.069937\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037129\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114787\n",
      "done\n",
      "Regression error on test: 0.358761\n",
      "Regression error on test: 0.298115\n",
      "0.35876092314720154\n",
      "Regression error on test: 0.100638\n",
      "Regression error on test: 0.150801\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069973\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101100\n",
      "done\n",
      "Regression error on test: 0.353341\n",
      "Regression error on test: 0.473758\n",
      "0.3533407747745514\n",
      "Regression error on test: 0.087309\n",
      "Regression error on test: 0.046985\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.137468\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092841\n",
      "done\n",
      "Regression error on test: 0.333873\n",
      "Regression error on test: 0.343945\n",
      "0.33387330174446106\n",
      "Regression error on test: 0.085655\n",
      "Regression error on test: 0.258611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042160\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088076\n",
      "done\n",
      "Regression error on test: 0.326099\n",
      "Regression error on test: 0.521334\n",
      "0.3260987102985382\n",
      "Regression error on test: 0.063612\n",
      "Regression error on test: 0.190105\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.247382\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081102\n",
      "done\n",
      "Regression error on test: 0.299056\n",
      "Regression error on test: 0.479723\n",
      "0.29905590415000916\n",
      "Regression error on test: 0.049122\n",
      "Regression error on test: 0.194607\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177879\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076916\n",
      "done\n",
      "Regression error on test: 0.274144\n",
      "Regression error on test: 0.391254\n",
      "0.2741442322731018\n",
      "Regression error on test: 0.035010\n",
      "Regression error on test: 0.022619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.183967\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065157\n",
      "done\n",
      "Regression error on test: 0.259741\n",
      "Regression error on test: 0.261921\n",
      "0.2597413957118988\n",
      "Regression error on test: 0.047071\n",
      "Regression error on test: 0.038521\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.020309\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038947\n",
      "done\n",
      "Regression error on test: 0.251055\n",
      "Regression error on test: 0.305172\n",
      "0.2510550916194916\n",
      "Regression error on test: 0.047282\n",
      "Regression error on test: 0.037099\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037575\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054444\n",
      "done\n",
      "Regression error on test: 0.259291\n",
      "Regression error on test: 0.258489\n",
      "0.25929075479507446\n",
      "Regression error on test: 0.058139\n",
      "Regression error on test: 0.027171\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031668\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053434\n",
      "done\n",
      "Regression error on test: 0.282061\n",
      "Regression error on test: 0.253897\n",
      "0.28206056356430054\n",
      "Regression error on test: 0.062502\n",
      "Regression error on test: 0.039856\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022632\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061206\n",
      "done\n",
      "Regression error on test: 0.297593\n",
      "Regression error on test: 0.243914\n",
      "0.29759272933006287\n",
      "Regression error on test: 0.076839\n",
      "Regression error on test: 0.017514\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036871\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079058\n",
      "done\n",
      "Regression error on test: 0.326751\n",
      "Regression error on test: 0.279083\n",
      "0.326750785112381\n",
      "Regression error on test: 0.092650\n",
      "Regression error on test: 0.030450\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017510\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092238\n",
      "done\n",
      "Regression error on test: 0.351109\n",
      "Regression error on test: 0.266199\n",
      "0.35110944509506226\n",
      "Regression error on test: 0.101631\n",
      "Regression error on test: 0.038180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027088\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.107469\n",
      "done\n",
      "Regression error on test: 0.364865\n",
      "Regression error on test: 0.250906\n",
      "0.36486464738845825\n",
      "Regression error on test: 0.101583\n",
      "Regression error on test: 0.045204\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029634\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118808\n",
      "done\n",
      "Regression error on test: 0.373377\n",
      "Regression error on test: 0.230607\n",
      "0.3733765482902527\n",
      "Regression error on test: 0.098531\n",
      "Regression error on test: 0.053482\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035556\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118776\n",
      "done\n",
      "Regression error on test: 0.380809\n",
      "Regression error on test: 0.247226\n",
      "0.38080939650535583\n",
      "Regression error on test: 0.095360\n",
      "Regression error on test: 0.143228\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053430\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096761\n",
      "done\n",
      "Regression error on test: 0.383308\n",
      "Regression error on test: 0.175058\n",
      "0.38330838084220886\n",
      "Regression error on test: 0.085635\n",
      "Regression error on test: 0.040639\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130196\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.122985\n",
      "done\n",
      "Regression error on test: 0.386189\n",
      "Regression error on test: 0.387529\n",
      "0.38618937134742737\n",
      "Regression error on test: 0.085331\n",
      "Regression error on test: 0.145662\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036928\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076722\n",
      "done\n",
      "Regression error on test: 0.365312\n",
      "Regression error on test: 0.486187\n",
      "0.36531195044517517\n",
      "Regression error on test: 0.073332\n",
      "Regression error on test: 0.070801\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132187\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068897\n",
      "done\n",
      "Regression error on test: 0.334898\n",
      "Regression error on test: 0.409219\n",
      "0.3348984122276306\n",
      "Regression error on test: 0.075009\n",
      "Regression error on test: 0.183229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057462\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079796\n",
      "done\n",
      "Regression error on test: 0.309346\n",
      "Regression error on test: 0.535495\n",
      "0.309345543384552\n",
      "Regression error on test: 0.061343\n",
      "Regression error on test: 0.175627\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.168949\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075882\n",
      "done\n",
      "Regression error on test: 0.272681\n",
      "Regression error on test: 0.522670\n",
      "0.27268120646476746\n",
      "Regression error on test: 0.050995\n",
      "Regression error on test: 0.120262\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161502\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075045\n",
      "done\n",
      "Regression error on test: 0.236238\n",
      "Regression error on test: 0.403751\n",
      "0.2362384796142578\n",
      "Regression error on test: 0.046384\n",
      "Regression error on test: 0.037693\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108337\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077359\n",
      "done\n",
      "Regression error on test: 0.210513\n",
      "Regression error on test: 0.336025\n",
      "0.21051330864429474\n",
      "Regression error on test: 0.049061\n",
      "Regression error on test: 0.014685\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029413\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073636\n",
      "done\n",
      "Regression error on test: 0.194982\n",
      "Regression error on test: 0.304935\n",
      "0.19498209655284882\n",
      "Regression error on test: 0.055631\n",
      "Regression error on test: 0.021774\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.013794\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065878\n",
      "done\n",
      "Regression error on test: 0.181006\n",
      "Regression error on test: 0.272216\n",
      "0.18100640177726746\n",
      "Regression error on test: 0.064370\n",
      "Regression error on test: 0.045976\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.016799\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046013\n",
      "done\n",
      "Regression error on test: 0.171424\n",
      "Regression error on test: 0.203868\n",
      "0.17142435908317566\n",
      "Regression error on test: 0.067106\n",
      "Regression error on test: 0.037598\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043318\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049520\n",
      "done\n",
      "Regression error on test: 0.167077\n",
      "Regression error on test: 0.178755\n",
      "0.16707675158977509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.072278\n",
      "Regression error on test: 0.025673\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030018\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048614\n",
      "done\n",
      "Regression error on test: 0.166541\n",
      "Regression error on test: 0.182052\n",
      "0.16654106974601746\n",
      "Regression error on test: 0.074156\n",
      "Regression error on test: 0.087569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022876\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054772\n",
      "done\n",
      "Regression error on test: 0.177487\n",
      "Regression error on test: 0.153690\n",
      "0.1774866282939911\n",
      "Regression error on test: 0.070530\n",
      "Regression error on test: 0.046570\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076533\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036155\n",
      "done\n",
      "Regression error on test: 0.189271\n",
      "Regression error on test: 0.168851\n",
      "0.18927137553691864\n",
      "Regression error on test: 0.069459\n",
      "Regression error on test: 0.072148\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036584\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037101\n",
      "done\n",
      "Regression error on test: 0.199294\n",
      "Regression error on test: 0.158242\n",
      "0.19929401576519012\n",
      "Regression error on test: 0.069770\n",
      "Regression error on test: 0.074150\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061360\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036015\n",
      "done\n",
      "Regression error on test: 0.208236\n",
      "Regression error on test: 0.146499\n",
      "0.20823587477207184\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.064470\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063461\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035976\n",
      "done\n",
      "Regression error on test: 0.216380\n",
      "Regression error on test: 0.180713\n",
      "0.21637962758541107\n",
      "Regression error on test: 0.068701\n",
      "Regression error on test: 0.080382\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057172\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039259\n",
      "done\n",
      "Regression error on test: 0.221287\n",
      "Regression error on test: 0.165177\n",
      "0.22128741443157196\n",
      "Regression error on test: 0.065381\n",
      "Regression error on test: 0.109164\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069312\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038292\n",
      "done\n",
      "Regression error on test: 0.233844\n",
      "Regression error on test: 0.176396\n",
      "0.23384395241737366\n",
      "Regression error on test: 0.059033\n",
      "Regression error on test: 0.073335\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097085\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032827\n",
      "done\n",
      "Regression error on test: 0.235233\n",
      "Regression error on test: 0.160392\n",
      "0.23523324728012085\n",
      "Regression error on test: 0.057307\n",
      "Regression error on test: 0.089314\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062410\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032468\n",
      "done\n",
      "Regression error on test: 0.238371\n",
      "Regression error on test: 0.173398\n",
      "0.23837050795555115\n",
      "Regression error on test: 0.051771\n",
      "Regression error on test: 0.044454\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078034\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028945\n",
      "done\n",
      "Regression error on test: 0.241276\n",
      "Regression error on test: 0.291507\n",
      "0.24127620458602905\n",
      "Regression error on test: 0.051454\n",
      "Regression error on test: 0.051316\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040950\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036498\n",
      "done\n",
      "Regression error on test: 0.232186\n",
      "Regression error on test: 0.271538\n",
      "0.23218566179275513\n",
      "Regression error on test: 0.049474\n",
      "Regression error on test: 0.035855\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038488\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.026380\n",
      "done\n",
      "Regression error on test: 0.225921\n",
      "Regression error on test: 0.269078\n",
      "0.2259206771850586\n",
      "Regression error on test: 0.050506\n",
      "Regression error on test: 0.075265\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027331\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034887\n",
      "done\n",
      "Regression error on test: 0.220163\n",
      "Regression error on test: 0.247661\n",
      "0.22016291320323944\n",
      "Regression error on test: 0.047875\n",
      "Regression error on test: 0.070642\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061528\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.025275\n",
      "done\n",
      "Regression error on test: 0.214841\n",
      "Regression error on test: 0.227937\n",
      "0.2148410528898239\n",
      "Regression error on test: 0.044485\n",
      "Regression error on test: 0.057288\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058014\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023760\n",
      "done\n",
      "Regression error on test: 0.213018\n",
      "Regression error on test: 0.229791\n",
      "0.21301794052124023\n",
      "Regression error on test: 0.043193\n",
      "Regression error on test: 0.047174\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046334\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.022667\n",
      "done\n",
      "Regression error on test: 0.211541\n",
      "Regression error on test: 0.290743\n",
      "0.21154071390628815\n",
      "Regression error on test: 0.045711\n",
      "Regression error on test: 0.045683\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042713\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.069119\n",
      "done\n",
      "Regression error on test: 0.201323\n",
      "Regression error on test: 0.190288\n",
      "0.2013225555419922\n",
      "Regression error on test: 0.050832\n",
      "Regression error on test: 0.056078\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036676\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.024276\n",
      "done\n",
      "Regression error on test: 0.200882\n",
      "Regression error on test: 0.191765\n",
      "0.2008817493915558\n",
      "Regression error on test: 0.058903\n",
      "Regression error on test: 0.033952\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045030\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.029052\n",
      "done\n",
      "Regression error on test: 0.196906\n",
      "Regression error on test: 0.202454\n",
      "0.19690635800361633\n",
      "Regression error on test: 0.066825\n",
      "Regression error on test: 0.041284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025366\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037175\n",
      "done\n",
      "Regression error on test: 0.192878\n",
      "Regression error on test: 0.200602\n",
      "0.19287800788879395\n",
      "Regression error on test: 0.068962\n",
      "Regression error on test: 0.031517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030643\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040689\n",
      "done\n",
      "Regression error on test: 0.195240\n",
      "Regression error on test: 0.208888\n",
      "0.19524012506008148\n",
      "Regression error on test: 0.070459\n",
      "Regression error on test: 0.046177\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023684\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050128\n",
      "done\n",
      "Regression error on test: 0.200457\n",
      "Regression error on test: 0.211501\n",
      "0.20045745372772217\n",
      "Regression error on test: 0.073136\n",
      "Regression error on test: 0.048955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038032\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048813\n",
      "done\n",
      "Regression error on test: 0.204080\n",
      "Regression error on test: 0.194442\n",
      "0.20407989621162415\n",
      "Regression error on test: 0.072086\n",
      "Regression error on test: 0.036740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038216\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044455\n",
      "done\n",
      "Regression error on test: 0.211465\n",
      "Regression error on test: 0.209705\n",
      "0.21146544814109802\n",
      "Regression error on test: 0.070692\n",
      "Regression error on test: 0.044373\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026027\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047489\n",
      "done\n",
      "Regression error on test: 0.220132\n",
      "Regression error on test: 0.215019\n",
      "0.22013191878795624\n",
      "Regression error on test: 0.067967\n",
      "Regression error on test: 0.072355\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032947\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048151\n",
      "done\n",
      "Regression error on test: 0.229265\n",
      "Regression error on test: 0.188561\n",
      "0.229265034198761\n",
      "Regression error on test: 0.065854\n",
      "Regression error on test: 0.096889\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060957\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046896\n",
      "done\n",
      "Regression error on test: 0.236927\n",
      "Regression error on test: 0.185880\n",
      "0.23692737519741058\n",
      "Regression error on test: 0.061476\n",
      "Regression error on test: 0.136783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085036\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043126\n",
      "done\n",
      "Regression error on test: 0.245079\n",
      "Regression error on test: 0.152011\n",
      "0.2450791448354721\n",
      "Regression error on test: 0.053248\n",
      "Regression error on test: 0.113175\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125110\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040383\n",
      "done\n",
      "Regression error on test: 0.258688\n",
      "Regression error on test: 0.162171\n",
      "0.2586883306503296\n",
      "Regression error on test: 0.045083\n",
      "Regression error on test: 0.062657\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.101658\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036312\n",
      "done\n",
      "Regression error on test: 0.271844\n",
      "Regression error on test: 0.224223\n",
      "0.2718440592288971\n",
      "Regression error on test: 0.044747\n",
      "Regression error on test: 0.046488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061534\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040701\n",
      "done\n",
      "Regression error on test: 0.287161\n",
      "Regression error on test: 0.261062\n",
      "0.2871612012386322\n",
      "Regression error on test: 0.042894\n",
      "Regression error on test: 0.072942\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045609\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040176\n",
      "done\n",
      "Regression error on test: 0.293182\n",
      "Regression error on test: 0.247725\n",
      "0.29318225383758545\n",
      "Regression error on test: 0.038665\n",
      "Regression error on test: 0.038453\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059590\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045962\n",
      "done\n",
      "Regression error on test: 0.297030\n",
      "Regression error on test: 0.268298\n",
      "0.2970304489135742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.042092\n",
      "Regression error on test: 0.022804\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034165\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040333\n",
      "done\n",
      "Regression error on test: 0.288786\n",
      "Regression error on test: 0.296370\n",
      "0.2887858748435974\n",
      "Regression error on test: 0.047586\n",
      "Regression error on test: 0.017127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022093\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045488\n",
      "done\n",
      "Regression error on test: 0.275285\n",
      "Regression error on test: 0.306350\n",
      "0.2752852439880371\n",
      "Regression error on test: 0.054457\n",
      "Regression error on test: 0.051220\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017225\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054264\n",
      "done\n",
      "Regression error on test: 0.260024\n",
      "Regression error on test: 0.265184\n",
      "0.260023832321167\n",
      "Regression error on test: 0.056978\n",
      "Regression error on test: 0.053108\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040249\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047742\n",
      "done\n",
      "Regression error on test: 0.248906\n",
      "Regression error on test: 0.267398\n",
      "0.24890591204166412\n",
      "Regression error on test: 0.058456\n",
      "Regression error on test: 0.054505\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041343\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049053\n",
      "done\n",
      "Regression error on test: 0.237896\n",
      "Regression error on test: 0.288103\n",
      "0.23789642751216888\n",
      "Regression error on test: 0.059196\n",
      "Regression error on test: 0.031521\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054393\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065152\n",
      "done\n",
      "Regression error on test: 0.224656\n",
      "Regression error on test: 0.293729\n",
      "0.22465598583221436\n",
      "Regression error on test: 0.060223\n",
      "Regression error on test: 0.059307\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029118\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052471\n",
      "done\n",
      "Regression error on test: 0.213578\n",
      "Regression error on test: 0.377394\n",
      "0.21357819437980652\n",
      "Regression error on test: 0.062761\n",
      "Regression error on test: 0.027955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051983\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.089953\n",
      "done\n",
      "Regression error on test: 0.190290\n",
      "Regression error on test: 0.321272\n",
      "0.1902899146080017\n",
      "Regression error on test: 0.065029\n",
      "Regression error on test: 0.030653\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025800\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076005\n",
      "done\n",
      "Regression error on test: 0.176353\n",
      "Regression error on test: 0.286206\n",
      "0.17635250091552734\n",
      "Regression error on test: 0.067043\n",
      "Regression error on test: 0.072724\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031433\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065433\n",
      "done\n",
      "Regression error on test: 0.164795\n",
      "Regression error on test: 0.185853\n",
      "0.16479504108428955\n",
      "Regression error on test: 0.066627\n",
      "Regression error on test: 0.077738\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060916\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027913\n",
      "done\n",
      "Regression error on test: 0.161276\n",
      "Regression error on test: 0.161363\n",
      "0.16127587854862213\n",
      "Regression error on test: 0.065062\n",
      "Regression error on test: 0.085843\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066513\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027314\n",
      "done\n",
      "Regression error on test: 0.160141\n",
      "Regression error on test: 0.153736\n",
      "0.16014081239700317\n",
      "Regression error on test: 0.062124\n",
      "Regression error on test: 0.076426\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.074136\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.024106\n",
      "done\n",
      "Regression error on test: 0.160747\n",
      "Regression error on test: 0.154005\n",
      "0.1607470065355301\n",
      "Regression error on test: 0.059821\n",
      "Regression error on test: 0.067885\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065324\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023536\n",
      "done\n",
      "Regression error on test: 0.161861\n",
      "Regression error on test: 0.157303\n",
      "0.16186122596263885\n",
      "Regression error on test: 0.057468\n",
      "Regression error on test: 0.061910\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056906\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023114\n",
      "done\n",
      "Regression error on test: 0.164609\n",
      "Regression error on test: 0.155698\n",
      "0.16460947692394257\n",
      "Regression error on test: 0.061770\n",
      "Regression error on test: 0.041785\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051252\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028269\n",
      "done\n",
      "Regression error on test: 0.160782\n",
      "Regression error on test: 0.182951\n",
      "0.16078175604343414\n",
      "Regression error on test: 0.144789\n",
      "Regression error on test: 0.204599\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.094520\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.125659\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.082971\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.112711\n",
      "done\n",
      "Regression error on test: 0.131772\n",
      "Regression error on test: 0.042639\n",
      "0.13177210092544556\n",
      "Regression error on test: 0.145688\n",
      "Regression error on test: 0.150315\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.193621\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.122634\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.152455\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101338\n",
      "done\n",
      "Regression error on test: 0.184600\n",
      "Regression error on test: 0.093331\n",
      "0.18459992110729218\n",
      "Regression error on test: 0.136736\n",
      "Regression error on test: 0.169615\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139394\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118162\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.098440\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103108\n",
      "done\n",
      "Regression error on test: 0.207958\n",
      "Regression error on test: 0.063799\n",
      "0.2079579383134842\n",
      "Regression error on test: 0.127920\n",
      "Regression error on test: 0.141182\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158886\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117124\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.118651\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110443\n",
      "done\n",
      "Regression error on test: 0.242952\n",
      "Regression error on test: 0.084222\n",
      "0.24295160174369812\n",
      "Regression error on test: 0.143248\n",
      "Regression error on test: 0.136221\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130576\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140802\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090799\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.142355\n",
      "done\n",
      "Regression error on test: 0.299013\n",
      "Regression error on test: 0.084511\n",
      "0.29901325702667236\n",
      "Regression error on test: 0.144645\n",
      "Regression error on test: 0.150048\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125672\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.150346\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.086115\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.159979\n",
      "done\n",
      "Regression error on test: 0.337131\n",
      "Regression error on test: 0.068855\n",
      "0.33713090419769287\n",
      "Regression error on test: 0.136637\n",
      "Regression error on test: 0.135629\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139512\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.143225\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.100002\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.156750\n",
      "done\n",
      "Regression error on test: 0.354753\n",
      "Regression error on test: 0.083461\n",
      "0.3547532558441162\n",
      "Regression error on test: 0.134216\n",
      "Regression error on test: 0.088064\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125086\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140573\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.085545\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.155101\n",
      "done\n",
      "Regression error on test: 0.363729\n",
      "Regression error on test: 0.182393\n",
      "0.3637291193008423\n",
      "Regression error on test: 0.131674\n",
      "Regression error on test: 0.170302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.081103\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.136389\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056652\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.144186\n",
      "done\n",
      "Regression error on test: 0.368891\n",
      "Regression error on test: 0.177624\n",
      "0.36889132857322693\n",
      "Regression error on test: 0.127905\n",
      "Regression error on test: 0.101916\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.156386\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.137266\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.104196\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.163199\n",
      "done\n",
      "Regression error on test: 0.367890\n",
      "Regression error on test: 0.436884\n",
      "0.36788952350616455\n",
      "Regression error on test: 0.129125\n",
      "Regression error on test: 0.213587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091866\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.135054\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069132\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.139927\n",
      "done\n",
      "Regression error on test: 0.343494\n",
      "Regression error on test: 0.570917\n",
      "0.34349408745765686\n",
      "Regression error on test: 0.121165\n",
      "Regression error on test: 0.060791\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.198919\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.141158\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.143914\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.167251\n",
      "done\n",
      "Regression error on test: 0.306705\n",
      "Regression error on test: 0.326911\n",
      "0.30670472979545593\n",
      "Regression error on test: 0.121355\n",
      "Regression error on test: 0.081464\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060993\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.121711\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.061212\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.122694\n",
      "done\n",
      "Regression error on test: 0.301218\n",
      "Regression error on test: 0.413736\n",
      "0.3012184500694275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.117664\n",
      "Regression error on test: 0.294457\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079870\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.125608\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.074753\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.133589\n",
      "done\n",
      "Regression error on test: 0.290323\n",
      "Regression error on test: 0.644839\n",
      "0.29032284021377563\n",
      "Regression error on test: 0.096449\n",
      "Regression error on test: 0.150195\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.279437\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132479\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.223098\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.173666\n",
      "done\n",
      "Regression error on test: 0.253652\n",
      "Regression error on test: 0.465688\n",
      "0.25365179777145386\n",
      "Regression error on test: 0.085740\n",
      "Regression error on test: 0.069959\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.136784\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.128728\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.087869\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.171567\n",
      "done\n",
      "Regression error on test: 0.234045\n",
      "Regression error on test: 0.245079\n",
      "0.23404453694820404\n",
      "Regression error on test: 0.091803\n",
      "Regression error on test: 0.111423\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061794\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066448\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039998\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059959\n",
      "done\n",
      "Regression error on test: 0.237400\n",
      "Regression error on test: 0.173220\n",
      "0.2374003678560257\n",
      "Regression error on test: 0.088243\n",
      "Regression error on test: 0.062646\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097886\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056209\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053070\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050422\n",
      "done\n",
      "Regression error on test: 0.258664\n",
      "Regression error on test: 0.234015\n",
      "0.25866439938545227\n",
      "Regression error on test: 0.090106\n",
      "Regression error on test: 0.132611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052024\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.070528\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029093\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066040\n",
      "done\n",
      "Regression error on test: 0.287353\n",
      "Regression error on test: 0.167606\n",
      "0.2873528301715851\n",
      "Regression error on test: 0.078688\n",
      "Regression error on test: 0.114119\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.118834\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065728\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.071575\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.072797\n",
      "done\n",
      "Regression error on test: 0.317365\n",
      "Regression error on test: 0.192931\n",
      "0.3173651397228241\n",
      "Regression error on test: 0.084808\n",
      "Regression error on test: 0.133988\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.103388\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080567\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.072471\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.087074\n",
      "done\n",
      "Regression error on test: 0.358520\n",
      "Regression error on test: 0.203024\n",
      "0.35852012038230896\n",
      "Regression error on test: 0.093019\n",
      "Regression error on test: 0.062687\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.119142\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101945\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063463\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.135630\n",
      "done\n",
      "Regression error on test: 0.403658\n",
      "Regression error on test: 0.272048\n",
      "0.40365782380104065\n",
      "Regression error on test: 0.096435\n",
      "Regression error on test: 0.044552\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061560\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.098871\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.055950\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103207\n",
      "done\n",
      "Regression error on test: 0.426108\n",
      "Regression error on test: 0.304779\n",
      "0.4261075556278229\n",
      "Regression error on test: 0.097979\n",
      "Regression error on test: 0.082305\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042878\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101564\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038189\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.105118\n",
      "done\n",
      "Regression error on test: 0.432311\n",
      "Regression error on test: 0.278129\n",
      "0.4323112368583679\n",
      "Regression error on test: 0.097754\n",
      "Regression error on test: 0.043110\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079267\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.105440\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.070945\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.114215\n",
      "done\n",
      "Regression error on test: 0.445569\n",
      "Regression error on test: 0.269616\n",
      "0.44556868076324463\n",
      "Regression error on test: 0.102056\n",
      "Regression error on test: 0.130587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041923\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109018\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039055\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109243\n",
      "done\n",
      "Regression error on test: 0.463153\n",
      "Regression error on test: 0.278637\n",
      "0.4631534814834595\n",
      "Regression error on test: 0.092418\n",
      "Regression error on test: 0.075820\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.113223\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132438\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059023\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.167043\n",
      "done\n",
      "Regression error on test: 0.467757\n",
      "Regression error on test: 0.385860\n",
      "0.467756986618042\n",
      "Regression error on test: 0.092611\n",
      "Regression error on test: 0.081279\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055560\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.144592\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021401\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.136323\n",
      "done\n",
      "Regression error on test: 0.471576\n",
      "Regression error on test: 0.520900\n",
      "0.47157567739486694\n",
      "Regression error on test: 0.088182\n",
      "Regression error on test: 0.018431\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065146\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076753\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029956\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.078789\n",
      "done\n",
      "Regression error on test: 0.457961\n",
      "Regression error on test: 0.467728\n",
      "0.4579613506793976\n",
      "Regression error on test: 0.093110\n",
      "Regression error on test: 0.175317\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.019989\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088651\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017602\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.088063\n",
      "done\n",
      "Regression error on test: 0.438789\n",
      "Regression error on test: 0.604481\n",
      "0.43878886103630066\n",
      "Regression error on test: 0.092913\n",
      "Regression error on test: 0.216100\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159665\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093422\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.104276\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110448\n",
      "done\n",
      "Regression error on test: 0.394260\n",
      "Regression error on test: 0.654401\n",
      "0.3942600190639496\n",
      "Regression error on test: 0.082954\n",
      "Regression error on test: 0.096846\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.196863\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096517\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.124716\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.132958\n",
      "done\n",
      "Regression error on test: 0.346207\n",
      "Regression error on test: 0.496546\n",
      "0.34620675444602966\n",
      "Regression error on test: 0.087096\n",
      "Regression error on test: 0.059991\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.093731\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092360\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.083891\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101945\n",
      "done\n",
      "Regression error on test: 0.313760\n",
      "Regression error on test: 0.366816\n",
      "0.31375983357429504\n",
      "Regression error on test: 0.090531\n",
      "Regression error on test: 0.080061\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060312\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.090580\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059900\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.090108\n",
      "done\n",
      "Regression error on test: 0.300012\n",
      "Regression error on test: 0.410703\n",
      "0.30001187324523926\n",
      "Regression error on test: 0.091859\n",
      "Regression error on test: 0.086125\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.075826\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104738\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063056\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.114833\n",
      "done\n",
      "Regression error on test: 0.280657\n",
      "Regression error on test: 0.445463\n",
      "0.28065651655197144\n",
      "Regression error on test: 0.087546\n",
      "Regression error on test: 0.034208\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077414\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109689\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060578\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.122102\n",
      "done\n",
      "Regression error on test: 0.260831\n",
      "Regression error on test: 0.324671\n",
      "0.2608312964439392\n",
      "Regression error on test: 0.087788\n",
      "Regression error on test: 0.077753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030656\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079396\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026984\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.078169\n",
      "done\n",
      "Regression error on test: 0.252245\n",
      "Regression error on test: 0.424047\n",
      "0.2522452771663666\n",
      "Regression error on test: 0.083151\n",
      "Regression error on test: 0.036989\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064133\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118772\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039768\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.130614\n",
      "done\n",
      "Regression error on test: 0.236627\n",
      "Regression error on test: 0.384756\n",
      "0.23662714660167694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.082381\n",
      "Regression error on test: 0.067713\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035147\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.090970\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034479\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.088980\n",
      "done\n",
      "Regression error on test: 0.221755\n",
      "Regression error on test: 0.276004\n",
      "0.22175532579421997\n",
      "Regression error on test: 0.078362\n",
      "Regression error on test: 0.173346\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060101\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061870\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043717\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058539\n",
      "done\n",
      "Regression error on test: 0.219546\n",
      "Regression error on test: 0.159192\n",
      "0.21954604983329773\n",
      "Regression error on test: 0.063331\n",
      "Regression error on test: 0.116513\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158234\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052297\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.101662\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068837\n",
      "done\n",
      "Regression error on test: 0.227339\n",
      "Regression error on test: 0.173868\n",
      "0.2273394912481308\n",
      "Regression error on test: 0.053866\n",
      "Regression error on test: 0.138260\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109848\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045609\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.092995\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047778\n",
      "done\n",
      "Regression error on test: 0.237295\n",
      "Regression error on test: 0.172077\n",
      "0.23729471862316132\n",
      "Regression error on test: 0.043768\n",
      "Regression error on test: 0.094345\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125014\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040995\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.092543\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055361\n",
      "done\n",
      "Regression error on test: 0.249263\n",
      "Regression error on test: 0.229336\n",
      "0.24926304817199707\n",
      "Regression error on test: 0.039895\n",
      "Regression error on test: 0.093344\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088551\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037334\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.073064\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045849\n",
      "done\n",
      "Regression error on test: 0.264217\n",
      "Regression error on test: 0.217149\n",
      "0.26421672105789185\n",
      "Regression error on test: 0.034079\n",
      "Regression error on test: 0.042992\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.086607\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035279\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.065282\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051902\n",
      "done\n",
      "Regression error on test: 0.273780\n",
      "Regression error on test: 0.247212\n",
      "0.2737800180912018\n",
      "Regression error on test: 0.033061\n",
      "Regression error on test: 0.036623\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039358\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032393\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031902\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033270\n",
      "done\n",
      "Regression error on test: 0.282815\n",
      "Regression error on test: 0.238811\n",
      "0.28281542658805847\n",
      "Regression error on test: 0.034858\n",
      "Regression error on test: 0.031388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031910\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038631\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021587\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046276\n",
      "done\n",
      "Regression error on test: 0.295435\n",
      "Regression error on test: 0.267866\n",
      "0.29543519020080566\n",
      "Regression error on test: 0.038224\n",
      "Regression error on test: 0.029289\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030617\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037318\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028476\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039600\n",
      "done\n",
      "Regression error on test: 0.300331\n",
      "Regression error on test: 0.236039\n",
      "0.3003307580947876\n",
      "Regression error on test: 0.039884\n",
      "Regression error on test: 0.027518\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023661\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043325\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015532\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046209\n",
      "done\n",
      "Regression error on test: 0.305171\n",
      "Regression error on test: 0.253911\n",
      "0.3051706552505493\n",
      "Regression error on test: 0.042521\n",
      "Regression error on test: 0.023040\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027457\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042274\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028117\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042325\n",
      "done\n",
      "Regression error on test: 0.312676\n",
      "Regression error on test: 0.237126\n",
      "0.3126763105392456\n",
      "Regression error on test: 0.048384\n",
      "Regression error on test: 0.021857\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023092\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048441\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023135\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048630\n",
      "done\n",
      "Regression error on test: 0.322763\n",
      "Regression error on test: 0.273421\n",
      "0.3227630853652954\n",
      "Regression error on test: 0.050033\n",
      "Regression error on test: 0.037282\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022200\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050266\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022675\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050101\n",
      "done\n",
      "Regression error on test: 0.324831\n",
      "Regression error on test: 0.291761\n",
      "0.3248308300971985\n",
      "Regression error on test: 0.048662\n",
      "Regression error on test: 0.055613\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035374\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049885\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031527\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051743\n",
      "done\n",
      "Regression error on test: 0.322712\n",
      "Regression error on test: 0.378872\n",
      "0.3227124810218811\n",
      "Regression error on test: 0.052130\n",
      "Regression error on test: 0.035185\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054903\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054221\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053489\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055928\n",
      "done\n",
      "Regression error on test: 0.305217\n",
      "Regression error on test: 0.312782\n",
      "0.3052169978618622\n",
      "Regression error on test: 0.054811\n",
      "Regression error on test: 0.032811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031650\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055159\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025604\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054103\n",
      "done\n",
      "Regression error on test: 0.296234\n",
      "Regression error on test: 0.337566\n",
      "0.2962340712547302\n",
      "Regression error on test: 0.055043\n",
      "Regression error on test: 0.054600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032631\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054418\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032227\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055795\n",
      "done\n",
      "Regression error on test: 0.288075\n",
      "Regression error on test: 0.365008\n",
      "0.2880747318267822\n",
      "Regression error on test: 0.054415\n",
      "Regression error on test: 0.065039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054180\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057231\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052619\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059155\n",
      "done\n",
      "Regression error on test: 0.273418\n",
      "Regression error on test: 0.316822\n",
      "0.2734184265136719\n",
      "Regression error on test: 0.051053\n",
      "Regression error on test: 0.045894\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063104\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047227\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060205\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046407\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.284438\n",
      "0.2647024095058441\n",
      "Regression error on test: 0.051035\n",
      "Regression error on test: 0.053886\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043164\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046639\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038394\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046114\n",
      "done\n",
      "Regression error on test: 0.257963\n",
      "Regression error on test: 0.328967\n",
      "0.2579631805419922\n",
      "Regression error on test: 0.048933\n",
      "Regression error on test: 0.081669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.047757\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065064\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038857\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075553\n",
      "done\n",
      "Regression error on test: 0.248783\n",
      "Regression error on test: 0.337994\n",
      "0.24878305196762085\n",
      "Regression error on test: 0.044736\n",
      "Regression error on test: 0.038354\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070469\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081390\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042690\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.102292\n",
      "done\n",
      "Regression error on test: 0.238841\n",
      "Regression error on test: 0.294098\n",
      "0.23884062469005585\n",
      "Regression error on test: 0.045454\n",
      "Regression error on test: 0.023573\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038444\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042113\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037833\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.041995\n",
      "done\n",
      "Regression error on test: 0.231860\n",
      "Regression error on test: 0.270577\n",
      "0.23185983300209045\n",
      "Regression error on test: 0.046971\n",
      "Regression error on test: 0.090293\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021725\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035067\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019459\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034230\n",
      "done\n",
      "Regression error on test: 0.228843\n",
      "Regression error on test: 0.203918\n",
      "0.22884345054626465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.043821\n",
      "Regression error on test: 0.061994\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078159\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027338\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036286\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043203\n",
      "done\n",
      "Regression error on test: 0.230210\n",
      "Regression error on test: 0.222953\n",
      "0.23021039366722107\n",
      "Regression error on test: 0.042227\n",
      "Regression error on test: 0.035126\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050785\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027084\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030864\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.029414\n",
      "done\n",
      "Regression error on test: 0.232743\n",
      "Regression error on test: 0.255972\n",
      "0.23274260759353638\n",
      "Regression error on test: 0.047610\n",
      "Regression error on test: 0.048322\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034840\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043934\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034181\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039630\n",
      "done\n",
      "Regression error on test: 0.228450\n",
      "Regression error on test: 0.218445\n",
      "0.22844964265823364\n",
      "Regression error on test: 0.053526\n",
      "Regression error on test: 0.031418\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038358\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033885\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018675\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.031976\n",
      "done\n",
      "Regression error on test: 0.226086\n",
      "Regression error on test: 0.229661\n",
      "0.2260863482952118\n",
      "Regression error on test: 0.056575\n",
      "Regression error on test: 0.045715\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028793\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042518\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023715\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036235\n",
      "done\n",
      "Regression error on test: 0.225170\n",
      "Regression error on test: 0.217046\n",
      "0.22517026960849762\n",
      "Regression error on test: 0.058598\n",
      "Regression error on test: 0.032868\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037621\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040201\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023674\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034297\n",
      "done\n",
      "Regression error on test: 0.226957\n",
      "Regression error on test: 0.237166\n",
      "0.22695668041706085\n",
      "Regression error on test: 0.063042\n",
      "Regression error on test: 0.039700\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029477\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046849\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023487\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040677\n",
      "done\n",
      "Regression error on test: 0.226117\n",
      "Regression error on test: 0.238570\n",
      "0.22611674666404724\n",
      "Regression error on test: 0.066996\n",
      "Regression error on test: 0.045533\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035550\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052471\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030287\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050950\n",
      "done\n",
      "Regression error on test: 0.236251\n",
      "Regression error on test: 0.224290\n",
      "0.23625051975250244\n",
      "Regression error on test: 0.069430\n",
      "Regression error on test: 0.038743\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035464\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051184\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021941\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048416\n",
      "done\n",
      "Regression error on test: 0.240930\n",
      "Regression error on test: 0.240413\n",
      "0.24093005061149597\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.058793\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032211\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057029\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025216\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.056576\n",
      "done\n",
      "Regression error on test: 0.253729\n",
      "Regression error on test: 0.217587\n",
      "0.2537294924259186\n",
      "Regression error on test: 0.066588\n",
      "Regression error on test: 0.046056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053169\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055477\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042024\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051079\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.248275\n",
      "0.26470187306404114\n",
      "Regression error on test: 0.068380\n",
      "Regression error on test: 0.088950\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042985\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060756\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034806\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058366\n",
      "done\n",
      "Regression error on test: 0.278891\n",
      "Regression error on test: 0.213043\n",
      "0.27889105677604675\n",
      "Regression error on test: 0.063563\n",
      "Regression error on test: 0.107488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076641\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062563\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032281\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075833\n",
      "done\n",
      "Regression error on test: 0.296243\n",
      "Regression error on test: 0.194812\n",
      "0.29624268412590027\n",
      "Regression error on test: 0.059090\n",
      "Regression error on test: 0.061899\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.095149\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067467\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.049840\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.091014\n",
      "done\n",
      "Regression error on test: 0.317561\n",
      "Regression error on test: 0.220500\n",
      "0.31756097078323364\n",
      "Regression error on test: 0.057614\n",
      "Regression error on test: 0.065955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053318\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067845\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038102\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.076526\n",
      "done\n",
      "Regression error on test: 0.334063\n",
      "Regression error on test: 0.234910\n",
      "0.33406320214271545\n",
      "Regression error on test: 0.062140\n",
      "Regression error on test: 0.077302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055223\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082138\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028466\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.098214\n",
      "done\n",
      "Regression error on test: 0.353975\n",
      "Regression error on test: 0.228766\n",
      "0.3539748191833496\n",
      "Regression error on test: 0.062371\n",
      "Regression error on test: 0.079238\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070214\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.084837\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.049927\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.105135\n",
      "done\n",
      "Regression error on test: 0.372552\n",
      "Regression error on test: 0.339908\n",
      "0.37255221605300903\n",
      "Regression error on test: 0.064429\n",
      "Regression error on test: 0.069872\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.075031\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052820\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059301\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050456\n",
      "done\n",
      "Regression error on test: 0.383426\n",
      "Regression error on test: 0.271085\n",
      "0.38342562317848206\n",
      "Regression error on test: 0.063655\n",
      "Regression error on test: 0.038643\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057697\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102793\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025542\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.124665\n",
      "done\n",
      "Regression error on test: 0.390243\n",
      "Regression error on test: 0.368408\n",
      "0.3902428150177002\n",
      "Regression error on test: 0.070119\n",
      "Regression error on test: 0.030479\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033202\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060755\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028743\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.062032\n",
      "done\n",
      "Regression error on test: 0.377002\n",
      "Regression error on test: 0.327311\n",
      "0.37700167298316956\n",
      "Regression error on test: 0.070296\n",
      "Regression error on test: 0.063970\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027133\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081318\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022614\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.077349\n",
      "done\n",
      "Regression error on test: 0.374148\n",
      "Regression error on test: 0.390166\n",
      "0.37414753437042236\n",
      "Regression error on test: 0.068259\n",
      "Regression error on test: 0.040783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062585\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063060\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058662\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059735\n",
      "done\n",
      "Regression error on test: 0.365729\n",
      "Regression error on test: 0.386559\n",
      "0.36572882533073425\n",
      "Regression error on test: 0.068756\n",
      "Regression error on test: 0.062762\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029974\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063596\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018798\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063611\n",
      "done\n",
      "Regression error on test: 0.350445\n",
      "Regression error on test: 0.407995\n",
      "0.35044509172439575\n",
      "Regression error on test: 0.068803\n",
      "Regression error on test: 0.047133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048547\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073302\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018035\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.072722\n",
      "done\n",
      "Regression error on test: 0.328281\n",
      "Regression error on test: 0.385522\n",
      "0.32828134298324585\n",
      "Regression error on test: 0.066642\n",
      "Regression error on test: 0.111214\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042373\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.069232\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032078\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.071974\n",
      "done\n",
      "Regression error on test: 0.314229\n",
      "Regression error on test: 0.434026\n",
      "0.3142291307449341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.058989\n",
      "Regression error on test: 0.079619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.099104\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.072774\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.070928\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.087979\n",
      "done\n",
      "Regression error on test: 0.290493\n",
      "Regression error on test: 0.414540\n",
      "0.2904933989048004\n",
      "Regression error on test: 0.057036\n",
      "Regression error on test: 0.099811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065685\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083461\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024853\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092332\n",
      "done\n",
      "Regression error on test: 0.272946\n",
      "Regression error on test: 0.448642\n",
      "0.27294573187828064\n",
      "Regression error on test: 0.060403\n",
      "Regression error on test: 0.062137\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085786\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088574\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.061990\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.096340\n",
      "done\n",
      "Regression error on test: 0.245828\n",
      "Regression error on test: 0.339258\n",
      "0.24582822620868683\n",
      "Regression error on test: 0.059411\n",
      "Regression error on test: 0.103280\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062446\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056295\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.062061\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053596\n",
      "done\n",
      "Regression error on test: 0.228155\n",
      "Regression error on test: 0.235996\n",
      "0.2281554490327835\n",
      "Regression error on test: 0.053799\n",
      "Regression error on test: 0.032249\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.092503\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038472\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.068973\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040866\n",
      "done\n",
      "Regression error on test: 0.220271\n",
      "Regression error on test: 0.298770\n",
      "0.22027131915092468\n",
      "Regression error on test: 0.055079\n",
      "Regression error on test: 0.043600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025413\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041635\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017453\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043565\n",
      "done\n",
      "Regression error on test: 0.206626\n",
      "Regression error on test: 0.305979\n",
      "0.2066257894039154\n",
      "Regression error on test: 0.055720\n",
      "Regression error on test: 0.045751\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043467\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059272\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042963\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063018\n",
      "done\n",
      "Regression error on test: 0.191440\n",
      "Regression error on test: 0.233722\n",
      "0.19144029915332794\n",
      "Regression error on test: 0.057435\n",
      "Regression error on test: 0.063239\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043481\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045410\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037151\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040253\n",
      "done\n",
      "Regression error on test: 0.187230\n",
      "Regression error on test: 0.186358\n",
      "0.18722979724407196\n",
      "Regression error on test: 0.057448\n",
      "Regression error on test: 0.025517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052658\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033321\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025407\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035760\n",
      "done\n",
      "Regression error on test: 0.184849\n",
      "Regression error on test: 0.245000\n",
      "0.1848488301038742\n",
      "Regression error on test: 0.060472\n",
      "Regression error on test: 0.034682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025625\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057911\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025186\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058977\n",
      "done\n",
      "Regression error on test: 0.176822\n",
      "Regression error on test: 0.196668\n",
      "0.1768217235803604\n",
      "Regression error on test: 0.061501\n",
      "Regression error on test: 0.060097\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026222\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035705\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012517\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037247\n",
      "done\n",
      "Regression error on test: 0.173460\n",
      "Regression error on test: 0.239064\n",
      "0.1734597533941269\n",
      "Regression error on test: 0.062084\n",
      "Regression error on test: 0.133477\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059432\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057778\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057521\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054707\n",
      "done\n",
      "Regression error on test: 0.173670\n",
      "Regression error on test: 0.177467\n",
      "0.17366990447044373\n",
      "Regression error on test: 0.059289\n",
      "Regression error on test: 0.052222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.122611\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031492\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.094467\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.025924\n",
      "done\n",
      "Regression error on test: 0.168952\n",
      "Regression error on test: 0.162530\n",
      "0.1689516305923462\n",
      "Regression error on test: 0.057997\n",
      "Regression error on test: 0.057566\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058843\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046575\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048980\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037851\n",
      "done\n",
      "Regression error on test: 0.216129\n",
      "Regression error on test: 0.165961\n",
      "0.21612943708896637\n",
      "Regression error on test: 0.073794\n",
      "Regression error on test: 0.059231\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046750\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058127\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011171\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061916\n",
      "done\n",
      "Regression error on test: 0.254908\n",
      "Regression error on test: 0.158954\n",
      "0.2549078166484833\n",
      "Regression error on test: 0.071745\n",
      "Regression error on test: 0.057058\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048491\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059070\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011323\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.062345\n",
      "done\n",
      "Regression error on test: 0.270274\n",
      "Regression error on test: 0.161945\n",
      "0.2702735364437103\n",
      "Regression error on test: 0.082382\n",
      "Regression error on test: 0.054173\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046827\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077610\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019850\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.088146\n",
      "done\n",
      "Regression error on test: 0.305084\n",
      "Regression error on test: 0.160258\n",
      "0.3050839900970459\n",
      "Regression error on test: 0.097677\n",
      "Regression error on test: 0.047381\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043482\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101352\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.009489\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110969\n",
      "done\n",
      "Regression error on test: 0.344543\n",
      "Regression error on test: 0.163280\n",
      "0.34454336762428284\n",
      "Regression error on test: 0.099663\n",
      "Regression error on test: 0.048677\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036744\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104919\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.007234\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110983\n",
      "done\n",
      "Regression error on test: 0.355526\n",
      "Regression error on test: 0.162178\n",
      "0.35552558302879333\n",
      "Regression error on test: 0.112753\n",
      "Regression error on test: 0.051180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037965\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117522\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.007448\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.120569\n",
      "done\n",
      "Regression error on test: 0.355586\n",
      "Regression error on test: 0.162218\n",
      "0.355586439371109\n",
      "Regression error on test: 0.123142\n",
      "Regression error on test: 0.047216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040495\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127792\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.006776\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.130103\n",
      "done\n",
      "Regression error on test: 0.353504\n",
      "Regression error on test: 0.263413\n",
      "0.3535038232803345\n",
      "Regression error on test: 0.135291\n",
      "Regression error on test: 0.033591\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045535\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.134406\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.040988\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.135005\n",
      "done\n",
      "Regression error on test: 0.342894\n",
      "Regression error on test: 0.298133\n",
      "0.34289366006851196\n",
      "Regression error on test: 0.151426\n",
      "Regression error on test: 0.123897\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030305\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.149072\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027491\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.148839\n",
      "done\n",
      "Regression error on test: 0.330533\n",
      "Regression error on test: 0.464954\n",
      "0.33053284883499146\n",
      "Regression error on test: 0.159658\n",
      "Regression error on test: 0.215538\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109944\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.178186\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057627\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.197313\n",
      "done\n",
      "Regression error on test: 0.298201\n",
      "Regression error on test: 0.553744\n",
      "0.298201322555542\n",
      "Regression error on test: 0.155887\n",
      "Regression error on test: 0.038740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.201048\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.186653\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.146697\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.219590\n",
      "done\n",
      "Regression error on test: 0.260420\n",
      "Regression error on test: 0.312611\n",
      "0.2604203224182129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.161906\n",
      "Regression error on test: 0.163422\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034718\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.153217\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029901\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.149923\n",
      "done\n",
      "Regression error on test: 0.251510\n",
      "Regression error on test: 0.510050\n",
      "0.2515101432800293\n",
      "Regression error on test: 0.153620\n",
      "Regression error on test: 0.207127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.148143\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.198272\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090857\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.244449\n",
      "done\n",
      "Regression error on test: 0.227162\n",
      "Regression error on test: 0.554852\n",
      "0.22716206312179565\n",
      "Regression error on test: 0.135698\n",
      "Regression error on test: 0.067245\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.190480\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.196086\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.129221\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.253355\n",
      "done\n",
      "Regression error on test: 0.203941\n",
      "Regression error on test: 0.273101\n",
      "0.2039414346218109\n",
      "Regression error on test: 0.149311\n",
      "Regression error on test: 0.179569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060404\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.112422\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042090\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.102251\n",
      "done\n",
      "Regression error on test: 0.201581\n",
      "Regression error on test: 0.162787\n",
      "0.20158079266548157\n",
      "Regression error on test: 0.134318\n",
      "Regression error on test: 0.155073\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160925\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.084187\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.093477\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066088\n",
      "done\n",
      "Regression error on test: 0.210833\n",
      "Regression error on test: 0.141392\n",
      "0.21083322167396545\n",
      "Regression error on test: 0.125349\n",
      "Regression error on test: 0.168702\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.138909\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082774\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.080386\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068405\n",
      "done\n",
      "Regression error on test: 0.231026\n",
      "Regression error on test: 0.157312\n",
      "0.23102594912052155\n",
      "Regression error on test: 0.117055\n",
      "Regression error on test: 0.194945\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.151672\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085073\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.091633\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.080908\n",
      "done\n",
      "Regression error on test: 0.261571\n",
      "Regression error on test: 0.174525\n",
      "0.2615712881088257\n",
      "Regression error on test: 0.116121\n",
      "Regression error on test: 0.206218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.176032\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096252\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.106471\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.107206\n",
      "done\n",
      "Regression error on test: 0.301176\n",
      "Regression error on test: 0.141638\n",
      "0.3011758625507355\n",
      "Regression error on test: 0.107900\n",
      "Regression error on test: 0.177830\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.188410\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100991\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.122360\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.122778\n",
      "done\n",
      "Regression error on test: 0.337312\n",
      "Regression error on test: 0.175934\n",
      "0.3373115062713623\n",
      "Regression error on test: 0.117214\n",
      "Regression error on test: 0.098930\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160041\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.123503\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.093317\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.160749\n",
      "done\n",
      "Regression error on test: 0.387430\n",
      "Regression error on test: 0.223510\n",
      "0.3874301314353943\n",
      "Regression error on test: 0.137951\n",
      "Regression error on test: 0.080555\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.082934\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.155274\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029062\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.180245\n",
      "done\n",
      "Regression error on test: 0.436770\n",
      "Regression error on test: 0.266569\n",
      "0.43676960468292236\n",
      "Regression error on test: 0.138017\n",
      "Regression error on test: 0.027908\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064063\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.162277\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024555\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.169051\n",
      "done\n",
      "Regression error on test: 0.454916\n",
      "Regression error on test: 0.322645\n",
      "0.454915851354599\n",
      "Regression error on test: 0.153624\n",
      "Regression error on test: 0.203377\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022634\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.160809\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019709\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.161490\n",
      "done\n",
      "Regression error on test: 0.446340\n",
      "Regression error on test: 0.249495\n",
      "0.446340411901474\n",
      "Regression error on test: 0.145058\n",
      "Regression error on test: 0.029640\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.182640\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.167158\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.119615\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.184305\n",
      "done\n",
      "Regression error on test: 0.449763\n",
      "Regression error on test: 0.255312\n",
      "0.4497632682323456\n",
      "Regression error on test: 0.153258\n",
      "Regression error on test: 0.065388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027209\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.156405\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022680\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.158814\n",
      "done\n",
      "Regression error on test: 0.453223\n",
      "Regression error on test: 0.343319\n",
      "0.4532226026058197\n",
      "Regression error on test: 0.157865\n",
      "Regression error on test: 0.085754\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063570\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.160237\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057512\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.161219\n",
      "done\n",
      "Regression error on test: 0.446307\n",
      "Regression error on test: 0.462765\n",
      "0.4463065266609192\n",
      "Regression error on test: 0.158946\n",
      "Regression error on test: 0.185604\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077721\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.163070\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057568\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.166633\n",
      "done\n",
      "Regression error on test: 0.429696\n",
      "Regression error on test: 0.570571\n",
      "0.42969611287117004\n",
      "Regression error on test: 0.155166\n",
      "Regression error on test: 0.124012\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169276\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.173430\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.108039\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.195682\n",
      "done\n",
      "Regression error on test: 0.388589\n",
      "Regression error on test: 0.502994\n",
      "0.3885892629623413\n",
      "Regression error on test: 0.159176\n",
      "Regression error on test: 0.270967\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107915\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189245\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.047540\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.222187\n",
      "done\n",
      "Regression error on test: 0.358044\n",
      "Regression error on test: 0.677121\n",
      "0.35804370045661926\n",
      "Regression error on test: 0.143990\n",
      "Regression error on test: 0.306304\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.252818\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189418\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.184767\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.237733\n",
      "done\n",
      "Regression error on test: 0.314204\n",
      "Regression error on test: 0.716904\n",
      "0.3142043352127075\n",
      "Regression error on test: 0.132494\n",
      "Regression error on test: 0.081218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.287629\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.192095\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.217592\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.254580\n",
      "done\n",
      "Regression error on test: 0.260108\n",
      "Regression error on test: 0.448031\n",
      "0.260108083486557\n",
      "Regression error on test: 0.144000\n",
      "Regression error on test: 0.183971\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078761\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.162697\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.074472\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.173939\n",
      "done\n",
      "Regression error on test: 0.231583\n",
      "Regression error on test: 0.236892\n",
      "0.23158305883407593\n",
      "Regression error on test: 0.146084\n",
      "Regression error on test: 0.117721\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161845\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073119\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.080010\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050350\n",
      "done\n",
      "Regression error on test: 0.224565\n",
      "Regression error on test: 0.283723\n",
      "0.2245648056268692\n",
      "Regression error on test: 0.156430\n",
      "Regression error on test: 0.111636\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.096858\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085919\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027923\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.060551\n",
      "done\n",
      "Regression error on test: 0.213813\n",
      "Regression error on test: 0.289904\n",
      "0.21381282806396484\n",
      "Regression error on test: 0.164548\n",
      "Regression error on test: 0.111461\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091103\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094443\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036652\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.070022\n",
      "done\n",
      "Regression error on test: 0.202130\n",
      "Regression error on test: 0.274158\n",
      "0.20212975144386292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.168545\n",
      "Regression error on test: 0.096564\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091867\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100683\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029802\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.082555\n",
      "done\n",
      "Regression error on test: 0.195746\n",
      "Regression error on test: 0.296661\n",
      "0.1957460641860962\n",
      "Regression error on test: 0.175893\n",
      "Regression error on test: 0.147802\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077111\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.108659\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018700\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.077813\n",
      "done\n",
      "Regression error on test: 0.186836\n",
      "Regression error on test: 0.159503\n",
      "0.18683631718158722\n",
      "Regression error on test: 0.178832\n",
      "Regression error on test: 0.164113\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130879\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114219\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.068072\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.062346\n",
      "done\n",
      "Regression error on test: 0.189518\n",
      "Regression error on test: 0.197538\n",
      "0.18951836228370667\n",
      "Regression error on test: 0.175644\n",
      "Regression error on test: 0.119106\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.145212\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.107752\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.084312\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.069801\n",
      "done\n",
      "Regression error on test: 0.193231\n",
      "Regression error on test: 0.238728\n",
      "0.19323137402534485\n",
      "Regression error on test: 0.182646\n",
      "Regression error on test: 0.191342\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.103591\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.123432\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060816\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.080670\n",
      "done\n",
      "Regression error on test: 0.190529\n",
      "Regression error on test: 0.175942\n",
      "0.190529465675354\n",
      "Regression error on test: 0.181285\n",
      "Regression error on test: 0.196284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.171385\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109771\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.106910\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.067631\n",
      "done\n",
      "Regression error on test: 0.196141\n",
      "Regression error on test: 0.162781\n",
      "0.19614122807979584\n",
      "Regression error on test: 0.175006\n",
      "Regression error on test: 0.204814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177026\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.106864\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.107134\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053702\n",
      "done\n",
      "Regression error on test: 0.206939\n",
      "Regression error on test: 0.166709\n",
      "0.20693941414356232\n",
      "Regression error on test: 0.167447\n",
      "Regression error on test: 0.221176\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.185017\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.110958\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.110784\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068708\n",
      "done\n",
      "Regression error on test: 0.233683\n",
      "Regression error on test: 0.176204\n",
      "0.23368339240550995\n",
      "Regression error on test: 0.148788\n",
      "Regression error on test: 0.192814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.200337\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.103179\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.122102\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.074972\n",
      "done\n",
      "Regression error on test: 0.251618\n",
      "Regression error on test: 0.173074\n",
      "0.25161781907081604\n",
      "Regression error on test: 0.133013\n",
      "Regression error on test: 0.151440\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.173900\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102267\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.102973\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084891\n",
      "done\n",
      "Regression error on test: 0.270645\n",
      "Regression error on test: 0.210321\n",
      "0.2706454396247864\n",
      "Regression error on test: 0.122893\n",
      "Regression error on test: 0.170039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132825\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104879\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069358\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.096973\n",
      "done\n",
      "Regression error on test: 0.288149\n",
      "Regression error on test: 0.207563\n",
      "0.2881491780281067\n",
      "Regression error on test: 0.111307\n",
      "Regression error on test: 0.177196\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.154986\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097703\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.099842\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.095554\n",
      "done\n",
      "Regression error on test: 0.295909\n",
      "Regression error on test: 0.186323\n",
      "0.29590868949890137\n",
      "Regression error on test: 0.099754\n",
      "Regression error on test: 0.132225\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159044\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096046\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.092704\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.105819\n",
      "done\n",
      "Regression error on test: 0.312279\n",
      "Regression error on test: 0.234668\n",
      "0.31227925419807434\n",
      "Regression error on test: 0.090488\n",
      "Regression error on test: 0.189127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.114111\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097958\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.049581\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.113091\n",
      "done\n",
      "Regression error on test: 0.323445\n",
      "Regression error on test: 0.211709\n",
      "0.32344508171081543\n",
      "Regression error on test: 0.079390\n",
      "Regression error on test: 0.177733\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169841\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.099463\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.098706\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.130930\n",
      "done\n",
      "Regression error on test: 0.341050\n",
      "Regression error on test: 0.232059\n",
      "0.34105047583580017\n",
      "Regression error on test: 0.069359\n",
      "Regression error on test: 0.133500\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158121\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102259\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.085220\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.146968\n",
      "done\n",
      "Regression error on test: 0.352893\n",
      "Regression error on test: 0.270763\n",
      "0.352893203496933\n",
      "Regression error on test: 0.060285\n",
      "Regression error on test: 0.129222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.120972\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091356\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.088137\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.121186\n",
      "done\n",
      "Regression error on test: 0.357090\n",
      "Regression error on test: 0.434149\n",
      "0.35708972811698914\n",
      "Regression error on test: 0.052655\n",
      "Regression error on test: 0.034584\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.116892\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039095\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.079450\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054890\n",
      "done\n",
      "Regression error on test: 0.345406\n",
      "Regression error on test: 0.355548\n",
      "0.3454064130783081\n",
      "Regression error on test: 0.055666\n",
      "Regression error on test: 0.035065\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031663\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045448\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026210\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043653\n",
      "done\n",
      "Regression error on test: 0.341045\n",
      "Regression error on test: 0.363350\n",
      "0.34104543924331665\n",
      "Regression error on test: 0.060072\n",
      "Regression error on test: 0.050242\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028216\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047911\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023452\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048592\n",
      "done\n",
      "Regression error on test: 0.337358\n",
      "Regression error on test: 0.385359\n",
      "0.33735790848731995\n",
      "Regression error on test: 0.062548\n",
      "Regression error on test: 0.054178\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038893\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046758\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022100\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045835\n",
      "done\n",
      "Regression error on test: 0.329977\n",
      "Regression error on test: 0.285158\n",
      "0.3299773931503296\n",
      "Regression error on test: 0.063296\n",
      "Regression error on test: 0.061669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043811\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094150\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026895\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.102085\n",
      "done\n",
      "Regression error on test: 0.331519\n",
      "Regression error on test: 0.350030\n",
      "0.3315185308456421\n",
      "Regression error on test: 0.064783\n",
      "Regression error on test: 0.039561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057229\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046047\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043458\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036484\n",
      "done\n",
      "Regression error on test: 0.327391\n",
      "Regression error on test: 0.346326\n",
      "0.3273911476135254\n",
      "Regression error on test: 0.068522\n",
      "Regression error on test: 0.078151\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035784\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051837\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029156\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049081\n",
      "done\n",
      "Regression error on test: 0.323734\n",
      "Regression error on test: 0.387763\n",
      "0.32373398542404175\n",
      "Regression error on test: 0.068630\n",
      "Regression error on test: 0.077424\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070666\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041267\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.047963\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033150\n",
      "done\n",
      "Regression error on test: 0.316336\n",
      "Regression error on test: 0.350486\n",
      "0.3163362443447113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.070834\n",
      "Regression error on test: 0.042758\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.068114\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043317\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042984\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033319\n",
      "done\n",
      "Regression error on test: 0.313635\n",
      "Regression error on test: 0.312728\n",
      "0.31363511085510254\n",
      "Regression error on test: 0.073850\n",
      "Regression error on test: 0.052918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032925\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046305\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020048\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.041176\n",
      "done\n",
      "Regression error on test: 0.312144\n",
      "Regression error on test: 0.317315\n",
      "0.31214433908462524\n",
      "Regression error on test: 0.075093\n",
      "Regression error on test: 0.064695\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.047684\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050522\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035120\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039086\n",
      "done\n",
      "Regression error on test: 0.310107\n",
      "Regression error on test: 0.311938\n",
      "0.3101067543029785\n",
      "Regression error on test: 0.077521\n",
      "Regression error on test: 0.079127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063042\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057860\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.055683\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046282\n",
      "done\n",
      "Regression error on test: 0.307643\n",
      "Regression error on test: 0.326474\n",
      "0.3076429069042206\n",
      "Regression error on test: 0.079261\n",
      "Regression error on test: 0.075003\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069570\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045387\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043370\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033434\n",
      "done\n",
      "Regression error on test: 0.304451\n",
      "Regression error on test: 0.311555\n",
      "0.30445122718811035\n",
      "Regression error on test: 0.079136\n",
      "Regression error on test: 0.061660\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064587\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043309\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.040887\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034484\n",
      "done\n",
      "Regression error on test: 0.301342\n",
      "Regression error on test: 0.300569\n",
      "0.30134159326553345\n",
      "Regression error on test: 0.080070\n",
      "Regression error on test: 0.076535\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052003\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046576\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029009\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036502\n",
      "done\n",
      "Regression error on test: 0.307600\n",
      "Regression error on test: 0.308756\n",
      "0.30759966373443604\n",
      "Regression error on test: 0.077504\n",
      "Regression error on test: 0.076955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065486\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042787\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028343\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032672\n",
      "done\n",
      "Regression error on test: 0.315123\n",
      "Regression error on test: 0.309754\n",
      "0.31512343883514404\n",
      "Regression error on test: 0.077705\n",
      "Regression error on test: 0.079229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065897\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047421\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038192\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040192\n",
      "done\n",
      "Regression error on test: 0.314961\n",
      "Regression error on test: 0.313785\n",
      "0.3149605691432953\n",
      "Regression error on test: 0.077502\n",
      "Regression error on test: 0.099462\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069657\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055329\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041277\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050759\n",
      "done\n",
      "Regression error on test: 0.309780\n",
      "Regression error on test: 0.323476\n",
      "0.3097795844078064\n",
      "Regression error on test: 0.071562\n",
      "Regression error on test: 0.072918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088562\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052847\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052385\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053189\n",
      "done\n",
      "Regression error on test: 0.312271\n",
      "Regression error on test: 0.297820\n",
      "0.31227076053619385\n",
      "Regression error on test: 0.068030\n",
      "Regression error on test: 0.065350\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062232\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053369\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034326\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054555\n",
      "done\n",
      "Regression error on test: 0.318478\n",
      "Regression error on test: 0.296940\n",
      "0.3184778392314911\n",
      "Regression error on test: 0.068847\n",
      "Regression error on test: 0.088975\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054157\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055732\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024234\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057605\n",
      "done\n",
      "Regression error on test: 0.326959\n",
      "Regression error on test: 0.287299\n",
      "0.3269594609737396\n",
      "Regression error on test: 0.064155\n",
      "Regression error on test: 0.096529\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078413\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056967\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039419\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.069492\n",
      "done\n",
      "Regression error on test: 0.329997\n",
      "Regression error on test: 0.294558\n",
      "0.32999682426452637\n",
      "Regression error on test: 0.059285\n",
      "Regression error on test: 0.073748\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.086655\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053505\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056687\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.064572\n",
      "done\n",
      "Regression error on test: 0.337613\n",
      "Regression error on test: 0.280458\n",
      "0.33761322498321533\n",
      "Regression error on test: 0.055278\n",
      "Regression error on test: 0.071000\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064526\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055128\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035775\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066910\n",
      "done\n",
      "Regression error on test: 0.339779\n",
      "Regression error on test: 0.363149\n",
      "0.33977919816970825\n",
      "Regression error on test: 0.053268\n",
      "Regression error on test: 0.050878\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067208\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051572\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057584\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055537\n",
      "done\n",
      "Regression error on test: 0.333962\n",
      "Regression error on test: 0.383994\n",
      "0.3339623212814331\n",
      "Regression error on test: 0.053194\n",
      "Regression error on test: 0.078958\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037855\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060669\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015784\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059915\n",
      "done\n",
      "Regression error on test: 0.320876\n",
      "Regression error on test: 0.308126\n",
      "0.32087597250938416\n",
      "Regression error on test: 0.048368\n",
      "Regression error on test: 0.077206\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078749\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049521\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.078108\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050447\n",
      "done\n",
      "Regression error on test: 0.314376\n",
      "Regression error on test: 0.261976\n",
      "0.314375638961792\n",
      "Regression error on test: 0.048787\n",
      "Regression error on test: 0.040056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070351\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059246\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057021\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.074365\n",
      "done\n",
      "Regression error on test: 0.318877\n",
      "Regression error on test: 0.348387\n",
      "0.3188765347003937\n",
      "Regression error on test: 0.050438\n",
      "Regression error on test: 0.037605\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039724\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046558\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037003\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046155\n",
      "done\n",
      "Regression error on test: 0.312372\n",
      "Regression error on test: 0.359891\n",
      "0.31237226724624634\n",
      "Regression error on test: 0.048699\n",
      "Regression error on test: 0.073517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035292\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044910\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030295\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044892\n",
      "done\n",
      "Regression error on test: 0.299888\n",
      "Regression error on test: 0.381756\n",
      "0.29988813400268555\n",
      "Regression error on test: 0.045367\n",
      "Regression error on test: 0.042051\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070475\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043365\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.062085\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045624\n",
      "done\n",
      "Regression error on test: 0.286350\n",
      "Regression error on test: 0.317673\n",
      "0.2863500714302063\n",
      "Regression error on test: 0.043471\n",
      "Regression error on test: 0.047826\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041988\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043219\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042159\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042435\n",
      "done\n",
      "Regression error on test: 0.279744\n",
      "Regression error on test: 0.370723\n",
      "0.27974411845207214\n",
      "Regression error on test: 0.043033\n",
      "Regression error on test: 0.033682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043247\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043758\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.033963\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046431\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.265693\n",
      "Regression error on test: 0.302118\n",
      "0.2656926214694977\n",
      "Regression error on test: 0.044369\n",
      "Regression error on test: 0.050902\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032370\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048408\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030767\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046279\n",
      "done\n",
      "Regression error on test: 0.259182\n",
      "Regression error on test: 0.304980\n",
      "0.259181946516037\n",
      "Regression error on test: 0.043689\n",
      "Regression error on test: 0.050133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050873\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041043\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048931\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039886\n",
      "done\n",
      "Regression error on test: 0.251869\n",
      "Regression error on test: 0.253130\n",
      "0.2518688440322876\n",
      "Regression error on test: 0.045896\n",
      "Regression error on test: 0.030703\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.049885\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042976\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048813\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.041331\n",
      "done\n",
      "Regression error on test: 0.252464\n",
      "Regression error on test: 0.243123\n",
      "0.2524639964103699\n",
      "Regression error on test: 0.046135\n",
      "Regression error on test: 0.081399\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022272\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037738\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.010030\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037467\n",
      "done\n",
      "Regression error on test: 0.251519\n",
      "Regression error on test: 0.306985\n",
      "0.251518577337265\n",
      "Regression error on test: 0.042942\n",
      "Regression error on test: 0.056561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.073143\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034011\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.045953\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037739\n",
      "done\n",
      "Regression error on test: 0.244537\n",
      "Regression error on test: 0.283344\n",
      "0.24453671276569366\n",
      "Regression error on test: 0.041054\n",
      "Regression error on test: 0.020216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052210\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033303\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039707\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034092\n",
      "done\n",
      "Regression error on test: 0.252111\n",
      "Regression error on test: 0.235050\n",
      "0.2521113455295563\n",
      "Regression error on test: 0.044212\n",
      "Regression error on test: 0.040201\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.019103\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051283\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018091\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055069\n",
      "done\n",
      "Regression error on test: 0.266514\n",
      "Regression error on test: 0.246375\n",
      "0.26651427149772644\n",
      "Regression error on test: 0.046182\n",
      "Regression error on test: 0.023085\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040068\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045107\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039732\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047687\n",
      "done\n",
      "Regression error on test: 0.277301\n",
      "Regression error on test: 0.251613\n",
      "0.27730053663253784\n",
      "Regression error on test: 0.048412\n",
      "Regression error on test: 0.043449\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.020524\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053952\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015985\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058678\n",
      "done\n",
      "Regression error on test: 0.281129\n",
      "Regression error on test: 0.230208\n",
      "0.28112924098968506\n",
      "Regression error on test: 0.048590\n",
      "Regression error on test: 0.047044\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043304\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045238\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041661\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038762\n",
      "done\n",
      "Regression error on test: 0.294545\n",
      "Regression error on test: 0.237011\n",
      "0.29454511404037476\n",
      "Regression error on test: 0.048329\n",
      "Regression error on test: 0.044101\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036345\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035044\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.008326\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035158\n",
      "done\n",
      "Regression error on test: 0.298135\n",
      "Regression error on test: 0.231849\n",
      "0.2981352210044861\n",
      "Regression error on test: 0.045603\n",
      "Regression error on test: 0.072201\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034369\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038329\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016073\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039075\n",
      "done\n",
      "Regression error on test: 0.295648\n",
      "Regression error on test: 0.259081\n",
      "0.29564815759658813\n",
      "Regression error on test: 0.107702\n",
      "Regression error on test: 0.139534\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065767\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088959\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.049375\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.078779\n",
      "done\n",
      "Regression error on test: 0.150728\n",
      "Regression error on test: 0.039339\n",
      "0.15072835981845856\n",
      "Regression error on test: 0.098447\n",
      "Regression error on test: 0.137116\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.129367\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081505\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.091241\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.070027\n",
      "done\n",
      "Regression error on test: 0.181189\n",
      "Regression error on test: 0.042918\n",
      "0.18118897080421448\n",
      "Regression error on test: 0.110597\n",
      "Regression error on test: 0.117420\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.126938\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101370\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.088769\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.097621\n",
      "done\n",
      "Regression error on test: 0.229031\n",
      "Regression error on test: 0.070183\n",
      "0.229030579328537\n",
      "Regression error on test: 0.117865\n",
      "Regression error on test: 0.118753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107157\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.116511\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.068676\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.120773\n",
      "done\n",
      "Regression error on test: 0.269985\n",
      "Regression error on test: 0.080901\n",
      "0.2699846029281616\n",
      "Regression error on test: 0.125451\n",
      "Regression error on test: 0.114937\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108321\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132010\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069200\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.144460\n",
      "done\n",
      "Regression error on test: 0.301020\n",
      "Regression error on test: 0.084510\n",
      "0.3010198771953583\n",
      "Regression error on test: 0.116219\n",
      "Regression error on test: 0.108688\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.104466\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126933\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.065195\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.147057\n",
      "done\n",
      "Regression error on test: 0.318761\n",
      "Regression error on test: 0.090517\n",
      "0.31876105070114136\n",
      "Regression error on test: 0.109202\n",
      "Regression error on test: 0.078587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.098213\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126004\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058930\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.153583\n",
      "done\n",
      "Regression error on test: 0.340227\n",
      "Regression error on test: 0.105296\n",
      "0.34022653102874756\n",
      "Regression error on test: 0.105053\n",
      "Regression error on test: 0.041248\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067986\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.125114\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029952\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.152010\n",
      "done\n",
      "Regression error on test: 0.355546\n",
      "Regression error on test: 0.221746\n",
      "0.3555458188056946\n",
      "Regression error on test: 0.103646\n",
      "Regression error on test: 0.069937\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037291\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114024\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027355\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.121538\n",
      "done\n",
      "Regression error on test: 0.358761\n",
      "Regression error on test: 0.298115\n",
      "0.35876092314720154\n",
      "Regression error on test: 0.100638\n",
      "Regression error on test: 0.150801\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070207\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101943\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069365\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103515\n",
      "done\n",
      "Regression error on test: 0.353341\n",
      "Regression error on test: 0.473758\n",
      "0.3533407747745514\n",
      "Regression error on test: 0.087309\n",
      "Regression error on test: 0.046985\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.137473\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092835\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.087474\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109131\n",
      "done\n",
      "Regression error on test: 0.333873\n",
      "Regression error on test: 0.343945\n",
      "0.33387327194213867\n",
      "Regression error on test: 0.085655\n",
      "Regression error on test: 0.258611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042620\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.089459\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036882\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.091233\n",
      "done\n",
      "Regression error on test: 0.326099\n",
      "Regression error on test: 0.521334\n",
      "0.3260987102985382\n",
      "Regression error on test: 0.063612\n",
      "Regression error on test: 0.190105\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.247390\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081084\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.205312\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.106465\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.299056\n",
      "Regression error on test: 0.479723\n",
      "0.29905590415000916\n",
      "Regression error on test: 0.049122\n",
      "Regression error on test: 0.194607\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177892\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076884\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.132039\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.112946\n",
      "done\n",
      "Regression error on test: 0.274144\n",
      "Regression error on test: 0.391254\n",
      "0.2741442620754242\n",
      "Regression error on test: 0.035010\n",
      "Regression error on test: 0.022619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.183976\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065149\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.147110\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.098833\n",
      "done\n",
      "Regression error on test: 0.259741\n",
      "Regression error on test: 0.261921\n",
      "0.2597413659095764\n",
      "Regression error on test: 0.047071\n",
      "Regression error on test: 0.038521\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.020612\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040575\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019274\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040853\n",
      "done\n",
      "Regression error on test: 0.251055\n",
      "Regression error on test: 0.305172\n",
      "0.2510550916194916\n",
      "Regression error on test: 0.047282\n",
      "Regression error on test: 0.037099\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037830\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053407\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035434\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059417\n",
      "done\n",
      "Regression error on test: 0.259291\n",
      "Regression error on test: 0.258489\n",
      "0.25929075479507446\n",
      "Regression error on test: 0.058139\n",
      "Regression error on test: 0.027171\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032108\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053456\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025823\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053482\n",
      "done\n",
      "Regression error on test: 0.282061\n",
      "Regression error on test: 0.253897\n",
      "0.28206053376197815\n",
      "Regression error on test: 0.062502\n",
      "Regression error on test: 0.039856\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021455\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061212\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014899\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061327\n",
      "done\n",
      "Regression error on test: 0.297593\n",
      "Regression error on test: 0.243914\n",
      "0.2975926995277405\n",
      "Regression error on test: 0.076839\n",
      "Regression error on test: 0.017514\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036451\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079790\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027246\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.082965\n",
      "done\n",
      "Regression error on test: 0.326751\n",
      "Regression error on test: 0.279083\n",
      "0.3267507255077362\n",
      "Regression error on test: 0.092650\n",
      "Regression error on test: 0.030450\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017156\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093399\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017766\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092864\n",
      "done\n",
      "Regression error on test: 0.351109\n",
      "Regression error on test: 0.266199\n",
      "0.35110941529273987\n",
      "Regression error on test: 0.101631\n",
      "Regression error on test: 0.038180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027112\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.107438\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022225\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.108758\n",
      "done\n",
      "Regression error on test: 0.364865\n",
      "Regression error on test: 0.250906\n",
      "0.36486461758613586\n",
      "Regression error on test: 0.101583\n",
      "Regression error on test: 0.045204\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028114\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118058\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019530\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.121607\n",
      "done\n",
      "Regression error on test: 0.373377\n",
      "Regression error on test: 0.230607\n",
      "0.3733765482902527\n",
      "Regression error on test: 0.098531\n",
      "Regression error on test: 0.053482\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034702\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.123323\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017156\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.129274\n",
      "done\n",
      "Regression error on test: 0.380809\n",
      "Regression error on test: 0.247226\n",
      "0.38080930709838867\n",
      "Regression error on test: 0.095360\n",
      "Regression error on test: 0.143228\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053378\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.099398\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052448\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103795\n",
      "done\n",
      "Regression error on test: 0.383308\n",
      "Regression error on test: 0.175058\n",
      "0.38330841064453125\n",
      "Regression error on test: 0.085635\n",
      "Regression error on test: 0.040639\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.131458\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.120232\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.089697\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.162114\n",
      "done\n",
      "Regression error on test: 0.386189\n",
      "Regression error on test: 0.387529\n",
      "0.38618937134742737\n",
      "Regression error on test: 0.085331\n",
      "Regression error on test: 0.145662\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038058\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.078087\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030453\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073914\n",
      "done\n",
      "Regression error on test: 0.365312\n",
      "Regression error on test: 0.486187\n",
      "0.36531201004981995\n",
      "Regression error on test: 0.073332\n",
      "Regression error on test: 0.070801\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132166\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068894\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.081555\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084328\n",
      "done\n",
      "Regression error on test: 0.334898\n",
      "Regression error on test: 0.409219\n",
      "0.3348983824253082\n",
      "Regression error on test: 0.075009\n",
      "Regression error on test: 0.183229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057493\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079783\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016802\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.086658\n",
      "done\n",
      "Regression error on test: 0.309346\n",
      "Regression error on test: 0.535495\n",
      "0.3093455731868744\n",
      "Regression error on test: 0.061343\n",
      "Regression error on test: 0.175627\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169008\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075814\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.120429\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.096981\n",
      "done\n",
      "Regression error on test: 0.272681\n",
      "Regression error on test: 0.522669\n",
      "0.27268120646476746\n",
      "Regression error on test: 0.050995\n",
      "Regression error on test: 0.120262\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161501\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075053\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.108505\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.111878\n",
      "done\n",
      "Regression error on test: 0.236238\n",
      "Regression error on test: 0.403751\n",
      "0.2362384796142578\n",
      "Regression error on test: 0.046384\n",
      "Regression error on test: 0.037693\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108325\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077410\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.066258\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.113214\n",
      "done\n",
      "Regression error on test: 0.210513\n",
      "Regression error on test: 0.336025\n",
      "0.21051329374313354\n",
      "Regression error on test: 0.049061\n",
      "Regression error on test: 0.014685\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029964\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076374\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014899\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.079134\n",
      "done\n",
      "Regression error on test: 0.194982\n",
      "Regression error on test: 0.304935\n",
      "0.19498211145401\n",
      "Regression error on test: 0.055631\n",
      "Regression error on test: 0.021774\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.013688\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061984\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012702\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059397\n",
      "done\n",
      "Regression error on test: 0.181006\n",
      "Regression error on test: 0.272216\n",
      "0.18100637197494507\n",
      "Regression error on test: 0.064370\n",
      "Regression error on test: 0.045976\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.016775\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049131\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014261\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045942\n",
      "done\n",
      "Regression error on test: 0.171424\n",
      "Regression error on test: 0.203868\n",
      "0.17142438888549805\n",
      "Regression error on test: 0.067106\n",
      "Regression error on test: 0.037598\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043097\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048378\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035075\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037822\n",
      "done\n",
      "Regression error on test: 0.167077\n",
      "Regression error on test: 0.178755\n",
      "0.16707678139209747\n",
      "Regression error on test: 0.072278\n",
      "Regression error on test: 0.025673\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030541\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050769\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019308\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043132\n",
      "done\n",
      "Regression error on test: 0.166541\n",
      "Regression error on test: 0.182051\n",
      "0.16654105484485626\n",
      "Regression error on test: 0.074156\n",
      "Regression error on test: 0.087569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023123\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059342\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019348\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054478\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.177487\n",
      "Regression error on test: 0.153690\n",
      "0.1774866133928299\n",
      "Regression error on test: 0.070530\n",
      "Regression error on test: 0.046570\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076536\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036171\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035440\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.026872\n",
      "done\n",
      "Regression error on test: 0.189271\n",
      "Regression error on test: 0.168851\n",
      "0.18927134573459625\n",
      "Regression error on test: 0.069459\n",
      "Regression error on test: 0.072148\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038685\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044532\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022542\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032270\n",
      "done\n",
      "Regression error on test: 0.199294\n",
      "Regression error on test: 0.158242\n",
      "0.19929403066635132\n",
      "Regression error on test: 0.069770\n",
      "Regression error on test: 0.074150\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061362\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036003\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023487\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027469\n",
      "done\n",
      "Regression error on test: 0.208236\n",
      "Regression error on test: 0.146499\n",
      "0.20823588967323303\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.064470\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063461\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035972\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025850\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027730\n",
      "done\n",
      "Regression error on test: 0.216380\n",
      "Regression error on test: 0.180713\n",
      "0.21637964248657227\n",
      "Regression error on test: 0.068701\n",
      "Regression error on test: 0.080382\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056577\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039202\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037525\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.028118\n",
      "done\n",
      "Regression error on test: 0.221287\n",
      "Regression error on test: 0.165177\n",
      "0.22128742933273315\n",
      "Regression error on test: 0.065381\n",
      "Regression error on test: 0.109164\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069313\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038284\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032903\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035535\n",
      "done\n",
      "Regression error on test: 0.233844\n",
      "Regression error on test: 0.176396\n",
      "0.23384399712085724\n",
      "Regression error on test: 0.059033\n",
      "Regression error on test: 0.073335\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097087\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032827\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058030\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035904\n",
      "done\n",
      "Regression error on test: 0.235233\n",
      "Regression error on test: 0.160392\n",
      "0.23523320257663727\n",
      "Regression error on test: 0.057307\n",
      "Regression error on test: 0.089314\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062423\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032490\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027053\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034353\n",
      "done\n",
      "Regression error on test: 0.238371\n",
      "Regression error on test: 0.173398\n",
      "0.23837050795555115\n",
      "Regression error on test: 0.051771\n",
      "Regression error on test: 0.044454\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078031\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028951\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041719\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034301\n",
      "done\n",
      "Regression error on test: 0.241276\n",
      "Regression error on test: 0.291507\n",
      "0.24127617478370667\n",
      "Regression error on test: 0.051454\n",
      "Regression error on test: 0.051316\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041877\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037594\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036059\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.031312\n",
      "done\n",
      "Regression error on test: 0.232186\n",
      "Regression error on test: 0.271538\n",
      "0.23218564689159393\n",
      "Regression error on test: 0.049474\n",
      "Regression error on test: 0.035855\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037789\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.026531\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012180\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.026254\n",
      "done\n",
      "Regression error on test: 0.225921\n",
      "Regression error on test: 0.269078\n",
      "0.2259206622838974\n",
      "Regression error on test: 0.050506\n",
      "Regression error on test: 0.075265\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025559\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031573\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015313\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032078\n",
      "done\n",
      "Regression error on test: 0.220163\n",
      "Regression error on test: 0.247661\n",
      "0.22016292810440063\n",
      "Regression error on test: 0.047875\n",
      "Regression error on test: 0.070642\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061521\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.025277\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016419\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.029656\n",
      "done\n",
      "Regression error on test: 0.214841\n",
      "Regression error on test: 0.227937\n",
      "0.2148410528898239\n",
      "Regression error on test: 0.044485\n",
      "Regression error on test: 0.057288\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057995\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023766\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025020\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.029483\n",
      "done\n",
      "Regression error on test: 0.213018\n",
      "Regression error on test: 0.229791\n",
      "0.21301795542240143\n",
      "Regression error on test: 0.043193\n",
      "Regression error on test: 0.047174\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046639\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.022607\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020063\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.024564\n",
      "done\n",
      "Regression error on test: 0.211541\n",
      "Regression error on test: 0.290743\n",
      "0.21154072880744934\n",
      "Regression error on test: 0.045711\n",
      "Regression error on test: 0.045683\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042505\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.071879\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032550\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084280\n",
      "done\n",
      "Regression error on test: 0.201323\n",
      "Regression error on test: 0.190288\n",
      "0.20132257044315338\n",
      "Regression error on test: 0.050832\n",
      "Regression error on test: 0.056078\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035676\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023079\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018670\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.020788\n",
      "done\n",
      "Regression error on test: 0.200882\n",
      "Regression error on test: 0.191765\n",
      "0.20088177919387817\n",
      "Regression error on test: 0.058903\n",
      "Regression error on test: 0.033952\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045185\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031260\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024144\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027898\n",
      "done\n",
      "Regression error on test: 0.196906\n",
      "Regression error on test: 0.202454\n",
      "0.19690635800361633\n",
      "Regression error on test: 0.066825\n",
      "Regression error on test: 0.041284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025612\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038806\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014360\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037157\n",
      "done\n",
      "Regression error on test: 0.192878\n",
      "Regression error on test: 0.200602\n",
      "0.19287805259227753\n",
      "Regression error on test: 0.068962\n",
      "Regression error on test: 0.031517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030847\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040697\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011558\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040713\n",
      "done\n",
      "Regression error on test: 0.195240\n",
      "Regression error on test: 0.208888\n",
      "0.1952400952577591\n",
      "Regression error on test: 0.070459\n",
      "Regression error on test: 0.046177\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.024451\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050056\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015377\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046433\n",
      "done\n",
      "Regression error on test: 0.200457\n",
      "Regression error on test: 0.211501\n",
      "0.20045743882656097\n",
      "Regression error on test: 0.073136\n",
      "Regression error on test: 0.048955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038061\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047875\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022223\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038231\n",
      "done\n",
      "Regression error on test: 0.204080\n",
      "Regression error on test: 0.194442\n",
      "0.20407988131046295\n",
      "Regression error on test: 0.072086\n",
      "Regression error on test: 0.036740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037873\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043192\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012524\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039036\n",
      "done\n",
      "Regression error on test: 0.211465\n",
      "Regression error on test: 0.209705\n",
      "0.21146544814109802\n",
      "Regression error on test: 0.070692\n",
      "Regression error on test: 0.044373\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026107\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047492\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011256\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050189\n",
      "done\n",
      "Regression error on test: 0.220132\n",
      "Regression error on test: 0.215019\n",
      "0.22013194859027863\n",
      "Regression error on test: 0.067967\n",
      "Regression error on test: 0.072355\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033028\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048931\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012016\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047774\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.229265\n",
      "Regression error on test: 0.188561\n",
      "0.229265034198761\n",
      "Regression error on test: 0.065854\n",
      "Regression error on test: 0.096889\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060952\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046894\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023154\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044569\n",
      "done\n",
      "Regression error on test: 0.236927\n",
      "Regression error on test: 0.185880\n",
      "0.2369273453950882\n",
      "Regression error on test: 0.061476\n",
      "Regression error on test: 0.136783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085027\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043105\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041059\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048492\n",
      "done\n",
      "Regression error on test: 0.245079\n",
      "Regression error on test: 0.152011\n",
      "0.2450791448354721\n",
      "Regression error on test: 0.053248\n",
      "Regression error on test: 0.113175\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125109\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040384\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.081325\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055069\n",
      "done\n",
      "Regression error on test: 0.258688\n",
      "Regression error on test: 0.162171\n",
      "0.258688360452652\n",
      "Regression error on test: 0.045083\n",
      "Regression error on test: 0.062657\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.101653\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036316\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058429\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059199\n",
      "done\n",
      "Regression error on test: 0.271844\n",
      "Regression error on test: 0.224223\n",
      "0.2718440592288971\n",
      "Regression error on test: 0.044747\n",
      "Regression error on test: 0.046488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061531\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040702\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058931\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039694\n",
      "done\n",
      "Regression error on test: 0.287161\n",
      "Regression error on test: 0.261062\n",
      "0.2871612012386322\n",
      "Regression error on test: 0.042894\n",
      "Regression error on test: 0.072942\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045356\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039863\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042138\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039411\n",
      "done\n",
      "Regression error on test: 0.293182\n",
      "Regression error on test: 0.247725\n",
      "0.29318225383758545\n",
      "Regression error on test: 0.038665\n",
      "Regression error on test: 0.038453\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059588\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045964\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017564\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.064856\n",
      "done\n",
      "Regression error on test: 0.297030\n",
      "Regression error on test: 0.268298\n",
      "0.29703041911125183\n",
      "Regression error on test: 0.042092\n",
      "Regression error on test: 0.022804\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035190\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040226\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030189\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040363\n",
      "done\n",
      "Regression error on test: 0.288786\n",
      "Regression error on test: 0.296370\n",
      "0.288785845041275\n",
      "Regression error on test: 0.047586\n",
      "Regression error on test: 0.017127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022042\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045030\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020006\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044611\n",
      "done\n",
      "Regression error on test: 0.275285\n",
      "Regression error on test: 0.306350\n",
      "0.2752852439880371\n",
      "Regression error on test: 0.054457\n",
      "Regression error on test: 0.051220\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017068\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053720\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017002\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053032\n",
      "done\n",
      "Regression error on test: 0.260024\n",
      "Regression error on test: 0.265184\n",
      "0.260023832321167\n",
      "Regression error on test: 0.056978\n",
      "Regression error on test: 0.053108\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041172\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047868\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014563\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047795\n",
      "done\n",
      "Regression error on test: 0.248906\n",
      "Regression error on test: 0.267398\n",
      "0.24890589714050293\n",
      "Regression error on test: 0.058456\n",
      "Regression error on test: 0.054505\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042370\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049178\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015282\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049043\n",
      "done\n",
      "Regression error on test: 0.237896\n",
      "Regression error on test: 0.288103\n",
      "0.2378964126110077\n",
      "Regression error on test: 0.059196\n",
      "Regression error on test: 0.031521\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054572\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062628\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053462\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066502\n",
      "done\n",
      "Regression error on test: 0.224656\n",
      "Regression error on test: 0.293729\n",
      "0.22465600073337555\n",
      "Regression error on test: 0.060223\n",
      "Regression error on test: 0.059307\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028871\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052477\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020076\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048520\n",
      "done\n",
      "Regression error on test: 0.213578\n",
      "Regression error on test: 0.377394\n",
      "0.21357819437980652\n",
      "Regression error on test: 0.062761\n",
      "Regression error on test: 0.027955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051655\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091323\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029125\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.107962\n",
      "done\n",
      "Regression error on test: 0.190290\n",
      "Regression error on test: 0.321272\n",
      "0.1902899146080017\n",
      "Regression error on test: 0.065029\n",
      "Regression error on test: 0.030653\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025971\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.078758\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025438\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073017\n",
      "done\n",
      "Regression error on test: 0.176353\n",
      "Regression error on test: 0.286206\n",
      "0.17635251581668854\n",
      "Regression error on test: 0.067043\n",
      "Regression error on test: 0.072724\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031586\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064012\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031373\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.065066\n",
      "done\n",
      "Regression error on test: 0.164795\n",
      "Regression error on test: 0.185853\n",
      "0.16479502618312836\n",
      "Regression error on test: 0.066627\n",
      "Regression error on test: 0.077738\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060934\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027974\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026951\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.017162\n",
      "done\n",
      "Regression error on test: 0.161276\n",
      "Regression error on test: 0.161363\n",
      "0.16127589344978333\n",
      "Regression error on test: 0.065062\n",
      "Regression error on test: 0.085843\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066511\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027307\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024594\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.021335\n",
      "done\n",
      "Regression error on test: 0.160141\n",
      "Regression error on test: 0.153736\n",
      "0.1601407825946808\n",
      "Regression error on test: 0.062124\n",
      "Regression error on test: 0.076426\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.074148\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.024120\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036074\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.018308\n",
      "done\n",
      "Regression error on test: 0.160747\n",
      "Regression error on test: 0.154005\n",
      "0.1607469767332077\n",
      "Regression error on test: 0.059821\n",
      "Regression error on test: 0.067885\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065321\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023529\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027481\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.018765\n",
      "done\n",
      "Regression error on test: 0.161861\n",
      "Regression error on test: 0.157303\n",
      "0.16186127066612244\n",
      "Regression error on test: 0.057468\n",
      "Regression error on test: 0.061910\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056915\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023147\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018547\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.021550\n",
      "done\n",
      "Regression error on test: 0.164609\n",
      "Regression error on test: 0.155698\n",
      "0.16460947692394257\n",
      "Regression error on test: 0.061770\n",
      "Regression error on test: 0.041785\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051252\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028267\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.013820\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.021742\n",
      "done\n",
      "Regression error on test: 0.160782\n",
      "Regression error on test: 0.182951\n",
      "0.16078177094459534\n",
      "Regression error on test: 0.144789\n",
      "Regression error on test: 0.204599\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.094959\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127762\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.084049\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.118082\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.079185\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110605\n",
      "done\n",
      "Regression error on test: 0.131772\n",
      "Regression error on test: 0.042639\n",
      "0.13177210092544556\n",
      "Regression error on test: 0.145688\n",
      "Regression error on test: 0.150315\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.193621\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.122633\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.152452\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101338\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.111283\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.085214\n",
      "done\n",
      "Regression error on test: 0.184600\n",
      "Regression error on test: 0.093331\n",
      "0.18459993600845337\n",
      "Regression error on test: 0.136736\n",
      "Regression error on test: 0.169615\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139394\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118163\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.098786\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103920\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.064497\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.095318\n",
      "done\n",
      "Regression error on test: 0.207958\n",
      "Regression error on test: 0.063799\n",
      "0.207957923412323\n",
      "Regression error on test: 0.127920\n",
      "Regression error on test: 0.141182\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158887\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117124\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.118654\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110442\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.078418\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110014\n",
      "done\n",
      "Regression error on test: 0.242952\n",
      "Regression error on test: 0.084222\n",
      "0.24295160174369812\n",
      "Regression error on test: 0.143248\n",
      "Regression error on test: 0.136221\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130576\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140803\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090803\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.142352\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.051627\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.148032\n",
      "done\n",
      "Regression error on test: 0.299013\n",
      "Regression error on test: 0.084511\n",
      "0.29901322722435\n",
      "Regression error on test: 0.144645\n",
      "Regression error on test: 0.150048\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125673\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.150345\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.086117\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.159979\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.046557\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.174939\n",
      "done\n",
      "Regression error on test: 0.337131\n",
      "Regression error on test: 0.068855\n",
      "0.3371308743953705\n",
      "Regression error on test: 0.136637\n",
      "Regression error on test: 0.135629\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139512\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.143224\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.100001\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.156753\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060490\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.178091\n",
      "done\n",
      "Regression error on test: 0.354753\n",
      "Regression error on test: 0.083461\n",
      "0.3547532558441162\n",
      "Regression error on test: 0.134216\n",
      "Regression error on test: 0.088064\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125082\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140579\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.085526\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.155098\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.045979\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.179630\n",
      "done\n",
      "Regression error on test: 0.363729\n",
      "Regression error on test: 0.182394\n",
      "0.3637291491031647\n",
      "Regression error on test: 0.131674\n",
      "Regression error on test: 0.170302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.080788\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.136758\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.054957\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.147496\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041238\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.155696\n",
      "done\n",
      "Regression error on test: 0.368891\n",
      "Regression error on test: 0.177624\n",
      "0.36889132857322693\n",
      "Regression error on test: 0.127905\n",
      "Regression error on test: 0.101916\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.156384\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.137269\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.104192\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.163191\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.057920\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.191999\n",
      "done\n",
      "Regression error on test: 0.367890\n",
      "Regression error on test: 0.436884\n",
      "0.36788952350616455\n",
      "Regression error on test: 0.129125\n",
      "Regression error on test: 0.213587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.092418\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.134734\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.070306\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.138607\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.062726\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.143623\n",
      "done\n",
      "Regression error on test: 0.343494\n",
      "Regression error on test: 0.570917\n",
      "0.34349411725997925\n",
      "Regression error on test: 0.121165\n",
      "Regression error on test: 0.060791\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.198977\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.141061\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.144161\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.167222\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.089363\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.197253\n",
      "done\n",
      "Regression error on test: 0.306705\n",
      "Regression error on test: 0.326911\n",
      "0.3067047595977783\n",
      "Regression error on test: 0.121355\n",
      "Regression error on test: 0.081464\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061025\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.121053\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060757\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.120195\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060687\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.120547\n",
      "done\n",
      "Regression error on test: 0.301218\n",
      "Regression error on test: 0.413736\n",
      "0.3012184202671051\n",
      "Regression error on test: 0.117664\n",
      "Regression error on test: 0.294457\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079640\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127272\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.074106\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.133514\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.072221\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.135330\n",
      "done\n",
      "Regression error on test: 0.290323\n",
      "Regression error on test: 0.644838\n",
      "0.29032281041145325\n",
      "Regression error on test: 0.096449\n",
      "Regression error on test: 0.150195\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.279433\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132480\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.223068\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.173714\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.166634\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.219935\n",
      "done\n",
      "Regression error on test: 0.253652\n",
      "Regression error on test: 0.465688\n",
      "0.25365179777145386\n",
      "Regression error on test: 0.085740\n",
      "Regression error on test: 0.069959\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.136772\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.128789\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.088469\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.166769\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.055194\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.206292\n",
      "done\n",
      "Regression error on test: 0.234045\n",
      "Regression error on test: 0.245079\n",
      "0.23404452204704285\n",
      "Regression error on test: 0.091803\n",
      "Regression error on test: 0.111423\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060819\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064602\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038798\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057965\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036457\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056857\n",
      "done\n",
      "Regression error on test: 0.237400\n",
      "Regression error on test: 0.173220\n",
      "0.2374003827571869\n",
      "Regression error on test: 0.088243\n",
      "Regression error on test: 0.062646\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097893\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056204\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053813\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050483\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037322\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053407\n",
      "done\n",
      "Regression error on test: 0.258664\n",
      "Regression error on test: 0.234015\n",
      "0.25866439938545227\n",
      "Regression error on test: 0.090106\n",
      "Regression error on test: 0.132611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052290\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.071851\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030016\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066018\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026594\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.065881\n",
      "done\n",
      "Regression error on test: 0.287353\n",
      "Regression error on test: 0.167606\n",
      "0.28735285997390747\n",
      "Regression error on test: 0.078688\n",
      "Regression error on test: 0.114119\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.118838\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065728\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.071296\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.072831\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.043755\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.083457\n",
      "done\n",
      "Regression error on test: 0.317365\n",
      "Regression error on test: 0.192931\n",
      "0.3173651397228241\n",
      "Regression error on test: 0.084808\n",
      "Regression error on test: 0.133988\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.102283\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080741\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069509\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.088864\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.048757\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.100184\n",
      "done\n",
      "Regression error on test: 0.358520\n",
      "Regression error on test: 0.203024\n",
      "0.35852012038230896\n",
      "Regression error on test: 0.093019\n",
      "Regression error on test: 0.062687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.119160\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101908\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063553\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.135555\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021835\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.151463\n",
      "done\n",
      "Regression error on test: 0.403658\n",
      "Regression error on test: 0.272048\n",
      "0.40365785360336304\n",
      "Regression error on test: 0.096435\n",
      "Regression error on test: 0.044552\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061359\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.098906\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056273\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.104392\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.051425\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.108712\n",
      "done\n",
      "Regression error on test: 0.426108\n",
      "Regression error on test: 0.304779\n",
      "0.42610761523246765\n",
      "Regression error on test: 0.097979\n",
      "Regression error on test: 0.082305\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043745\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100711\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039595\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.102985\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036503\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.108845\n",
      "done\n",
      "Regression error on test: 0.432311\n",
      "Regression error on test: 0.278129\n",
      "0.4323112964630127\n",
      "Regression error on test: 0.097754\n",
      "Regression error on test: 0.043110\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079792\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104811\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.071859\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109830\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.067718\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.116734\n",
      "done\n",
      "Regression error on test: 0.445569\n",
      "Regression error on test: 0.269615\n",
      "0.44556868076324463\n",
      "Regression error on test: 0.102056\n",
      "Regression error on test: 0.130587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041268\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109890\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038247\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.111766\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037945\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.113688\n",
      "done\n",
      "Regression error on test: 0.463154\n",
      "Regression error on test: 0.278637\n",
      "0.46315351128578186\n",
      "Regression error on test: 0.092418\n",
      "Regression error on test: 0.075820\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.113149\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132744\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059479\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.168209\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042609\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.185990\n",
      "done\n",
      "Regression error on test: 0.467757\n",
      "Regression error on test: 0.385860\n",
      "0.4677569270133972\n",
      "Regression error on test: 0.092611\n",
      "Regression error on test: 0.081279\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055190\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.149076\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019591\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.151689\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020823\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.149779\n",
      "done\n",
      "Regression error on test: 0.471576\n",
      "Regression error on test: 0.520900\n",
      "0.47157564759254456\n",
      "Regression error on test: 0.088182\n",
      "Regression error on test: 0.018431\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065952\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076755\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029394\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.079794\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025794\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.079291\n",
      "done\n",
      "Regression error on test: 0.457961\n",
      "Regression error on test: 0.467728\n",
      "0.4579613506793976\n",
      "Regression error on test: 0.093110\n",
      "Regression error on test: 0.175317\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.020684\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094116\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017629\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092301\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016455\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.088705\n",
      "done\n",
      "Regression error on test: 0.438789\n",
      "Regression error on test: 0.604480\n",
      "0.43878886103630066\n",
      "Regression error on test: 0.092913\n",
      "Regression error on test: 0.216100\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160192\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092576\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.107962\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109443\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060896\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.135881\n",
      "done\n",
      "Regression error on test: 0.394260\n",
      "Regression error on test: 0.654401\n",
      "0.3942600190639496\n",
      "Regression error on test: 0.082954\n",
      "Regression error on test: 0.096846\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.196849\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096540\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.124632\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.133055\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052959\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.173053\n",
      "done\n",
      "Regression error on test: 0.346207\n",
      "Regression error on test: 0.496546\n",
      "0.34620675444602966\n",
      "Regression error on test: 0.087096\n",
      "Regression error on test: 0.059991\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.093591\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093083\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.082887\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.098361\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.079715\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.101989\n",
      "done\n",
      "Regression error on test: 0.313760\n",
      "Regression error on test: 0.366816\n",
      "0.31375986337661743\n",
      "Regression error on test: 0.090531\n",
      "Regression error on test: 0.080061\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059994\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091270\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060153\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092655\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059365\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.092732\n",
      "done\n",
      "Regression error on test: 0.300012\n",
      "Regression error on test: 0.410703\n",
      "0.30001184344291687\n",
      "Regression error on test: 0.091859\n",
      "Regression error on test: 0.086125\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076007\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102870\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.064341\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.111452\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059050\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.117619\n",
      "done\n",
      "Regression error on test: 0.280656\n",
      "Regression error on test: 0.445463\n",
      "0.28065648674964905\n",
      "Regression error on test: 0.087546\n",
      "Regression error on test: 0.034208\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079590\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.105667\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063452\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.123634\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.055475\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.137369\n",
      "done\n",
      "Regression error on test: 0.260831\n",
      "Regression error on test: 0.324671\n",
      "0.2608312964439392\n",
      "Regression error on test: 0.087788\n",
      "Regression error on test: 0.077753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031339\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081178\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027809\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.081619\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027203\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.080795\n",
      "done\n",
      "Regression error on test: 0.252245\n",
      "Regression error on test: 0.424047\n",
      "0.2522452473640442\n",
      "Regression error on test: 0.083151\n",
      "Regression error on test: 0.036989\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065471\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.106739\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.045016\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.124234\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037909\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.134546\n",
      "done\n",
      "Regression error on test: 0.236627\n",
      "Regression error on test: 0.384756\n",
      "0.23662708699703217\n",
      "Regression error on test: 0.082381\n",
      "Regression error on test: 0.067713\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035244\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092309\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034008\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.093041\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.034543\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.095290\n",
      "done\n",
      "Regression error on test: 0.221755\n",
      "Regression error on test: 0.276004\n",
      "0.22175529599189758\n",
      "Regression error on test: 0.078362\n",
      "Regression error on test: 0.173346\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059674\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060587\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043204\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059022\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040607\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.057899\n",
      "done\n",
      "Regression error on test: 0.219546\n",
      "Regression error on test: 0.159192\n",
      "0.21954606473445892\n",
      "Regression error on test: 0.063331\n",
      "Regression error on test: 0.116513\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158241\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052295\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.101588\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.070665\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056501\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.092333\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.227339\n",
      "Regression error on test: 0.173868\n",
      "0.2273394614458084\n",
      "Regression error on test: 0.053866\n",
      "Regression error on test: 0.138260\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.110812\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046020\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.094782\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047317\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.083807\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.052262\n",
      "done\n",
      "Regression error on test: 0.237295\n",
      "Regression error on test: 0.172077\n",
      "0.23729468882083893\n",
      "Regression error on test: 0.043768\n",
      "Regression error on test: 0.094345\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.126035\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040467\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.093953\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.052325\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.076943\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.063690\n",
      "done\n",
      "Regression error on test: 0.249263\n",
      "Regression error on test: 0.229336\n",
      "0.24926307797431946\n",
      "Regression error on test: 0.039895\n",
      "Regression error on test: 0.093344\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088382\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037603\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.071738\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045957\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.062506\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058526\n",
      "done\n",
      "Regression error on test: 0.264217\n",
      "Regression error on test: 0.217149\n",
      "0.26421669125556946\n",
      "Regression error on test: 0.034079\n",
      "Regression error on test: 0.042992\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.086857\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034145\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.066676\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049504\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053353\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.064396\n",
      "done\n",
      "Regression error on test: 0.273780\n",
      "Regression error on test: 0.247212\n",
      "0.27378004789352417\n",
      "Regression error on test: 0.033061\n",
      "Regression error on test: 0.036623\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039552\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031815\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031793\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035342\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.029820\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040028\n",
      "done\n",
      "Regression error on test: 0.282815\n",
      "Regression error on test: 0.238811\n",
      "0.28281542658805847\n",
      "Regression error on test: 0.034858\n",
      "Regression error on test: 0.031388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032107\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037975\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021778\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040093\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020801\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044378\n",
      "done\n",
      "Regression error on test: 0.295435\n",
      "Regression error on test: 0.267866\n",
      "0.29543519020080566\n",
      "Regression error on test: 0.038224\n",
      "Regression error on test: 0.029289\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030571\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037251\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028549\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039110\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027438\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041987\n",
      "done\n",
      "Regression error on test: 0.300331\n",
      "Regression error on test: 0.236039\n",
      "0.3003307282924652\n",
      "Regression error on test: 0.039884\n",
      "Regression error on test: 0.027518\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.024330\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042676\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015765\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046148\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014982\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046271\n",
      "done\n",
      "Regression error on test: 0.305171\n",
      "Regression error on test: 0.253911\n",
      "0.30517077445983887\n",
      "Regression error on test: 0.042521\n",
      "Regression error on test: 0.023040\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028144\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042596\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027472\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042392\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027276\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042468\n",
      "done\n",
      "Regression error on test: 0.312676\n",
      "Regression error on test: 0.237126\n",
      "0.3126762807369232\n",
      "Regression error on test: 0.048384\n",
      "Regression error on test: 0.021857\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023143\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048293\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023012\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048244\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023271\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048714\n",
      "done\n",
      "Regression error on test: 0.322763\n",
      "Regression error on test: 0.273421\n",
      "0.322763055562973\n",
      "Regression error on test: 0.050033\n",
      "Regression error on test: 0.037282\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021981\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049943\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021998\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049997\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022025\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050007\n",
      "done\n",
      "Regression error on test: 0.324831\n",
      "Regression error on test: 0.291761\n",
      "0.3248308002948761\n",
      "Regression error on test: 0.048662\n",
      "Regression error on test: 0.055613\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034741\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051004\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031941\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051696\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032528\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053179\n",
      "done\n",
      "Regression error on test: 0.322712\n",
      "Regression error on test: 0.378872\n",
      "0.32271242141723633\n",
      "Regression error on test: 0.052130\n",
      "Regression error on test: 0.035185\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054825\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055304\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052875\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055912\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053168\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.057925\n",
      "done\n",
      "Regression error on test: 0.305217\n",
      "Regression error on test: 0.312782\n",
      "0.30521702766418457\n",
      "Regression error on test: 0.054811\n",
      "Regression error on test: 0.032811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031410\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053767\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025427\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053755\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026197\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054328\n",
      "done\n",
      "Regression error on test: 0.296234\n",
      "Regression error on test: 0.337566\n",
      "0.2962341010570526\n",
      "Regression error on test: 0.055043\n",
      "Regression error on test: 0.054600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032720\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054369\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032489\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053498\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032111\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054588\n",
      "done\n",
      "Regression error on test: 0.288075\n",
      "Regression error on test: 0.365008\n",
      "0.2880747616291046\n",
      "Regression error on test: 0.054415\n",
      "Regression error on test: 0.065039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054266\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057938\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052699\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.056560\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052058\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059934\n",
      "done\n",
      "Regression error on test: 0.273418\n",
      "Regression error on test: 0.316822\n",
      "0.27341845631599426\n",
      "Regression error on test: 0.051053\n",
      "Regression error on test: 0.045894\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063878\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048048\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060954\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047286\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059429\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046721\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.284438\n",
      "0.26470237970352173\n",
      "Regression error on test: 0.051035\n",
      "Regression error on test: 0.053886\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042852\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046393\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037485\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045363\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036970\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045405\n",
      "done\n",
      "Regression error on test: 0.257963\n",
      "Regression error on test: 0.328967\n",
      "0.2579631805419922\n",
      "Regression error on test: 0.048933\n",
      "Regression error on test: 0.081669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048499\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064007\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039213\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.076728\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036039\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.079534\n",
      "done\n",
      "Regression error on test: 0.248783\n",
      "Regression error on test: 0.337994\n",
      "0.24878306686878204\n",
      "Regression error on test: 0.044736\n",
      "Regression error on test: 0.038354\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070993\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080024\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042657\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.105077\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032721\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.116514\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.238841\n",
      "Regression error on test: 0.294098\n",
      "0.23884063959121704\n",
      "Regression error on test: 0.045454\n",
      "Regression error on test: 0.023573\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038161\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042133\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037525\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038207\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037311\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039861\n",
      "done\n",
      "Regression error on test: 0.231860\n",
      "Regression error on test: 0.270577\n",
      "0.23185986280441284\n",
      "Regression error on test: 0.046971\n",
      "Regression error on test: 0.090293\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021494\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035821\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019470\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036614\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019118\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.033375\n",
      "done\n",
      "Regression error on test: 0.228843\n",
      "Regression error on test: 0.203918\n",
      "0.22884348034858704\n",
      "Regression error on test: 0.043821\n",
      "Regression error on test: 0.061994\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078153\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027336\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037185\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043176\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022042\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.051996\n",
      "done\n",
      "Regression error on test: 0.230210\n",
      "Regression error on test: 0.222953\n",
      "0.23021037876605988\n",
      "Regression error on test: 0.042227\n",
      "Regression error on test: 0.035126\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051472\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027111\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031293\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.029969\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028297\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.032037\n",
      "done\n",
      "Regression error on test: 0.232743\n",
      "Regression error on test: 0.255972\n",
      "0.2327425628900528\n",
      "Regression error on test: 0.047610\n",
      "Regression error on test: 0.048322\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034803\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040886\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034063\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037775\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033781\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034983\n",
      "done\n",
      "Regression error on test: 0.228450\n",
      "Regression error on test: 0.218445\n",
      "0.22844961285591125\n",
      "Regression error on test: 0.053526\n",
      "Regression error on test: 0.031418\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038124\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034699\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019727\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032272\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017166\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031950\n",
      "done\n",
      "Regression error on test: 0.226086\n",
      "Regression error on test: 0.229661\n",
      "0.2260863184928894\n",
      "Regression error on test: 0.056575\n",
      "Regression error on test: 0.045715\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028895\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044264\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024446\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040399\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023452\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040524\n",
      "done\n",
      "Regression error on test: 0.225170\n",
      "Regression error on test: 0.217046\n",
      "0.22517023980617523\n",
      "Regression error on test: 0.058598\n",
      "Regression error on test: 0.032868\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037527\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038855\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022950\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033956\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021005\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.033295\n",
      "done\n",
      "Regression error on test: 0.226957\n",
      "Regression error on test: 0.237166\n",
      "0.22695665061473846\n",
      "Regression error on test: 0.063042\n",
      "Regression error on test: 0.039700\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029916\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049612\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024360\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042717\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022097\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040455\n",
      "done\n",
      "Regression error on test: 0.226117\n",
      "Regression error on test: 0.238570\n",
      "0.22611671686172485\n",
      "Regression error on test: 0.066996\n",
      "Regression error on test: 0.045533\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036061\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054715\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030986\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049814\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.029632\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.049103\n",
      "done\n",
      "Regression error on test: 0.236251\n",
      "Regression error on test: 0.224290\n",
      "0.23625053465366364\n",
      "Regression error on test: 0.069430\n",
      "Regression error on test: 0.038743\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035312\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049940\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021537\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047375\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021067\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046229\n",
      "done\n",
      "Regression error on test: 0.240930\n",
      "Regression error on test: 0.240413\n",
      "0.24093002080917358\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.058793\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034041\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059869\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025848\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055983\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024959\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054452\n",
      "done\n",
      "Regression error on test: 0.253729\n",
      "Regression error on test: 0.217587\n",
      "0.2537294924259186\n",
      "Regression error on test: 0.066588\n",
      "Regression error on test: 0.046056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053714\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055084\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041292\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050549\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036683\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.051008\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.248275\n",
      "0.26470187306404114\n",
      "Regression error on test: 0.068380\n",
      "Regression error on test: 0.088950\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043180\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060762\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034911\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058973\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031965\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058020\n",
      "done\n",
      "Regression error on test: 0.278891\n",
      "Regression error on test: 0.213043\n",
      "0.278890997171402\n",
      "Regression error on test: 0.063563\n",
      "Regression error on test: 0.107488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076625\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062569\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031992\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075874\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016461\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.075666\n",
      "done\n",
      "Regression error on test: 0.296243\n",
      "Regression error on test: 0.194812\n",
      "0.2962426543235779\n",
      "Regression error on test: 0.059090\n",
      "Regression error on test: 0.061899\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.095149\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067464\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048868\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.095835\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020868\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.106822\n",
      "done\n",
      "Regression error on test: 0.317561\n",
      "Regression error on test: 0.220500\n",
      "0.31756100058555603\n",
      "Regression error on test: 0.057614\n",
      "Regression error on test: 0.065955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054707\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066610\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039791\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073976\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033367\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.082879\n",
      "done\n",
      "Regression error on test: 0.334063\n",
      "Regression error on test: 0.234910\n",
      "0.3340631127357483\n",
      "Regression error on test: 0.062140\n",
      "Regression error on test: 0.077302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055514\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080233\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030093\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.095782\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023439\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.096329\n",
      "done\n",
      "Regression error on test: 0.353975\n",
      "Regression error on test: 0.228766\n",
      "0.35397475957870483\n",
      "Regression error on test: 0.062371\n",
      "Regression error on test: 0.079238\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070634\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082627\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052296\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.098385\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.044165\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.112344\n",
      "done\n",
      "Regression error on test: 0.372552\n",
      "Regression error on test: 0.339908\n",
      "0.37255215644836426\n",
      "Regression error on test: 0.064429\n",
      "Regression error on test: 0.069872\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.074728\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052346\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057649\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051364\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.046233\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.055863\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.383426\n",
      "Regression error on test: 0.271085\n",
      "0.38342565298080444\n",
      "Regression error on test: 0.063655\n",
      "Regression error on test: 0.038643\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057763\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102784\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026879\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.117890\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025938\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.116526\n",
      "done\n",
      "Regression error on test: 0.390243\n",
      "Regression error on test: 0.368408\n",
      "0.39024287462234497\n",
      "Regression error on test: 0.070119\n",
      "Regression error on test: 0.030479\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034096\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060267\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028869\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058969\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028280\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059911\n",
      "done\n",
      "Regression error on test: 0.377002\n",
      "Regression error on test: 0.327311\n",
      "0.37700164318084717\n",
      "Regression error on test: 0.070296\n",
      "Regression error on test: 0.063970\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026902\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.078277\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023092\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.080359\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022411\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.079403\n",
      "done\n",
      "Regression error on test: 0.374148\n",
      "Regression error on test: 0.390166\n",
      "0.3741475045681\n",
      "Regression error on test: 0.068259\n",
      "Regression error on test: 0.040783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063094\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064099\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059994\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061358\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.058195\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059987\n",
      "done\n",
      "Regression error on test: 0.365729\n",
      "Regression error on test: 0.386560\n",
      "0.3657287657260895\n",
      "Regression error on test: 0.068756\n",
      "Regression error on test: 0.062762\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030468\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063608\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019522\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063709\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019310\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.063983\n",
      "done\n",
      "Regression error on test: 0.350445\n",
      "Regression error on test: 0.407995\n",
      "0.35044509172439575\n",
      "Regression error on test: 0.068803\n",
      "Regression error on test: 0.047133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048473\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.074384\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017375\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.078205\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018646\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.074081\n",
      "done\n",
      "Regression error on test: 0.328281\n",
      "Regression error on test: 0.385522\n",
      "0.3282812833786011\n",
      "Regression error on test: 0.066642\n",
      "Regression error on test: 0.111214\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042326\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068925\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032309\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.071960\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.029631\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.073382\n",
      "done\n",
      "Regression error on test: 0.314229\n",
      "Regression error on test: 0.434026\n",
      "0.31422919034957886\n",
      "Regression error on test: 0.058989\n",
      "Regression error on test: 0.079619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.099664\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073599\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069062\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092570\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.055424\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105165\n",
      "done\n",
      "Regression error on test: 0.290493\n",
      "Regression error on test: 0.414540\n",
      "0.2904933989048004\n",
      "Regression error on test: 0.057036\n",
      "Regression error on test: 0.099811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065662\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083540\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025912\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.097371\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023173\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.091899\n",
      "done\n",
      "Regression error on test: 0.272946\n",
      "Regression error on test: 0.448642\n",
      "0.2729457914829254\n",
      "Regression error on test: 0.060403\n",
      "Regression error on test: 0.062137\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085749\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088613\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.062182\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.096344\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060345\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.101476\n",
      "done\n",
      "Regression error on test: 0.245828\n",
      "Regression error on test: 0.339258\n",
      "0.24582824110984802\n",
      "Regression error on test: 0.059411\n",
      "Regression error on test: 0.103280\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061996\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056346\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.061802\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057333\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.061413\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053721\n",
      "done\n",
      "Regression error on test: 0.228155\n",
      "Regression error on test: 0.235996\n",
      "0.22815543413162231\n",
      "Regression error on test: 0.053799\n",
      "Regression error on test: 0.032249\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.093528\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039112\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.070985\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039253\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.057878\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.047098\n",
      "done\n",
      "Regression error on test: 0.220271\n",
      "Regression error on test: 0.298770\n",
      "0.2202712744474411\n",
      "Regression error on test: 0.055079\n",
      "Regression error on test: 0.043600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026129\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046055\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017918\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038236\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017900\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039637\n",
      "done\n",
      "Regression error on test: 0.206626\n",
      "Regression error on test: 0.305979\n",
      "0.2066257894039154\n",
      "Regression error on test: 0.055720\n",
      "Regression error on test: 0.045751\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043764\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064215\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043087\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.064341\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042537\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.064423\n",
      "done\n",
      "Regression error on test: 0.191440\n",
      "Regression error on test: 0.233722\n",
      "0.19144029915332794\n",
      "Regression error on test: 0.057435\n",
      "Regression error on test: 0.063239\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042737\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041831\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034416\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035753\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031870\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034096\n",
      "done\n",
      "Regression error on test: 0.187230\n",
      "Regression error on test: 0.186358\n",
      "0.18722979724407196\n",
      "Regression error on test: 0.057448\n",
      "Regression error on test: 0.025517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052655\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033825\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025969\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036384\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015817\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034560\n",
      "done\n",
      "Regression error on test: 0.184849\n",
      "Regression error on test: 0.245000\n",
      "0.184848815202713\n",
      "Regression error on test: 0.060472\n",
      "Regression error on test: 0.034682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025616\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054363\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025003\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059011\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024961\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054117\n",
      "done\n",
      "Regression error on test: 0.176822\n",
      "Regression error on test: 0.196668\n",
      "0.1768217384815216\n",
      "Regression error on test: 0.061501\n",
      "Regression error on test: 0.060097\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026637\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038143\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012693\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034910\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.012420\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034158\n",
      "done\n",
      "Regression error on test: 0.173460\n",
      "Regression error on test: 0.239064\n",
      "0.1734597384929657\n",
      "Regression error on test: 0.062084\n",
      "Regression error on test: 0.133477\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059304\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058990\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057561\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049991\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056810\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050330\n",
      "done\n",
      "Regression error on test: 0.173670\n",
      "Regression error on test: 0.177467\n",
      "0.17366991937160492\n",
      "Regression error on test: 0.059289\n",
      "Regression error on test: 0.052222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.121744\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028553\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090433\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027370\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.072613\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042385\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.168952\n",
      "Regression error on test: 0.162530\n",
      "0.168951615691185\n",
      "Regression error on test: 0.057997\n",
      "Regression error on test: 0.057566\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057835\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043430\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.046883\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035244\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041941\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034288\n",
      "done\n",
      "Regression error on test: 0.216129\n",
      "Regression error on test: 0.165961\n",
      "0.21612940728664398\n",
      "Regression error on test: 0.073794\n",
      "Regression error on test: 0.059231\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046749\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058125\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012856\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063896\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.007331\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.060307\n",
      "done\n",
      "Regression error on test: 0.254908\n",
      "Regression error on test: 0.158954\n",
      "0.2549078166484833\n",
      "Regression error on test: 0.071745\n",
      "Regression error on test: 0.057058\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048491\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059071\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011078\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.060835\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.006214\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.069368\n",
      "done\n",
      "Regression error on test: 0.270274\n",
      "Regression error on test: 0.161945\n",
      "0.27027350664138794\n",
      "Regression error on test: 0.082382\n",
      "Regression error on test: 0.054173\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046682\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077643\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018233\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.090593\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.010441\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.084753\n",
      "done\n",
      "Regression error on test: 0.305084\n",
      "Regression error on test: 0.160258\n",
      "0.3050840497016907\n",
      "Regression error on test: 0.097677\n",
      "Regression error on test: 0.047381\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043481\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101354\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.009283\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.106535\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.006110\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105600\n",
      "done\n",
      "Regression error on test: 0.344543\n",
      "Regression error on test: 0.163280\n",
      "0.34454345703125\n",
      "Regression error on test: 0.099663\n",
      "Regression error on test: 0.048677\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036744\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104920\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.005321\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.111946\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.007109\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105322\n",
      "done\n",
      "Regression error on test: 0.355526\n",
      "Regression error on test: 0.162178\n",
      "0.35552552342414856\n",
      "Regression error on test: 0.112753\n",
      "Regression error on test: 0.051180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037964\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117525\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.009315\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.120564\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.005268\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.119564\n",
      "done\n",
      "Regression error on test: 0.355586\n",
      "Regression error on test: 0.162218\n",
      "0.355586439371109\n",
      "Regression error on test: 0.123142\n",
      "Regression error on test: 0.047216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040494\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127793\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.006724\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.129260\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.005091\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.135014\n",
      "done\n",
      "Regression error on test: 0.353504\n",
      "Regression error on test: 0.263413\n",
      "0.3535038232803345\n",
      "Regression error on test: 0.135291\n",
      "Regression error on test: 0.033591\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.044007\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.135175\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038224\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.135175\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037655\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.135841\n",
      "done\n",
      "Regression error on test: 0.342894\n",
      "Regression error on test: 0.298133\n",
      "0.3428936302661896\n",
      "Regression error on test: 0.151426\n",
      "Regression error on test: 0.123897\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030205\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.149746\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026578\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.149180\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026555\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.149547\n",
      "done\n",
      "Regression error on test: 0.330533\n",
      "Regression error on test: 0.464954\n",
      "0.33053287863731384\n",
      "Regression error on test: 0.159658\n",
      "Regression error on test: 0.215538\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109926\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.178230\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057532\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.198774\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025006\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.203204\n",
      "done\n",
      "Regression error on test: 0.298201\n",
      "Regression error on test: 0.553744\n",
      "0.2982012629508972\n",
      "Regression error on test: 0.155887\n",
      "Regression error on test: 0.038740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.201046\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.186653\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.146691\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.219593\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.092325\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.257003\n",
      "done\n",
      "Regression error on test: 0.260420\n",
      "Regression error on test: 0.312611\n",
      "0.2604202926158905\n",
      "Regression error on test: 0.161906\n",
      "Regression error on test: 0.163422\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034046\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.149929\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029634\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.143458\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028150\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.143465\n",
      "done\n",
      "Regression error on test: 0.251510\n",
      "Regression error on test: 0.510050\n",
      "0.2515101730823517\n",
      "Regression error on test: 0.153620\n",
      "Regression error on test: 0.207127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.148141\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.198284\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090836\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.244503\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036151\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.282745\n",
      "done\n",
      "Regression error on test: 0.227162\n",
      "Regression error on test: 0.554852\n",
      "0.22716204822063446\n",
      "Regression error on test: 0.135698\n",
      "Regression error on test: 0.067245\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.190463\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.196140\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.128738\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.255702\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.079634\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.296754\n",
      "done\n",
      "Regression error on test: 0.203941\n",
      "Regression error on test: 0.273101\n",
      "0.2039414346218109\n",
      "Regression error on test: 0.149311\n",
      "Regression error on test: 0.179569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060676\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.112280\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042183\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101573\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041154\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.108530\n",
      "done\n",
      "Regression error on test: 0.201581\n",
      "Regression error on test: 0.162787\n",
      "0.20158080756664276\n",
      "Regression error on test: 0.134318\n",
      "Regression error on test: 0.155073\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160946\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.084261\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.094265\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066310\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.057765\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.068426\n",
      "done\n",
      "Regression error on test: 0.210833\n",
      "Regression error on test: 0.141392\n",
      "0.21083326637744904\n",
      "Regression error on test: 0.125349\n",
      "Regression error on test: 0.168702\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.138875\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082672\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.078939\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068514\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.048997\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.071504\n",
      "done\n",
      "Regression error on test: 0.231026\n",
      "Regression error on test: 0.157312\n",
      "0.23102594912052155\n",
      "Regression error on test: 0.117055\n",
      "Regression error on test: 0.194945\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.151660\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085054\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.091649\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.081856\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052980\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.090054\n",
      "done\n",
      "Regression error on test: 0.261571\n",
      "Regression error on test: 0.174525\n",
      "0.26157134771347046\n",
      "Regression error on test: 0.116121\n",
      "Regression error on test: 0.206218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.175954\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096220\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.106146\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.107340\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052874\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.136103\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.301176\n",
      "Regression error on test: 0.141638\n",
      "0.30117589235305786\n",
      "Regression error on test: 0.107900\n",
      "Regression error on test: 0.177830\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.188504\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100952\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.123144\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.119884\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.082939\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.134104\n",
      "done\n",
      "Regression error on test: 0.337311\n",
      "Regression error on test: 0.175934\n",
      "0.3373114764690399\n",
      "Regression error on test: 0.117214\n",
      "Regression error on test: 0.098930\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160069\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.123471\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.093480\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.160567\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036203\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.191238\n",
      "done\n",
      "Regression error on test: 0.387430\n",
      "Regression error on test: 0.223510\n",
      "0.3874301314353943\n",
      "Regression error on test: 0.137951\n",
      "Regression error on test: 0.080555\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.082927\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.155293\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029580\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.176148\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015173\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.184416\n",
      "done\n",
      "Regression error on test: 0.436770\n",
      "Regression error on test: 0.266569\n",
      "0.43676960468292236\n",
      "Regression error on test: 0.138017\n",
      "Regression error on test: 0.027908\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064028\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.164923\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021782\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.180412\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018541\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.180393\n",
      "done\n",
      "Regression error on test: 0.454916\n",
      "Regression error on test: 0.322645\n",
      "0.4549158215522766\n",
      "Regression error on test: 0.153624\n",
      "Regression error on test: 0.203377\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023496\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.160175\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019722\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.160128\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019864\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.160775\n",
      "done\n",
      "Regression error on test: 0.446340\n",
      "Regression error on test: 0.249495\n",
      "0.4463404715061188\n",
      "Regression error on test: 0.145058\n",
      "Regression error on test: 0.029640\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.180977\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.169295\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.115235\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.190565\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.092130\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.207780\n",
      "done\n",
      "Regression error on test: 0.449763\n",
      "Regression error on test: 0.255312\n",
      "0.44976332783699036\n",
      "Regression error on test: 0.153258\n",
      "Regression error on test: 0.065388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025951\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.158765\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022610\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.158545\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022594\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.157901\n",
      "done\n",
      "Regression error on test: 0.453223\n",
      "Regression error on test: 0.343319\n",
      "0.4532226026058197\n",
      "Regression error on test: 0.157865\n",
      "Regression error on test: 0.085754\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062995\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.161634\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.055462\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.164695\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053672\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.165482\n",
      "done\n",
      "Regression error on test: 0.446307\n",
      "Regression error on test: 0.462765\n",
      "0.4463065564632416\n",
      "Regression error on test: 0.158946\n",
      "Regression error on test: 0.185604\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077223\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.163342\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057371\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.165705\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053394\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.167318\n",
      "done\n",
      "Regression error on test: 0.429696\n",
      "Regression error on test: 0.570571\n",
      "0.42969605326652527\n",
      "Regression error on test: 0.155166\n",
      "Regression error on test: 0.124012\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169265\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.173454\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.107983\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.195704\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.054092\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.212314\n",
      "done\n",
      "Regression error on test: 0.388589\n",
      "Regression error on test: 0.502994\n",
      "0.3885892629623413\n",
      "Regression error on test: 0.159176\n",
      "Regression error on test: 0.270967\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107919\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189222\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.047567\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.219971\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015159\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.225295\n",
      "done\n",
      "Regression error on test: 0.358044\n",
      "Regression error on test: 0.677121\n",
      "0.3580436408519745\n",
      "Regression error on test: 0.143990\n",
      "Regression error on test: 0.306304\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.252818\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189429\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.184757\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.237771\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.117021\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.283435\n",
      "done\n",
      "Regression error on test: 0.314204\n",
      "Regression error on test: 0.716904\n",
      "0.3142043650150299\n",
      "Regression error on test: 0.132494\n",
      "Regression error on test: 0.081218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.287631\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.192093\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.217619\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.254573\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.147698\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.317777\n",
      "done\n",
      "Regression error on test: 0.260108\n",
      "Regression error on test: 0.448032\n",
      "0.2601081132888794\n",
      "Regression error on test: 0.144000\n",
      "Regression error on test: 0.183971\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077414\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.176305\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.073115\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.175932\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.073280\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.171122\n",
      "done\n",
      "Regression error on test: 0.231583\n",
      "Regression error on test: 0.236892\n",
      "0.23158305883407593\n",
      "Regression error on test: 0.146084\n",
      "Regression error on test: 0.117721\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161872\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073201\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.080635\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049973\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.029318\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.055023\n",
      "done\n",
      "Regression error on test: 0.224565\n",
      "Regression error on test: 0.283723\n",
      "0.224564790725708\n",
      "Regression error on test: 0.156430\n",
      "Regression error on test: 0.111636\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.096828\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085810\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028309\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.065116\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020459\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.070172\n",
      "done\n",
      "Regression error on test: 0.213813\n",
      "Regression error on test: 0.289904\n",
      "0.21381281316280365\n",
      "Regression error on test: 0.164548\n",
      "Regression error on test: 0.111461\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091127\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094582\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036447\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.070054\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033157\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.072186\n",
      "done\n",
      "Regression error on test: 0.202130\n",
      "Regression error on test: 0.274158\n",
      "0.2021297663450241\n",
      "Regression error on test: 0.168546\n",
      "Regression error on test: 0.096564\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091854\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100623\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028963\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.074327\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020336\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.069714\n",
      "done\n",
      "Regression error on test: 0.195746\n",
      "Regression error on test: 0.296661\n",
      "0.195746049284935\n",
      "Regression error on test: 0.175893\n",
      "Regression error on test: 0.147802\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077122\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.108721\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017993\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.079682\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014603\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.089899\n",
      "done\n",
      "Regression error on test: 0.186836\n",
      "Regression error on test: 0.159503\n",
      "0.18683630228042603\n",
      "Regression error on test: 0.178832\n",
      "Regression error on test: 0.164113\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130868\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114130\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.067783\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063668\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025982\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050485\n",
      "done\n",
      "Regression error on test: 0.189518\n",
      "Regression error on test: 0.197538\n",
      "0.18951833248138428\n",
      "Regression error on test: 0.175644\n",
      "Regression error on test: 0.119106\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.145658\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109781\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.084925\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.064676\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.061368\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.061271\n",
      "done\n",
      "Regression error on test: 0.193231\n",
      "Regression error on test: 0.238728\n",
      "0.19323135912418365\n",
      "Regression error on test: 0.182646\n",
      "Regression error on test: 0.191342\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.103285\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.121236\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059952\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.078763\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.044216\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.066539\n",
      "done\n",
      "Regression error on test: 0.190529\n",
      "Regression error on test: 0.175942\n",
      "0.1905294954776764\n",
      "Regression error on test: 0.181285\n",
      "Regression error on test: 0.196284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.171369\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109682\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.106421\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.060550\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.074530\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043844\n",
      "done\n",
      "Regression error on test: 0.196141\n",
      "Regression error on test: 0.162781\n",
      "0.19614125788211823\n",
      "Regression error on test: 0.175006\n",
      "Regression error on test: 0.204814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177020\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.106783\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.107838\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057430\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.066677\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044220\n",
      "done\n",
      "Regression error on test: 0.206939\n",
      "Regression error on test: 0.166709\n",
      "0.20693939924240112\n",
      "Regression error on test: 0.167447\n",
      "Regression error on test: 0.221176\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.185050\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.111079\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.110930\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068747\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.043581\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.067134\n",
      "done\n",
      "Regression error on test: 0.233683\n",
      "Regression error on test: 0.176204\n",
      "0.23368340730667114\n",
      "Regression error on test: 0.148788\n",
      "Regression error on test: 0.192814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.200440\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.103438\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.122635\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075048\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053190\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.080663\n",
      "done\n",
      "Regression error on test: 0.251618\n",
      "Regression error on test: 0.173074\n",
      "0.25161781907081604\n",
      "Regression error on test: 0.133013\n",
      "Regression error on test: 0.151440\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.173894\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102244\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.103836\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084732\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.049250\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.092592\n",
      "done\n",
      "Regression error on test: 0.270645\n",
      "Regression error on test: 0.210321\n",
      "0.2706454396247864\n",
      "Regression error on test: 0.122893\n",
      "Regression error on test: 0.170039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132845\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104913\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.071119\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.096949\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037903\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.097311\n",
      "done\n",
      "Regression error on test: 0.288149\n",
      "Regression error on test: 0.207563\n",
      "0.28814923763275146\n",
      "Regression error on test: 0.111307\n",
      "Regression error on test: 0.177196\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.154977\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097698\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.099786\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.095580\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052427\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.104983\n",
      "done\n",
      "Regression error on test: 0.295909\n",
      "Regression error on test: 0.186323\n",
      "0.29590868949890137\n",
      "Regression error on test: 0.099754\n",
      "Regression error on test: 0.132225\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159039\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096041\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090914\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109163\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.044504\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.122641\n",
      "done\n",
      "Regression error on test: 0.312279\n",
      "Regression error on test: 0.234668\n",
      "0.31227928400039673\n",
      "Regression error on test: 0.090488\n",
      "Regression error on test: 0.189127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.114065\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097989\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.051673\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110626\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032976\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.116300\n",
      "done\n",
      "Regression error on test: 0.323445\n",
      "Regression error on test: 0.211709\n",
      "0.32344508171081543\n",
      "Regression error on test: 0.079390\n",
      "Regression error on test: 0.177733\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169776\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.099550\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.097220\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.133459\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.055143\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.157350\n",
      "done\n",
      "Regression error on test: 0.341051\n",
      "Regression error on test: 0.232059\n",
      "0.34105050563812256\n",
      "Regression error on test: 0.069359\n",
      "Regression error on test: 0.133500\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158089\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102325\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.084907\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.145350\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040009\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.165239\n",
      "done\n",
      "Regression error on test: 0.352893\n",
      "Regression error on test: 0.270763\n",
      "0.3528931736946106\n",
      "Regression error on test: 0.060285\n",
      "Regression error on test: 0.129222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.120928\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094390\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.085550\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.122982\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.065557\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.143219\n",
      "done\n",
      "Regression error on test: 0.357090\n",
      "Regression error on test: 0.434149\n",
      "0.35708972811698914\n",
      "Regression error on test: 0.052655\n",
      "Regression error on test: 0.034584\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.117147\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039126\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.079417\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055013\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053482\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.073901\n",
      "done\n",
      "Regression error on test: 0.345406\n",
      "Regression error on test: 0.355548\n",
      "0.34540635347366333\n",
      "Regression error on test: 0.055666\n",
      "Regression error on test: 0.035065\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031846\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044898\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025969\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043276\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025266\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043007\n",
      "done\n",
      "Regression error on test: 0.341045\n",
      "Regression error on test: 0.363350\n",
      "0.34104543924331665\n",
      "Regression error on test: 0.060072\n",
      "Regression error on test: 0.050242\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027484\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047315\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024263\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048582\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024369\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.049307\n",
      "done\n",
      "Regression error on test: 0.337358\n",
      "Regression error on test: 0.385359\n",
      "0.3373579680919647\n",
      "Regression error on test: 0.062548\n",
      "Regression error on test: 0.054178\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038467\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046098\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022189\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046429\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022618\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.047190\n",
      "done\n",
      "Regression error on test: 0.329977\n",
      "Regression error on test: 0.285158\n",
      "0.329977422952652\n",
      "Regression error on test: 0.063296\n",
      "Regression error on test: 0.061669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041879\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.099975\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026000\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.106458\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025877\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.102407\n",
      "done\n",
      "Regression error on test: 0.331518\n",
      "Regression error on test: 0.350030\n",
      "0.3315184712409973\n",
      "Regression error on test: 0.064783\n",
      "Regression error on test: 0.039561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056988\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044328\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042607\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036505\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037334\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034464\n",
      "done\n",
      "Regression error on test: 0.327391\n",
      "Regression error on test: 0.346326\n",
      "0.3273911774158478\n",
      "Regression error on test: 0.068522\n",
      "Regression error on test: 0.078151\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035183\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049687\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028849\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051204\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028652\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044558\n",
      "done\n",
      "Regression error on test: 0.323734\n",
      "Regression error on test: 0.387763\n",
      "0.32373398542404175\n",
      "Regression error on test: 0.068630\n",
      "Regression error on test: 0.077424\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.071143\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043931\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.049829\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033509\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040006\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031617\n",
      "done\n",
      "Regression error on test: 0.316336\n",
      "Regression error on test: 0.350486\n",
      "0.3163362443447113\n",
      "Regression error on test: 0.070834\n",
      "Regression error on test: 0.042758\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.068013\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041674\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041522\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032790\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030325\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.033242\n",
      "done\n",
      "Regression error on test: 0.313635\n",
      "Regression error on test: 0.312728\n",
      "0.3136351704597473\n",
      "Regression error on test: 0.073850\n",
      "Regression error on test: 0.052918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032989\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045285\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019772\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.041927\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019523\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043761\n",
      "done\n",
      "Regression error on test: 0.312144\n",
      "Regression error on test: 0.317315\n",
      "0.31214433908462524\n",
      "Regression error on test: 0.075093\n",
      "Regression error on test: 0.064695\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046258\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047261\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.033288\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036757\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030564\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.035525\n",
      "done\n",
      "Regression error on test: 0.310107\n",
      "Regression error on test: 0.311938\n",
      "0.3101067841053009\n",
      "Regression error on test: 0.077521\n",
      "Regression error on test: 0.079127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063019\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060524\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056318\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047382\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052735\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041535\n",
      "done\n",
      "Regression error on test: 0.307643\n",
      "Regression error on test: 0.326474\n",
      "0.3076428771018982\n",
      "Regression error on test: 0.079261\n",
      "Regression error on test: 0.075003\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069493\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046450\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043567\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032815\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.035017\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.029112\n",
      "done\n",
      "Regression error on test: 0.304451\n",
      "Regression error on test: 0.311555\n",
      "0.30445125699043274\n",
      "Regression error on test: 0.079136\n",
      "Regression error on test: 0.061660\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065782\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047668\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042519\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033045\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036555\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.029254\n",
      "done\n",
      "Regression error on test: 0.301342\n",
      "Regression error on test: 0.300569\n",
      "0.30134159326553345\n",
      "Regression error on test: 0.080070\n",
      "Regression error on test: 0.076535\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052014\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046605\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028984\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037101\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024171\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034465\n",
      "done\n",
      "Regression error on test: 0.307600\n",
      "Regression error on test: 0.308756\n",
      "0.30759966373443604\n",
      "Regression error on test: 0.077504\n",
      "Regression error on test: 0.076955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065495\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042801\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028776\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032679\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018623\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.032639\n",
      "done\n",
      "Regression error on test: 0.315123\n",
      "Regression error on test: 0.309754\n",
      "0.31512337923049927\n",
      "Regression error on test: 0.077705\n",
      "Regression error on test: 0.079229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065913\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047451\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037925\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040009\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030160\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040730\n",
      "done\n",
      "Regression error on test: 0.314961\n",
      "Regression error on test: 0.313785\n",
      "0.3149605691432953\n",
      "Regression error on test: 0.077502\n",
      "Regression error on test: 0.099462\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.068978\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054851\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.040296\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050749\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030050\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054716\n",
      "done\n",
      "Regression error on test: 0.309780\n",
      "Regression error on test: 0.323476\n",
      "0.3097796142101288\n",
      "Regression error on test: 0.071562\n",
      "Regression error on test: 0.072918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088563\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052849\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.051403\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053626\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.035505\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.062839\n",
      "done\n",
      "Regression error on test: 0.312271\n",
      "Regression error on test: 0.297820\n",
      "0.3122708201408386\n",
      "Regression error on test: 0.068030\n",
      "Regression error on test: 0.065350\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062047\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052632\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031388\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054833\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024575\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056449\n",
      "done\n",
      "Regression error on test: 0.318478\n",
      "Regression error on test: 0.296940\n",
      "0.3184778690338135\n",
      "Regression error on test: 0.068847\n",
      "Regression error on test: 0.088975\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054549\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055804\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024882\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057958\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019223\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059437\n",
      "done\n",
      "Regression error on test: 0.326959\n",
      "Regression error on test: 0.287299\n",
      "0.3269594609737396\n",
      "Regression error on test: 0.064155\n",
      "Regression error on test: 0.096529\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078410\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056972\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039123\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073120\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018189\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.080133\n",
      "done\n",
      "Regression error on test: 0.329997\n",
      "Regression error on test: 0.294558\n",
      "0.3299967646598816\n",
      "Regression error on test: 0.059285\n",
      "Regression error on test: 0.073748\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.086543\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053701\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056103\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063121\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.044144\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.071797\n",
      "done\n",
      "Regression error on test: 0.337613\n",
      "Regression error on test: 0.280458\n",
      "0.3376132845878601\n",
      "Regression error on test: 0.055278\n",
      "Regression error on test: 0.071000\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063725\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055613\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036080\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066930\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027761\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.071354\n",
      "done\n",
      "Regression error on test: 0.339779\n",
      "Regression error on test: 0.363149\n",
      "0.339779257774353\n",
      "Regression error on test: 0.053268\n",
      "Regression error on test: 0.050878\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067605\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051685\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057904\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053489\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.054982\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.057918\n",
      "done\n",
      "Regression error on test: 0.333962\n",
      "Regression error on test: 0.383994\n",
      "0.3339623510837555\n",
      "Regression error on test: 0.053194\n",
      "Regression error on test: 0.078958\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037916\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060675\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016060\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059186\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016279\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.062215\n",
      "done\n",
      "Regression error on test: 0.320876\n",
      "Regression error on test: 0.308126\n",
      "0.32087594270706177\n",
      "Regression error on test: 0.048368\n",
      "Regression error on test: 0.077206\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079186\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049974\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.078735\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049123\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.078169\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050463\n",
      "done\n",
      "Regression error on test: 0.314376\n",
      "Regression error on test: 0.261976\n",
      "0.314375638961792\n",
      "Regression error on test: 0.048787\n",
      "Regression error on test: 0.040056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069535\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066356\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052528\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.080694\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.045876\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.087289\n",
      "done\n",
      "Regression error on test: 0.318877\n",
      "Regression error on test: 0.348387\n",
      "0.31887659430503845\n",
      "Regression error on test: 0.050438\n",
      "Regression error on test: 0.037605\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039295\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046151\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037207\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044870\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037119\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044874\n",
      "done\n",
      "Regression error on test: 0.312372\n",
      "Regression error on test: 0.359891\n",
      "0.31237226724624634\n",
      "Regression error on test: 0.048699\n",
      "Regression error on test: 0.073517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035514\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045139\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030898\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045009\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030758\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044819\n",
      "done\n",
      "Regression error on test: 0.299888\n",
      "Regression error on test: 0.381756\n",
      "0.2998881936073303\n",
      "Regression error on test: 0.045367\n",
      "Regression error on test: 0.042051\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070959\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043126\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.064209\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045616\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059577\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046080\n",
      "done\n",
      "Regression error on test: 0.286350\n",
      "Regression error on test: 0.317673\n",
      "0.2863500416278839\n",
      "Regression error on test: 0.043471\n",
      "Regression error on test: 0.047826\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042281\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043832\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042272\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042606\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041976\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043588\n",
      "done\n",
      "Regression error on test: 0.279744\n",
      "Regression error on test: 0.370723\n",
      "0.27974408864974976\n",
      "Regression error on test: 0.043033\n",
      "Regression error on test: 0.033682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042803\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043499\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034088\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045008\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033198\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.047206\n",
      "done\n",
      "Regression error on test: 0.265693\n",
      "Regression error on test: 0.302118\n",
      "0.2656926214694977\n",
      "Regression error on test: 0.044369\n",
      "Regression error on test: 0.050902\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032368\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049610\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030132\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049662\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030299\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.049106\n",
      "done\n",
      "Regression error on test: 0.259182\n",
      "Regression error on test: 0.304980\n",
      "0.2591819763183594\n",
      "Regression error on test: 0.043689\n",
      "Regression error on test: 0.050133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050172\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040038\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048389\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038830\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.047882\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.037949\n",
      "done\n",
      "Regression error on test: 0.251869\n",
      "Regression error on test: 0.253130\n",
      "0.2518688440322876\n",
      "Regression error on test: 0.045896\n",
      "Regression error on test: 0.030703\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.049892\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042985\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048756\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.041846\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.047815\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040232\n",
      "done\n",
      "Regression error on test: 0.252464\n",
      "Regression error on test: 0.243123\n",
      "0.25246402621269226\n",
      "Regression error on test: 0.046135\n",
      "Regression error on test: 0.081399\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022567\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037484\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.010438\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037308\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.011734\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.037316\n",
      "done\n",
      "Regression error on test: 0.251519\n",
      "Regression error on test: 0.306985\n",
      "0.2515185475349426\n",
      "Regression error on test: 0.042942\n",
      "Regression error on test: 0.056561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.073408\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034034\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.046623\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037113\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.039063\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040622\n",
      "done\n",
      "Regression error on test: 0.244537\n",
      "Regression error on test: 0.283344\n",
      "0.24453671276569366\n",
      "Regression error on test: 0.041054\n",
      "Regression error on test: 0.020216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052109\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033049\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039304\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034499\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037118\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.036464\n",
      "done\n",
      "Regression error on test: 0.252111\n",
      "Regression error on test: 0.235050\n",
      "0.2521113157272339\n",
      "Regression error on test: 0.044212\n",
      "Regression error on test: 0.040201\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.019027\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052205\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017252\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053127\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017220\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050287\n",
      "done\n",
      "Regression error on test: 0.266514\n",
      "Regression error on test: 0.246375\n",
      "0.26651430130004883\n",
      "Regression error on test: 0.046182\n",
      "Regression error on test: 0.023085\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040369\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046117\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039567\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044126\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.039352\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045709\n",
      "done\n",
      "Regression error on test: 0.277301\n",
      "Regression error on test: 0.251613\n",
      "0.27730050683021545\n",
      "Regression error on test: 0.048412\n",
      "Regression error on test: 0.043449\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017691\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.064617\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014318\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063620\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014096\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058711\n",
      "done\n",
      "Regression error on test: 0.281129\n",
      "Regression error on test: 0.230208\n",
      "0.28112930059432983\n",
      "Regression error on test: 0.048590\n",
      "Regression error on test: 0.047044\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042827\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043483\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041258\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039594\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040632\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.038284\n",
      "done\n",
      "Regression error on test: 0.294545\n",
      "Regression error on test: 0.237011\n",
      "0.29454508423805237\n",
      "Regression error on test: 0.048329\n",
      "Regression error on test: 0.044101\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036404\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034945\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.009337\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036177\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.009007\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034987\n",
      "done\n",
      "Regression error on test: 0.298135\n",
      "Regression error on test: 0.231849\n",
      "0.2981351912021637\n",
      "Regression error on test: 0.045603\n",
      "Regression error on test: 0.072201\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033648\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038421\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015960\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038527\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015406\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040047\n",
      "done\n",
      "Regression error on test: 0.295648\n",
      "Regression error on test: 0.259081\n",
      "0.29564815759658813\n",
      "Regression error on test: 0.107702\n",
      "Regression error on test: 0.139534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065364\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.087341\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.047565\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075964\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041106\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.073228\n",
      "done\n",
      "Regression error on test: 0.150728\n",
      "Regression error on test: 0.039339\n",
      "0.15072835981845856\n",
      "Regression error on test: 0.098447\n",
      "Regression error on test: 0.137116\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.129367\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081504\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.091240\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.070026\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053114\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.073622\n",
      "done\n",
      "Regression error on test: 0.181189\n",
      "Regression error on test: 0.042918\n",
      "0.18118895590305328\n",
      "Regression error on test: 0.110597\n",
      "Regression error on test: 0.117420\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.126937\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101370\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.088767\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.097620\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.050598\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.108979\n",
      "done\n",
      "Regression error on test: 0.229031\n",
      "Regression error on test: 0.070183\n",
      "0.229030579328537\n",
      "Regression error on test: 0.117865\n",
      "Regression error on test: 0.118753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107156\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.116511\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.068668\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.120773\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031426\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.137141\n",
      "done\n",
      "Regression error on test: 0.269985\n",
      "Regression error on test: 0.080901\n",
      "0.2699846029281616\n",
      "Regression error on test: 0.125451\n",
      "Regression error on test: 0.114937\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108322\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132007\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069203\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.144461\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031849\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.167835\n",
      "done\n",
      "Regression error on test: 0.301020\n",
      "Regression error on test: 0.084510\n",
      "0.30101993680000305\n",
      "Regression error on test: 0.116219\n",
      "Regression error on test: 0.108688\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.104465\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126932\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.065192\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.147056\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027902\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.173075\n",
      "done\n",
      "Regression error on test: 0.318761\n",
      "Regression error on test: 0.090517\n",
      "0.3187609910964966\n",
      "Regression error on test: 0.109202\n",
      "Regression error on test: 0.078587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.098211\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.126011\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058919\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.153590\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025816\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.182078\n",
      "done\n",
      "Regression error on test: 0.340227\n",
      "Regression error on test: 0.105296\n",
      "0.34022653102874756\n",
      "Regression error on test: 0.105053\n",
      "Regression error on test: 0.041248\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067989\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.125102\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030138\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.150809\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.010632\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.167271\n",
      "done\n",
      "Regression error on test: 0.355546\n",
      "Regression error on test: 0.221746\n",
      "0.3555458188056946\n",
      "Regression error on test: 0.103646\n",
      "Regression error on test: 0.069937\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037458\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114086\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027325\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.126783\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025539\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.124622\n",
      "done\n",
      "Regression error on test: 0.358761\n",
      "Regression error on test: 0.298115\n",
      "0.35876092314720154\n",
      "Regression error on test: 0.100638\n",
      "Regression error on test: 0.150801\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069918\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102410\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069339\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103019\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.069069\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.104208\n",
      "done\n",
      "Regression error on test: 0.353341\n",
      "Regression error on test: 0.473758\n",
      "0.35334083437919617\n",
      "Regression error on test: 0.087309\n",
      "Regression error on test: 0.046985\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.137487\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.092816\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.087550\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109106\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040456\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.125249\n",
      "done\n",
      "Regression error on test: 0.333873\n",
      "Regression error on test: 0.343945\n",
      "0.3338732123374939\n",
      "Regression error on test: 0.085655\n",
      "Regression error on test: 0.258611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042101\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.090555\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037334\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.090020\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036943\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.091030\n",
      "done\n",
      "Regression error on test: 0.326099\n",
      "Regression error on test: 0.521334\n",
      "0.3260987102985382\n",
      "Regression error on test: 0.063612\n",
      "Regression error on test: 0.190105\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.247358\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.081192\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.205147\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.106637\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.162958\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.133613\n",
      "done\n",
      "Regression error on test: 0.299056\n",
      "Regression error on test: 0.479723\n",
      "0.29905590415000916\n",
      "Regression error on test: 0.049122\n",
      "Regression error on test: 0.194607\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177892\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076845\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.132101\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.112775\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.086294\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.149898\n",
      "done\n",
      "Regression error on test: 0.274144\n",
      "Regression error on test: 0.391254\n",
      "0.2741442620754242\n",
      "Regression error on test: 0.035010\n",
      "Regression error on test: 0.022619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.183966\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065210\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.145750\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103161\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.111694\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.138257\n",
      "done\n",
      "Regression error on test: 0.259741\n",
      "Regression error on test: 0.261921\n",
      "0.2597413659095764\n",
      "Regression error on test: 0.047071\n",
      "Regression error on test: 0.038521\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.020868\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040558\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018768\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038737\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018557\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.038128\n",
      "done\n",
      "Regression error on test: 0.251055\n",
      "Regression error on test: 0.305172\n",
      "0.25105512142181396\n",
      "Regression error on test: 0.047282\n",
      "Regression error on test: 0.037099\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038092\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052471\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036314\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058390\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033607\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.067300\n",
      "done\n",
      "Regression error on test: 0.259291\n",
      "Regression error on test: 0.258489\n",
      "0.2592907249927521\n",
      "Regression error on test: 0.058139\n",
      "Regression error on test: 0.027171\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032159\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053419\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026307\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053692\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025902\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053451\n",
      "done\n",
      "Regression error on test: 0.282061\n",
      "Regression error on test: 0.253897\n",
      "0.28206053376197815\n",
      "Regression error on test: 0.062502\n",
      "Regression error on test: 0.039856\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021476\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061582\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014399\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061616\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014077\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.062355\n",
      "done\n",
      "Regression error on test: 0.297593\n",
      "Regression error on test: 0.243914\n",
      "0.29759272933006287\n",
      "Regression error on test: 0.076839\n",
      "Regression error on test: 0.017514\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036554\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080633\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026299\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.085528\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024341\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.089924\n",
      "done\n",
      "Regression error on test: 0.326751\n",
      "Regression error on test: 0.279083\n",
      "0.3267507553100586\n",
      "Regression error on test: 0.092650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.030450\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017219\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093408\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017299\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092719\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017995\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.092593\n",
      "done\n",
      "Regression error on test: 0.351109\n",
      "Regression error on test: 0.266199\n",
      "0.35110941529273987\n",
      "Regression error on test: 0.101631\n",
      "Regression error on test: 0.038180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026202\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.108573\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021803\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109953\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021817\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.108381\n",
      "done\n",
      "Regression error on test: 0.364865\n",
      "Regression error on test: 0.250906\n",
      "0.36486461758613586\n",
      "Regression error on test: 0.101583\n",
      "Regression error on test: 0.045204\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031144\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.112926\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020411\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.118904\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017213\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.125331\n",
      "done\n",
      "Regression error on test: 0.373377\n",
      "Regression error on test: 0.230607\n",
      "0.3733765780925751\n",
      "Regression error on test: 0.098531\n",
      "Regression error on test: 0.053482\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035155\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.120103\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018670\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.130213\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015924\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.134973\n",
      "done\n",
      "Regression error on test: 0.380809\n",
      "Regression error on test: 0.247226\n",
      "0.38080930709838867\n",
      "Regression error on test: 0.095360\n",
      "Regression error on test: 0.143228\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053270\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.095957\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052493\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.097396\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.051252\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.098904\n",
      "done\n",
      "Regression error on test: 0.383308\n",
      "Regression error on test: 0.175058\n",
      "0.38330841064453125\n",
      "Regression error on test: 0.085635\n",
      "Regression error on test: 0.040639\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.131457\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.120235\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.091000\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.155980\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.063350\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.189430\n",
      "done\n",
      "Regression error on test: 0.386189\n",
      "Regression error on test: 0.387529\n",
      "0.38618943095207214\n",
      "Regression error on test: 0.085331\n",
      "Regression error on test: 0.145662\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037830\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077678\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031290\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073344\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026302\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.073646\n",
      "done\n",
      "Regression error on test: 0.365312\n",
      "Regression error on test: 0.486187\n",
      "0.36531195044517517\n",
      "Regression error on test: 0.073332\n",
      "Regression error on test: 0.070801\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132173\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068893\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.081580\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084319\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031515\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105268\n",
      "done\n",
      "Regression error on test: 0.334898\n",
      "Regression error on test: 0.409219\n",
      "0.3348983824253082\n",
      "Regression error on test: 0.075009\n",
      "Regression error on test: 0.183229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057436\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079806\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016122\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.086134\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014025\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.086606\n",
      "done\n",
      "Regression error on test: 0.309346\n",
      "Regression error on test: 0.535494\n",
      "0.309345543384552\n",
      "Regression error on test: 0.061343\n",
      "Regression error on test: 0.175627\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169018\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075795\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.120043\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.095946\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.094962\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110001\n",
      "done\n",
      "Regression error on test: 0.272681\n",
      "Regression error on test: 0.522669\n",
      "0.27268120646476746\n",
      "Regression error on test: 0.050995\n",
      "Regression error on test: 0.120262\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161508\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.075042\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.108542\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.111852\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060206\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.146418\n",
      "done\n",
      "Regression error on test: 0.236238\n",
      "Regression error on test: 0.403751\n",
      "0.236238494515419\n",
      "Regression error on test: 0.046384\n",
      "Regression error on test: 0.037693\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.108336\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077362\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.066721\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.111654\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.045230\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.128082\n",
      "done\n",
      "Regression error on test: 0.210513\n",
      "Regression error on test: 0.336025\n",
      "0.21051329374313354\n",
      "Regression error on test: 0.049061\n",
      "Regression error on test: 0.014685\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030489\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073580\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016010\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.076376\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016491\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.079116\n",
      "done\n",
      "Regression error on test: 0.194982\n",
      "Regression error on test: 0.304935\n",
      "0.19498211145401\n",
      "Regression error on test: 0.055631\n",
      "Regression error on test: 0.021774\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.014074\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067178\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012973\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063246\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.012881\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.061946\n",
      "done\n",
      "Regression error on test: 0.181006\n",
      "Regression error on test: 0.272216\n",
      "0.18100640177726746\n",
      "Regression error on test: 0.064370\n",
      "Regression error on test: 0.045976\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.017771\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052421\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.013322\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048012\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.013815\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.051210\n",
      "done\n",
      "Regression error on test: 0.171424\n",
      "Regression error on test: 0.203868\n",
      "0.17142435908317566\n",
      "Regression error on test: 0.067106\n",
      "Regression error on test: 0.037598\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043050\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048408\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035074\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.041496\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032783\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.037124\n",
      "done\n",
      "Regression error on test: 0.167077\n",
      "Regression error on test: 0.178755\n",
      "0.16707675158977509\n",
      "Regression error on test: 0.072278\n",
      "Regression error on test: 0.025673\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029542\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048604\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019414\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049471\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019471\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042871\n",
      "done\n",
      "Regression error on test: 0.166541\n",
      "Regression error on test: 0.182051\n",
      "0.16654103994369507\n",
      "Regression error on test: 0.074156\n",
      "Regression error on test: 0.087569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023016\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057084\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019213\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054519\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019243\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053115\n",
      "done\n",
      "Regression error on test: 0.177487\n",
      "Regression error on test: 0.153690\n",
      "0.1774866133928299\n",
      "Regression error on test: 0.070530\n",
      "Regression error on test: 0.046570\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076533\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036158\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035190\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.028113\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.013862\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031599\n",
      "done\n",
      "Regression error on test: 0.189271\n",
      "Regression error on test: 0.168851\n",
      "0.18927137553691864\n",
      "Regression error on test: 0.069459\n",
      "Regression error on test: 0.072148\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037624\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045616\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023479\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.035962\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018964\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031480\n",
      "done\n",
      "Regression error on test: 0.199294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.158242\n",
      "0.1992940455675125\n",
      "Regression error on test: 0.069770\n",
      "Regression error on test: 0.074150\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061363\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036028\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023571\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027390\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014671\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.027477\n",
      "done\n",
      "Regression error on test: 0.208236\n",
      "Regression error on test: 0.146499\n",
      "0.20823587477207184\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.064470\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063459\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.035970\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025421\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027851\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.013746\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.029441\n",
      "done\n",
      "Regression error on test: 0.216380\n",
      "Regression error on test: 0.180713\n",
      "0.21637964248657227\n",
      "Regression error on test: 0.068701\n",
      "Regression error on test: 0.080382\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056105\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039240\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036977\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.029476\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030506\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.026828\n",
      "done\n",
      "Regression error on test: 0.221287\n",
      "Regression error on test: 0.165177\n",
      "0.22128742933273315\n",
      "Regression error on test: 0.065381\n",
      "Regression error on test: 0.109164\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069308\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038275\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032758\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036358\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019028\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043157\n",
      "done\n",
      "Regression error on test: 0.233844\n",
      "Regression error on test: 0.176396\n",
      "0.23384396731853485\n",
      "Regression error on test: 0.059033\n",
      "Regression error on test: 0.073335\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097108\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032842\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058458\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034473\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.043317\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046835\n",
      "done\n",
      "Regression error on test: 0.235233\n",
      "Regression error on test: 0.160392\n",
      "0.23523321747779846\n",
      "Regression error on test: 0.057307\n",
      "Regression error on test: 0.089314\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062413\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032473\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027614\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033255\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017312\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.037463\n",
      "done\n",
      "Regression error on test: 0.238371\n",
      "Regression error on test: 0.173398\n",
      "0.23837052285671234\n",
      "Regression error on test: 0.051771\n",
      "Regression error on test: 0.044454\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078056\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028967\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.040225\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036978\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028477\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.037895\n",
      "done\n",
      "Regression error on test: 0.241276\n",
      "Regression error on test: 0.291507\n",
      "0.24127615988254547\n",
      "Regression error on test: 0.051454\n",
      "Regression error on test: 0.051316\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040554\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036503\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037381\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037416\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036059\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.032067\n",
      "done\n",
      "Regression error on test: 0.232186\n",
      "Regression error on test: 0.271538\n",
      "0.23218563199043274\n",
      "Regression error on test: 0.049474\n",
      "Regression error on test: 0.035855\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039275\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.026522\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011500\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.026508\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.010625\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.026699\n",
      "done\n",
      "Regression error on test: 0.225921\n",
      "Regression error on test: 0.269078\n",
      "0.2259206771850586\n",
      "Regression error on test: 0.050506\n",
      "Regression error on test: 0.075265\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027611\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034077\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015914\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.030622\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014753\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.029135\n",
      "done\n",
      "Regression error on test: 0.220163\n",
      "Regression error on test: 0.247661\n",
      "0.22016292810440063\n",
      "Regression error on test: 0.047875\n",
      "Regression error on test: 0.070642\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061530\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.025275\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015368\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037237\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.011500\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031299\n",
      "done\n",
      "Regression error on test: 0.214841\n",
      "Regression error on test: 0.227937\n",
      "0.2148410677909851\n",
      "Regression error on test: 0.044485\n",
      "Regression error on test: 0.057288\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058003\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023763\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024372\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032125\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018247\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.033246\n",
      "done\n",
      "Regression error on test: 0.213018\n",
      "Regression error on test: 0.229791\n",
      "0.21301797032356262\n",
      "Regression error on test: 0.043193\n",
      "Regression error on test: 0.047174\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045235\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.022918\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018428\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.025054\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015714\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.029006\n",
      "done\n",
      "Regression error on test: 0.211541\n",
      "Regression error on test: 0.290743\n",
      "0.21154069900512695\n",
      "Regression error on test: 0.045711\n",
      "Regression error on test: 0.045683\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042869\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.069154\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.033141\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.085689\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030077\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.087045\n",
      "done\n",
      "Regression error on test: 0.201323\n",
      "Regression error on test: 0.190288\n",
      "0.2013225555419922\n",
      "Regression error on test: 0.050832\n",
      "Regression error on test: 0.056078\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036655\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.024987\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019367\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.020794\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017786\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.020722\n",
      "done\n",
      "Regression error on test: 0.200882\n",
      "Regression error on test: 0.191765\n",
      "0.20088176429271698\n",
      "Regression error on test: 0.058903\n",
      "Regression error on test: 0.033952\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.044990\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028242\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022481\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.027270\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022311\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.027432\n",
      "done\n",
      "Regression error on test: 0.196906\n",
      "Regression error on test: 0.202454\n",
      "0.19690632820129395\n",
      "Regression error on test: 0.066825\n",
      "Regression error on test: 0.041284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025322\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039700\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.014082\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037187\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014270\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041614\n",
      "done\n",
      "Regression error on test: 0.192878\n",
      "Regression error on test: 0.200602\n",
      "0.19287799298763275\n",
      "Regression error on test: 0.068962\n",
      "Regression error on test: 0.031517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030330\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038107\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011768\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038698\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.011468\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040001\n",
      "done\n",
      "Regression error on test: 0.195240\n",
      "Regression error on test: 0.208888\n",
      "0.1952401101589203\n",
      "Regression error on test: 0.070459\n",
      "Regression error on test: 0.046177\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.024421\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050085\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015728\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051096\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015366\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.047264\n",
      "done\n",
      "Regression error on test: 0.200457\n",
      "Regression error on test: 0.211501\n",
      "0.20045745372772217\n",
      "Regression error on test: 0.073136\n",
      "Regression error on test: 0.048955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037391\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046120\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021741\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040920\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020376\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043195\n",
      "done\n",
      "Regression error on test: 0.204080\n",
      "Regression error on test: 0.194442\n",
      "0.20407989621162415\n",
      "Regression error on test: 0.072086\n",
      "Regression error on test: 0.036740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037879\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043204\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012623\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039048\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.012739\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042045\n",
      "done\n",
      "Regression error on test: 0.211465\n",
      "Regression error on test: 0.209705\n",
      "0.2114654928445816\n",
      "Regression error on test: 0.070692\n",
      "Regression error on test: 0.044373\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.026207\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048823\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011405\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050963\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.011260\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046847\n",
      "done\n",
      "Regression error on test: 0.220132\n",
      "Regression error on test: 0.215019\n",
      "0.22013194859027863\n",
      "Regression error on test: 0.067967\n",
      "Regression error on test: 0.072355\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033465\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048923\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012282\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050191\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.012558\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048894\n",
      "done\n",
      "Regression error on test: 0.229265\n",
      "Regression error on test: 0.188561\n",
      "0.22926509380340576\n",
      "Regression error on test: 0.065854\n",
      "Regression error on test: 0.096889\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060952\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046895\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023562\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045543\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015778\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044464\n",
      "done\n",
      "Regression error on test: 0.236927\n",
      "Regression error on test: 0.185880\n",
      "0.2369273453950882\n",
      "Regression error on test: 0.061476\n",
      "Regression error on test: 0.136783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085028\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043119\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.040811\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049807\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016747\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056735\n",
      "done\n",
      "Regression error on test: 0.245079\n",
      "Regression error on test: 0.152011\n",
      "0.2450791746377945\n",
      "Regression error on test: 0.053248\n",
      "Regression error on test: 0.113175\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125115\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040382\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.081360\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055010\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037586\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.091799\n",
      "done\n",
      "Regression error on test: 0.258688\n",
      "Regression error on test: 0.162171\n",
      "0.2586883306503296\n",
      "Regression error on test: 0.045083\n",
      "Regression error on test: 0.062657\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.101657\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.036307\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058456\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059173\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018409\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.076394\n",
      "done\n",
      "Regression error on test: 0.271844\n",
      "Regression error on test: 0.224223\n",
      "0.27184411883354187\n",
      "Regression error on test: 0.044747\n",
      "Regression error on test: 0.046488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061774\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040090\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058033\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039137\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056423\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039196\n",
      "done\n",
      "Regression error on test: 0.287161\n",
      "Regression error on test: 0.261062\n",
      "0.2871612012386322\n",
      "Regression error on test: 0.042894\n",
      "Regression error on test: 0.072942\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.045412\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039728\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042209\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039405\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041082\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039314\n",
      "done\n",
      "Regression error on test: 0.293182\n",
      "Regression error on test: 0.247725\n",
      "0.29318225383758545\n",
      "Regression error on test: 0.038665\n",
      "Regression error on test: 0.038453\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059588\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045965\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017605\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061876\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.010574\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.060488\n",
      "done\n",
      "Regression error on test: 0.297030\n",
      "Regression error on test: 0.268298\n",
      "0.29703041911125183\n",
      "Regression error on test: 0.042092\n",
      "Regression error on test: 0.022804\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035460\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040230\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029440\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040946\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027538\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040939\n",
      "done\n",
      "Regression error on test: 0.288786\n",
      "Regression error on test: 0.296370\n",
      "0.288785845041275\n",
      "Regression error on test: 0.047586\n",
      "Regression error on test: 0.017127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022024\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045732\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020472\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044622\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020103\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045102\n",
      "done\n",
      "Regression error on test: 0.275285\n",
      "Regression error on test: 0.306350\n",
      "0.2752852439880371\n",
      "Regression error on test: 0.054457\n",
      "Regression error on test: 0.051220\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.016792\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051317\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017884\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054619\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017084\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056173\n",
      "done\n",
      "Regression error on test: 0.260024\n",
      "Regression error on test: 0.265184\n",
      "0.2600238025188446\n",
      "Regression error on test: 0.056978\n",
      "Regression error on test: 0.053108\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041144\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047864\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015583\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048918\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.011876\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048554\n",
      "done\n",
      "Regression error on test: 0.248906\n",
      "Regression error on test: 0.267398\n",
      "0.24890591204166412\n",
      "Regression error on test: 0.058456\n",
      "Regression error on test: 0.054505\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041328\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048989\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015548\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048949\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014798\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048944\n",
      "done\n",
      "Regression error on test: 0.237896\n",
      "Regression error on test: 0.288103\n",
      "0.2378964126110077\n",
      "Regression error on test: 0.059196\n",
      "Regression error on test: 0.031521\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054338\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062650\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053168\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.065624\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053443\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.069761\n",
      "done\n",
      "Regression error on test: 0.224656\n",
      "Regression error on test: 0.293729\n",
      "0.22465600073337555\n",
      "Regression error on test: 0.060223\n",
      "Regression error on test: 0.059307\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028853\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052458\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020719\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049615\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019262\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.052551\n",
      "done\n",
      "Regression error on test: 0.213578\n",
      "Regression error on test: 0.377394\n",
      "0.21357819437980652\n",
      "Regression error on test: 0.062761\n",
      "Regression error on test: 0.027955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052489\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.088516\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031261\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.097975\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025913\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.114703\n",
      "done\n",
      "Regression error on test: 0.190290\n",
      "Regression error on test: 0.321272\n",
      "0.19028989970684052\n",
      "Regression error on test: 0.065029\n",
      "Regression error on test: 0.030653\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027308\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.069720\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024983\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075732\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024986\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.067585\n",
      "done\n",
      "Regression error on test: 0.176353\n",
      "Regression error on test: 0.286206\n",
      "0.17635251581668854\n",
      "Regression error on test: 0.067043\n",
      "Regression error on test: 0.072724\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030696\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068177\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030651\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066509\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030630\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.067590\n",
      "done\n",
      "Regression error on test: 0.164795\n",
      "Regression error on test: 0.185853\n",
      "0.16479504108428955\n",
      "Regression error on test: 0.066627\n",
      "Regression error on test: 0.077738\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060941\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027994\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026636\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.017166\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020747\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.016806\n",
      "done\n",
      "Regression error on test: 0.161276\n",
      "Regression error on test: 0.161363\n",
      "0.16127590835094452\n",
      "Regression error on test: 0.065062\n",
      "Regression error on test: 0.085843\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066511\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027304\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024410\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.022945\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.006931\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.019948\n",
      "done\n",
      "Regression error on test: 0.160141\n",
      "Regression error on test: 0.153736\n",
      "0.1601407825946808\n",
      "Regression error on test: 0.062124\n",
      "Regression error on test: 0.076426\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.074124\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.024068\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.036590\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.017076\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018380\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.027808\n",
      "done\n",
      "Regression error on test: 0.160747\n",
      "Regression error on test: 0.154005\n",
      "0.1607469618320465\n",
      "Regression error on test: 0.059821\n",
      "Regression error on test: 0.067885\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065322\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023532\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027224\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.021887\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.010960\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.020234\n",
      "done\n",
      "Regression error on test: 0.161861\n",
      "Regression error on test: 0.157303\n",
      "0.16186124086380005\n",
      "Regression error on test: 0.057468\n",
      "Regression error on test: 0.061910\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.056924\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.023166\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019901\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.017568\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014500\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.017632\n",
      "done\n",
      "Regression error on test: 0.164609\n",
      "Regression error on test: 0.155698\n",
      "0.16460944712162018\n",
      "Regression error on test: 0.061770\n",
      "Regression error on test: 0.041785\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.051252\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.028268\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.013266\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.021818\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.005684\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.025336\n",
      "done\n",
      "Regression error on test: 0.160782\n",
      "Regression error on test: 0.182951\n",
      "0.16078175604343414\n",
      "Regression error on test: 0.144789\n",
      "Regression error on test: 0.204599\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.092839\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.122532\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.081871\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.112795\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.077469\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105355\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.075139\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.104045\n",
      "done\n",
      "Regression error on test: 0.131772\n",
      "Regression error on test: 0.042639\n",
      "0.13177210092544556\n",
      "Regression error on test: 0.145688\n",
      "Regression error on test: 0.150315\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.193621\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.122633\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.152454\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101341\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.111287\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.085215\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.070116\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.088970\n",
      "done\n",
      "Regression error on test: 0.184600\n",
      "Regression error on test: 0.093331\n",
      "0.18459992110729218\n",
      "Regression error on test: 0.136736\n",
      "Regression error on test: 0.169615\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139391\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.118158\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.098582\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103918\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.065197\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.095729\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.039593\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.095171\n",
      "done\n",
      "Regression error on test: 0.207958\n",
      "Regression error on test: 0.063799\n",
      "0.2079579383134842\n",
      "Regression error on test: 0.127920\n",
      "Regression error on test: 0.141182\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158885\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117124\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.118649\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110443\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.078416\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110018\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038177\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.126826\n",
      "done\n",
      "Regression error on test: 0.242952\n",
      "Regression error on test: 0.084222\n",
      "0.24295160174369812\n",
      "Regression error on test: 0.143248\n",
      "Regression error on test: 0.136221\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130574\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140804\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090795\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.142354\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.051130\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.148647\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028040\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.155608\n",
      "done\n",
      "Regression error on test: 0.299013\n",
      "Regression error on test: 0.084511\n",
      "0.2990131974220276\n",
      "Regression error on test: 0.144645\n",
      "Regression error on test: 0.150048\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125671\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.150348\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.086112\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.159980\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.046556\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.174937\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.011996\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.185420\n",
      "done\n",
      "Regression error on test: 0.337131\n",
      "Regression error on test: 0.068855\n",
      "0.33713090419769287\n",
      "Regression error on test: 0.136637\n",
      "Regression error on test: 0.135629\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.139511\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.143225\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.100001\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.156748\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060496\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.178081\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.021772\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.203300\n",
      "done\n",
      "Regression error on test: 0.354753\n",
      "Regression error on test: 0.083461\n",
      "0.3547532260417938\n",
      "Regression error on test: 0.134216\n",
      "Regression error on test: 0.088064\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125085\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140575\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.085545\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.155080\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.046000\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.179625\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.015621\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.189943\n",
      "done\n",
      "Regression error on test: 0.363729\n",
      "Regression error on test: 0.182394\n",
      "0.3637290894985199\n",
      "Regression error on test: 0.131674\n",
      "Regression error on test: 0.170302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079929\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.137377\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.054551\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.145435\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042352\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.153843\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038066\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.160536\n",
      "done\n",
      "Regression error on test: 0.368891\n",
      "Regression error on test: 0.177624\n",
      "0.36889126896858215\n",
      "Regression error on test: 0.127905\n",
      "Regression error on test: 0.101916\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.156389\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.137261\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.104304\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.161000\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060416\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.193457\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030537\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.218208\n",
      "done\n",
      "Regression error on test: 0.367889\n",
      "Regression error on test: 0.436884\n",
      "0.36788949370384216\n",
      "Regression error on test: 0.129125\n",
      "Regression error on test: 0.213587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091838\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.135341\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069003\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.140319\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.061230\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.143643\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.058748\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.144750\n",
      "done\n",
      "Regression error on test: 0.343494\n",
      "Regression error on test: 0.570917\n",
      "0.34349411725997925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.121165\n",
      "Regression error on test: 0.060791\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.198945\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.141119\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.144017\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.167280\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.089239\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.197415\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.047290\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.220911\n",
      "done\n",
      "Regression error on test: 0.306705\n",
      "Regression error on test: 0.326911\n",
      "0.30670472979545593\n",
      "Regression error on test: 0.121355\n",
      "Regression error on test: 0.081464\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061340\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.119309\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060805\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.119061\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.061250\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.120556\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.060576\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.121476\n",
      "done\n",
      "Regression error on test: 0.301218\n",
      "Regression error on test: 0.413736\n",
      "0.3012184500694275\n",
      "Regression error on test: 0.117664\n",
      "Regression error on test: 0.294457\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.081282\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.121527\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.077310\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.129112\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.073209\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.136494\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.071741\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.137366\n",
      "done\n",
      "Regression error on test: 0.290323\n",
      "Regression error on test: 0.644838\n",
      "0.29032278060913086\n",
      "Regression error on test: 0.096449\n",
      "Regression error on test: 0.150195\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.279448\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.132454\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.223157\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.173568\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.166888\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.219685\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.110646\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.269557\n",
      "done\n",
      "Regression error on test: 0.253652\n",
      "Regression error on test: 0.465688\n",
      "0.25365179777145386\n",
      "Regression error on test: 0.085740\n",
      "Regression error on test: 0.069959\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.136801\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.128657\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.086677\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.173305\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053126\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.201157\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.043380\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.212683\n",
      "done\n",
      "Regression error on test: 0.234045\n",
      "Regression error on test: 0.245079\n",
      "0.23404453694820404\n",
      "Regression error on test: 0.091803\n",
      "Regression error on test: 0.111423\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060555\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063729\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038412\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057307\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036153\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056819\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.036038\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.057474\n",
      "done\n",
      "Regression error on test: 0.237400\n",
      "Regression error on test: 0.173220\n",
      "0.2374003678560257\n",
      "Regression error on test: 0.088243\n",
      "Regression error on test: 0.062646\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.097895\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056225\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053205\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050570\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036995\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053362\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.033255\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.054804\n",
      "done\n",
      "Regression error on test: 0.258664\n",
      "Regression error on test: 0.234015\n",
      "0.2586643695831299\n",
      "Regression error on test: 0.090106\n",
      "Regression error on test: 0.132611\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050490\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068826\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027876\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.065424\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026440\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.065034\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026396\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.066385\n",
      "done\n",
      "Regression error on test: 0.287353\n",
      "Regression error on test: 0.167606\n",
      "0.2873528301715851\n",
      "Regression error on test: 0.078688\n",
      "Regression error on test: 0.114119\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.118845\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.065727\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.071592\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.072835\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.043587\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.088011\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.032189\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.101413\n",
      "done\n",
      "Regression error on test: 0.317365\n",
      "Regression error on test: 0.192931\n",
      "0.3173651695251465\n",
      "Regression error on test: 0.084808\n",
      "Regression error on test: 0.133988\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.102788\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.080749\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069569\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.090283\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.047033\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105297\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038256\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.113533\n",
      "done\n",
      "Regression error on test: 0.358520\n",
      "Regression error on test: 0.203024\n",
      "0.3585202097892761\n",
      "Regression error on test: 0.093019\n",
      "Regression error on test: 0.062687\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.119120\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101990\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063345\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.135829\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021941\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.155401\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.019465\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.151847\n",
      "done\n",
      "Regression error on test: 0.403658\n",
      "Regression error on test: 0.272048\n",
      "0.40365785360336304\n",
      "Regression error on test: 0.096435\n",
      "Regression error on test: 0.044552\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.061543\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.098911\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056786\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101027\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.054672\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.104129\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.050473\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.109839\n",
      "done\n",
      "Regression error on test: 0.426108\n",
      "Regression error on test: 0.304779\n",
      "0.42610761523246765\n",
      "Regression error on test: 0.097979\n",
      "Regression error on test: 0.082305\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042750\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101609\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038413\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.103458\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036471\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110296\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.036602\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.106359\n",
      "done\n",
      "Regression error on test: 0.432311\n",
      "Regression error on test: 0.278129\n",
      "0.4323112368583679\n",
      "Regression error on test: 0.097754\n",
      "Regression error on test: 0.043110\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.079397\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104798\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.070925\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.115314\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.065988\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.120711\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.066380\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.120630\n",
      "done\n",
      "Regression error on test: 0.445569\n",
      "Regression error on test: 0.269615\n",
      "0.44556868076324463\n",
      "Regression error on test: 0.102056\n",
      "Regression error on test: 0.130587\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.041543\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109082\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038755\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.114283\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037996\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.118116\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.037965\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.114701\n",
      "done\n",
      "Regression error on test: 0.463153\n",
      "Regression error on test: 0.278637\n",
      "0.4631534814834595\n",
      "Regression error on test: 0.092418\n",
      "Regression error on test: 0.075820\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.113503\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.128868\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.062136\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.165511\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.043217\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.185772\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038523\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.181049\n",
      "done\n",
      "Regression error on test: 0.467757\n",
      "Regression error on test: 0.385860\n",
      "0.46775689721107483\n",
      "Regression error on test: 0.092611\n",
      "Regression error on test: 0.081279\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.055601\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.140450\n",
      "done\n",
      "epoch: 1, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TRAINING -> mean_err: 0.019998\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.143079\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020549\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.139099\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020738\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.137330\n",
      "done\n",
      "Regression error on test: 0.471576\n",
      "Regression error on test: 0.520900\n",
      "0.47157564759254456\n",
      "Regression error on test: 0.088182\n",
      "Regression error on test: 0.018431\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064890\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.076857\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029009\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.078015\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025877\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.077705\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.025414\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.077634\n",
      "done\n",
      "Regression error on test: 0.457961\n",
      "Regression error on test: 0.467728\n",
      "0.4579612910747528\n",
      "Regression error on test: 0.093110\n",
      "Regression error on test: 0.175317\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.016946\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.090675\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017443\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.090019\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016694\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.095228\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.018869\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.092368\n",
      "done\n",
      "Regression error on test: 0.438789\n",
      "Regression error on test: 0.604481\n",
      "0.43878886103630066\n",
      "Regression error on test: 0.092913\n",
      "Regression error on test: 0.216100\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159668\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093414\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.106219\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.107666\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.065444\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.125956\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.040085\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.142159\n",
      "done\n",
      "Regression error on test: 0.394260\n",
      "Regression error on test: 0.654401\n",
      "0.3942600190639496\n",
      "Regression error on test: 0.082954\n",
      "Regression error on test: 0.096846\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.196851\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096535\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.124678\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.132977\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053235\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.176586\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.018841\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.179682\n",
      "done\n",
      "Regression error on test: 0.346207\n",
      "Regression error on test: 0.496546\n",
      "0.34620675444602966\n",
      "Regression error on test: 0.087096\n",
      "Regression error on test: 0.059991\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.092298\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.095050\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.081283\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.101693\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.078021\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.107779\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.076618\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.108712\n",
      "done\n",
      "Regression error on test: 0.313760\n",
      "Regression error on test: 0.366816\n",
      "0.31375986337661743\n",
      "Regression error on test: 0.090531\n",
      "Regression error on test: 0.080061\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059890\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091282\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060194\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.090967\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059289\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.091736\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.060139\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.092266\n",
      "done\n",
      "Regression error on test: 0.300012\n",
      "Regression error on test: 0.410703\n",
      "0.30001187324523926\n",
      "Regression error on test: 0.091859\n",
      "Regression error on test: 0.086125\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076277\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.103778\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.064145\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.112491\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.058337\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.119989\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.055529\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.129257\n",
      "done\n",
      "Regression error on test: 0.280657\n",
      "Regression error on test: 0.445463\n",
      "0.28065651655197144\n",
      "Regression error on test: 0.087546\n",
      "Regression error on test: 0.034208\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077868\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109744\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059953\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.126637\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.054348\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.137168\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.053367\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.149871\n",
      "done\n",
      "Regression error on test: 0.260831\n",
      "Regression error on test: 0.324671\n",
      "0.2608312964439392\n",
      "Regression error on test: 0.087788\n",
      "Regression error on test: 0.077753\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029701\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.079473\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027551\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.079313\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026842\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.079141\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026847\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.080081\n",
      "done\n",
      "Regression error on test: 0.252245\n",
      "Regression error on test: 0.424047\n",
      "0.2522452771663666\n",
      "Regression error on test: 0.083151\n",
      "Regression error on test: 0.036989\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064777\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114127\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.041654\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.137081\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036537\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.141036\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.035539\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.148204\n",
      "done\n",
      "Regression error on test: 0.236627\n",
      "Regression error on test: 0.384756\n",
      "0.23662713170051575\n",
      "Regression error on test: 0.082381\n",
      "Regression error on test: 0.067713\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.035406\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.093625\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034097\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.091607\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033972\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.092396\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.033911\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.090378\n",
      "done\n",
      "Regression error on test: 0.221755\n",
      "Regression error on test: 0.276004\n",
      "0.22175532579421997\n",
      "Regression error on test: 0.078362\n",
      "Regression error on test: 0.173346\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058909\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059829\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042003\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058593\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040414\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.057534\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.039578\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.057545\n",
      "done\n",
      "Regression error on test: 0.219546\n",
      "Regression error on test: 0.159192\n",
      "0.21954607963562012\n",
      "Regression error on test: 0.063331\n",
      "Regression error on test: 0.116513\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158223\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052297\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.101494\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.070702\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056818\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.090103\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.036467\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.110902\n",
      "done\n",
      "Regression error on test: 0.227339\n",
      "Regression error on test: 0.173868\n",
      "0.2273394614458084\n",
      "Regression error on test: 0.053866\n",
      "Regression error on test: 0.138260\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109621\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045642\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.092328\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049021\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.081804\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.055146\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.075263\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.061766\n",
      "done\n",
      "Regression error on test: 0.237295\n",
      "Regression error on test: 0.172077\n",
      "0.23729465901851654\n",
      "Regression error on test: 0.043768\n",
      "Regression error on test: 0.094345\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.125881\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040920\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.092850\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054205\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.075682\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.067133\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.069510\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.071812\n",
      "done\n",
      "Regression error on test: 0.249263\n",
      "Regression error on test: 0.229336\n",
      "0.24926309287548065\n",
      "Regression error on test: 0.039895\n",
      "Regression error on test: 0.093344\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.089041\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037613\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.072640\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.043655\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.064361\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053028\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.058474\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.062707\n",
      "done\n",
      "Regression error on test: 0.264217\n",
      "Regression error on test: 0.217149\n",
      "0.26421666145324707\n",
      "Regression error on test: 0.034079\n",
      "Regression error on test: 0.042992\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.086979\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034162\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.066833\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048374\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053486\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.065866\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.049735\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.073475\n",
      "done\n",
      "Regression error on test: 0.273780\n",
      "Regression error on test: 0.247212\n",
      "0.2737799882888794\n",
      "Regression error on test: 0.033061\n",
      "Regression error on test: 0.036623\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039435\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033174\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030907\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036007\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030610\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041923\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.029358\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.039313\n",
      "done\n",
      "Regression error on test: 0.282815\n",
      "Regression error on test: 0.238811\n",
      "0.28281542658805847\n",
      "Regression error on test: 0.034858\n",
      "Regression error on test: 0.031388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031480\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037973\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.020994\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.046270\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021361\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041729\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020751\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.042648\n",
      "done\n",
      "Regression error on test: 0.295435\n",
      "Regression error on test: 0.267866\n",
      "0.2954351603984833\n",
      "Regression error on test: 0.038224\n",
      "Regression error on test: 0.029289\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030619\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037318\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028242\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039580\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027194\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040144\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.027288\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.041411\n",
      "done\n",
      "Regression error on test: 0.300331\n",
      "Regression error on test: 0.236039\n",
      "0.3003307580947876\n",
      "Regression error on test: 0.039884\n",
      "Regression error on test: 0.027518\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023387\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043920\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.015188\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047631\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014917\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046978\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.015269\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.047136\n",
      "done\n",
      "Regression error on test: 0.305171\n",
      "Regression error on test: 0.253911\n",
      "0.3051706850528717\n",
      "Regression error on test: 0.042521\n",
      "Regression error on test: 0.023040\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027457\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042322\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027406\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042352\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027500\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042368\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.027406\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.042841\n",
      "done\n",
      "Regression error on test: 0.312676\n",
      "Regression error on test: 0.237126\n",
      "0.312676340341568\n",
      "Regression error on test: 0.048384\n",
      "Regression error on test: 0.021857\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.023170\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048951\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022913\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048659\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022904\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048737\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.022841\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.048439\n",
      "done\n",
      "Regression error on test: 0.322763\n",
      "Regression error on test: 0.273421\n",
      "0.322763055562973\n",
      "Regression error on test: 0.050033\n",
      "Regression error on test: 0.037282\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021856\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049968\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022968\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050210\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022287\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050202\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.022201\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.050379\n",
      "done\n",
      "Regression error on test: 0.324831\n",
      "Regression error on test: 0.291761\n",
      "0.3248308300971985\n",
      "Regression error on test: 0.048662\n",
      "Regression error on test: 0.055613\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034570\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051036\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031843\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051241\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031571\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050095\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.031507\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.051157\n",
      "done\n",
      "Regression error on test: 0.322712\n",
      "Regression error on test: 0.378872\n",
      "0.3227124512195587\n",
      "Regression error on test: 0.052130\n",
      "Regression error on test: 0.035185\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054967\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054771\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.053155\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057862\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052966\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058562\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.052154\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.057269\n",
      "done\n",
      "Regression error on test: 0.305217\n",
      "Regression error on test: 0.312782\n",
      "0.30521702766418457\n",
      "Regression error on test: 0.054811\n",
      "Regression error on test: 0.032811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030676\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053930\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025631\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054580\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025210\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053620\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.025605\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.053742\n",
      "done\n",
      "Regression error on test: 0.296234\n",
      "Regression error on test: 0.337566\n",
      "0.29623404145240784\n",
      "Regression error on test: 0.055043\n",
      "Regression error on test: 0.054600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032541\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054207\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032130\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053924\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032399\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.053851\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.032314\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.057209\n",
      "done\n",
      "Regression error on test: 0.288075\n",
      "Regression error on test: 0.365008\n",
      "0.288074791431427\n",
      "Regression error on test: 0.054415\n",
      "Regression error on test: 0.065039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054390\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056590\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052719\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059918\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052524\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059861\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.051703\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.062917\n",
      "done\n",
      "Regression error on test: 0.273418\n",
      "Regression error on test: 0.316822\n",
      "0.27341845631599426\n",
      "Regression error on test: 0.051053\n",
      "Regression error on test: 0.045894\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063484\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047773\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060215\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047094\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059418\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046519\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.058846\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.046248\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.284438\n",
      "0.2647024095058441\n",
      "Regression error on test: 0.051035\n",
      "Regression error on test: 0.053886\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042908\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045941\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037547\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045358\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.036334\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045309\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.036522\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.045270\n",
      "done\n",
      "Regression error on test: 0.257963\n",
      "Regression error on test: 0.328967\n",
      "0.2579632103443146\n",
      "Regression error on test: 0.048933\n",
      "Regression error on test: 0.081669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048935\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.066151\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038174\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.076724\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.035883\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.076109\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.035861\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.077756\n",
      "done\n",
      "Regression error on test: 0.248783\n",
      "Regression error on test: 0.337994\n",
      "0.24878308176994324\n",
      "Regression error on test: 0.044736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.038354\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.072003\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077332\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.045066\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.102307\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033386\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.119396\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030501\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.126608\n",
      "done\n",
      "Regression error on test: 0.238841\n",
      "Regression error on test: 0.294098\n",
      "0.23884062469005585\n",
      "Regression error on test: 0.045454\n",
      "Regression error on test: 0.023573\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.038841\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044196\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037687\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038198\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037336\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039882\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.037187\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.039737\n",
      "done\n",
      "Regression error on test: 0.231860\n",
      "Regression error on test: 0.270577\n",
      "0.23185983300209045\n",
      "Regression error on test: 0.046971\n",
      "Regression error on test: 0.090293\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021040\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033474\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019273\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034920\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019184\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034042\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.019190\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.034735\n",
      "done\n",
      "Regression error on test: 0.228843\n",
      "Regression error on test: 0.203918\n",
      "0.22884348034858704\n",
      "Regression error on test: 0.043821\n",
      "Regression error on test: 0.061994\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078165\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027336\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039328\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036641\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024513\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050664\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020350\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.050793\n",
      "done\n",
      "Regression error on test: 0.230210\n",
      "Regression error on test: 0.222953\n",
      "0.23021039366722107\n",
      "Regression error on test: 0.042227\n",
      "Regression error on test: 0.035126\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050776\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.027087\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031336\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.028172\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028790\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034433\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028372\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.032119\n",
      "done\n",
      "Regression error on test: 0.232743\n",
      "Regression error on test: 0.255972\n",
      "0.232742577791214\n",
      "Regression error on test: 0.047610\n",
      "Regression error on test: 0.048322\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034712\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039021\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.033920\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038703\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.034316\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.040304\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.034389\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.038130\n",
      "done\n",
      "Regression error on test: 0.228450\n",
      "Regression error on test: 0.218445\n",
      "0.22844965755939484\n",
      "Regression error on test: 0.053526\n",
      "Regression error on test: 0.031418\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037277\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033208\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018160\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032428\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017084\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031966\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.017160\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.032868\n",
      "done\n",
      "Regression error on test: 0.226086\n",
      "Regression error on test: 0.229661\n",
      "0.2260863482952118\n",
      "Regression error on test: 0.056575\n",
      "Regression error on test: 0.045715\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029069\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044267\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024424\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038481\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023162\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.036861\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.023423\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.036460\n",
      "done\n",
      "Regression error on test: 0.225170\n",
      "Regression error on test: 0.217046\n",
      "0.22517022490501404\n",
      "Regression error on test: 0.058598\n",
      "Regression error on test: 0.032868\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037367\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037737\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022264\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034745\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020852\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034325\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020720\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.033050\n",
      "done\n",
      "Regression error on test: 0.226957\n",
      "Regression error on test: 0.237166\n",
      "0.22695666551589966\n",
      "Regression error on test: 0.063042\n",
      "Regression error on test: 0.039700\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.028566\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045131\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022653\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040635\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022531\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041822\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.021854\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.040311\n",
      "done\n",
      "Regression error on test: 0.226117\n",
      "Regression error on test: 0.238570\n",
      "0.22611671686172485\n",
      "Regression error on test: 0.066996\n",
      "Regression error on test: 0.045533\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036156\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053178\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030152\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051611\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.029876\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.051470\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030287\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.051306\n",
      "done\n",
      "Regression error on test: 0.236251\n",
      "Regression error on test: 0.224290\n",
      "0.23625056445598602\n",
      "Regression error on test: 0.069430\n",
      "Regression error on test: 0.038743\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036148\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051222\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021812\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047323\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020856\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046182\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020917\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.047006\n",
      "done\n",
      "Regression error on test: 0.240930\n",
      "Regression error on test: 0.240413\n",
      "0.24093003571033478\n",
      "Regression error on test: 0.069420\n",
      "Regression error on test: 0.058793\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033041\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057560\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025168\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053884\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025299\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054486\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.025303\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.055634\n",
      "done\n",
      "Regression error on test: 0.253729\n",
      "Regression error on test: 0.217587\n",
      "0.2537294626235962\n",
      "Regression error on test: 0.066588\n",
      "Regression error on test: 0.046056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.053137\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.053697\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039881\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050337\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.035845\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.049890\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.035638\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.049851\n",
      "done\n",
      "Regression error on test: 0.264702\n",
      "Regression error on test: 0.248275\n",
      "0.26470187306404114\n",
      "Regression error on test: 0.068380\n",
      "Regression error on test: 0.088950\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042873\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060690\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034420\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.058514\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031222\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.057794\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030517\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.057775\n",
      "done\n",
      "Regression error on test: 0.278891\n",
      "Regression error on test: 0.213043\n",
      "0.27889102697372437\n",
      "Regression error on test: 0.063563\n",
      "Regression error on test: 0.107488\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.076632\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062561\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.032647\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.076620\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015978\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.081067\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.016327\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.080855\n",
      "done\n",
      "Regression error on test: 0.296243\n",
      "Regression error on test: 0.194812\n",
      "0.2962426543235779\n",
      "Regression error on test: 0.059090\n",
      "Regression error on test: 0.061899\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.095158\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.067456\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.049376\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.093373\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.021680\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110993\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.017751\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.117319\n",
      "done\n",
      "Regression error on test: 0.317561\n",
      "Regression error on test: 0.220500\n",
      "0.31756100058555603\n",
      "Regression error on test: 0.057614\n",
      "Regression error on test: 0.065955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054543\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.068437\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037780\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075592\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031931\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.089103\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.029310\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.089629\n",
      "done\n",
      "Regression error on test: 0.334063\n",
      "Regression error on test: 0.234910\n",
      "0.33406326174736023\n",
      "Regression error on test: 0.062140\n",
      "Regression error on test: 0.077302\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054836\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083049\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028793\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.088761\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024679\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.102505\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.022760\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.104429\n",
      "done\n",
      "Regression error on test: 0.353975\n",
      "Regression error on test: 0.228766\n",
      "0.3539747893810272\n",
      "Regression error on test: 0.062371\n",
      "Regression error on test: 0.079238\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070766\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083697\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.051539\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.099629\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.043816\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.112131\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.041557\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.114673\n",
      "done\n",
      "Regression error on test: 0.372552\n",
      "Regression error on test: 0.339908\n",
      "0.37255218625068665\n",
      "Regression error on test: 0.064429\n",
      "Regression error on test: 0.069872\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.074894\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052810\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059750\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050062\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.048524\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.055342\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.040762\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.064682\n",
      "done\n",
      "Regression error on test: 0.383426\n",
      "Regression error on test: 0.271085\n",
      "0.3834255635738373\n",
      "Regression error on test: 0.063655\n",
      "Regression error on test: 0.038643\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058488\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.098248\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028685\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.108200\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026045\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.113562\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026068\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.113897\n",
      "done\n",
      "Regression error on test: 0.390243\n",
      "Regression error on test: 0.368408\n",
      "0.39024287462234497\n",
      "Regression error on test: 0.070119\n",
      "Regression error on test: 0.030479\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033517\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063477\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028485\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059758\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028148\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058859\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028362\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.058700\n",
      "done\n",
      "Regression error on test: 0.377002\n",
      "Regression error on test: 0.327311\n",
      "0.37700164318084717\n",
      "Regression error on test: 0.070296\n",
      "Regression error on test: 0.063970\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027475\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073568\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023591\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.082451\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022757\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.081493\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.022609\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.080522\n",
      "done\n",
      "Regression error on test: 0.374148\n",
      "Regression error on test: 0.390166\n",
      "0.3741475045681\n",
      "Regression error on test: 0.068259\n",
      "Regression error on test: 0.040783\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062275\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.062508\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.058576\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059096\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056482\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058304\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.056184\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.058153\n",
      "done\n",
      "Regression error on test: 0.365729\n",
      "Regression error on test: 0.386559\n",
      "0.3657287657260895\n",
      "Regression error on test: 0.068756\n",
      "Regression error on test: 0.062762\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031094\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.063535\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.018463\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063748\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018442\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.063586\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.018418\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.063771\n",
      "done\n",
      "Regression error on test: 0.350445\n",
      "Regression error on test: 0.407995\n",
      "0.35044509172439575\n",
      "Regression error on test: 0.068803\n",
      "Regression error on test: 0.047133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048455\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.074404\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.017487\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073198\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018430\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.075304\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.017585\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.077161\n",
      "done\n",
      "Regression error on test: 0.328281\n",
      "Regression error on test: 0.385522\n",
      "0.3282812833786011\n",
      "Regression error on test: 0.066642\n",
      "Regression error on test: 0.111214\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040020\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.070687\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029748\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075872\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.029017\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.075677\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028668\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.076084\n",
      "done\n",
      "Regression error on test: 0.314229\n",
      "Regression error on test: 0.434026\n",
      "0.31422919034957886\n",
      "Regression error on test: 0.058989\n",
      "Regression error on test: 0.079619\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.099556\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073518\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069238\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.091348\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056192\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.098825\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.053992\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.102546\n",
      "done\n",
      "Regression error on test: 0.290493\n",
      "Regression error on test: 0.414540\n",
      "0.290493369102478\n",
      "Regression error on test: 0.057036\n",
      "Regression error on test: 0.099811\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065633\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.083598\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025682\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.096143\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023454\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.089523\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.024070\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.093736\n",
      "done\n",
      "Regression error on test: 0.272946\n",
      "Regression error on test: 0.448642\n",
      "0.2729457914829254\n",
      "Regression error on test: 0.060403\n",
      "Regression error on test: 0.062137\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085492\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091235\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063180\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.099081\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060075\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.102898\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.059919\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.102398\n",
      "done\n",
      "Regression error on test: 0.245828\n",
      "Regression error on test: 0.339258\n",
      "0.24582824110984802\n",
      "Regression error on test: 0.059411\n",
      "Regression error on test: 0.103280\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062189\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057278\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.061640\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054447\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060864\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.052771\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.060830\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.054275\n",
      "done\n",
      "Regression error on test: 0.228155\n",
      "Regression error on test: 0.235996\n",
      "0.2281554490327835\n",
      "Regression error on test: 0.053799\n",
      "Regression error on test: 0.032249\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.094080\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.038760\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069569\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040889\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056390\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048009\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.052200\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.056295\n",
      "done\n",
      "Regression error on test: 0.220271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.298770\n",
      "0.2202712893486023\n",
      "Regression error on test: 0.055079\n",
      "Regression error on test: 0.043600\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.024906\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.040463\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016687\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044422\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.017867\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.041472\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.016636\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.039616\n",
      "done\n",
      "Regression error on test: 0.206626\n",
      "Regression error on test: 0.305979\n",
      "0.20662575960159302\n",
      "Regression error on test: 0.055720\n",
      "Regression error on test: 0.045751\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043296\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061772\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042768\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.064314\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042579\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.066884\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.042779\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.064481\n",
      "done\n",
      "Regression error on test: 0.191440\n",
      "Regression error on test: 0.233722\n",
      "0.19144026935100555\n",
      "Regression error on test: 0.057435\n",
      "Regression error on test: 0.063239\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042732\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.041813\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.034082\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033544\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031027\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.032673\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030475\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.032319\n",
      "done\n",
      "Regression error on test: 0.187230\n",
      "Regression error on test: 0.186358\n",
      "0.18722979724407196\n",
      "Regression error on test: 0.057448\n",
      "Regression error on test: 0.025517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052101\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.032602\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023698\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037073\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.016179\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.035132\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.015614\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.036360\n",
      "done\n",
      "Regression error on test: 0.184849\n",
      "Regression error on test: 0.245000\n",
      "0.1848488450050354\n",
      "Regression error on test: 0.060472\n",
      "Regression error on test: 0.034682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025222\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055548\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.025515\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057821\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024956\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056487\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.025827\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.058765\n",
      "done\n",
      "Regression error on test: 0.176822\n",
      "Regression error on test: 0.196668\n",
      "0.1768217235803604\n",
      "Regression error on test: 0.061501\n",
      "Regression error on test: 0.060097\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.025226\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.034261\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.012452\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.037268\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.012386\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034902\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.013432\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.036385\n",
      "done\n",
      "Regression error on test: 0.173460\n",
      "Regression error on test: 0.239064\n",
      "0.1734597384929657\n",
      "Regression error on test: 0.062084\n",
      "Regression error on test: 0.133477\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.059136\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056566\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057452\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055837\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056638\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.055151\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.056256\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.054469\n",
      "done\n",
      "Regression error on test: 0.173670\n",
      "Regression error on test: 0.177467\n",
      "0.17366991937160492\n",
      "Regression error on test: 0.059289\n",
      "Regression error on test: 0.052222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.122832\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.031528\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.094403\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.025891\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.076607\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.036126\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.061878\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.048368\n",
      "done\n",
      "Regression error on test: 0.168952\n",
      "Regression error on test: 0.162530\n",
      "0.1689516305923462\n",
      "Regression error on test: 0.057997\n",
      "Regression error on test: 0.057566\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.058227\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043506\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.046996\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.034116\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041881\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.033347\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.041541\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.032854\n",
      "done\n",
      "Regression error on test: 0.216129\n",
      "Regression error on test: 0.165961\n",
      "0.21612943708896637\n",
      "Regression error on test: 0.073794\n",
      "Regression error on test: 0.059231\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046750\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.058123\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011137\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.061076\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.006573\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.058895\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.008282\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.060317\n",
      "done\n",
      "Regression error on test: 0.254908\n",
      "Regression error on test: 0.158954\n",
      "0.2549077868461609\n",
      "Regression error on test: 0.071745\n",
      "Regression error on test: 0.057058\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.048492\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.059070\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.011680\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.059161\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.007715\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.066059\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.005767\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.067093\n",
      "done\n",
      "Regression error on test: 0.270274\n",
      "Regression error on test: 0.161945\n",
      "0.2702735364437103\n",
      "Regression error on test: 0.082382\n",
      "Regression error on test: 0.054173\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046954\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.077616\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.019591\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.086964\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.012137\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.093115\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.011979\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.080836\n",
      "done\n",
      "Regression error on test: 0.305084\n",
      "Regression error on test: 0.160258\n",
      "0.3050840497016907\n",
      "Regression error on test: 0.097677\n",
      "Regression error on test: 0.047381\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.043483\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.101348\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.008727\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.107563\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.005840\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.110971\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.005901\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.110963\n",
      "done\n",
      "Regression error on test: 0.344543\n",
      "Regression error on test: 0.163280\n",
      "0.3445434272289276\n",
      "Regression error on test: 0.099663\n",
      "Regression error on test: 0.048677\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036743\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104923\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.006549\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110992\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.006940\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.105749\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.005611\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.110070\n",
      "done\n",
      "Regression error on test: 0.355526\n",
      "Regression error on test: 0.162178\n",
      "0.35552552342414856\n",
      "Regression error on test: 0.112753\n",
      "Regression error on test: 0.051180\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037965\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.117523\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.006593\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.120042\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.005515\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.123206\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.007894\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.119581\n",
      "done\n",
      "Regression error on test: 0.355586\n",
      "Regression error on test: 0.162218\n",
      "0.355586439371109\n",
      "Regression error on test: 0.123142\n",
      "Regression error on test: 0.047216\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.040494\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.127792\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.007311\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.130558\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.004745\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.131039\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.004327\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.133202\n",
      "done\n",
      "Regression error on test: 0.353504\n",
      "Regression error on test: 0.263413\n",
      "0.35350388288497925\n",
      "Regression error on test: 0.135291\n",
      "Regression error on test: 0.033591\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.044673\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.134466\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039859\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.135128\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.038869\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.136364\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.037712\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.135527\n",
      "done\n",
      "Regression error on test: 0.342894\n",
      "Regression error on test: 0.298133\n",
      "0.34289368987083435\n",
      "Regression error on test: 0.151426\n",
      "Regression error on test: 0.123897\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.029008\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.148859\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028148\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.148865\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.027126\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.149311\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026855\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.149418\n",
      "done\n",
      "Regression error on test: 0.330533\n",
      "Regression error on test: 0.464954\n",
      "0.33053287863731384\n",
      "Regression error on test: 0.159658\n",
      "Regression error on test: 0.215538\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.109916\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.178250\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057492\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.197406\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025986\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.203297\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.024998\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.204823\n",
      "done\n",
      "Regression error on test: 0.298201\n",
      "Regression error on test: 0.553744\n",
      "0.2982013523578644\n",
      "Regression error on test: 0.155887\n",
      "Regression error on test: 0.038740\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.201058\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.186603\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.146753\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.219518\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.092406\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.256931\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038423\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.300669\n",
      "done\n",
      "Regression error on test: 0.260420\n",
      "Regression error on test: 0.312611\n",
      "0.2604203224182129\n",
      "Regression error on test: 0.161906\n",
      "Regression error on test: 0.163422\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033923\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.146710\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027799\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.142404\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028747\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.140286\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028368\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.139222\n",
      "done\n",
      "Regression error on test: 0.251510\n",
      "Regression error on test: 0.510050\n",
      "0.2515101432800293\n",
      "Regression error on test: 0.153620\n",
      "Regression error on test: 0.207127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.148133\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.198320\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.090784\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.244579\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.038515\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.274758\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.023330\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.287665\n",
      "done\n",
      "Regression error on test: 0.227162\n",
      "Regression error on test: 0.554852\n",
      "0.22716207802295685\n",
      "Regression error on test: 0.135698\n",
      "Regression error on test: 0.067245\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.190470\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.196102\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.129735\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.249220\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.083927\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.300833\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.051915\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.335442\n",
      "done\n",
      "Regression error on test: 0.203941\n",
      "Regression error on test: 0.273101\n",
      "0.2039414793252945\n",
      "Regression error on test: 0.149311\n",
      "Regression error on test: 0.179569\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.060539\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.113982\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042039\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.098428\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.040591\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.093848\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.039021\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.102569\n",
      "done\n",
      "Regression error on test: 0.201581\n",
      "Regression error on test: 0.162787\n",
      "0.20158079266548157\n",
      "Regression error on test: 0.134318\n",
      "Regression error on test: 0.155073\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160985\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.084370\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.093282\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066115\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053182\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.069247\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.040002\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.077201\n",
      "done\n",
      "Regression error on test: 0.210833\n",
      "Regression error on test: 0.141392\n",
      "0.21083326637744904\n",
      "Regression error on test: 0.125349\n",
      "Regression error on test: 0.168702\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.138929\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.082837\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.080442\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068417\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.050973\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.071872\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.042972\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.072912\n",
      "done\n",
      "Regression error on test: 0.231026\n",
      "Regression error on test: 0.157312\n",
      "0.23102593421936035\n",
      "Regression error on test: 0.117055\n",
      "Regression error on test: 0.194945\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.151686\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085082\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.092608\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.080973\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.055582\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.089494\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.044885\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.098249\n",
      "done\n",
      "Regression error on test: 0.261571\n",
      "Regression error on test: 0.174525\n",
      "0.2615712583065033\n",
      "Regression error on test: 0.116121\n",
      "Regression error on test: 0.206218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.175906\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096197\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.104463\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.110313\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.051450\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.129089\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038531\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.140669\n",
      "done\n",
      "Regression error on test: 0.301176\n",
      "Regression error on test: 0.141638\n",
      "0.30117592215538025\n",
      "Regression error on test: 0.107900\n",
      "Regression error on test: 0.177830\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.188437\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100979\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.121651\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.125064\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.079145\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.141174\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.069106\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.148939\n",
      "done\n",
      "Regression error on test: 0.337311\n",
      "Regression error on test: 0.175934\n",
      "0.3373114764690399\n",
      "Regression error on test: 0.117214\n",
      "Regression error on test: 0.098930\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.160079\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.123450\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.093486\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.160698\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033132\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.191413\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.021507\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.199426\n",
      "done\n",
      "Regression error on test: 0.387430\n",
      "Regression error on test: 0.223510\n",
      "0.38743019104003906\n",
      "Regression error on test: 0.137951\n",
      "Regression error on test: 0.080555\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.082891\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.155396\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027969\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.178764\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015121\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.179237\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.014614\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.181137\n",
      "done\n",
      "Regression error on test: 0.436770\n",
      "Regression error on test: 0.266569\n",
      "0.43676963448524475\n",
      "Regression error on test: 0.138017\n",
      "Regression error on test: 0.027908\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.064102\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.162204\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021517\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.181840\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018351\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.178896\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.018741\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.186291\n",
      "done\n",
      "Regression error on test: 0.454916\n",
      "Regression error on test: 0.322645\n",
      "0.4549157917499542\n",
      "Regression error on test: 0.153624\n",
      "Regression error on test: 0.203377\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.022630\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.158230\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021289\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.157049\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020287\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.161481\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020056\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.162177\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.446340\n",
      "Regression error on test: 0.249495\n",
      "0.4463404715061188\n",
      "Regression error on test: 0.145058\n",
      "Regression error on test: 0.029640\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.180825\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.169555\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.117270\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.183609\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.094598\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.205575\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.075906\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.225626\n",
      "done\n",
      "Regression error on test: 0.449763\n",
      "Regression error on test: 0.255312\n",
      "0.44976329803466797\n",
      "Regression error on test: 0.153258\n",
      "Regression error on test: 0.065388\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.027605\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.156097\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022914\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.157246\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.022626\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.156997\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.022487\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.157909\n",
      "done\n",
      "Regression error on test: 0.453223\n",
      "Regression error on test: 0.343319\n",
      "0.4532225430011749\n",
      "Regression error on test: 0.157865\n",
      "Regression error on test: 0.085754\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063558\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.160240\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.057218\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.163121\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.054643\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.164657\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.054074\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.163850\n",
      "done\n",
      "Regression error on test: 0.446306\n",
      "Regression error on test: 0.462765\n",
      "0.4463064968585968\n",
      "Regression error on test: 0.158946\n",
      "Regression error on test: 0.185604\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077543\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.162771\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.059253\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.165031\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.054252\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.167263\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.051297\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.168295\n",
      "done\n",
      "Regression error on test: 0.429696\n",
      "Regression error on test: 0.570571\n",
      "0.42969605326652527\n",
      "Regression error on test: 0.155166\n",
      "Regression error on test: 0.124012\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169275\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.173424\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.108045\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.195664\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052627\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.215636\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.039572\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.229493\n",
      "done\n",
      "Regression error on test: 0.388589\n",
      "Regression error on test: 0.502994\n",
      "0.3885892629623413\n",
      "Regression error on test: 0.159176\n",
      "Regression error on test: 0.270967\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.107911\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189255\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.047619\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.219964\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014154\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.219779\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.014890\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.225148\n",
      "done\n",
      "Regression error on test: 0.358044\n",
      "Regression error on test: 0.677121\n",
      "0.3580436706542969\n",
      "Regression error on test: 0.143990\n",
      "Regression error on test: 0.306304\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.252839\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.189334\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.184878\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.237634\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.120060\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.279770\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.072569\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.314149\n",
      "done\n",
      "Regression error on test: 0.314204\n",
      "Regression error on test: 0.716904\n",
      "0.3142043650150299\n",
      "Regression error on test: 0.132494\n",
      "Regression error on test: 0.081218\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.287669\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.191968\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.217808\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.254428\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.147896\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.317717\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.077952\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.382572\n",
      "done\n",
      "Regression error on test: 0.260108\n",
      "Regression error on test: 0.448032\n",
      "0.2601081132888794\n",
      "Regression error on test: 0.144000\n",
      "Regression error on test: 0.183971\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078560\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.167270\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.073454\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.176624\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.073198\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.178664\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.072899\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.178509\n",
      "done\n",
      "Regression error on test: 0.231583\n",
      "Regression error on test: 0.236892\n",
      "0.23158307373523712\n",
      "Regression error on test: 0.146084\n",
      "Regression error on test: 0.117721\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.161846\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.073124\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.078848\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.051338\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028241\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.052055\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026400\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.057294\n",
      "done\n",
      "Regression error on test: 0.224565\n",
      "Regression error on test: 0.283723\n",
      "0.224564790725708\n",
      "Regression error on test: 0.156430\n",
      "Regression error on test: 0.111636\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.096828\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085791\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027392\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.062794\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020387\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.070177\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020891\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.063367\n",
      "done\n",
      "Regression error on test: 0.213813\n",
      "Regression error on test: 0.289904\n",
      "0.21381281316280365\n",
      "Regression error on test: 0.164548\n",
      "Regression error on test: 0.111461\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091125\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.094585\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037956\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.077631\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033681\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.075287\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.034217\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.074576\n",
      "done\n",
      "Regression error on test: 0.202130\n",
      "Regression error on test: 0.274158\n",
      "0.2021297663450241\n",
      "Regression error on test: 0.168545\n",
      "Regression error on test: 0.096564\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.091856\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.100636\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.027133\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.067096\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.020280\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.066956\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.020231\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.069498\n",
      "done\n",
      "Regression error on test: 0.195746\n",
      "Regression error on test: 0.296661\n",
      "0.195746049284935\n",
      "Regression error on test: 0.175893\n",
      "Regression error on test: 0.147802\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.077683\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.112769\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022417\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.092733\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.014268\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.089352\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.014399\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.093891\n",
      "done\n",
      "Regression error on test: 0.186836\n",
      "Regression error on test: 0.159503\n",
      "0.18683628737926483\n",
      "Regression error on test: 0.178832\n",
      "Regression error on test: 0.164113\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.130896\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.114302\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.068491\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.065401\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.026725\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.050629\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.019457\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.055020\n",
      "done\n",
      "Regression error on test: 0.189518\n",
      "Regression error on test: 0.197538\n",
      "0.18951837718486786\n",
      "Regression error on test: 0.175644\n",
      "Regression error on test: 0.119106\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.144452\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.105875\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.082584\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.063072\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.060131\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056825\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.058554\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.052481\n",
      "done\n",
      "Regression error on test: 0.193231\n",
      "Regression error on test: 0.238728\n",
      "0.19323137402534485\n",
      "Regression error on test: 0.182646\n",
      "Regression error on test: 0.191342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.104218\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.121411\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.060613\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084618\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.044647\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.068305\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.043478\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.071154\n",
      "done\n",
      "Regression error on test: 0.190529\n",
      "Regression error on test: 0.175942\n",
      "0.1905294805765152\n",
      "Regression error on test: 0.181285\n",
      "Regression error on test: 0.196284\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.171390\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.109785\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.108017\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.065792\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.078052\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044577\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.061227\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.041387\n",
      "done\n",
      "Regression error on test: 0.196141\n",
      "Regression error on test: 0.162781\n",
      "0.19614124298095703\n",
      "Regression error on test: 0.175006\n",
      "Regression error on test: 0.204814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.177068\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.107074\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.107731\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055024\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.063408\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.043822\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.052856\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.042789\n",
      "done\n",
      "Regression error on test: 0.206939\n",
      "Regression error on test: 0.166709\n",
      "0.20693938434123993\n",
      "Regression error on test: 0.167447\n",
      "Regression error on test: 0.221176\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.185004\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.110885\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.110676\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.068653\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042445\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.069328\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.027335\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.073564\n",
      "done\n",
      "Regression error on test: 0.233683\n",
      "Regression error on test: 0.176204\n",
      "0.23368342220783234\n",
      "Regression error on test: 0.148788\n",
      "Regression error on test: 0.192814\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.200438\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.103443\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.122603\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.075008\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.056868\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.077286\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.040022\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.083882\n",
      "done\n",
      "Regression error on test: 0.251618\n",
      "Regression error on test: 0.173074\n",
      "0.25161778926849365\n",
      "Regression error on test: 0.133013\n",
      "Regression error on test: 0.151440\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.173869\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102192\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.102814\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.084881\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.045842\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.095382\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.029494\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.103695\n",
      "done\n",
      "Regression error on test: 0.270645\n",
      "Regression error on test: 0.210321\n",
      "0.270645409822464\n",
      "Regression error on test: 0.122893\n",
      "Regression error on test: 0.170039\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.132830\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.104888\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.069080\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.097046\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.034968\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.099499\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.036200\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.097308\n",
      "done\n",
      "Regression error on test: 0.288149\n",
      "Regression error on test: 0.207563\n",
      "0.2881492078304291\n",
      "Regression error on test: 0.111307\n",
      "Regression error on test: 0.177196\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.155009\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097730\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.099621\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.095889\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052849\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.104238\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.044956\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.106758\n",
      "done\n",
      "Regression error on test: 0.295909\n",
      "Regression error on test: 0.186323\n",
      "0.2959086298942566\n",
      "Regression error on test: 0.099754\n",
      "Regression error on test: 0.132225\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.159061\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.096055\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.091003\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.109178\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.045168\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.123964\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.035430\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.129105\n",
      "done\n",
      "Regression error on test: 0.312279\n",
      "Regression error on test: 0.234668\n",
      "0.3122793138027191\n",
      "Regression error on test: 0.090488\n",
      "Regression error on test: 0.189127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.114033\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.097995\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.052210\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.106788\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.035610\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.111941\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.032536\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.119918\n",
      "done\n",
      "Regression error on test: 0.323445\n",
      "Regression error on test: 0.211709\n",
      "0.3234451115131378\n",
      "Regression error on test: 0.079390\n",
      "Regression error on test: 0.177733\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.169868\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.099429\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.099827\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.125705\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.062116\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.149440\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.045318\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.155892\n",
      "done\n",
      "Regression error on test: 0.341051\n",
      "Regression error on test: 0.232059\n",
      "0.34105053544044495\n",
      "Regression error on test: 0.069359\n",
      "Regression error on test: 0.133500\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.158070\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.102373\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.085132\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.143795\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.041247\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.165468\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.035911\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.164884\n",
      "done\n",
      "Regression error on test: 0.352893\n",
      "Regression error on test: 0.270763\n",
      "0.3528931736946106\n",
      "Regression error on test: 0.060285\n",
      "Regression error on test: 0.129222\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.122004\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.091402\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.087580\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.121397\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.065370\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.145249\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.056018\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.158360\n",
      "done\n",
      "Regression error on test: 0.357090\n",
      "Regression error on test: 0.434149\n",
      "0.35708969831466675\n",
      "Regression error on test: 0.052655\n",
      "Regression error on test: 0.034584\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.116643\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039447\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.076729\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.055162\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.053311\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.076797\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.045355\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.087417\n",
      "done\n",
      "Regression error on test: 0.345406\n",
      "Regression error on test: 0.355548\n",
      "0.3454063832759857\n",
      "Regression error on test: 0.055666\n",
      "Regression error on test: 0.035065\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.031492\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044938\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.026208\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044062\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025643\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042492\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.025121\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.042135\n",
      "done\n",
      "Regression error on test: 0.341045\n",
      "Regression error on test: 0.363350\n",
      "0.34104543924331665\n",
      "Regression error on test: 0.060072\n",
      "Regression error on test: 0.050242\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.030595\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051331\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.023689\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.047967\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.023582\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.048660\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.023634\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.050092\n",
      "done\n",
      "Regression error on test: 0.337358\n",
      "Regression error on test: 0.385359\n",
      "0.33735790848731995\n",
      "Regression error on test: 0.062548\n",
      "Regression error on test: 0.054178\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039856\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048010\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.022261\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045592\n",
      "done\n",
      "epoch: 2, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TRAINING -> mean_err: 0.022446\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045595\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.022330\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.045599\n",
      "done\n",
      "Regression error on test: 0.329977\n",
      "Regression error on test: 0.285158\n",
      "0.32997745275497437\n",
      "Regression error on test: 0.063296\n",
      "Regression error on test: 0.061669\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.044863\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.085239\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029382\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.099121\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025922\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.099568\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026131\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.104453\n",
      "done\n",
      "Regression error on test: 0.331519\n",
      "Regression error on test: 0.350030\n",
      "0.3315185308456421\n",
      "Regression error on test: 0.064783\n",
      "Regression error on test: 0.039561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.057116\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045161\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042665\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036008\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037056\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.034687\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.036474\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.034171\n",
      "done\n",
      "Regression error on test: 0.327391\n",
      "Regression error on test: 0.346326\n",
      "0.32739120721817017\n",
      "Regression error on test: 0.068522\n",
      "Regression error on test: 0.078151\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.034958\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050647\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.029240\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044033\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028971\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045360\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028616\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.043862\n",
      "done\n",
      "Regression error on test: 0.323734\n",
      "Regression error on test: 0.387763\n",
      "0.32373398542404175\n",
      "Regression error on test: 0.068630\n",
      "Regression error on test: 0.077424\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070776\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043062\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048213\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032127\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.039513\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.031647\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.037056\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.031992\n",
      "done\n",
      "Regression error on test: 0.316336\n",
      "Regression error on test: 0.350486\n",
      "0.31633618474006653\n",
      "Regression error on test: 0.070834\n",
      "Regression error on test: 0.042758\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.067899\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043294\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043324\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.033573\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032180\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.032616\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.029093\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.033195\n",
      "done\n",
      "Regression error on test: 0.313635\n",
      "Regression error on test: 0.312728\n",
      "0.3136351406574249\n",
      "Regression error on test: 0.073850\n",
      "Regression error on test: 0.052918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.033431\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.050291\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.021404\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042854\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019385\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042114\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.019649\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.044840\n",
      "done\n",
      "Regression error on test: 0.312144\n",
      "Regression error on test: 0.317315\n",
      "0.31214436888694763\n",
      "Regression error on test: 0.075093\n",
      "Regression error on test: 0.064695\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.046952\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.051625\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.035219\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.039078\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030681\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.035533\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030738\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.035675\n",
      "done\n",
      "Regression error on test: 0.310107\n",
      "Regression error on test: 0.311938\n",
      "0.3101067841053009\n",
      "Regression error on test: 0.077521\n",
      "Regression error on test: 0.079127\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.063175\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.061836\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.056931\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.048532\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.052107\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039548\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.049132\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.033924\n",
      "done\n",
      "Regression error on test: 0.307643\n",
      "Regression error on test: 0.326474\n",
      "0.30764293670654297\n",
      "Regression error on test: 0.079261\n",
      "Regression error on test: 0.075003\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.069340\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044336\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042142\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.031194\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.034667\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.028039\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.033378\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.028041\n",
      "done\n",
      "Regression error on test: 0.304451\n",
      "Regression error on test: 0.311555\n",
      "0.30445122718811035\n",
      "Regression error on test: 0.079136\n",
      "Regression error on test: 0.061660\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065713\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048799\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.044375\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036202\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037719\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.029294\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.035784\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.026990\n",
      "done\n",
      "Regression error on test: 0.301342\n",
      "Regression error on test: 0.300569\n",
      "0.30134153366088867\n",
      "Regression error on test: 0.080070\n",
      "Regression error on test: 0.076535\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.052011\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.046609\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028703\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.036503\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.024321\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.035447\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.024186\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.036066\n",
      "done\n",
      "Regression error on test: 0.307600\n",
      "Regression error on test: 0.308756\n",
      "0.30759966373443604\n",
      "Regression error on test: 0.077504\n",
      "Regression error on test: 0.076955\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065489\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042798\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.028558\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.032670\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019254\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.032511\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.018553\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.032532\n",
      "done\n",
      "Regression error on test: 0.315123\n",
      "Regression error on test: 0.309754\n",
      "0.31512343883514404\n",
      "Regression error on test: 0.077705\n",
      "Regression error on test: 0.079229\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066175\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.048084\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.038873\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.040661\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.031510\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.039863\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028375\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.041693\n",
      "done\n",
      "Regression error on test: 0.314961\n",
      "Regression error on test: 0.313785\n",
      "0.3149605691432953\n",
      "Regression error on test: 0.077502\n",
      "Regression error on test: 0.099462\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070511\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.057689\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.045323\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.050861\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.032578\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.052374\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.028719\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.054169\n",
      "done\n",
      "Regression error on test: 0.309780\n",
      "Regression error on test: 0.323476\n",
      "0.3097796142101288\n",
      "Regression error on test: 0.071562\n",
      "Regression error on test: 0.072918\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.088561\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052850\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.051441\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.054105\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.035235\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.063709\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030339\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.068025\n",
      "done\n",
      "Regression error on test: 0.312271\n",
      "Regression error on test: 0.297820\n",
      "0.31227079033851624\n",
      "Regression error on test: 0.068030\n",
      "Regression error on test: 0.065350\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.062184\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052909\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.033224\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053491\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.025377\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.056998\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.024052\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.060248\n",
      "done\n",
      "Regression error on test: 0.318478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression error on test: 0.296940\n",
      "0.3184778392314911\n",
      "Regression error on test: 0.068847\n",
      "Regression error on test: 0.088975\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.054151\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.055750\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.024111\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.057300\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.019482\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059018\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.019134\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.061675\n",
      "done\n",
      "Regression error on test: 0.326959\n",
      "Regression error on test: 0.287299\n",
      "0.3269594609737396\n",
      "Regression error on test: 0.064155\n",
      "Regression error on test: 0.096529\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078413\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.056969\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.039136\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.073154\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.018158\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.080179\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.017643\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.078465\n",
      "done\n",
      "Regression error on test: 0.329997\n",
      "Regression error on test: 0.294558\n",
      "0.329996794462204\n",
      "Regression error on test: 0.059285\n",
      "Regression error on test: 0.073748\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.085960\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054261\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.054496\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066390\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042553\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.075104\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.038692\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.083403\n",
      "done\n",
      "Regression error on test: 0.337613\n",
      "Regression error on test: 0.280458\n",
      "0.33761322498321533\n",
      "Regression error on test: 0.055278\n",
      "Regression error on test: 0.071000\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.065292\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.054350\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037797\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.066802\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.028347\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.071189\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.026343\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.067425\n",
      "done\n",
      "Regression error on test: 0.339779\n",
      "Regression error on test: 0.363149\n",
      "0.339779257774353\n",
      "Regression error on test: 0.053268\n",
      "Regression error on test: 0.050878\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.066174\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.052541\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.055941\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.053869\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.055393\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.054074\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.054206\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.053844\n",
      "done\n",
      "Regression error on test: 0.333962\n",
      "Regression error on test: 0.383994\n",
      "0.3339623212814331\n",
      "Regression error on test: 0.053194\n",
      "Regression error on test: 0.078958\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.037555\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.060660\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.016081\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.060629\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.015924\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.059871\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.015853\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.060599\n",
      "done\n",
      "Regression error on test: 0.320876\n",
      "Regression error on test: 0.308126\n",
      "0.32087597250938416\n",
      "Regression error on test: 0.048368\n",
      "Regression error on test: 0.077206\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.078969\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.049536\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.078227\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049138\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.078611\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.051002\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.077790\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.051013\n",
      "done\n",
      "Regression error on test: 0.314376\n",
      "Regression error on test: 0.261976\n",
      "0.314375638961792\n",
      "Regression error on test: 0.048787\n",
      "Regression error on test: 0.040056\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.068263\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.071948\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048340\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.080705\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.045495\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.087309\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.045097\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.087291\n",
      "done\n",
      "Regression error on test: 0.318877\n",
      "Regression error on test: 0.348387\n",
      "0.31887656450271606\n",
      "Regression error on test: 0.050438\n",
      "Regression error on test: 0.037605\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.039442\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047023\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.037447\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045461\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037050\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044273\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.037208\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.045489\n",
      "done\n",
      "Regression error on test: 0.312372\n",
      "Regression error on test: 0.359891\n",
      "0.31237223744392395\n",
      "Regression error on test: 0.048699\n",
      "Regression error on test: 0.073517\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.036729\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.045676\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.031693\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045010\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030458\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.044845\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.030185\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.044790\n",
      "done\n",
      "Regression error on test: 0.299888\n",
      "Regression error on test: 0.381756\n",
      "0.2998881936073303\n",
      "Regression error on test: 0.045367\n",
      "Regression error on test: 0.042051\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.070812\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.043117\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.063995\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045188\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.059227\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.049667\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.058278\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.053591\n",
      "done\n",
      "Regression error on test: 0.286350\n",
      "Regression error on test: 0.317673\n",
      "0.2863500416278839\n",
      "Regression error on test: 0.043471\n",
      "Regression error on test: 0.047826\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042558\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.042758\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.043435\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042605\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.042095\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042636\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.042272\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.042499\n",
      "done\n",
      "Regression error on test: 0.279744\n",
      "Regression error on test: 0.370723\n",
      "0.27974408864974976\n",
      "Regression error on test: 0.043033\n",
      "Regression error on test: 0.033682\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.042900\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044396\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.033781\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.045420\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.033684\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.046145\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.032913\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.046944\n",
      "done\n",
      "Regression error on test: 0.265693\n",
      "Regression error on test: 0.302118\n",
      "0.26569268107414246\n",
      "Regression error on test: 0.044369\n",
      "Regression error on test: 0.050902\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.032903\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.047346\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.030774\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.049704\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.030256\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.051100\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.029908\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.049863\n",
      "done\n",
      "Regression error on test: 0.259182\n",
      "Regression error on test: 0.304980\n",
      "0.2591819167137146\n",
      "Regression error on test: 0.043689\n",
      "Regression error on test: 0.050133\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.050028\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.039772\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048060\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038346\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.048419\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.038511\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.047560\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.039098\n",
      "done\n",
      "Regression error on test: 0.251869\n",
      "Regression error on test: 0.253130\n",
      "0.2518688440322876\n",
      "Regression error on test: 0.045896\n",
      "Regression error on test: 0.030703\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.049867\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.044077\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.048930\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.042889\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.047990\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.042286\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.047182\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.041685\n",
      "done\n",
      "Regression error on test: 0.252464\n",
      "Regression error on test: 0.243123\n",
      "0.25246402621269226\n",
      "Regression error on test: 0.046135\n",
      "Regression error on test: 0.081399\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.021742\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.037418\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.010272\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.038051\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.010485\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.038425\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.011036\n",
      "epoch: 3, \n",
      " VAL -> mean_err: 0.037850\n",
      "done\n",
      "Regression error on test: 0.251519\n",
      "Regression error on test: 0.306985\n",
      "0.251518577337265\n",
      "Regression error on test: 0.042942\n",
      "Regression error on test: 0.056561\n",
      "epoch: 0, \n",
      " TRAINING -> mean_err: 0.072298\n",
      "epoch: 0, \n",
      " VAL -> mean_err: 0.033997\n",
      "done\n",
      "epoch: 1, \n",
      " TRAINING -> mean_err: 0.042861\n",
      "epoch: 1, \n",
      " VAL -> mean_err: 0.044003\n",
      "done\n",
      "epoch: 2, \n",
      " TRAINING -> mean_err: 0.037620\n",
      "epoch: 2, \n",
      " VAL -> mean_err: 0.045075\n",
      "done\n",
      "epoch: 3, \n",
      " TRAINING -> mean_err: 0.037655"
     ]
    }
   ],
   "source": [
    "loss_hist_2 = []\n",
    "loss_hist_1 = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    a, b, c, d = test_nomaml(i)\n",
    "    loss_hist_1.append(np.mean(a))\n",
    "    loss_hist_2.append(np.mean(b))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.286055070124095"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27632596057285613"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
