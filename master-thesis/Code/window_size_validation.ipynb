{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import load_data as ld\n",
    "from pytorchtools import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from metrics import mae\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "task_size = None\n",
    "stride = 1\n",
    "#window_size = 20\n",
    "batch_size = 1024\n",
    "output_dim = 1\n",
    "input_dim = 14\n",
    "learning_rate = 0.0001\n",
    "max_epochs = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (52534, 50, 14)\n",
      "y shape: (52534, 1)\n",
      "x shape: (52534, 50, 14)\n",
      "y shape: (52534, 1)\n",
      "x shape: (52534, 50, 14)\n",
      "y shape: (52534, 1)\n",
      "x shape: (52534, 50, 14)\n",
      "y shape: (52534, 1)\n",
      "x shape: (52534, 50, 14)\n",
      "y shape: (52534, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset, validation_dataset, test_dataset = ld.load_data_pollution(window_size, task_size, stride=1, mode=\"no-meta-learning\")\n",
    "\n",
    "train_dataset.x = train_dataset.x.reshape(-1, train_dataset.dim*window_size)\n",
    "validation_dataset.x = validation_dataset.x.reshape(-1, validation_dataset.dim*window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"../Models/linear_model.pt\"\n",
    "patience = 10\n",
    "early_stopping = EarlyStopping(patience=patience, model_file=model_file, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, seq_len):\n",
    "        \n",
    "        super(LinearModel, self).__init__()\n",
    "        self.n_features = input_dim*seq_len\n",
    "        self.linear = nn.Linear(self.n_features, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.linear(x.view(-1,self.n_features))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(input_dim, output_dim, window_size )\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 5)\n",
    "\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(validation_dataset, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18704155853774299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1149168621955607\n",
      "Train loss: 0.11015040830661375\n",
      "0.07566579304674952\n",
      "Train loss: 0.07681438394759861\n",
      "0.0576220886179698\n",
      "Train loss: 0.0630681213908179\n",
      "0.0485698562489137\n",
      "Train loss: 0.057620661728868566\n",
      "0.044463968871049794\n",
      "Train loss: 0.05503770291692375\n",
      "0.042972651135857035\n",
      "Train loss: 0.05340026704093216\n",
      "0.040453702087567676\n",
      "Train loss: 0.052112684906940834\n",
      "0.03877282658538044\n",
      "Train loss: 0.05105176829909277\n",
      "0.039005717300279956\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train loss: 0.05114051879111877\n",
      "0.03783508968546379\n",
      "Train loss: 0.0502357460749215\n",
      "0.037324091349161995\n",
      "Train loss: 0.04944461902169266\n",
      "0.036814146525580634\n",
      "Train loss: 0.04883152438693978\n",
      "0.035824179168427936\n",
      "Train loss: 0.048340661275382425\n",
      "0.03545933120653573\n",
      "Train loss: 0.04795435502935336\n",
      "0.03674184178555044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train loss: 0.04788645282019936\n",
      "0.03579885051889414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train loss: 0.04790829389787612\n",
      "0.03606833542810272\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train loss: 0.047879261084284704\n",
      "0.03608802890189983\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train loss: 0.047870829449213344\n",
      "0.03506250277691453\n",
      "Train loss: 0.04756562173776134\n",
      "0.035450456287919915\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Train loss: 0.047591524644144054\n",
      "0.036823163943251545\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Train loss: 0.04763095087749881\n",
      "0.03509423298815922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Train loss: 0.04760426295566481\n",
      "0.035538201705832495\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Train loss: 0.04753970949231729\n",
      "0.035477175170919986\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Train loss: 0.047535118673523544\n",
      "0.03548595617582825\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Train loss: 0.04738441912830084\n",
      "0.03587914153490467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Train loss: 0.04737392931565234\n",
      "0.03553514027454717\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Train loss: 0.04736971820780716\n",
      "0.03561807502996174\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Train loss: 0.047373680719217645\n",
      "0.03566230017035631\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "val_loss_list = []\n",
    "for i in range(max_epochs):\n",
    "    \n",
    "    #train_iter = iter(train_loader)\n",
    "    train_loss = 0.0\n",
    "    for x_train, y_train in train_loader:\n",
    "    \n",
    "        model.zero_grad()\n",
    "        x_train, y_train = torch.tensor(x_train).float(), torch.tensor(y_train).float()\n",
    "\n",
    "        #model.batch_size = x_train.shape[0]\n",
    "        #hidden_init = model.init_hidden()\n",
    "        y_pred = model(x_train)\n",
    "        loss = mae(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.numpy()*x_train.shape[0]\n",
    "    print(\"Train loss:\", train_loss/len(train_dataset))\n",
    "        \n",
    "        \n",
    "    val_loss = 0.0\n",
    "    for x_val, y_val in val_loader:\n",
    "        x_val, y_val = torch.tensor(x_val).float(), torch.tensor(y_val).float()\n",
    "        #if(x_val.shape[0]==batch_size):\n",
    "        model.batch_size = x_val.shape[0]\n",
    "        y_pred = model(x_val)\n",
    "        val_loss += mae(y_pred, y_val).data.numpy()*x_val.shape[0]\n",
    "    val_loss /= (len(validation_dataset))\n",
    "    \n",
    "    #if(val_loss>prev_loss):\n",
    "    #    break\n",
    "        \n",
    "    prev_loss = val_loss\n",
    "    val_loss_list.append(val_loss)\n",
    "    print(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load(model_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x209013c1488>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\envs\\pytorch12\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "for x_val, y_val in val_loader:\n",
    "    x_val, y_val = torch.tensor(x_val).float(), torch.tensor(y_val).float()\n",
    "    #if(x_val.shape[0]==batch_size):\n",
    "    model.batch_size = x_val.shape[0]\n",
    "    y_pred = model(x_val)\n",
    "    val_loss += mae(y_pred, y_val).data.numpy()*x_val.shape[0]\n",
    "val_loss /= (len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0350625025631858"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
